{
  "3e8ae694-e1ab-4eb3-b35c-ffa0107f47c7": {
    "pk": "3e8ae694-e1ab-4eb3-b35c-ffa0107f47c7",
    "abstract": "**Abstract**\n\nGraph Neural Networks (GNNs) have emerged as powerful tools for learning from graph-structured data, yet their deployment in safety-critical applications and their generalization capabilities remain areas of active research. This paper proposes a novel hybrid approach that combines the strengths of Position-aware GNNs (P-GNNs) and Identity-aware GNNs (ID-GNNs) to enhance the expressive power and performance of GNNs in complex graph-based tasks. Additionally, we introduce a specialized evaluation framework for GNNs used in safety-critical applications, such as autonomous driving and healthcare. This framework includes robustness testing, adversarial attack simulations, and reliability assessments to ensure the safe deployment of GNN models. Furthermore, we propose new topology-aware generalization metrics that incorporate topological features of the graph, such as node centrality and community structure, to better predict the performance of GNNs on unseen data. Our experimental results demonstrate that these new generalization metrics correlate highly with generalization error, outperforming existing topological bounds across a wide range of datasets, models, and optimizers. By integrating these advancements, our work aims to provide a comprehensive solution for improving the reliability and generalization of GNNs in both standard and safety-critical environments.",
    "title": null,
    "content": null,
    "conference": null
  }
}

{
  "cb8e0bde-efad-4532-b666-b0e975e40c56": {
    "pk": "cb8e0bde-efad-4532-b666-b0e975e40c56",
    "name": "Jiaxuan You",
    "bio": "I am a researcher dedicated to enhancing healthcare delivery through innovative machine learning techniques. My recent work focuses on developing an automated medical procedure order recommender that streamlines patient referrals from primary care to specialty care. By leveraging a heterogeneous graph neural network, I model structured electronic health records to tackle this challenge, framing the recommendation task as a link prediction problem. \n\nMy approach has demonstrated a significant 14% improvement in personalized recommendations compared to state-of-the-art neural network models and existing clinical tools, such as referral guidelines and checklists. This research not only highlights the potential of graph representation learning in healthcare but also underscores my commitment to bridging the gap between technology and clinical practice, ultimately aiming to improve patient outcomes and streamline healthcare processes.",
    "collaborators": [
      "S. Fouladvand",
      "F. R. Gomez",
      "H. Nilforoshan",
      "M. Noshad",
      "R. Sosic",
      "J. Leskovec",
      "J. H. Chen"
    ],
    "pub_titles": [
      "Graph-Based Clinical Recommender: Predicting Specialists Procedure Orders using Graph Representation Learning"
    ],
    "pub_abstracts": [
      "An automated medical procedure order recommender can facilitate patient referrals and consultations from primary care providers to specialty care sites. Here, we propose to solve this task using a novel graph representation learning approach. We develop a heterogeneous graph neural network to model structured electronic health records and formulate the procedure recommender task as a link prediction problem. Our experimental results show that our model achieves a 14% improvement in personalized recommendations over state-of-the-art neural network models and existing clinical tools including referral guidelines and check lists."
    ],
    "domain": [
      "Graph Neural Network",
      "Healthcare",
      "Recommendation Systems"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "68914bfa-5577-4b57-ac0b-91d5f6564f01": {
    "pk": "68914bfa-5577-4b57-ac0b-91d5f6564f01",
    "name": "Jure Leskovec",
    "bio": "I am a researcher dedicated to advancing the intersection of machine learning and real-world applications, particularly in healthcare, social networks, and relational data. My recent work has focused on developing innovative frameworks like PlaNet, a geometric deep learning system that leverages clinical knowledge graphs to enhance precision medicine and optimize clinical trial designs. I have also explored the potential of large language models (LLMs) for generating realistic social networks, addressing biases, and improving network generation methods.\n\nMy contributions extend to relational deep learning, where I introduced a blueprint for end-to-end learning on relational databases, significantly reducing the need for manual feature engineering. I have developed P LATO, a method that utilizes auxiliary knowledge graphs to improve performance on high-dimensional tabular datasets, and I have created benchmarks like RelBench and WILDS to facilitate research in relational learning and distribution shifts.\n\nAdditionally, I have investigated the dynamics of socioeconomic mixing in urban environments, revealing counterintuitive findings about exposure segregation in large metropolitan areas. My work aims to bridge the gap between complex data structures and practical machine learning applications, ultimately striving to harness AI for meaningful societal impact. Through my research, I seek to empower systems that can adapt to diverse populations and complex interactions, paving the way for more effective and equitable solutions in various domains.",
    "collaborators": [
      "Kexin Huang",
      "Weihua Hu",
      "Matthias Fey",
      "Michihiro Yasunaga",
      "J. E. Lenssen",
      "Rex Ying",
      "Emma Pierson",
      "Rishabh Ranjan",
      "Joshua Robinson",
      "Jiaxuan You",
      "Minkai Xu",
      "H. Nilforoshan",
      "Hongyu Ren",
      "Jiaqi Han",
      "Stefano Ermon",
      "Shirley Wu",
      "Shiyu Zhao",
      "Qian Huang",
      "V. Ioannidis",
      "Karthik Subbian",
      "James Zou",
      "Yiwen Yuan",
      "Zecheng Zhang",
      "Kaidi Cao",
      "Camilo Ruiz",
      "Maria Brbi\u00b4c",
      "Prabhat Agarwal",
      "Serina Chang",
      "Alicja Chaszczewicz",
      "Emma Wang",
      "Maya Josifovska",
      "Mingjian Jiang",
      "Yuxuan Song",
      "Jialin Chen",
      "Aosong Feng",
      "L. Tassiulas",
      "Eric A. Riesel",
      "Tsach Mackey",
      "Catherine K. Badding",
      "Alison B Altman",
      "Danna E Freedman",
      "Paridhi Maheshwari",
      "Yanan Wang",
      "R. Sosi\u010d",
      "Akihiro Nitta",
      "Vid Kocijan",
      "Tianyu Fu",
      "Andrew Wang",
      "Yu Wang",
      "Tomas Geffner",
      "Karsten Kreis",
      "Weili Nie",
      "Yilun Xu",
      "Arash Vahdat",
      "Alejandro Dobles",
      "Xinwei He",
      "S. Fouladvand",
      "F. R. Gomez",
      "M. Noshad",
      "J. You",
      "R. Sosic",
      "J. H. Chen",
      "Wenli Looi",
      "Blanca Villanueva",
      "N. Fishman",
      "Yiling Chen",
      "John Sholar",
      "Beth Redbird",
      "David B. Grusky",
      "Pang Wei Koh",
      "Shiori Sagawa",
      "H. Marklund",
      "Sang Michael Xie",
      "Marvin Zhang",
      "Akshay Balsubramani",
      "Richard Lanas Phillips",
      "Irena Gao",
      "Tony Lee",
      "Etiene David",
      "I. Stavness",
      "Wei Guo",
      "Berton A. Earnshaw",
      "I. Haque",
      "Sara Beery",
      "A. Kundaje",
      "Sergey Levine",
      "Chelsea Finn",
      "Percy Liang"
    ],
    "pub_titles": [
      "Predicting drug outcome of population via clinical knowledge graph",
      "LLMs generate structurally realistic social networks but overestimate political homophily",
      "Position: Relational Deep Learning - Graph Representation Learning on Relational Databases",
      "$f$-PO: Generalizing Preference Optimization with $f$-divergence Minimization",
      "From Similarity to Superiority: Channel Clustering for Time Series Forecasting",
      "Crystal Structure Determination from Powder Diffraction Patterns with Generative Machine Learning.",
      "AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning",
      "TimeGraphs: Graph-based Temporal Reasoning",
      "PyTorch Frame: A Modular Framework for Multi-Modal Tabular Learning",
      "Representation Learning for Frequent Subgraph Mining",
      "STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases",
      "Energy-Based Diffusion Language Models for Text Generation",
      "RelBench: A Benchmark for Deep Learning on Relational Databases",
      "Relational Deep Learning: Graph Representation Learning on Relational Databases",
      "High dimensional, tabular deep learning with an auxiliary knowledge graph",
      "Graph-Based Clinical Recommender: Predicting Specialists Procedure Orders using Graph Representation Learning",
      "Human mobility networks reveal increased segregation in large cities",
      "Tabular Deep Learning when d \u226b n by Using an Auxiliary Knowledge Graph",
      "WILDS: A Benchmark of in-the-Wild Distribution Shifts"
    ],
    "pub_abstracts": [
      "Optimal treatments depend on numerous factors such as drug chemical properties, disease biology, and patient characteristics to which the treatment is applied. To realize the promise of AI in healthcare, there is a need for designing systems that can capture patient heterogeneity and relevant biomedical knowledge. Here we present PlaNet, a geometric deep learning framework that reasons over population variability, disease biology, and drug chemistry by representing knowledge in the form of a massive clinical knowledge graph that can be enhanced by language models. Our framework is applicable to any sub-population, any drug as well drug combinations, any disease, and to a wide range of pharmacological tasks. We apply the PlaNet framework to reason about outcomes of clinical trials: PlaNet predicts drug efficacy and adverse events, even for experimental drugs and their combinations that have never been seen by the model. Furthermore, PlaNet can estimate the effect of changing population on the trial outcome with direct implications on patient stratification in clinical trials. PlaNet takes fundamental steps towards AI-guided clinical trials design, offering valuable guidance for realizing the vision of precision medicine using AI.",
      "Generating social networks is essential for many applications, such as epidemic modeling and social simulations. Prior approaches either involve deep learning models, which require many observed networks for training, or stylized models, which are limited in their realism and flexibility. In contrast, LLMs offer the potential for zero-shot and flexible network generation. However, two key questions are: (1) are LLM's generated networks realistic, and (2) what are risks of bias, given the importance of demographics in forming social ties? To answer these questions, we develop three prompting methods for network generation and compare the generated networks to real social networks. We find that more realistic networks are generated with\"local\"methods, where the LLM constructs relations for one persona at a time, compared to\"global\"methods that construct the entire network at once. We also find that the generated networks match real networks on many characteristics, including density, clustering, community structure, and degree. However, we find that LLMs emphasize political homophily over all other types of homophily and overestimate political homophily relative to real-world measures.",
      "Much of the world\u2019s most valued data is stored in relational databases and data warehouses, where the data is organized into tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming because no ML algorithm can directly learn from multiple connected tables. Current approaches can only learn from a single table, so data must first be manually joined and aggregated into this format, the laborious process known as feature engineering. This position paper introduces Relational Deep Learning (RDL) , a blueprint for end-to-end learning on relational databases. The key is to represent relational databases as temporal, heterogeneous graphs, with a node for each row in each table, and edges specified by primary-foreign key links. Graph Neural Networks then learn representations that leverage all input data, without any manual feature engineering. We also introduce R EL B ENCH , and benchmark and testing suite, demonstrating strong initial results. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability.",
      "Preference optimization has made significant progress recently, with numerous methods developed to align language models with human preferences. This paper introduces $f$-divergence Preference Optimization ($f$-PO), a novel framework that generalizes and extends existing approaches. $f$-PO minimizes $f$-divergences between the optimized policy and the optimal policy, encompassing a broad family of alignment methods using various divergences. Our approach unifies previous algorithms like DPO and EXO, while offering new variants through different choices of $f$-divergences. We provide theoretical analysis of $f$-PO's properties and conduct extensive experiments on state-of-the-art language models using benchmark datasets. Results demonstrate $f$-PO's effectiveness across various tasks, achieving superior performance compared to existing methods on popular benchmarks such as AlpacaEval 2, Arena-Hard, and MT-Bench. Additionally, we present ablation studies exploring the impact of different $f$-divergences, offering insights into the trade-offs between regularization and performance in offline preference optimization. Our work contributes both practical algorithms and theoretical understanding to the field of language model alignment. Code is available at https://github.com/MinkaiXu/fPO.",
      "Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent (CI) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent (CD) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adaptable Channel Clustering Module (CCM). CCM dynamically groups channels characterized by intrinsic similarities and leverages cluster identity instead of channel identity, combining the best of CD and CI worlds. Extensive experiments on real-world datasets demonstrate that CCM can (1) boost the performance of CI and CD models by an average margin of 2.4% and 7.2% on long-term and short-term forecasting, respectively; (2) enable zero-shot forecasting with mainstream time series forecasting models; (3) uncover intrinsic time series patterns among channels and improve interpretability of complex time series models.",
      "Powder X-ray diffraction (PXRD) is a cornerstone technique in materials characterization. However, complete structure determination from PXRD patterns alone remains time-consuming and is often intractable, especially for novel materials. Current machine learning (ML) approaches to PXRD analysis predict only a subset of the total information that comprises a crystal structure. We developed a pioneering generative ML model designed to solve crystal structures from real-world experimental PXRD data. In addition to strong performance on simulated diffraction patterns, we demonstrate full structure solutions over a large set of experimental diffraction patterns. Benchmarking our model, we predicted the structure for 134 experimental patterns from the RRUFF database and thousands of simulated patterns from the Materials Project on which our model achieves state-of-the-art 42 and 67% match rate, respectively. Further, we applied our model to determine the unreported structures of materials such as NaCu2P2, Ca2MnTeO6, ZrGe6Ni6, LuOF, and HoNdV2O8 from the Powder Diffraction File database. We extended this methodology to new materials created in our lab at high pressure with previously unsolved structures and found the new binary compounds Rh3Bi, RuBi2, and KBi3. We expect that our model will open avenues toward materials discovery under conditions which preclude single crystal growth and toward automated materials discovery pipelines, opening the door to new domains of chemistry.",
      "Large language model (LLM) agents have demonstrated impressive capabilities in utilizing external tools and knowledge to boost accuracy and reduce hallucinations. However, developing prompting techniques that enable LLM agents to effectively use these tools and knowledge remains a heuristic and labor-intensive task. Here, we introduce AvaTaR, a novel and automated framework that optimizes an LLM agent to effectively leverage provided tools, improving performance on a given task. During optimization, we design a comparator module to iteratively deliver insightful and comprehensive prompts to the LLM agent by contrastively reasoning between positive and negative examples sampled from training data. We demonstrate AvaTaR on four complex multimodal retrieval datasets featuring textual, visual, and relational information, and three general question-answering (QA) datasets. We find AvaTaR consistently outperforms state-of-the-art approaches across all seven tasks, exhibiting strong generalization ability when applied to novel cases and achieving an average relative improvement of 14% on the Hit@1 metric for the retrieval datasets and 13% for the QA datasets. Code and dataset are available at https://github.com/zou-group/avatar.",
      "Many real-world systems exhibit temporal, dynamic behaviors, which are captured as time series of complex agent interactions. To perform temporal reasoning, current methods primarily encode temporal dynamics through simple sequence-based models. However, in general these models fail to efficiently capture the full spectrum of rich dynamics in the input, since the dynamics is not uniformly distributed. In particular, relevant information might be harder to extract and computing power is wasted for processing all individual timesteps, even if they contain no significant changes or no new information. Here we propose TimeGraphs, a novel approach that characterizes dynamic interactions as a hierarchical temporal graph, diverging from traditional sequential representations. Our approach models the interactions using a compact graph-based representation, enabling adaptive reasoning across diverse time scales. Adopting a self-supervised method, TimeGraphs constructs a multi-level event hierarchy from a temporal input, which is then used to efficiently reason about the unevenly distributed dynamics. This construction process is scalable and incremental to accommodate streaming data. We evaluate TimeGraphs on multiple datasets with complex, dynamic agent interactions, including a football simulator, the Resistance game, and the MOMA human activity dataset. The results demonstrate both robustness and efficiency of TimeGraphs on a range of temporal reasoning tasks. Our approach obtains state-of-the-art performance and leads to a performance increase of up to 12.2% on event prediction and recognition tasks over current approaches. Our experiments further demonstrate a wide array of capabilities including zero-shot generalization, robustness in case of data sparsity, and adaptability to streaming data flow.",
      "We present PyTorch Frame, a PyTorch-based framework for deep learning over multi-modal tabular data. PyTorch Frame makes tabular deep learning easy by providing a PyTorch-based data structure to handle complex tabular data, introducing a model abstraction to enable modular implementation of tabular models, and allowing external foundation models to be incorporated to handle complex columns (e.g., LLMs for text columns). We demonstrate the usefulness of PyTorch Frame by implementing diverse tabular models in a modular way, successfully applying these models to complex multi-modal tabular data, and integrating our framework with PyTorch Geometric, a PyTorch library for Graph Neural Networks (GNNs), to perform end-to-end learning over relational databases.",
      "Identifying frequent subgraphs, also called network motifs, is crucial in analyzing and predicting properties of real-world networks. However, finding large commonly-occurring motifs remains a challenging problem not only due to its NP-hard subroutine of subgraph counting, but also the exponential growth of the number of possible subgraphs patterns. Here we present Subgraph Pattern Miner (SPMiner), a novel neural approach for approximately finding frequent subgraphs in a large target graph. SPMiner combines graph neural networks, order embedding space, and an efficient search strategy to identify network subgraph patterns that appear most frequently in the target graph. SPMiner first decomposes the target graph into many overlapping subgraphs and then encodes each subgraph into an order embedding space. SPMiner then uses a monotonic walk in the order embedding space to identify frequent motifs. Compared to existing approaches and possible neural alternatives, SPMiner is more accurate, faster, and more scalable. For 5- and 6-node motifs, we show that SPMiner can almost perfectly identify the most frequent motifs while being 100x faster than exact enumeration methods. In addition, SPMiner can also reliably identify frequent 10-node motifs, which is well beyond the size limit of exact enumeration approaches. And last, we show that SPMiner can find large up to 20 node motifs with 10-100x higher frequency than those found by current approximate methods.",
      "Answering real-world complex queries, such as complex product search, often requires accurate retrieval from semi-structured knowledge bases that involve blend of unstructured (e.g., textual descriptions of products) and structured (e.g., entity relations of products) information. However, many previous works studied textual and relational retrieval tasks as separate topics. To address the gap, we develop STARK, a large-scale Semi-structure retrieval benchmark on Textual and Relational Knowledge Bases. Our benchmark covers three domains: product search, academic paper search, and queries in precision medicine. We design a novel pipeline to synthesize realistic user queries that integrate diverse relational information and complex textual properties, together with their ground-truth answers (items). We conduct rigorous human evaluation to validate the quality of our synthesized queries. We further enhance the benchmark with high-quality human-generated queries to provide an authentic reference. STARK serves as a comprehensive testbed for evaluating the performance of retrieval systems driven by large language models (LLMs). Our experiments suggest that STARK presents significant challenges to the current retrieval and LLM systems, highlighting the need for more capable semi-structured retrieval systems. The benchmark data and code are available on https://github.com/snap-stanford/STaRK.",
      "Despite remarkable progress in autoregressive language models, alternative generative paradigms beyond left-to-right generation are still being actively explored. Discrete diffusion models, with the capacity for parallel generation, have recently emerged as a promising alternative. Unfortunately, these models still underperform the autoregressive counterparts, with the performance gap increasing when reducing the number of sampling steps. Our analysis reveals that this degradation is a consequence of an imperfect approximation used by diffusion models. In this work, we propose Energy-based Diffusion Language Model (EDLM), an energy-based model operating at the full sequence level for each diffusion step, introduced to improve the underlying approximation used by diffusion models. More specifically, we introduce an EBM in a residual form, and show that its parameters can be obtained by leveraging a pretrained autoregressive model or by finetuning a bidirectional transformer via noise contrastive estimation. We also propose an efficient generation algorithm via parallel important sampling. Comprehensive experiments on language modeling benchmarks show that our model can consistently outperform state-of-the-art diffusion models by a significant margin, and approaches autoregressive models' perplexity. We further show that, without any generation performance drop, our framework offers a 1.3$\\times$ sampling speedup over existing diffusion models.",
      "We present RelBench, a public benchmark for solving predictive tasks over relational databases with graph neural networks. RelBench provides databases and tasks spanning diverse domains and scales, and is intended to be a foundational infrastructure for future research. We use RelBench to conduct the first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024), which combines graph neural network predictive models with (deep) tabular models that extract initial entity-level representations from raw tables. End-to-end learned RDL models fully exploit the predictive signal encoded in primary-foreign key links, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular models. To thoroughly evaluate RDL against this prior gold-standard, we conduct an in-depth user study where an experienced data scientist manually engineers features for each task. In this study, RDL learns better models whilst reducing human work needed by more than an order of magnitude. This demonstrates the power of deep learning for solving predictive tasks over relational databases, opening up many new research opportunities enabled by RelBench.",
      "Much of the world's most valued data is stored in relational databases and data warehouses, where the data is organized into many tables connected by primary-foreign key relations. However, building machine learning models using this data is both challenging and time consuming. The core problem is that no machine learning method is capable of learning on multiple tables interconnected by primary-foreign key relations. Current methods can only learn from a single table, so the data must first be manually joined and aggregated into a single training table, the process known as feature engineering. Feature engineering is slow, error prone and leads to suboptimal models. Here we introduce an end-to-end deep representation learning approach to directly learn on data laid out across multiple tables. We name our approach Relational Deep Learning (RDL). The core idea is to view relational databases as a temporal, heterogeneous graph, with a node for each row in each table, and edges specified by primary-foreign key links. Message Passing Graph Neural Networks can then automatically learn across the graph to extract representations that leverage all input data, without any manual feature engineering. Relational Deep Learning leads to more accurate models that can be built much faster. To facilitate research in this area, we develop RelBench, a set of benchmark datasets and an implementation of Relational Deep Learning. The data covers a wide spectrum, from discussions on Stack Exchange to book reviews on the Amazon Product Catalog. Overall, we define a new research area that generalizes graph machine learning and broadens its applicability to a wide set of AI use cases.",
      "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high d -dimensional features but limited n samples (i.e. d \u226b n ), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose P LATO , a method that achieves strong performance on tabular data with d \u226b n by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In P LATO , each input feature corresponds to a node in the auxiliary KG. In the MLP\u2019s first layer, each input feature also corresponds to a weight vector. P LATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP\u2019s first layer. P LATO captures this inductive bias by inferring the weight vector for each input feature from its corresponding node in the KG via a trainable message-passing function. Across 6 d \u226b n datasets, P LATO outperforms 13 state-of-the-art baselines by up to 10.19%.",
      "An automated medical procedure order recommender can facilitate patient referrals and consultations from primary care providers to specialty care sites. Here, we propose to solve this task using a novel graph representation learning approach. We develop a heterogeneous graph neural network to model structured electronic health records and formulate the procedure recommender task as a link prediction problem. Our experimental results show that our model achieves a 14% improvement in personalized recommendations over state-of-the-art neural network models and existing clinical tools including referral guidelines and check lists.",
      "A long-standing expectation is that large, dense, and cosmopolitan areas support socioeconomic mixing and exposure between diverse individuals. It has been difficult to assess this hypothesis because past approaches to measuring socioeconomic mixing have relied on static residential housing data rather than real-life exposures between people at work, in places of leisure, and in home neighborhoods. Here we develop a new measure of exposure segregation (ES) that captures the socioeconomic diversity of everyday encounters. Leveraging cell phone mobility data to represent 1.6 billion exposures among 9.6 million people in the United States, we measure exposure segregation across 382 Metropolitan Statistical Areas (MSAs) and 2829 counties. We discover that exposure segregation is 67% higher in the 10 largest Metropolitan Statistical Areas (MSAs) than in small MSAs with fewer than 100,000 residents. This means that, contrary to expectation, residents of large cosmopolitan areas have significantly less exposure to diverse individuals. Second, we find evidence that large cities offer a greater choice of differentiated spaces targeted to specific socioeconomic groups, a dynamic that accounts for this increase in everyday socioeconomic segregation. Third, we discover that this segregation-increasing effect is countered when a city's hubs (e.g. shopping malls) are positioned to bridge diverse neighborhoods and thus attract people of all socioeconomic statuses. Overall, our findings challenge a long-standing conjecture in human geography and urban design, and highlight how built environment can both prevent and facilitate exposure between diverse individuals.",
      "Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high d -dimensional features but limited n samples ( i.e. d \u226b n ), machine learning models struggle to achieve strong performance. Here, our key insight is that even in tabular datasets with limited labeled data, input features often represent real-world entities about which there is abundant prior information which can be structured as an auxiliary knowledge graph (KG). For example, in a tabular medical dataset where every input feature is the amount of a gene in a patient\u2019s tumor and the label is the patient\u2019s survival, there is an auxiliary knowledge graph connecting gene names with drug, disease, and human anatomy nodes. We therefore propose P LATO , a machine learning model for tabular data with d \u226b n and an auxiliary KG with input features as nodes. P LATO uses a modified multilayer perceptron (MLP) to predict the output labels from the tabular data and the auxiliary KG with two components. First, P LATO predicts the parameters in the first layer of the MLP from the auxiliary KG. P LATO thereby reduces the number of trainable parameters in the MLP and integrates auxiliary information about the input features. Second, P LATO predicts different parameters in the first layer of the MLP for every input sample, thereby increasing the MLP\u2019s representational capacity by allowing it to use different prior information for every input sample. Across 10 state-of-the-art baselines and 6 d \u226b n datasets, P LATO exceeds or matches the prior state-of-the-art, achieving performance improvements of up to 10.19%. Overall, P LATO uses an auxiliary KG about input features to enable tabular deep learning prediction when d \u226b n .",
      "Distribution shifts -- where the training distribution differs from the test distribution -- can substantially degrade the accuracy of machine learning (ML) systems deployed in the wild. Despite their ubiquity in the real-world deployments, these distribution shifts are under-represented in the datasets widely used in the ML community today. To address this gap, we present WILDS, a curated benchmark of 10 datasets reflecting a diverse range of distribution shifts that naturally arise in real-world applications, such as shifts across hospitals for tumor identification; across camera traps for wildlife monitoring; and across time and location in satellite imaging and poverty mapping. On each dataset, we show that standard training yields substantially lower out-of-distribution than in-distribution performance. This gap remains even with models trained by existing methods for tackling distribution shifts, underscoring the need for new methods for training models that are more robust to the types of distribution shifts that arise in practice. To facilitate method development, we provide an open-source package that automates dataset loading, contains default model architectures and hyperparameters, and standardizes evaluations. Code and leaderboards are available at https://wilds.stanford.edu."
    ],
    "domain": [
      "Graph Neural Network",
      "Machine Learning",
      "Healthcare AI",
      "Knowledge Graph"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "8bd6b464-2e61-444b-8158-8f61346ad3a6": {
    "pk": "8bd6b464-2e61-444b-8158-8f61346ad3a6",
    "name": "Stefanie Jegelka",
    "bio": "I am a researcher deeply engaged in the intersection of optimization, neural networks, and graph learning. My recent work explores the intricate relationships between optimization algorithms and the generalization capabilities of neural networks, particularly focusing on the implicit biases introduced by stochastic gradient descent (SGD). I have investigated how label noise SGD can lead to simpler models by converging to low-rank features, bridging the gap between model simplicity and optimization dynamics.\n\nMy research also delves into the expressivity and learnability of Transformers, demonstrating their ability to simulate multi-step algorithms like gradient descent. I have developed novel sharpness measures to enhance optimization in overparameterized models, contributing to the understanding of how flatness regularization can improve generalization.\n\nIn the realm of graph machine learning, I have introduced innovative sampling theories and algorithms that address the challenges of large-scale graph representation. My work on Recursive Neighborhood Pooling GNNs (RNP-GNNs) quantifies the power of recursion in graph representation, while my studies on graph neural networks (GNNs) explore their generalization capabilities across different graph structures.\n\nAdditionally, I have contributed to the field of self-supervised learning, proposing methods that enforce geometric structures in embedding spaces to improve performance on downstream tasks. My research aims to provide theoretical insights and practical solutions that enhance the robustness and efficiency of machine learning models across various domains.",
    "collaborators": [
      "Khashayar Gatmiry",
      "Sashank J. Reddi",
      "B. Tahmasebi",
      "Derek Lim",
      "Joshua Robinson",
      "Zhiyuan Li",
      "Nikunj Saunshi",
      "Sanjiv Kumar",
      "Thien Le",
      "Sharut Gupta",
      "Soledad Villar",
      "Ching-Yao Chuang",
      "Ashkan Soleymani",
      "Dara Bahri",
      "P. Jaillet",
      "Jon Schneider",
      "Luana Ruiz",
      "Bharathan Sundar",
      "N. Chandramoorthy",
      "H. Owhadi",
      "Tengyu Ma",
      "Varun Jampani",
      "Yuanzhen Li",
      "A. Torralba",
      "M. Murphy",
      "E. Fraenkel",
      "T. Kind",
      "D. Healey",
      "T. Butler",
      "Martin Grohe",
      "Stephan G\u00fcnnemann",
      "Christopher Morris",
      "Nikolaos Karalias",
      "Andreas Loukas"
    ],
    "pub_titles": [
      "Simplicity Bias via Global Convergence of Sharpness Minimization",
      "A Universal Class of Sharpness-Aware Minimization Algorithms",
      "Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning?",
      "Computing Optimal Regularizers for Online Linear Optimization",
      "On the Role of Depth and Looping for In-Context Learning with Task Diversity",
      "A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on Large Graphs",
      "Limits, approximation and size transferability for GNNs on sparse graphs via graphops",
      "Session F Abstracts Exploiting Non-Convergent Dynamics in GAN Training",
      "The Power of Recursion in Graph Neural Networks for Counting Substructures",
      "Learning Structured Representations with Equivariant Contrastive Learning",
      "The Inductive Bias of Flatness Regularization for Deep Matrix Factorization",
      "Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning",
      "Debiasing Vision-Language Models via Biased Prompts",
      "The Exact Sample Complexity Gain from Invariances for Kernel Regression on Manifolds",
      "Sample Complexity Bounds for Estimating Probability Divergences under Invariances",
      "Efficiently predicting high resolution mass spectra with graph neural networks",
      "Theory of Graph Neural Networks: Representation and Learning",
      "Graph Embeddings: Theory meets Practice (Dagstuhl Seminar 22132)",
      "Neural Set Function Extensions: Learning with Discrete Functions in High Dimensions"
    ],
    "pub_abstracts": [
      "The remarkable generalization ability of neural networks is usually attributed to the implicit bias of SGD, which often yields models with lower complexity using simpler (e.g. linear) and low-rank features. Recent works have provided empirical and theoretical evidence for the bias of particular variants of SGD (such as label noise SGD) toward flatter regions of the loss landscape. Despite the folklore intuition that flat solutions are 'simple', the connection with the simplicity of the final trained model (e.g. low-rank) is not well understood. In this work, we take a step toward bridging this gap by studying the simplicity structure that arises from minimizers of the sharpness for a class of two-layer neural networks. We show that, for any high dimensional training data and certain activations, with small enough step size, label noise SGD always converges to a network that replicates a single linear feature across all neurons; thereby, implying a simple rank one feature matrix. To obtain this result, our main technical contribution is to show that label noise SGD always minimizes the sharpness on the manifold of models with zero loss for two-layer networks. Along the way, we discover a novel property -- a local geodesic convexity -- of the trace of Hessian of the loss at approximate stationary points on the manifold of zero loss, which links sharpness to the geometry of the manifold. This tool may be of independent interest.",
      "Recently, there has been a surge in interest in developing optimization algorithms for overparameterized models as achieving generalization is believed to require algorithms with suitable biases. This interest centers on minimizing sharpness of the original loss function; the Sharpness-Aware Minimization (SAM) algorithm has proven effective. However, most literature only considers a few sharpness measures, such as the maximum eigenvalue or trace of the training loss Hessian, which may not yield meaningful insights for non-convex optimization scenarios like neural networks. Additionally, many sharpness measures are sensitive to parameter invariances in neural networks, magnifying significantly under rescaling parameters. Motivated by these challenges, we introduce a new class of sharpness measures in this paper, leading to new sharpness-aware objective functions. We prove that these measures are \\textit{universally expressive}, allowing any function of the training loss Hessian matrix to be represented by appropriate hyperparameters. Furthermore, we show that the proposed objective functions explicitly bias towards minimizing their corresponding sharpness measures, and how they allow meaningful applications to models with parameter invariances (such as scale-invariances). Finally, as instances of our proposed general framework, we present \\textit{Frob-SAM} and \\textit{Det-SAM}, which are specifically designed to minimize the Frobenius norm and the determinant of the Hessian of the training loss, respectively. We also demonstrate the advantages of our general framework through extensive experiments.",
      "The remarkable capability of Transformers to do reasoning and few-shot learning, without any fine-tuning, is widely conjectured to stem from their ability to implicitly simulate a multi-step algorithms -- such as gradient descent -- with their weights in a single forward pass. Recently, there has been progress in understanding this complex phenomenon from an expressivity point of view, by demonstrating that Transformers can express such multi-step algorithms. However, our knowledge about the more fundamental aspect of its learnability, beyond single layer models, is very limited. In particular, can training Transformers enable convergence to algorithmic solutions? In this work we resolve this for in-context linear regression with linear looped Transformers -- a multi-layer model with weight sharing that is conjectured to have an inductive bias to learn fix-point iterative algorithms. More specifically, for this setting we show that the global minimizer of the population training loss implements multi-step preconditioned gradient descent, with a preconditioner that adapts to the data distribution. Furthermore, we show a fast convergence for gradient flow on the regression loss, despite the non-convexity of the landscape, by proving a novel gradient dominance condition. To our knowledge, this is the first theoretical analysis for multi-layer Transformer in this setting. We further validate our theoretical findings through synthetic experiments.",
      "Follow-the-Regularized-Leader (FTRL) algorithms are a popular class of learning algorithms for online linear optimization (OLO) that guarantee sub-linear regret, but the choice of regularizer can significantly impact dimension-dependent factors in the regret bound. We present an algorithm that takes as input convex and symmetric action sets and loss sets for a specific OLO instance, and outputs a regularizer such that running FTRL with this regularizer guarantees regret within a universal constant factor of the best possible regret bound. In particular, for any choice of (convex, symmetric) action set and loss set we prove that there exists an instantiation of FTRL which achieves regret within a constant factor of the best possible learning algorithm, strengthening the universality result of Srebro et al., 2011. Our algorithm requires preprocessing time and space exponential in the dimension $d$ of the OLO instance, but can be run efficiently online assuming a membership and linear optimization oracle for the action and loss sets, respectively (and is fully polynomial time for the case of constant dimension $d$). We complement this with a lower bound showing that even deciding whether a given regularizer is $\\alpha$-strongly-convex with respect to a given norm is NP-hard.",
      "The intriguing in-context learning (ICL) abilities of deep Transformer models have lately garnered significant attention. By studying in-context linear regression on unimodal Gaussian data, recent empirical and theoretical works have argued that ICL emerges from Transformers' abilities to simulate learning algorithms like gradient descent. However, these works fail to capture the remarkable ability of Transformers to learn multiple tasks in context. To this end, we study in-context learning for linear regression with diverse tasks, characterized by data covariance matrices with condition numbers ranging from $[1, \\kappa]$, and highlight the importance of depth in this setting. More specifically, (a) we show theoretical lower bounds of $\\log(\\kappa)$ (or $\\sqrt{\\kappa}$) linear attention layers in the unrestricted (or restricted) attention setting and, (b) we show that multilayer Transformers can indeed solve such tasks with a number of layers that matches the lower bounds. However, we show that this expressivity of multilayer Transformer comes at the price of robustness. In particular, multilayer Transformers are not robust to even distributional shifts as small as $O(e^{-L})$ in Wasserstein distance, where $L$ is the depth of the network. We then demonstrate that Looped Transformers -- a special class of multilayer Transformers with weight-sharing -- not only exhibit similar expressive power but are also provably robust under mild assumptions. Besides out-of-distribution generalization, we also show that Looped Transformers are the only models that exhibit a monotonic behavior of loss with respect to depth.",
      "Large-scale graph machine learning is challenging as the complexity of learning models scales with the graph size. Subsampling the graph is a viable alternative, but sampling on graphs is nontrivial as graphs are non-Euclidean. Existing graph sampling techniques require not only computing the spectra of large matrices but also repeating these computations when the graph changes, e.g., grows. In this paper, we introduce a signal sampling theory for a type of graph limit -- the graphon. We prove a Poincar\\'e inequality for graphon signals and show that complements of node subsets satisfying this inequality are unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting connections with spectral clustering and Gaussian elimination, we prove that such sampling sets are consistent in the sense that unique sampling sets on a convergent graph sequence converge to unique sampling sets on the graphon. We then propose a related graphon signal sampling algorithm for large graphs, and demonstrate its good empirical performance on graph machine learning tasks.",
      "Can graph neural networks generalize to graphs that are different from the graphs they were trained on, e.g., in size? In this work, we study this question from a theoretical perspective. While recent work established such transferability and approximation results via graph limits, e.g., via graphons, these only apply non-trivially to dense graphs. To include frequently encountered sparse graphs such as bounded-degree or power law graphs, we take a perspective of taking limits of operators derived from graphs, such as the aggregation operation that makes up GNNs. This leads to the recently introduced limit notion of graphops (Backhausz and Szegedy, 2022). We demonstrate how the operator perspective allows us to develop quantitative bounds on the distance between a finite GNN and its limit on an infinite graph, as well as the distance between the GNN on graphs of different sizes that share structural properties, under a regularity assumption verified for various graph sequences. Our results hold for dense and sparse graphs, and various notions of graph limits.",
      "It is well-studied that generative adversarial network (GAN) training can suffer from instabilities due to the challenge of finding a Nash equilibrium for the zero-sum game. Here, we are interested in studying GANs with non-convergent training dynamics, and exploiting their statistical properties to achieve robust generalization. We first explore the toy setting of learning Gaussian mixtures, and deliberately induce unstable behaviors such as oscillation. Under these dynamics, we introduce ensembling (time-averaging over training) as an approach to handle, or even exploit, non-convergence, along with multiple ensembling schemes. We show various empirical results where ensembling of models outperforms a single model, including even some simple, low-dimensional toy settings. These results present a promising direction for GAN research, as they imply convergent dynamics are not necessary to achieve strong performance in practice.",
      "To achieve a graph representation, most Graph Neural Networks (GNNs) follow two steps: first, each graph is decomposed into a number of sub-graphs (which we call the recursion step), and then the collection of subgraphs is encoded by several iterative pooling steps. While recently proposed higher-order networks show a remarkable increase in the expressive power through a single recursion on larger neighborhoods followed by iterative pooling, the power of deeper recursion in GNNs without any iterative pooling is still not fully understood. To make it concrete, we consider a pure recursion-based GNN which we call Recursive Neighborhood Pooling GNN (RNP-GNN). The expressive power of an RNP-GNN and its computational cost quantifies the power of (pure) recursion for a graph representation network. We quantify the power by means of counting substructures, which is one main limitation of the Message Passing graph Neural Networks (MPNNs), and show how RNP-GNN can exploit the sparsity of the underlying graph to achieve low-cost powerful representations. We also compare the recent lower bounds on the time complexity and show how recursion-based networks are near optimal.",
      "Self-supervised learning converts raw perceptual data to a compact space using Euclidean distances to measure variations in data. In this paper, we enhance the embedding space by enforcing transformations of input space to correspond to simple (i.e., linear) transformations of embedding space. Speci\ufb01cally, in the contrastive learning setting, we introduce an equivariance objective and theoretically prove and empirically demonstrate that its minima forces augmentations on inputs to correspond to rotations on the spherical embedding space. Our method, C ARE : C ontrastive A ugmentation-induced R otational E quivariance, improves performance on downstream tasks by only allowing small rotations.",
      "Recent works on over-parameterized neural networks have shown that the stochasticity in optimizers has the implicit regularization effect of minimizing the sharpness of the loss function (in particular, the trace of its Hessian) over the family zero-loss solutions. More explicit forms of flatness regularization also empirically improve the generalization performance. However, it remains unclear why and when flatness regularization leads to better generalization. This work takes the first step toward understanding the inductive bias of the minimum trace of the Hessian solutions in an important setting: learning deep linear networks from linear measurements, also known as \\emph{deep matrix factorization}. We show that for all depth greater than one, with the standard Restricted Isometry Property (RIP) on the measurements, minimizing the trace of Hessian is approximately equivalent to minimizing the Schatten 1-norm of the corresponding end-to-end matrix parameters (i.e., the product of all layer matrices), which in turn leads to better generalization. We empirically verify our theoretical findings on synthetic datasets.",
      "Self-supervised learning converts raw perceptual data such as images to a compact space where simple Euclidean distances measure meaningful variations in data. In this paper, we extend this formulation by adding additional geometric structure to the embedding space by enforcing transformations of input space to correspond to simple (i.e., linear) transformations of embedding space. Specifically, in the contrastive learning setting, we introduce an equivariance objective and theoretically prove that its minima forces augmentations on input space to correspond to rotations on the spherical embedding space. We show that merely combining our equivariant loss with a non-collapse term results in non-trivial representations, without requiring invariance to data augmentations. Optimal performance is achieved by also encouraging approximate invariance, where input augmentations correspond to small rotations. Our method, CARE: Contrastive Augmentation-induced Rotational Equivariance, leads to improved performance on downstream tasks, and ensures sensitivity in embedding space to important variations in data (e.g., color) that standard contrastive methods do not achieve. Code is available at https://github.com/Sharut/CARE.",
      "Machine learning models have been shown to inherit biases from their training datasets. This can be particularly problematic for vision-language foundation models trained on uncurated datasets scraped from the internet. The biases can be amplified and propagated to downstream applications like zero-shot classifiers and text-to-image generative models. In this study, we propose a general approach for debiasing vision-language foundation models by projecting out biased directions in the text embedding. In particular, we show that debiasing only the text embedding with a calibrated projection matrix suffices to yield robust classifiers and fair generative models. The proposed closed-form solution enables easy integration into large-scale pipelines, and empirical results demonstrate that our approach effectively reduces social bias and spurious correlation in both discriminative and generative vision-language models without the need for additional data or training.",
      "In practice, encoding invariances into models helps sample complexity. In this work, we tighten and generalize theoretical results on how invariances improve sample complexity. In particular, we provide minimax optimal rates for kernel ridge regression on any manifold, with a target function that is invariant to an arbitrary group action on the manifold. Our results hold for (almost) any group action, even groups of positive dimension. For a finite group, the gain increases the\"effective\"number of samples by the group size. For groups of positive dimension, the gain is observed by a reduction in the manifold's dimension, in addition to a factor proportional to the volume of the quotient space. Our proof takes the viewpoint of differential geometry, in contrast to the more common strategy of using invariant polynomials. Hence, this new geometric viewpoint on learning with invariances may be of independent interest.",
      "Group-invariant probability distributions appear in many data-generative models in machine learning, such as graphs, point clouds, and images. In practice, one often needs to estimate divergences between such distributions. In this work, we study how the inherent invariances, with respect to any smooth action of a Lie group on a manifold, improve sample complexity when estimating the 1-Wasserstein distance, the Sobolev Integral Probability Metrics (Sobolev IPMs), the Maximum Mean Discrepancy (MMD), and also the complexity of the density estimation problem (in the $L^2$ and $L^\\infty$ distance). Our results indicate a two-fold gain: (1) reducing the sample complexity by a multiplicative factor corresponding to the group size (for finite groups) or the normalized volume of the quotient space (for groups of positive dimension); (2) improving the exponent in the convergence rate (for groups of positive dimension). These results are completely new for groups of positive dimension and extend recent bounds for finite group actions.",
      "Identifying a small molecule from its mass spectrum is the primary open problem in computational metabolomics. This is typically cast as information retrieval: an unknown spectrum is matched against spectra predicted computationally from a large database of chemical structures. However, current approaches to spectrum prediction model the output space in ways that force a tradeoff between capturing high resolution mass information and tractable learning. We resolve this tradeoff by casting spectrum prediction as a mapping from an input molecular graph to a probability distribution over molecular formulas. We discover that a large corpus of mass spectra can be closely approximated using a fixed vocabulary constituting only 2% of all observed formulas. This enables efficient spectrum prediction using an architecture similar to graph classification - GrAFF-MS - achieving significantly lower prediction error and orders-of-magnitude faster runtime than state-of-the-art methods.",
      "Graph Neural Networks (GNNs), neural network architectures targeted to learning representations of graphs, have become a popular learning model for prediction tasks on nodes, graphs and configurations of points, with wide success in practice. This article summarizes a selection of the emerging theoretical results on approximation and learning properties of widely used message passing GNNs and higher-order GNNs, focusing on representation, generalization and extrapolation. Along the way, it summarizes mathematical connections.",
      "Vectorial representations of graphs and relational structures, so-called graph embeddings, make it possible to apply standard tools from data mining, machine learning, and statistics to the graph domain. In particular, graph embeddings aim to capture important information about, both, the graph structure and available side information as a vector, to enable downstream tasks such as classification, regression, or clustering. Starting from the 1960s in chemoinformatics, research in various communities has resulted in a plethora of approaches, often with recurring ideas. However, most of the field advancements are driven by intuition and empiricism, often tailored to a specific application domain. Until recently, the area has received little stimulus from theoretical computer science, graph theory, and learning theory. The Dagstuhl Seminar 22132 \u201cGraph Embeddings: Theory meets Practice\u201d, was aimed to gather leading applied and theoretical researchers in graph embeddings and adjacent areas, such as graph isomorphism, bio-and chemoinformatics, and graph theory, to stimulate an increased exchange of ideas between these communities.",
      "Integrating functions on discrete domains into neural networks is key to developing their capability to reason about discrete objects. But, discrete domains are (1) not naturally amenable to gradient-based optimization, and (2) incompatible with deep learning architectures that rely on representations in high-dimensional vector spaces. In this work, we address both difficulties for set functions, which capture many important discrete problems. First, we develop a framework for extending set functions onto low-dimensional continuous domains, where many extensions are naturally defined. Our framework subsumes many well-known extensions as special cases. Second, to avoid undesirable low-dimensional neural network bottlenecks, we convert low-dimensional extensions into representations in high-dimensional spaces, taking inspiration from the success of semidefinite programs for combinatorial optimization. Empirically, we observe benefits of our extensions for unsupervised neural combinatorial optimization, in particular with high-dimensional representations."
    ],
    "domain": [
      "Machine Learning",
      "Graph Neural Network",
      "Optimization",
      "Self-Supervised Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "1269a065-58e7-4b3a-8a69-a6bf5d36c5fc": {
    "pk": "1269a065-58e7-4b3a-8a69-a6bf5d36c5fc",
    "name": "Silvio Lattanzi",
    "bio": "I am a researcher specializing in algorithm design and analysis, particularly in the context of graph theory and machine learning. My work focuses on developing efficient algorithms for classic problems such as maximizing monotone submodular functions, clustering, and facility location, often under constraints like differential privacy and dynamic data streams. \n\nRecently, I have explored the intersection of graph neural networks and traditional algorithmic challenges, contributing to the TensorFlow-GNN library, which supports scalable graph learning. My research also delves into the complexities of correlation clustering and the effects of side information on clustering algorithms, revealing insights into both adversarial and random perturbations.\n\nI am particularly passionate about creating algorithms that not only perform well in theory but also demonstrate practical efficiency in real-world applications. My work on dynamic algorithms, such as those for the Densest Subgraph problem and the facility location problem, showcases my commitment to addressing the challenges posed by real-time data changes. \n\nThrough my research, I aim to bridge the gap between theoretical computer science and practical machine learning applications, providing robust solutions that can adapt to the evolving landscape of data.",
    "collaborators": [
      "A. Norouzi-Fard",
      "Paul Dutting",
      "Federico Fusco",
      "Morteza Zadimoghaddam",
      "Sergei Vassilvitskii",
      "Vincent Cohen-Addad",
      "Nikos Parotsidis",
      "O. Svensson",
      "Bryan Perozzi",
      "Anton Tsitsulin",
      "M. Bressan",
      "Nicol\u00f2 Cesa-Bianchi",
      "Andrea Paudice",
      "V. Mirrokni",
      "Michael Kapralov",
      "A. Mousavifar",
      "M. Dinitz",
      "Satyen Kale",
      "K. Fountoulakis",
      "Dake He",
      "Shenghao Yang",
      "Chenglin Fan",
      "Slobodan Mitrovi'c",
      "Jakub Tarnawski",
      "Flavio Chierichetti",
      "Ravi Kumar",
      "Sayan Bhattacharya",
      "Maximilian Thiessen",
      "Buddhima Gamlath",
      "Andreas Maggiori",
      "Alessandro Epasto",
      "Andr\u00e9s Mu\u00f1oz",
      "David Saulpic",
      "Chris Schwiegelshohn",
      "Akash Kumar",
      "Oleksandr Ferludin",
      "Arno Eigenwillig",
      "Martin J. Blais",
      "Dustin Zelle",
      "Jan Pfeifer",
      "Alvaro Sanchez-Gonzalez",
      "Sibon Li",
      "Sami Abu-El-Haija",
      "P. Battaglia",
      "Neslihan Bulut",
      "Jonathan J. Halcrow",
      "Filipe Almeida",
      "A. Linhares",
      "Brandon Mayer",
      "John Palowitch",
      "Mihir Paradkar",
      "Jennifer She",
      "Kevin Villela",
      "Lisa Wang",
      "David Wong",
      "Grzegorz Gluch",
      "C. Sohler"
    ],
    "pub_titles": [
      "Fully Dynamic Submodular Maximization over Matroids",
      "Speeding Up Bellman Ford via Minimum Violation Permutations",
      "Almost Tight Bounds for Differentially Private Densest Subgraph",
      "On Classification Thresholds for Graph Attention with Edge Features",
      "Near-Optimal Correlation Clustering with Privacy",
      "The Gibbs-Rand Model",
      "Efficient and Stable Fully Dynamic Facility Location",
      "Deletion Robust Non-Monotone Submodular Maximization over Matroids",
      "Active Learning of Classifiers with Label and Seed Queries",
      "Deletion Robust Submodular Maximization over Matroids",
      "Approximate Cluster Recovery from Noisy Labels",
      "Online and Consistent Correlation Clustering",
      "Scalable Differentially Private Clustering via Hierarchically Separated Trees",
      "Learning Hierarchical Structure of Clusterable Graphs",
      "TF-GNN: Graph Neural Networks in TensorFlow",
      "Spectral Clustering Oracles in Sublinear Time",
      "Exact Recovery of Clusters in Finite Metric Spaces Using Oracle Queries"
    ],
    "pub_abstracts": [
      "Maximizing monotone submodular functions under a matroid constraint is a classic algorithmic problem with multiple applications in data mining and machine learning. We study this significant problem in the fully dynamic setting, where elements can be both inserted and deleted in real-time.    Our main result is a randomized algorithm that maintains an efficient data structure with an    \\({\\tilde{O}({k^{2}}{\\varepsilon})}\\)    amortized update time (in the number of insertions and deletions) and yields a    \\({(4+O(\\varepsilon))}\\)    -approximate solution with respect to the dynamic optimum, where    \\(k\\)    is the rank of the matroid. ",
      "The Bellman-Ford algorithm is a basic primitive for computing single source shortest paths in graphs with negative edge-weights. Its running time is governed by the order the algorithm examines vertices for iterative updates on the value of their shortest path. In this work we study this problem through the lens of \u2018Algorithms with Pre-dictions,\u2019 and show how to leverage auxiliary information from similar instances to improve the running time. We do this by identifying the key problem of Minimum Violation Permutations, and give algorithms with strong approximation guarantees as well as formal lower bounds. We complement the theoretical analysis with an empirical evaluation, showing that this approach can lead to a signi\ufb01cant speed up in practice.",
      "We study the Densest Subgraph (DSG) problem under the additional constraint of differential privacy. DSG is a fundamental theoretical question which plays a central role in graph analytics, and so privacy is a natural requirement. All known private algorithms for Densest Subgraph lose constant multiplicative factors, despite the existence of non-private exact algorithms. We show that, perhaps surprisingly, this loss is not necessary: in both the classic differential privacy model and the LEDP model (local edge differential privacy, introduced recently by Dhulipala et al. [FOCS 2022]), we give $(\\epsilon, \\delta)$-differentially private algorithms with no multiplicative loss whatsoever. In other words, the loss is \\emph{purely additive}. Moreover, our additive losses match or improve the best-known previous additive loss (in any version of differential privacy) when $1/\\delta$ is polynomial in $n$, and are almost tight: in the centralized setting, our additive loss is $O(\\log n /\\epsilon)$ while there is a known lower bound of $\\Omega(\\sqrt{\\log n / \\epsilon})$. We also give a number of extensions. First, we show how to extend our techniques to both the node-weighted and the directed versions of the problem. Second, we give a separate algorithm with pure differential privacy (as opposed to approximate DP) but with worse approximation bounds. And third, we give a new algorithm for privately computing the optimal density which implies a separation between the structural problem of privately computing the densest subgraph and the numeric problem of privately computing the density of the densest subgraph.",
      "The recent years we have seen the rise of graph neural networks for prediction tasks on graphs. One of the dominant architectures is graph attention due to its ability to make predictions using weighted edge features and not only node features. In this paper we analyze, theoretically and empirically, graph attention networks and their ability of correctly labelling nodes in a classic classification task. More specifically, we study the performance of graph attention on the classic contextual stochastic block model (CSBM). In CSBM the nodes and edge features are obtained from a mixture of Gaussians and the edges from a stochastic block model. We consider a general graph attention mechanism that takes random edge features as input to determine the attention coefficients. We study two cases, in the first one, when the edge features are noisy, we prove that the majority of the attention coefficients are up to a constant uniform. This allows us to prove that graph attention with edge features is not better than simple graph convolution for achieving perfect node classification. Second, we prove that when the edge features are clean graph attention can distinguish intra- from inter-edges and this makes graph attention better than classic graph convolution.",
      "Correlation clustering is a central problem in unsupervised learning, with applications spanning community detection, duplicate detection, automated labelling and many more. In the correlation clustering problem one receives as input a set of nodes and for each node a list of co-clustering preferences, and the goal is to output a clustering that minimizes the disagreement with the specified nodes' preferences. In this paper, we introduce a simple and computationally efficient algorithm for the correlation clustering problem with provable privacy guarantees. Our approximation guarantees are stronger than those shown in prior work and are optimal up to logarithmic factors.",
      "Due to its many applications, the clustering ensemble problem has been subject of intense algorithmic study over the last two decades. The input to this problem is a set of clusterings; its goal is to output a clustering that minimizes the average distance to the input clusterings. In this paper, we propose, to the best of our knowledge, the first generative model for this problem. Our Gibbs-like model is parameterized by a center clustering, and by a scale ; the probability of a particular clustering decays exponentially with its scaled Rand distance to the center clustering. For our new model, we give polynomial-time algorithms for sampling, when the center clustering has a constant number of clusters and reconstruction, when the scale parameter is small. En route, we establish several interesting properties of our model. Our work shows that the combinatorial structure of a Gibbs-like model for clusterings is more intricate and challenging than the corresponding and well-studied (Mallows) model for permutations.",
      "We consider the classic facility location problem in fully dynamic data streams, where elements can be both inserted and deleted. In this problem, one is interested in maintaining a stable and high quality solution throughout the data stream while using only little time per update (insertion or deletion). We study the problem and provide the first algorithm that at the same time maintains a constant approximation and incurs polylogarithmic amortized recourse per update. We complement our theoretical results with an experimental analysis showing the practical efficiency of our method.",
      "Maximizing a submodular function is a fundamental task in machine learning and in this paper we study the deletion robust version of the problem under the classic matroids constraint. Here the goal is to extract a small size summary of the dataset that contains a high value independent set even after an adversary deleted some elements. We present constant-factor approximation algorithms, whose space complexity depends on the rank $k$ of the matroid and the number $d$ of deleted elements. In the centralized setting we present a $(4.597+O(\\varepsilon))$-approximation algorithm with summary size $O( \\frac{k+d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$ that is improved to a $(3.582+O(\\varepsilon))$-approximation with $O(k + \\frac{d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$ summary size when the objective is monotone. In the streaming setting we provide a $(9.435 + O(\\varepsilon))$-approximation algorithm with summary size and memory $O(k + \\frac{d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$; the approximation factor is then improved to $(5.582+O(\\varepsilon))$ in the monotone case.",
      "We study exact active learning of binary and multiclass classifiers with margin. Given an $n$-point set $X \\subset \\mathbb{R}^m$, we want to learn any unknown classifier on $X$ whose classes have finite strong convex hull margin, a new notion extending the SVM margin. In the standard active learning setting, where only label queries are allowed, learning a classifier with strong convex hull margin $\\gamma$ requires in the worst case $\\Omega\\big(1+\\frac{1}{\\gamma}\\big)^{(m-1)/2}$ queries. On the other hand, using the more powerful seed queries (a variant of equivalence queries), the target classifier could be learned in $O(m \\log n)$ queries via Littlestone's Halving algorithm; however, Halving is computationally inefficient. In this work we show that, by carefully combining the two types of queries, a binary classifier can be learned in time $\\operatorname{poly}(n+m)$ using only $O(m^2 \\log n)$ label queries and $O\\big(m \\log \\frac{m}{\\gamma}\\big)$ seed queries; the result extends to $k$-class classifiers at the price of a $k!k^2$ multiplicative overhead. Similar results hold when the input points have bounded bit complexity, or when only one class has strong convex hull margin against the rest. We complement the upper bounds by showing that in the worst case any algorithm needs $\\Omega\\big(k m \\log \\frac{1}{\\gamma}\\big)$ seed and label queries to learn a $k$-class classifier with strong convex hull margin $\\gamma$.",
      "Maximizing a monotone submodular function is a fundamental task in machine learning. In this paper, we study the deletion robust version of the problem under the classic matroids constraint. Here the goal is to extract a small size summary of the dataset that contains a high value independent set even after an adversary deleted some elements. We present constant-factor approximation algorithms, whose space complexity depends on the rank $k$ of the matroid and the number $d$ of deleted elements. In the centralized setting we present a $(3.582+O(\\varepsilon))$-approximation algorithm with summary size $O(k + \\frac{d \\log k}{\\varepsilon^2})$. In the streaming setting we provide a $(5.582+O(\\varepsilon))$-approximation algorithm with summary size and memory $O(k + \\frac{d \\log k}{\\varepsilon^2})$. We complement our theoretical results with an in-depth experimental analysis showing the effectiveness of our algorithms on real-world datasets.",
      "Designing algorithms for machine learning problems targeting beyond worst-case analysis and, in particular, analyzing the effect of side-information on the complexity of such problems is a very important line of research with many practical applications. In this paper we study the classic k-means clustering problem in the presence of noisy labels: in addition to a set of points and parameter k , we receive cluster labels of each point generated by either an adversarial or a random perturbation of the optimal solution. Our main goal is to formally study the effect of this extra information on the complexity of the k-means problem. In particular, in the context of random perturbations, we give an ef\ufb01cient algorithm that \ufb01nds a clustering of cost within a factor 1 + o (1) of the optimum even when the label of each point is perturbed with a large probability (think 99%). In contrast, we show that side-information with adversarial perturbations does not help, namely the problem remains as hard as the original k -means problem even if only a small (cid:15) fraction of the labels are perturbed. We complement this negative result by giving a simple algorithm in the case when the adversary is only allowed to perturb an (cid:15) fraction of the labels per each cluster .",
      "In the correlation clustering problem the input is a signed graph where the sign indicates whether each pair of points should be placed in the same cluster or not. The goal of the problem is to compute a clustering which minimizes the number of disagreements with such recommendation. Thanks to its many practical applications, correlation clustering is a fundamental unsupervised learning problem and has been extensively studied in many different settings. In this paper we study the problem in the classic online setting with recourse; The vertices of the graphs arrive in an online manner and the goal is to maintain an approximate clustering while minimizing the number of times each vertex changes cluster. Our main contribution is an algorithm that achieves logarithmic recourse per vertex in the worst case. We also complement this result with a tight lower bound. Finally we show experimentally that our algorithm achieves better performances than state-of-the-art algorithms on real world data.",
      "We study the private k-median and k-means clustering problem in d dimensional Euclidean space. By leveraging tree embeddings, we give an efficient and easy to implement algorithm, that is empirically competitive with state of the art non private methods. We prove that our method computes a solution with cost at most O(d3/2 log n)\u2046 OPT + O(kd2 log2 n/\u03b52), where \u03b5 is the privacy guarantee. (The dimension term, d, can be replaced with O(log k) using standard dimension reduction techniques.) Although the worst-case guarantee is worse than that of state of the art private clustering methods, the algorithm we propose is practical, runs in near-linear, \u00d5 (nkd), time and scales to tens of millions of points. We also show that our method is amenable to parallelization in large-scale distributed computing environments. In particular we show that our private algorithms can be implemented in logarithmic number of MPC rounds in the sublinear memory regime. Finally, we complement our theoretical analysis with an empirical evaluation demonstrating the algorithm's efficiency and accuracy in comparison to other privacy clustering baselines.",
      "We consider the problem of learning the hierarchical cluster structure of graphs in the seeded model, where besides the input graph the algorithm is provided with a small number of `seeds', i.e. correctly clustered data points. In particular, we ask whether one can approximate the Dasgupta cost of a graph, a popular measure of hierarchical clusterability, in sublinear time and using a small number of seeds. Our main result is an $O(\\sqrt{\\log k})$ approximation to Dasgupta cost of $G$ in $\\approx \\text{poly}(k)\\cdot n^{1/2+O(\\epsilon)}$ time using $\\approx \\text{poly}(k)\\cdot n^{O(\\epsilon)}$ seeds, effectively giving a sublinear time simulation of the algorithm of Charikar and Chatziafratis[SODA'17] on clusterable graphs. To the best of our knowledge, ours is the first result on approximating the hierarchical clustering properties of such graphs in sublinear time.",
      "TensorFlow-GNN (TF-GNN) is a scalable library for Graph Neural Networks in TensorFlow. It is designed from the bottom up to support the kinds of rich heterogeneous graph data that occurs in today's information ecosystems. In addition to enabling machine learning researchers and advanced developers, TF-GNN offers low-code solutions to empower the broader developer community in graph learning. Many production models at Google use TF-GNN, and it has been recently released as an open source project. In this paper we describe the TF-GNN data model, its Keras message passing API, and relevant capabilities such as graph sampling and distributed training.",
      "Given a graph $G$ that can be partitioned into $k$ disjoint expanders with outer conductance upper bounded by $\\epsilon\\ll 1$, can we efficiently construct a small space data structure that allows quickly classifying vertices of $G$ according to the expander (cluster) they belong to? Formally, we would like an efficient local computation algorithm that misclassifies at most an $O(\\epsilon)$ fraction of vertices in every expander. We refer to such a data structure as a \\textit{spectral clustering oracle}. Our main result is a spectral clustering oracle with query time $O^*(n^{1/2+O(\\epsilon)})$ and preprocessing time $2^{O(\\frac{1}{\\epsilon} k^4 \\log^2(k))} n^{1/2+O(\\epsilon)}$ that provides misclassification error $O(\\epsilon \\log k)$ per cluster for any $\\epsilon \\ll 1/\\log k$. More generally, query time can be reduced at the expense of increasing the preprocessing time appropriately (as long as the product is about $n^{1+O(\\epsilon)}$) -- this in particular gives a nearly linear time spectral clustering primitive. The main technical contribution is a sublinear time oracle that provides dot product access to the spectral embedding of $G$ by estimating distributions of short random walks from vertices in $G$. The distributions themselves provide a poor approximation to the spectral embedding, but we show that an appropriate linear transformation can be used to achieve high precision dot product access. We then show that dot product access to the spectral embedding is sufficient to design a clustering oracle. At a high level our approach amounts to hyperplane partitioning in the spectral embedding of $G$, but crucially operates on a nested sequence of carefully defined subspaces in the spectral embedding to achieve per cluster recovery guarantees.",
      "We investigate the problem of exact cluster recovery using oracle queries. Previous results show that clusters in Euclidean spaces that are convex and separated with a margin can be reconstructed exactly using only $O(\\log n)$ same-cluster queries, where $n$ is the number of input points. In this work, we study this problem in the more challenging non-convex setting. We introduce a structural characterization of clusters, called $(\\beta,\\gamma)$-convexity, that can be applied to any finite set of points equipped with a metric (or even a semimetric, as the triangle inequality is not needed). Using $(\\beta,\\gamma)$-convexity, we can translate natural density properties of clusters (which include, for instance, clusters that are strongly non-convex in $\\mathbb{R}^d$) into a graph-theoretic notion of convexity. By exploiting this convexity notion, we design a deterministic algorithm that recovers $(\\beta,\\gamma)$-convex clusters using $O(k^2 \\log n + k^2 (6/\\beta\\gamma)^{dens(X)})$ same-cluster queries, where $k$ is the number of clusters and $dens(X)$ is the density dimension of the semimetric. We show that an exponential dependence on the density dimension is necessary, and we also show that, if we are allowed to make $O(k^2 + k\\log n)$ additional queries to a\"cluster separation\"oracle, then we can recover clusters that have different and arbitrary scales, even when the scale of each cluster is unknown."
    ],
    "domain": [
      "Graph Algorithms",
      "Clustering",
      "Differential Privacy",
      "Active Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "3a5ce245-6a2c-4a0d-97d3-eccc9ce924a4": {
    "pk": "3a5ce245-6a2c-4a0d-97d3-eccc9ce924a4",
    "name": "Rex Ying",
    "bio": "I am a researcher dedicated to uncovering the intricate relationships among brain regions through the analysis of functional magnetic resonance imaging (fMRI) signals. My work addresses a critical gap in current methodologies, which often focus solely on pairwise connections and neglect the high-order relationships that can provide deeper insights into brain function and phenotypic predictions. \n\nTo tackle this challenge, I developed a novel approach called HYBRID, which aims to extract maximally informative and minimally redundant (MIMR) high-order relationships from fMRI data. This method employs a CONSTRUCTOR to identify hyperedge structures and a WEIGHTER to compute weights for each hyperedge, effectively navigating the exponential search space that typically complicates such analyses. By leveraging an innovative information bottleneck framework, I ensure that the relationships identified are both meaningful and efficient.\n\nMy comprehensive experiments demonstrate that HYBRID significantly outperforms state-of-the-art predictive models, achieving an average improvement of 11.2% in the quality of hyperedges. I am passionate about advancing our understanding of brain connectivity and its implications for phenotypic predictions, and I strive to contribute to the field with robust, data-driven methodologies.",
    "collaborators": [
      "Weikang Qiu",
      "Huangrui Chu",
      "Selena Wang",
      "Haolan Zuo",
      "Xiaoxiao Li",
      "Yize Zhao"
    ],
    "pub_titles": [
      "Learning High-Order Relationships of Brain Regions"
    ],
    "pub_abstracts": [
      "Discovering reliable and informative relationships among brain regions from functional magnetic resonance imaging (fMRI) signals is essential in phenotypic predictions. Most of the current methods fail to accurately characterize those interactions because they only focus on pairwise connections and overlook the high-order relationships of brain regions. We propose that these high-order relationships should be maximally informative and minimally redundant (MIMR). However, identifying such high-order relationships is challenging and under-explored due to the exponential search space and the absence of a tractable objective. In response to this gap, we propose a novel method named HYBRID which aims to extract MIMR high-order relationships from fMRI data. HYBRID employs a CONSTRUCTOR to identify hyperedge structures, and a WEIGHTER to compute a weight for each hyperedge, which avoids searching in exponential space. HYBRID achieves the MIMR objective through an innovative information bottleneck framework named multi-head drop-bottleneck with theoretical guarantees. Our comprehensive experiments demonstrate the effectiveness of our model. Our model outperforms the state-of-the-art predictive model by an average of 11.2%, regarding the quality of hyperedges measured by CPM, a standard protocol for studying brain connections."
    ],
    "domain": [
      "Neuroscience",
      "Machine Learning",
      "Functional MRI",
      "High-order Relationships"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
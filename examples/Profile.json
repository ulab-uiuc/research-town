{
  "69fbeb35-c901-4f7a-a5bd-53904be209d8": {
    "pk": "69fbeb35-c901-4f7a-a5bd-53904be209d8",
    "name": "Jiaxuan You",
    "bio": "I am a researcher dedicated to exploring the intersection of machine learning and data privacy, particularly focusing on membership inference attacks (MIAs) in diffusion models. My recent work critically evaluates the effectiveness of existing MIAs, revealing significant flaws and overly optimistic performance estimates in their evaluation. I introduced CopyMark, a novel benchmark designed specifically for pre-trained diffusion models, which emphasizes unbiased datasets and fair evaluation pipelines. \n\nThrough extensive experimentation, I have demonstrated that the current methods for MIAs are not as reliable as previously thought, especially under practical conditions. This research not only highlights the limitations of existing approaches but also aims to foster a more realistic understanding of unauthorized data usage in training models. I am passionate about advancing the field by providing tools and insights that can lead to more robust privacy-preserving techniques in machine learning. My work is available for the community on GitHub, reflecting my commitment to open science and collaboration.",
    "collaborators": [
      "Chumeng Liang"
    ],
    "pub_titles": [
      "Real-World Benchmarks Make Membership Inference Attacks Fail on Diffusion Models"
    ],
    "pub_abstracts": [
      "Membership inference attacks (MIAs) on diffusion models have emerged as potential evidence of unauthorized data usage in training pre-trained diffusion models. These attacks aim to detect the presence of specific images in training datasets of diffusion models. Our study delves into the evaluation of state-of-the-art MIAs on diffusion models and reveals critical flaws and overly optimistic performance estimates in existing MIA evaluation. We introduce CopyMark, a more realistic MIA benchmark that distinguishes itself through the support for pre-trained diffusion models, unbiased datasets, and fair evaluation pipelines. Through extensive experiments, we demonstrate that the effectiveness of current MIA methods significantly degrades under these more practical conditions. Based on our results, we alert that MIA, in its current state, is not a reliable approach for identifying unauthorized data usage in pre-trained diffusion models. To the best of our knowledge, we are the first to discover the performance overestimation of MIAs on diffusion models and present a unified benchmark for more realistic evaluation. Our code is available on GitHub: \\url{https://github.com/caradryanl/CopyMark}."
    ],
    "domain": [
      "Membership Inference Attack",
      "Diffusion Models",
      "Data Privacy",
      "Machine Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "5d008538-48f5-49b5-93eb-ab8b08c583fd": {
    "pk": "5d008538-48f5-49b5-93eb-ab8b08c583fd",
    "name": "Jure Leskovec",
    "bio": "I am a researcher deeply engaged in the intersection of artificial intelligence and biological sciences, with a focus on developing innovative methodologies to model complex systems and enhance our understanding of cellular dynamics. My recent work has explored a variety of topics, including the inference of dynamic networks from time-aggregated data, the creation of AI Virtual Cells for simulating cellular behavior, and the synthesis of high-quality tabular data through advanced generative models like TabDiff.\n\nOne of my notable contributions is the Equivariant Graph Neural Operator (EGNO), which models the intricate three-dimensional dynamics of relational systems, capturing temporal correlations in a principled manner. I have also developed the Universal Cell Embedding (UCE), a foundation model that provides a unified representation of diverse cell types, enabling significant insights into cellular organization and function.\n\nIn addition to my work in cell biology, I have ventured into the realm of drug discovery with AliDiff, a framework that aligns generative models with desired chemical properties, enhancing the design of ligand molecules for specific protein targets. My research also extends to the development of BioDiscoveryAgent, an intelligent agent that designs experiments and navigates complex biological hypotheses.\n\nThrough my work, I aim to bridge the gap between computational methods and biological applications, fostering collaborations across disciplines to drive forward our understanding of life sciences and improve health outcomes. I am committed to leveraging AI to unlock new possibilities in scientific discovery and innovation.",
    "collaborators": [
      "Yusuf Roohani",
      "Stefano Ermon",
      "Yanay Rosen",
      "Minkai Xu",
      "M. Zitnik",
      "Aviv Regev",
      "Tailin Wu",
      "Serina Chang",
      "Charlotte Bunne",
      "Ankit Gupta",
      "Xikun Zhang",
      "Marcel Roed",
      "Theo Alexandrov",
      "Mohammed AlQuraishi",
      "Patricia Brennan",
      "Daniel B. Burkhardt",
      "Andrea Califano",
      "J. Cool",
      "A. Dernburg",
      "Kirsty Ewing",
      "Emily B. Fox",
      "Matthias Haury",
      "Amy E. Herr",
      "Eric Horvitz",
      "Patrick D. Hsu",
      "Viren Jain",
      "Gregory R. Johnson",
      "Thomas Kalil",
      "David R. Kelley",
      "A. Kreshuk",
      "Tim Mitchison",
      "Stephani Otte",
      "J. Shendure",
      "N. Sofroniew",
      "Fabian Theis",
      "Christina V. Theodoris",
      "S. Upadhyayula",
      "M. Valer",
      "Bo Wang",
      "Eric Xing",
      "S. Yeung-Levy",
      "Theofanis Karaletsos",
      "Emma Lundberg",
      "Stephen R. Quake",
      "K. Azizzadenesheli",
      "Qian Huang",
      "Percy Liang",
      "Hongyu Ren",
      "Frederic Koehler",
      "Zhaonan Qu",
      "Johan Ugander",
      "S. Kelley",
      "Juntong Shi",
      "Harper Hua",
      "Hengrui Zhang",
      "Jiaqi Han",
      "Aaron Lou",
      "Jean Kossaifi",
      "Arvind Ramanathan",
      "A. Anandkumar",
      "M. Brbi\u0107",
      "Kyle Swanson",
      "Ziang Li",
      "Hanchen Wang",
      "W. Neiswanger",
      "Hongtao Zheng",
      "Jialiang Xu",
      "Michael Moor",
      "Zhiyin Lin",
      "Benjamin Yan",
      "Swapnil Bembde",
      "Qi Xiu",
      "Chi Heem Wong",
      "Yu Qin",
      "Frank Kloster",
      "Alex Luo",
      "Raj Palleti",
      "J. Magnusson",
      "Daniel Stauber",
      "Yinglin Situ",
      "Paloma Ruiz de Castroviejo Teba",
      "R. Sandberg",
      "Lei S. Qi",
      "Jian Vora",
      "Zach Steinhart",
      "Alex Marson",
      "Shana O. Kelley",
      "Siyi Gu",
      "Alexander Powers",
      "Weili Nie",
      "Tomas Geffner",
      "Karsten Kreis",
      "Arash Vahdat",
      "Kathryn J. Edin",
      "Corey D. Fields",
      "David B. Grusky",
      "Marybeth J. Mattingly",
      "Kristen Olson",
      "Charles Varner",
      "Takashi Maruyama"
    ],
    "pub_titles": [
      "Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting",
      "How to Build the Virtual Cell with Artificial Intelligence: Priorities and Opportunities",
      "TabDiff: a Multi-Modal Diffusion Model for Tabular Data Generation",
      "Equivariant Graph Neural Operator for Modeling 3D Dynamics",
      "Metric Mirages in Cell Embeddings",
      "Uncertainty Quantification for Forward and Inverse Problems of PDEs via Latent Global Evolution",
      "Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs",
      "Learning production functions for supply chains with graph neural networks",
      "PreciCE: Precision engineering of cell fates via data-driven multi-gene control of transcriptional networks",
      "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments",
      "Aligning Target-Aware Molecule Diffusion Models with Exact Energy Optimization",
      "Listening to the Voices of America",
      "Compositional Generative Inverse Design",
      "Countrywide natural experiment reveals impact of built environment on physical activity",
      "Universal Cell Embeddings: A Foundation Model for Cell Biology",
      "PRODIGY: Enabling In-context Learning Over Graphs",
      "Neural Graph Reasoning: Complex Logical Query Answering Meets Graph Databases",
      "Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems"
    ],
    "pub_abstracts": [
      "A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn's algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF's parameter estimates. When IPF fails to converge on sparse network data, we introduce a principled algorithm that guarantees IPF converges under minimal changes to the network structure. Finally, we conduct experiments with synthetic and real-world data, which demonstrate the practical value of our theoretical and algorithmic contributions.",
      "The cell is arguably the most fundamental unit of life and is central to understanding biology. Accurate modeling of cells is important for this understanding as well as for determining the root causes of disease. Recent advances in artificial intelligence (AI), combined with the ability to generate large-scale experimental data, present novel opportunities to model cells. Here we propose a vision of leveraging advances in AI to construct virtual cells, high-fidelity simulations of cells and cellular systems under different conditions that are directly learned from biological data across measurements and scales. We discuss desired capabilities of such AI Virtual Cells, including generating universal representations of biological entities across scales, and facilitating interpretable in silico experiments to predict and understand their behavior using Virtual Instruments. We further address the challenges, opportunities and requirements to realize this vision including data needs, evaluation strategies, and community standards and engagement to ensure biological accuracy and broad utility. We envision a future where AI Virtual Cells help identify new drug targets, predict cellular responses to perturbations, as well as scale hypothesis exploration. With open science collaborations across the biomedical ecosystem that includes academia, philanthropy, and the biopharma and AI industries, a comprehensive predictive understanding of cell mechanisms and interactions has come into reach.",
      "Synthesizing high-quality tabular data is an important topic in many data science tasks, ranging from dataset augmentation to privacy protection. However, developing expressive generative models for tabular data is challenging due to its inherent heterogeneous data types, complex inter-correlations, and intricate column-wise distributions. In this paper, we introduce TabDiff, a joint diffusion framework that models all multi-modal distributions of tabular data in one model. Our key innovation is the development of a joint continuous-time diffusion process for numerical and categorical data, where we propose feature-wise learnable diffusion processes to counter the high disparity of different feature distributions. TabDiff is parameterized by a transformer handling different input types, and the entire framework can be efficiently optimized in an end-to-end fashion. We further introduce a multi-modal stochastic sampler to automatically correct the accumulated decoding error during sampling, and propose classifier-free guidance for conditional missing column value imputation. Comprehensive experiments on seven datasets demonstrate that TabDiff achieves superior average performance over existing competitive baselines across all eight metrics, with up to $22.5\\%$ improvement over the state-of-the-art model on pair-wise column correlation estimations. Code is available at https://github.com/MinkaiXu/TabDiff.",
      "Modeling the complex three-dimensional (3D) dynamics of relational systems is an important problem in the natural sciences, with applications ranging from molecular simulations to particle mechanics. Machine learning methods have achieved good success by learning graph neural networks to model spatial interactions. However, these approaches do not faithfully capture temporal correlations since they only model next-step predictions. In this work, we propose Equivariant Graph Neural Operator (EGNO), a novel and principled method that directly models dynamics as trajectories instead of just next-step prediction. Different from existing methods, EGNO explicitly learns the temporal evolution of 3D dynamics where we formulate the dynamics as a function over time and learn neural operators to approximate it. To capture the temporal correlations while keeping the intrinsic SE(3)-equivariance, we develop equivariant temporal convolutions parameterized in the Fourier space and build EGNO by stacking the Fourier layers over equivariant networks. EGNO is the first operator learning framework that is capable of modeling solution dynamics functions over time while retaining 3D equivariance. Comprehensive experiments in multiple domains, including particle simulations, human motion capture, and molecular dynamics, demonstrate the significantly superior performance of EGNO against existing methods, thanks to the equivariant temporal modeling. Our code is available at https://github.com/MinkaiXu/egno.",
      "Although biological studies increasingly rely on embeddings of single cell profiles, the quality of these embeddings can be challenging to assess. Such evaluations are especially important for avoiding misleading biological interpretations, assessing the accuracy of integration methods, and establishing the zero-shot capabilities of foundational models. Here, we posit that current evaluation metrics can be highly misleading. We show this by training a three-layer perceptron, Islander , which outperforms all 11 leading embedding methods on a diverse set of cell atlases, but in fact distorts biological structures, limiting its utility for biological discovery. We then present a metric, scGraph, to flag such distortions. Our work should help learn more robust and reliable cell embeddings.",
      "Deep learning-based surrogate models have demonstrated remarkable advantages over classical solvers in terms of speed, often achieving speedups of 10 to 1000 times over traditional partial differential equation (PDE) solvers. However, a significant challenge hindering their widespread adoption in both scientific and industrial domains is the lack of understanding about their prediction uncertainties, particularly in scenarios that involve critical decision making. To address this limitation, we propose a method that integrates efficient and precise uncertainty quantification into a deep learning-based surrogate model. Our method, termed Latent Evolution of PDEs with Uncertainty Quantification (LE-PDE-UQ), endows deep learning-based surrogate models with robust and efficient uncertainty quantification capabilities for both forward and inverse problems. LE-PDE-UQ leverages latent vectors within a latent space to evolve both the system's state and its corresponding uncertainty estimation. The latent vectors are decoded to provide predictions for the system's state as well as estimates of its uncertainty. In extensive experiments, we demonstrate the accurate uncertainty quantification performance of our approach, surpassing that of strong baselines including deep ensembles, Bayesian neural network layers, and dropout. Our method excels at propagating uncertainty over extended auto-regressive rollouts, making it suitable for scenarios involving long-term predictions. Our code is available at: https://github.com/AI4Science-WestlakeU/le-pde-uq.",
      "Despite impressive advances in recent multimodal large language models (MLLMs), state-of-the-art models such as from the GPT-4 suite still struggle with knowledge-intensive tasks. To address this, we consider Reverse Image Retrieval (RIR) augmented generation, a simple yet effective strategy to augment MLLMs with web-scale reverse image search results. RIR robustly improves knowledge-intensive visual question answering (VQA) of GPT-4V by 37-43%, GPT-4 Turbo by 25-27%, and GPT-4o by 18-20% in terms of open-ended VQA evaluation metrics. To our surprise, we discover that RIR helps the model to better access its own world knowledge. Concretely, our experiments suggest that RIR augmentation helps by providing further visual and textual cues without necessarily containing the direct answer to a query. In addition, we elucidate cases in which RIR can hurt performance and conduct a human evaluation. Finally, we find that the overall advantage of using RIR makes it difficult for an agent that can choose to use RIR to perform better than an approach where RIR is the default setting.",
      "The global economy relies on the flow of goods over supply chain networks, with nodes as firms and edges as transactions between firms. While we may observe these external transactions, they are governed by unseen production functions, which determine how firms internally transform the input products they receive into output products that they sell. In this setting, it can be extremely valuable to infer these production functions, to improve supply chain visibility and to forecast future transactions more accurately. However, existing graph neural networks (GNNs) cannot capture these hidden relationships between nodes' inputs and outputs. Here, we introduce a new class of models for this setting by combining temporal GNNs with a novel inventory module, which learns production functions via attention weights and a special loss function. We evaluate our models extensively on real supply chains data and data generated from our new open-source simulator, SupplySim. Our models successfully infer production functions, outperforming the strongest baseline by 6%-50% (across datasets), and forecast future transactions, outperforming the strongest baseline by 11%-62%",
      "The directed differentiation of stem cells into specific cell types is critical for regenerative medicine and cell-based applications. However, current methods for cell fate control are inefficient, imprecise, and rely on laborious trial-and-error. To address these limitations, we present a method for data-driven multi-gene modulation of transcriptional networks. We develop bidirectional CRISPR-based tools based on dCas12a, Cas13d, and dCas9 for simultaneously activating and repressing many genes. Due to the vast combinatorial complexity of multi-gene regulation, we introduce a machine learning-based computational algorithm that uses single-cell RNA sequencing data to predict multi-gene perturbation sets for converting a starting cell type into a desired target cell type. By combining these technologies, we establish a unified workflow for data-driven cell fate engineering and demonstrate its efficacy in controlling early stem cell differentiation while suppressing alternative lineages through logic-based cell fate operations. This approach represents a significant advancement in the use of synthetic biology to engineer cell identity.",
      "Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent, using Claude 3.5 Sonnet, achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.",
      "Generating ligand molecules for specific protein targets, known as structure-based drug design, is a fundamental problem in therapeutics development and biological discovery. Recently, target-aware generative models, especially diffusion models, have shown great promise in modeling protein-ligand interactions and generating candidate drugs. However, existing models primarily focus on learning the chemical distribution of all drug candidates, which lacks effective steerability on the chemical quality of model generations. In this paper, we propose a novel and general alignment framework to align pretrained target diffusion models with preferred functional properties, named AliDiff. AliDiff shifts the target-conditioned chemical distribution towards regions with higher binding affinity and structural rationality, specified by user-defined reward functions, via the preference optimization approach. To avoid the overfitting problem in common preference optimization objectives, we further develop an improved Exact Energy Preference Optimization method to yield an exact and efficient alignment of the diffusion models, and provide the closed-form expression for the converged distribution. Empirical studies on the CrossDocked2020 benchmark show that AliDiff can generate molecules with state-of-the-art binding energies with up to -7.07 Avg. Vina Score, while maintaining strong molecular properties. Code is available at https://github.com/MinkaiXu/AliDiff.",
      ".",
      "Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method generalizes to more objects for N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task. Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm.",
      "While physical activity is critical to human health, most people do not meet recommended guidelines. More walkable built environments have the potential to increase activity across the population. However, previous studies on the built environment and physical activity have led to mixed findings, possibly due to methodological limitations such as small cohorts, few or single locations, over-reliance on self-reported measures, and cross-sectional designs. Here, we address these limitations by leveraging a large U.S. cohort of smartphone users (N=2,112,288) to evaluate within-person longitudinal behavior changes that occurred over 248,266 days of objectively-measured physical activity across 7,447 relocations among 1,609 U.S. cities. By analyzing the results of this natural experiment, which exposed individuals to differing built environments, we find that increases in walkability are associated with significant increases in physical activity after relocation (and vice versa). These changes hold across subpopulations of different genders, age, and body-mass index (BMI), and are sustained over three months after moving.The added activity observed after moving to a more walkable location is predominantly composed of moderate-to-vigorous physical activity (MVPA), which is linked to an array of associated health benefits across the life course. A simulation experiment demonstrates that substantial walkability improvements (i.e., bringing all US locations to the walkability level of Chicago or Philadelphia) may lead to 10.3% or 33 million more Americans meeting aerobic physical activity guidelines. Evidence against residential self-selection confounding is reported. Our findings provide robust evidence supporting the importance of the built environment in directly improving health-enhancing physical activity, in addition to offering potential guidance for public policy activities in this area.",
      "Developing a universal representation of cells which encompasses the tremendous molecular diversity of cell types within the human body and more generally, across species, would be transformative for cell biology. Recent work using single-cell transcriptomic approaches to create molecular definitions of cell types in the form of cell atlases has provided the necessary data for such an endeavor. Here, we present the Universal Cell Embedding (UCE) foundation model. UCE was trained on a corpus of cell atlas data from human and other species in a completely self-supervised way without any data annotations. UCE offers a unified biological latent space that can represent any cell, regardless of tissue or species. This universal cell embedding captures important biological variation despite the presence of experimental noise across diverse datasets. An important aspect of UCE\u2019s universality is that any new cell from any organism can be mapped to this embedding space with no additional data labeling, model training or fine-tuning. We applied UCE to create the Integrated Mega-scale Atlas, embedding 36 million cells, with more than 1,000 uniquely named cell types, from hundreds of experiments, dozens of tissues and eight species. We uncovered new insights about the organization of cell types and tissues within this universal cell embedding space, and leveraged it to infer function of newly discovered cell types. UCE\u2019s embedding space exhibits emergent behavior, uncovering new biology that it was never explicitly trained for, such as identifying developmental lineages and embedding data from novel species not included in the training set. Overall, by enabling a universal representation for every cell state and type, UCE provides a valuable tool for analysis, annotation and hypothesis generation as the scale and diversity of single cell datasets continues to grow.",
      "In-context learning is the ability of a pretrained model to adapt to novel and diverse downstream tasks by conditioning on prompt examples, without optimizing any parameters. While large language models have demonstrated this ability, how in-context learning could be performed over graphs is unexplored. In this paper, we develop \\textbf{Pr}etraining \\textbf{O}ver \\textbf{D}iverse \\textbf{I}n-Context \\textbf{G}raph S\\textbf{y}stems (PRODIGY), the first pretraining framework that enables in-context learning over graphs. The key idea of our framework is to formulate in-context learning over graphs with a novel \\emph{prompt graph} representation, which connects prompt examples and queries. We then propose a graph neural network architecture over the prompt graph and a corresponding family of in-context pretraining objectives. With PRODIGY, the pretrained model can directly perform novel downstream classification tasks on unseen graphs via in-context learning. We provide empirical evidence of the effectiveness of our framework by showcasing its strong in-context learning performance on tasks involving citation networks and knowledge graphs. Our approach outperforms the in-context learning accuracy of contrastive pretraining baselines with hard-coded adaptation by 18\\% on average across all setups. Moreover, it also outperforms standard finetuning with limited data by 33\\% on average with in-context learning.",
      "Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves a far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs in a latent space. The task received a significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications. Refining the CLQA task, we introduce the concept of Neural Graph Databases (NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we design a graph store, a feature store, and further embed information in a latent embedding store using an encoder. Given a query, Neural Query Engine learns how to perform query planning and execution in order to efficiently retrieve the correct results by interacting with the Neural Graph Storage. Compared with traditional graph DBs, NGDBs allow for a flexible and unified modeling of features in diverse modalities using the embedding store. Moreover, when the graph is incomplete, they can provide robust retrieval of answers which a normal graph DB cannot recover. Finally, we point out promising directions, unsolved problems and applications of NGDB for future research.",
      "Advances in artificial intelligence (AI) are fueling a new paradigm of discoveries in natural sciences. Today, AI has started to advance natural sciences by improving, accelerating, and enabling our understanding of natural phenomena at a wide range of spatial and temporal scales, giving rise to a new area of research known as AI for science (AI4Science). Being an emerging research paradigm, AI4Science is unique in that it is an enormous and highly interdisciplinary area. Thus, a unified and technical treatment of this field is needed yet challenging. This work aims to provide a technically thorough account of a subarea of AI4Science; namely, AI for quantum, atomistic, and continuum systems. These areas aim at understanding the physical world from the subatomic (wavefunctions and electron density), atomic (molecules, proteins, materials, and interactions), to macro (fluids, climate, and subsurface) scales and form an important subarea of AI4Science. A unique advantage of focusing on these areas is that they largely share a common set of challenges, thereby allowing a unified and foundational treatment. A key common challenge is how to capture physics first principles, especially symmetries, in natural systems by deep learning methods. We provide an in-depth yet intuitive account of techniques to achieve equivariance to symmetry transformations. We also discuss other common technical challenges, including explainability, out-of-distribution generalization, knowledge transfer with foundation and large language models, and uncertainty quantification. To facilitate learning and education, we provide categorized lists of resources that we found to be useful. We strive to be thorough and unified and hope this initial effort may trigger more community interests and efforts to further advance AI4Science."
    ],
    "domain": [
      "Graph Neural Network",
      "Machine Learning",
      "Bioinformatics",
      "AI for Science"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "7b7c87e1-8add-48f8-a1c8-0f891099f6a2": {
    "pk": "7b7c87e1-8add-48f8-a1c8-0f891099f6a2",
    "name": "Silvio Lattanzi",
    "bio": "I am a researcher specializing in optimization, particularly in the realm of submodular functions and their applications in data mining and machine learning. My recent work focuses on maximizing monotone submodular functions under cardinality constraints in dynamic environments, where elements arrive in a streaming fashion. I have developed algorithms that balance the trade-offs between maintaining a stable solution and achieving a constant approximation to the optimal solution. \n\nIn my studies, I have explored online submodular maximization, investigating how the need for stability affects approximation ratios. I established tight information-theoretic bounds for both general monotone submodular functions and coverage functions, revealing significant insights into the performance of deterministic versus randomized algorithms. My work not only contributes theoretical advancements but also includes experimental analyses that demonstrate the effectiveness of my algorithms in real-world scenarios. I am passionate about bridging the gap between theory and practice, and I strive to develop solutions that are both efficient and applicable in dynamic settings.",
    "collaborators": [
      "Paul Dutting",
      "Federico Fusco",
      "A. Norouzi-Fard",
      "Morteza Zadimoghaddam",
      "Ola Svensson"
    ],
    "pub_titles": [
      "Consistent Submodular Maximization",
      "The Cost of Consistency: Submodular Maximization with Constant Recourse"
    ],
    "pub_abstracts": [
      "Maximizing monotone submodular functions under cardinality constraints is a classic optimization task with several applications in data mining and machine learning. In this paper we study this problem in a dynamic environment with consistency constraints: elements arrive in a streaming fashion and the goal is maintaining a constant approximation to the optimal solution while having a stable solution (i.e., the number of changes between two consecutive solutions is bounded). We provide algorithms in this setting with different trade-offs between consistency and approximation quality. We also complement our theoretical results with an experimental analysis showing the effectiveness of our algorithms in real-world instances.",
      "In this work, we study online submodular maximization, and how the requirement of maintaining a stable solution impacts the approximation. In particular, we seek bounds on the best-possible approximation ratio that is attainable when the algorithm is allowed to make at most a constant number of updates per step. We show a tight information-theoretic bound of $\\tfrac{2}{3}$ for general monotone submodular functions, and an improved (also tight) bound of $\\tfrac{3}{4}$ for coverage functions. Since both these bounds are attained by non poly-time algorithms, we also give a poly-time randomized algorithm that achieves a $0.51$-approximation. Combined with an information-theoretic hardness of $\\tfrac{1}{2}$ for deterministic algorithms from prior work, our work thus shows a separation between deterministic and randomized algorithms, both information theoretically and for poly-time algorithms."
    ],
    "domain": [
      "Optimization",
      "Submodular Functions",
      "Online Algorithms",
      "Streaming Algorithms"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "2048c6ee-7c7d-4ffa-a886-26608988d889": {
    "pk": "2048c6ee-7c7d-4ffa-a886-26608988d889",
    "name": "Rex Ying",
    "bio": "I am a researcher specializing in hyperbolic neural networks and their applications in modeling complex hierarchical data structures. My recent work has focused on developing innovative architectures that leverage hyperbolic geometry to enhance the performance of deep learning models. For instance, I introduced LResNet, a Lorentzian residual neural network that integrates residual connections while maintaining stability and efficiency. This work has shown significant improvements in both graph and vision tasks compared to existing methods.\n\nI also pioneered Hypformer, a hyperbolic Transformer that addresses the challenges of adapting Transformers to hyperbolic space, enabling efficient processing of large-scale data. My research extends to recommendation systems, where I developed HARec, a framework that balances content exploration and exploitation through hyperbolic representation learning.\n\nIn addition to theoretical advancements, I have contributed to practical applications by creating the Dynamic Text-attributed Graph Benchmark (DTGB), which facilitates research on dynamic text-attributed graphs. This benchmark addresses the need for standardized evaluation procedures in this emerging field.\n\nMy work emphasizes the importance of understanding the underlying structures in data, leading to the development of algorithms like the universal hyperbolic cone (UHCone) that capture implicit hierarchical relationships without requiring prior information. Through these contributions, I aim to push the boundaries of what is possible in machine learning and data representation, fostering advancements across various domains.",
    "collaborators": [
      "Menglin Yang",
      "Irwin King",
      "Delvin Ce Zhang",
      "Jiahong Liu",
      "Harshit Verma",
      "Aosong Feng",
      "Neil He",
      "Qiyao Ma",
      "Mingxuan Ju",
      "Tong Zhao",
      "Neil Shah",
      "Bo Xiong",
      "Jihong Liu",
      "Jiasheng Zhang",
      "Jialin Chen",
      "Shuang Liang",
      "Jie Shao",
      "Hady W. Lauw"
    ],
    "pub_titles": [
      "Lorentzian Residual Neural Networks",
      "Hypformer: Exploring Efficient Hyperbolic Transformer Fully in Hyperbolic Space",
      "HARec: Hyperbolic Graph-LLM Alignment for Exploration and Exploitation in Recommender Systems",
      "Hyperbolic Fine-tuning for Large Language Models",
      "DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs",
      "Text-Attributed Graph Representation Learning: Methods, Applications, and Challenges",
      "UHCone: Universal Hyperbolic Cone For Implicit Hierarchical Learning"
    ],
    "pub_abstracts": [
      "Hyperbolic neural networks have emerged as a powerful tool for modeling hierarchical data structures prevalent in real-world datasets. Notably, residual connections, which facilitate the direct flow of information across layers, have been instrumental in the success of deep neural networks. However, current methods for constructing hyperbolic residual networks suffer from limitations such as increased model complexity, numerical instability, and errors due to multiple mappings to and from the tangent space. To address these limitations, we introduce LResNet, a novel Lorentzian residual neural network based on the weighted Lorentzian centroid in the Lorentz model of hyperbolic geometry. Our method enables the efficient integration of residual connections in Lorentz hyperbolic neural networks while preserving their hierarchical representation capabilities. We demonstrate that our method can theoretically derive previous methods while offering improved stability, efficiency, and effectiveness. Extensive experiments on both graph and vision tasks showcase the superior performance and robustness of our method compared to state-of-the-art Euclidean and hyperbolic alternatives. Our findings highlight the potential of \\method for building more expressive neural networks in hyperbolic embedding space as a generally applicable method to multiple architectures, including CNNs, GNNs, and graph Transformers.",
      "Hyperbolic geometry have shown significant potential in modeling complex structured data, particularly those with underlying tree-like and hierarchical structures. Despite the impressive performance of various hyperbolic neural networks across numerous domains, research on adapting the Transformer to hyperbolic space remains limited. Previous attempts have mainly focused on modifying self-attention modules in the Transformer. However, these efforts have fallen short of developing a complete hyperbolic Transformer. This stems primarily from: (i) the absence of well-defined modules in hyperbolic space, including linear transformation layers, LayerNorm layers, activation functions, dropout operations, etc. (ii) the quadratic time complexity of the existing hyperbolic self-attention module w.r.t the number of input tokens, which hinders its scalability. To address these challenges, we propose, Hypformer, a novel hyperbolic Transformer based on the Lorentz model of hyperbolic geometry. In Hypformer, we introduce two foundational blocks that define the essential modules of the Transformer in hyperbolic space. Furthermore, we develop a linear self-attention mechanism in hyperbolic space, enabling hyperbolic Transformer to process billion-scale graph data and long-sequence inputs for the first time. Our experimental results confirm the effectiveness and efficiency of Hypformer across various datasets, demonstrating its potential as an effective and scalable solution for large-scale data representation and large models.",
      "Modern recommendation systems often create information cocoons, limiting users' exposure to diverse content. To enhance user experience, a crucial challenge is developing systems that can balance content exploration and exploitation, allowing users to adjust their recommendation preferences. Intuitively, this balance can be achieved through a tree-structured representation, where depth search facilitates exploitation and breadth search enables exploration. However, current works face two challenges to achieve this target: (1) Euclidean methods fail to fully capture hierarchical structures and lack flexibility in balancing exploration-exploitation, while (2) hyperbolic approaches, despite better hierarchical modeling, suffer from insufficient semantic alignment due to their reliance on Euclidean text encoders. To address these challenges, we propose HARec, a hyperbolic representation learning framework that jointly aligns user-item collaborative information with textual descriptions in hyperbolic space. Our framework introduces two key technique novelty: (1) a hierarchical-aware graph-llm alignment mechanism that enables better hierarchical representation, and (2) a hyperbolic hierarchical tree structure that facilitates user-adjustable exploration-exploitation trade-offs. Extensive experiments demonstrate that HARec consistently outperforms both Euclidean and hyperbolic baselines, achieving up to 5.49% improvement in utility metrics and 11.39% increase in diversity metrics.",
      "Large language models (LLMs) have demonstrated remarkable performance on various tasks. However, it remains an open question whether the default Euclidean space is the most suitable choice for embedding tokens in LLMs. In this study, we first investigate the non-Euclidean characteristics of LLMs. Our findings reveal that token frequency follows a power-law distribution, with high-frequency tokens clustering near the origin and low-frequency tokens positioned farther away. Additionally, token embeddings exhibit a high degree of hyperbolicity, indicating a latent tree-like structure in the embedding space. Building on the observation, we propose to efficiently fine-tune LLMs in hyperbolic space to better exploit the underlying complex structures. However, we found that this fine-tuning in hyperbolic space cannot be achieved with naive application of exponential and logarithmic maps, when the embedding and weight matrices both reside in Euclidean space. To address this technique issue, we introduce a new method called hyperbolic low-rank efficient fine-tuning, HypLoRA, that performs low-rank adaptation directly on the hyperbolic manifold, avoiding the cancellation effect caused by the exponential and logarithmic maps, thus preserving the hyperbolic modeling capabilities. Through extensive experiments, we demonstrate that HypLoRA significantly enhances the performance of LLMs on reasoning tasks, particularly for complex reasoning problems. In particular, HypLoRA improves the performance in the complex AQuA dataset by up to 13.0%, showcasing its effectiveness in handling complex reasoning challenges",
      "Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world scenarios, where each node and edge are associated with text descriptions, and both the graph structure and text descriptions evolve over time. Despite their broad applicability, there is a notable scarcity of benchmark datasets tailored to DyTAGs, which hinders the potential advancement in many research fields. To address this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB), a collection of large-scale, time-evolving graphs from diverse domains, with nodes and edges enriched by dynamically changing text attributes and categories. To facilitate the use of DTGB, we design standardized evaluation procedures based on four real-world use cases: future link prediction, destination node retrieval, edge classification, and textual relation generation. These tasks require models to understand both dynamic graph structures and natural language, highlighting the unique challenges posed by DyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB, evaluating 7 popular dynamic graph learning algorithms and their variants of adapting to text attributes with LLM embeddings, along with 6 powerful large language models (LLMs). Our results show the limitations of existing models in handling DyTAGs. Our analysis also demonstrates the utility of DTGB in investigating the incorporation of structural and textual dynamics. The proposed DTGB fosters research on DyTAGs and their broad applications. It offers a comprehensive benchmark for evaluating and advancing models to handle the interplay between dynamic graph structures and natural language. The dataset and source code are available at https://github.com/zjs123/DTGB.",
      "Text documents are usually connected in a graph structure, resulting in an important class of data named text-attributed graph, e.g., paper citation graph and Web page hyperlink graph. On the one hand, Graph Neural Networks (GNNs) consider text in each document as general vertex attribute and do not specifically deal with text data. On the other hand, Pre-trained Language Models (PLMs) and Topic Models (TMs) learn effective document embeddings. However, most models focus on text content in each single document only, ignoring link adjacency across documents. The above two challenges motivate the development of text-attributed graph representation learning, combining GNNs with PLMs and TMs into a unified model and learning document embeddings preserving both modalities, which fulfill applications, e.g., text classification, citation recommendation, question answering, etc. In this lecture-style tutorial, we will provide a systematic review of text-attributed graph, including its formal definition, recent methods, diverse applications, and challenges. Specifically, i) we will formally define text-attributed graph and briefly review GNNs, PLMs, and TMs, which are the fundamentals of some existing methods. ii) We will then revisit the technical details of text-attributed graph models, which are generally split into two categories, PLM-based and TM-based. iii) Besides, we will show diverse applications built on text-attributed graph. iv) Finally, we will discuss some challenges of existing models and propose solutions for future research.",
      "Hierarchical structures play a vital role in numerous fields, from linguistics, biology, and network science to computer vision, as they represent asymmetric dependencies that are crucial for acquiring high-quality representations and inductive bias. The hyperbolic entailment cone is an effective geometric approach for preserving these relationships by optimizing child nodes to reside within their parent\u2019s hyperbolic entailment cone. However, this method necessitates prior information on superior-subordinate hierarchical relationships, which significantly restricts its generality in most real-world data where such prior is implicit and unknown. To address this limitation, we pro-pose the universal hyperbolic cone (UHCone), an effective algorithm designed to capture implicit hierarchical structures in data, making it suitable for a wide range of real-world scenarios. Our approach utilizes the hyperbolic embedding to infer hierarchical relationships first and then reinforce them with cone constraints. This method eliminates the need for prior information on superior-subordinate hierarchies, enabling broader application scenarios. We evaluated the UHCone al-gorithm on various applications and consistently observed an improvement over baseline methods and the largest improvement up to 4.71%, demonstrating its effectiveness and versatility in capturing implicit hierarchical relationships."
    ],
    "domain": [
      "Hyperbolic Geometry",
      "Graph Neural Network",
      "Representation Learning",
      "Natural Language Processing"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
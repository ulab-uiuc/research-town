{"paper_key": "ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively reduce emergency department (ED) crowding and length of stay (LOS) by optimizing laboratory test recommendations using an artificial intelligence diagnostic assistant?\n\n---\n\n**[Question 2] - Why is it interesting and important?**  \nSolving the problem of ED crowding and LOS is crucial for improving patient outcomes, reducing morbidity and mortality, and enhancing the overall efficiency of healthcare systems. By developing an AI-driven diagnostic assistant, we can streamline the laboratory testing process, minimize unnecessary tests, and ensure timely interventions for high-risk patients. This research could lead to significant advancements in emergency medicine, influencing future studies on resource allocation, patient management, and the integration of AI in clinical settings, ultimately improving the quality of care provided in EDs.\n\n---\n\n**[Question 3] - Why is it hard?**  \nAddressing ED crowding and optimizing laboratory testing is complex due to the variability in patient presentations, the need for real-time decision-making, and the integration of diverse data sources. Naive approaches may fail because they do not account for the dynamic nature of patient conditions or the interdependencies between tests and outcomes. Technical challenges include developing accurate predictive models that can handle high-dimensional data and ensuring that recommendations are clinically relevant and actionable. Additionally, practical obstacles involve clinician acceptance and the integration of AI systems into existing workflows.\n\n---\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on isolated aspects of ED efficiency without a comprehensive approach to laboratory testing recommendations. Limitations include a lack of robust datasets that reflect real-world ED practices and insufficient collaboration between AI researchers and clinical practitioners. Barriers such as the complexity of patient data, the need for real-time processing, and the challenge of creating user-friendly interfaces have hindered progress. Our approach differs by utilizing a curated benchmark dataset (MIMIC-ED-Assist) and a personalized AI model (ED-Copilot) that leverages historical patient data to make informed recommendations, addressing both the technical and practical gaps in prior work.\n\n---\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves developing the ED-Copilot system, which utilizes a bio-medical pre-trained language model (BioGPT) fine-tuned on patient data to suggest laboratory test groups. We will use the MIMIC-ED-Assist dataset, which includes critical outcomes and ED LOS as prediction targets. The performance will be evaluated based on the", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question this proposal aims to address is: How can a hybrid framework that integrates Position-aware Graph Neural Networks (P-GNNs) with large language models (LLMs) be developed to effectively analyze and interpret both structured clinical data and unstructured clinical narratives in order to enhance predictive capabilities for patient outcomes while ensuring ethical decision-making and transparency?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem holds significant implications for the research community, particularly in the fields of healthcare informatics and personalized medicine. By developing a framework that combines P-GNNs and LLMs, we can bridge the gap between structured and unstructured data, leading to a more comprehensive understanding of patient health. This holistic approach can potentially transform predictive analytics in healthcare, advancing knowledge on the interplay between clinical data and patient narratives. Furthermore, the integration of causal inference techniques will enhance the ethical dimension of decision-making processes, ensuring that insights derived from data are not only accurate but also responsible. Such advancements could lead to improved patient outcomes, more efficient clinical workflows, and the creation of tailored treatment plans that prioritize patient safety.\n\n[Question 3]: Why is it hard?  \nAddressing this problem presents several challenges and complexities. Firstly, integrating P-GNNs with LLMs requires sophisticated alignment of data modalities; structured data often lacks the contextual richness present in unstructured narratives, making naive integration approaches likely to overlook critical information. Additionally, the dynamic relationships captured by P-GNNs can be challenging to represent in a way that LLMs can understand, necessitating innovative methodologies to create contextually rich node embeddings. The technical obstacles include the need for substantial computational resources to process vast amounts of clinical data in real-time, as well as the theoretical challenge of ensuring that causal inference methods are accurately applied to avoid biased outcomes. Furthermore, ensuring interpretability and transparency in the resulting predictions adds another layer of complexity, as it requires robust frameworks to elucidate the decision-making processes of the integrated model.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research often focused either on structured clinical data or unstructured narratives, leading to a fragmented understanding of patient health. Many existing solutions have limitations in their ability to combine these data types effectively, primarily due to a lack of interdisciplinary approaches that leverage both advanced machine learning techniques and healthcare expertise. Barriers such as insufficient datasets that encompass both structured and unstructured data, as well as the complexity of developing models that can interpret these data types cohesively, have hindered progress. This proposal distinguishes itself by specifically targeting the integration of P-GNNs and LLMs within a unified framework, utilizing causal inference techniques to enhance both predictive accuracy and ethical decision-making, which has not been comprehensively addressed in prior work.\n\n[Question 5]: What are the key components of my approach and results?  \nThe proposed methodology involves developing a hybrid framework that combines P-GNNs and LLMs through a multi-step process. Initially, we will curate a comprehensive dataset that includes both structured clinical data (e.g., electronic health records) and unstructured clinical narratives (e.g., clinical notes). The embedding generation will involve training P-GNNs to capture the dynamic relationships within the structured data while simultaneously fine-tuning LLMs on the unstructured narratives to enhance contextual understanding. Metrics for evaluation will include predictive accuracy for patient outcomes, interpretability scores, and transparency measures to assess ethical decision-making. The expected outcomes include the generation of contextually rich node embeddings that improve predictive capabilities and provide interpretable insights into patient care, ultimately facilitating personalized medicine applications that prioritize patient safety and clinical efficiency.", "referenced_intros": [" \n\n1 Introduction\n\nWeak learners refer to classifiers that are able to attain better performance than random chance, by some given margin, on any specified distribution over training data. One of the early breakthroughs in machine learning established that this weak learning was sufficient for arbitrarily strong classification, via an ensembling procedure\u00a0(Schapire, 1990). This approach in turn led to the development of boosting algorithms\u00a0(Freund and Schapire, 1997), a class of approaches that continue to perform extremely well, particularly on tabular datasets that lack the input space\nregularity of vision or language tasks.\n\n\nIn a seemingly separate thread of research, large language models (LLMs) based on transformers\u00a0(Vaswani et\u00a0al., 2017) in recent years have come to dominate many natural language domains. These models are often finetuned on the data of new downstream tasks (Devlin et\u00a0al., 2018; Liu et\u00a0al., 2019), but in recent years have also been shown to exhibit strong performance as zero-shot or few-shot learning solely via prompting the model\u00a0(Brown et\u00a0al., 2020) with a piece of context string.\n\n\nIn this paper, we align these two threads of research and ask a simple question: can LLMs also serve as weak learners in a boosting framework, specifically on tabular data (where boosting methods are most commonly applied)? We answer this question largely in the affirmative. Specifically, we show that by appropriately converting tabular data to text form, and asking LLMs to summarize a carefully chosen set of examples from the data, we produce a summary of the examples that can serve as a template (i.e., a prompt) for a tabular data classifier, and one which typically achieves this weak learning aim. This enables us to correspondingly integrate this collection of LLM-generated weak learners into a boosting framework.\n\n\nWe show that the resulting approach performs well in many settings, easily outperforming zero-shot and few-shot classification, as well as \u201csingle-shot\u201d summaries generated by the LLM. This is all done without any retraining or finetuning of the LLM itself, but rather only via prompting. Furthermore, on certain domains (particularly those with very few examples, where leveraging the prior knowledge built into LLMs would be of particular importance), we show that the approach can even outperform traditional tree-based boosting and LLM-based finetuning methods and its performance would likely improve as LLMs capabilities improve. Overall, we believe this work highlights the potential of incorporating LLMs as sub-routines of a larger machine learning system.\n\n \n\n2 Related Works\n\nDeep Learning for Tabular Data.\n\nTabular data refers to a generic data format that represents data as a collection of discrete or continuous attributes\u00a0(Borisov et\u00a0al., 2021). Due to their flexibility, tabular data are ubiquitous in many ML settings. However, such flexibility comes with a cost \u2013 they lack the inherent structure found in images or text, which makes applying deep learning to them challenging. Furthermore, they are often domain-specific and may have a relatively small number of data points. As a result, traditional deep learning methods, which thrive on large datasets and high-dimensional data, have seen limited success when applied to tabular data \u00a0(Gorishniy et\u00a0al., 2021; Shwartz-Ziv and Armon, 2022).\n\n\nRecently, however, there has been increasing interest in applying deep learning to", " Introduction\nLanguage is at the heart of health and medicine, underpinning interactions between people and care providers.\nProgress in Large Language Models (LLMs) has enabled the exploration of medical-domain capabilities in\narti\ufb01cial intelligence (AI) systems that can understand and communicate using language, promising richer\nhuman-AI interaction and collaboration. In particular, these models have demonstrated impressive capabilities\non multiple-choice research benchmarks [1\u20133].\nIn our prior work on Med-PaLM, we demonstrated the importance of a comprehensive benchmark for medical\nquestion-answering, human evaluation of model answers, and alignment strategies in the medical domain [1].\nWe introduced MultiMedQA, a diverse benchmark for medical question-answering spanning medical exams,\nconsumer health, and medical research. We proposed a human evaluation rubric enabling physicians and\nlay-people to perform detailed assessment of model answers. Our initial model, Flan-PaLM, was the \ufb01rst to\n\u0003Equal contributions. yEqual leadership.\nzCorresponding authors: {karansinghal, taotu, shekazizi, alankarthi, natviv}@google.comarXiv:2305.09617v1  [cs.CL]  16 May 2023Dec 20 Sep 21 Mar 22 Oct 22 Dec 22 Dec 22 Dec 22 Mar 2330405060708090MedQA (USMLE-Style) Accuracy (%)\nGPT-Neo\n33.3PubMedBERT\n38.1BioLinkBERT\n45.1DRAGON\n47.5BioMedLM\n50.3GPT 3.5\n60.2Med-PaLM\n67.2Med-PaLM 2\n86.5\n0 20 40 60 80 100Better reflects consensus\nBetter reading comprehension\nBetter knowledge recall\nBetter reasoningHigh Quality Answer Traits\n0 20 40 60 80 100\n% ResponsesMore inaccurate/irrelevant information\nOmits more information\nMore evidence of demographic bias\nGreater extent of harm\nGreater likelihood of harmPotential Answer Risks\nMed-PaLM 2 Tie Physician Figure 1jMed-PaLM 2 performance on MultiMedQA Left: Med-PaLM 2 achieved an accuracy of 86.5% on USMLE-style\nquestions in the MedQA dataset. Right: In a pairwise ranking study on 1066 consumer medical questions, Med-PaLM 2 answers\nwere preferred over physician answers by a panel of physicians across eight of nine axes in our evaluation framework.\nexceed the commonly quoted passmark on the MedQA dataset comprising questions in the style of the US\nMedical Licensing Exam (USMLE). However, human evaluation revealed that further work was needed to\nensure the AI output, including long-form answers to open-ended questions, are safe and aligned with human\nvalues and expectations in this safety-critical domain (a process generally referred to as \"alignment\"). To\nbridge this, we leveraged instruction prompt-tuning to develop Med-PaLM, resulting in substantially improved\nphysician evaluations over Flan-PaLM. However, there remained key shortfalls in the quality of model answers\ncompared to physicians. Similarly, although Med-PaLM achieved state-of-the-art on every multiple-choice\nbenchmark in MultiMedQA, these scores left room for improvement.\nHere, we bridge these gaps and further advance LLM capabilities in medicine with Med-PaLM 2. We developed\nthis model using a combination of an improved base LLM (PaLM 2 [4]), medical domain-speci\ufb01c \ufb01netuning\nand a novel prompting strategy that enabled improved medical reasoning. Med-PaLM 2 improves upon\nMed-PaLM by over 19% on MedQA as depicted in Figure 1 (left). The model also approached or exceeded\nstate-of-the-art performance on MedMCQA, PubMedQA, and MMLU clinical topics datasets.\nWhile these benchmarks are a useful measure of the knowledge encoded in LLMs, they do not capture\nthe model\u2019s ability to generate factual, safe responses to questions that require nuanced answers, typical\nin real-world medical question-answering. We study this by applying our previously published rubric for\nevaluation by physicians and lay-people [1]. Further, we introduce two additional human evaluations: \ufb01rst,\na pairwise ranking evaluation of model and physician answers to consumer medical questions along nine\nclinically relevant axes; second, a physician assessment of model responses on two newly introduced adversarial\ntesting datasets designed to probe the", " Introduction\nOver the past several years, large transformer models have\nestablished themselves as the premier methodology for gen-\nerative tasks in natural language processing (Brown et al.,\n2020; Sanh et al., 2021; Chowdhery et al., 2022). Beyond\nNLP, transformers have also made big splashes as genera-\ntive models in areas as diverse as text-to-image synthesis\n(Ramesh et al., 2022; Crowson et al., 2022; Rombach et al.,\n*Equal contribution1EleutherAI2Booz Allen Hamilton,\nMcLean, USA3Yale University, New Haven, USA4University of\nCambridge, UK5Indraprastha Institute of Information Technology\nDelhi, India6Stability AI7Datasaur.ai, USA8Institute for Logic,\nLanguage and Computation, University of Amsterdam, Nether-\nlands. Correspondence to: Stella Biderman <stella@eleuther.ai >,\nHailey Schoelkopf <hailey@eleuther.ai >.\nProceedings of the 40thInternational Conference on Machine\nLearning , Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright\n2023 by the author(s).2022), protein modeling (Jumper et al., 2021; Ahdritz et al.,\n2022), and computer programming (Chen et al., 2021; Xu\net al., 2022; Fried et al., 2022). Despite these successes,\nvery little is known about how and why these models are so\nsuccessful.\nCritical to understanding the functioning of transformers\nis better understanding how these models behave along\ntwo axes: training and scaling. It is well established that\nthere are regular and predictable patterns in the behavior of\ntrained language models as they scale (Kaplan et al., 2020;\nHenighan et al., 2020; Hernandez et al., 2021; Mikami et al.,\n2021; Pu et al., 2021; Sharma & Kaplan, 2020; Ghorbani\net al., 2021), but prior work connecting these \u201cScaling Laws\u201d\nto the learning dynamics of language models is minimal.\nOne of the driving reasons for this gap in research is a lack\nof access to appropriate model suites to test theories: al-\nthough there are more publicly available LLMs than ever,\nthey do not meet common requirements for researchers, as\ndiscussed in Section 2 of this paper. Of the research along\nthese lines that does exist (McGrath et al., 2021; Tirumala\net al., 2022; Xia et al., 2022), it is overwhelmingly done on\nnon-public models or model checkpoints, further emphasiz-\ning the importance of having publicly available model suites\nfor scientific research.\nIn this paper we introduce Pythia , a suite of decoder-only\nautoregressive language models ranging from 70M to 12B\nparameters designed specifically to facilitate such scientific\nresearch. The Pythia suite is the only publicly released suite\nof LLMs that satisfies three key properties:\n1.Models span several orders of magnitude of model\nscale.\n2.All models were trained on the same data in the same\norder.\n3.The data and intermediate checkpoints are publicly\navailable for study.\nWe train 8 model sizes each on both the Pile (Gao et al.,\n2020; Biderman et al., 2022) and the Pile after deduplication,\nproviding 2 copies of the suite which can be compared.\n1arXiv:2304.01373v2  [cs.CL]  31 May 2023Pythia: A Suite for Analyzing Large Language Models\nModel Size Non-Embedding Params Layers Model Dim Heads Learning Rate Equivalent Models\n70 M 18,915,328 6 512 8 10.0\u00d710\u22124\u2014\n160 M 85,056,000 12 768 12 6.0\u00d710\u22124GPT-Neo 125M, OPT-125M\n410 M 302,311,424 24 1024 16 3.0\u00d710\u22124OPT-350M\n1.0 B 805,736,448 16 2048 8 3.0\u00d710\u22124\u2014\n1.4 B 1,208,602,624 24 2048 16 2.0\u00d710\u22124GPT-Neo 1.3B, OPT-1.3B\n2.8 B 2,517,652,480 32 2560 32 1.6\u00d710\u22124GPT-Neo 2.7B, OPT-2.7B\n6.9 B 6,444,163,072 32 4096 32 1.2\u00d710\u22124OPT-6.7B\n12 B 11,327,027,200 36 5120 40 1.2\u00d710\u22124\u2014\nTable 1. Models in the Pythia suite and select hyperparameters. For a full list of hyper-parameters, see Appendix G.4 we provide plots of benchmarks over training.\nFull evaluation data, as well as evaluations on a wider", " Introduction\nLarge Languages Models (LLMs) trained on mas-\nsive corpora of texts have shown their ability to per-\nform new tasks from textual instructions or from a\nfew examples (Brown et al., 2020). These few-shot\nproperties \ufb01rst appeared when scaling models to a\nsuf\ufb01cient size (Kaplan et al., 2020), resulting in a\nline of work that focuses on further scaling these\nmodels (Chowdhery et al., 2022; Rae et al., 2021).\nThese efforts are based on the assumption that\nmore parameters will lead to better performance.\nHowever, recent work from Hoffmann et al. (2022)\nshows that, for a given compute budget, the best\nperformances are not achieved by the largest mod-\nels, but by smaller models trained on more data.\nThe objective of the scaling laws from Hoff-\nmann et al. (2022) is to determine how to best\nscale the dataset and model sizes for a particular\ntraining compute budget. However, this objective\ndisregards the inference budget, which becomes\ncritical when serving a language model at scale.\nIn this context, given a target level of performance,\nthe preferred model is not the fastest to train but the\nfastest at inference, and although it may be cheaper\nto train a large model to reach a certain level of\n\u0003Equal contribution. Correspondence: {htouvron,\nthibautlav,gizacard,egrave,glample}@meta.com\n1https://github.com/facebookresearch/llamaperformance, a smaller one trained longer will\nultimately be cheaper at inference. For instance,\nalthough Hoffmann et al. (2022) recommends\ntraining a 10B model on 200B tokens, we \ufb01nd\nthat the performance of a 7B model continues to\nimprove even after 1T tokens.\nThe focus of this work is to train a series of\nlanguage models that achieve the best possible per-\nformance at various inference budgets, by training\non more tokens than what is typically used. The\nresulting models, called LLaMA , ranges from 7B\nto 65B parameters with competitive performance\ncompared to the best existing LLMs. For instance,\nLLaMA-13B outperforms GPT-3 on most bench-\nmarks, despite being 10 \u0002smaller. We believe that\nthis model will help democratize the access and\nstudy of LLMs, since it can be run on a single GPU.\nAt the higher-end of the scale, our 65B-parameter\nmodel is also competitive with the best large lan-\nguage models such as Chinchilla or PaLM-540B.\nUnlike Chinchilla, PaLM, or GPT-3, we only\nuse publicly available data, making our work com-\npatible with open-sourcing, while most existing\nmodels rely on data which is either not publicly\navailable or undocumented (e.g. \u201cBooks \u2013 2TB\u201d or\n\u201cSocial media conversations\u201d). There exist some\nexceptions, notably OPT (Zhang et al., 2022),\nGPT-NeoX (Black et al., 2022), BLOOM (Scao\net al., 2022) and GLM (Zeng et al., 2022), but none\nthat are competitive with PaLM-62B or Chinchilla.\nIn the rest of this paper, we present an overview\nof the modi\ufb01cations we made to the transformer\narchitecture (Vaswani et al., 2017), as well as our\ntraining method. We then report the performance of\nour models and compare with others LLMs on a set\nof standard benchmarks. Finally, we expose some\nof the biases and toxicity encoded in our models,\nusing some of the most recent benchmarks from\nthe responsible AI community.arXiv:2302.13971v1  [cs.CL]  27 Feb 20232 Approach\nOur training approach is similar to the methods\ndescribed in previous work (Brown et al., 2020;\nChowdhery et al., 2022), and is inspired by the\nChinchilla scaling laws (Hoffmann et al., 2022).\nWe train large transformers on a large quantity of\ntextual data using a standard optimizer.\n2.1 Pre-training Data\nOur training dataset is a mixture of several sources,\nreported", " introduction and overview of the literature. Clinica Chimica Acta , 427:111\u2013117, 2014.\nJarom\u00edr Janisch, Tom\u00e1\u0161 Pevn `y, and Viliam Lis `y. Classi\ufb01cation with costly features using deep rein-\nforcement learning. In Proceedings of the AAAI Conference on Arti\ufb01cial Intelligence , volume 33,\npp. 3959\u20133966, 2019.\nShihao Ji and Lawrence Carin. Cost-sensitive feature acquisition and classi\ufb01cation. Pattern Recogni-\ntion, 40(5):1474\u20131485, 2007.\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad\nGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a\nfreely accessible critical care database. Scienti\ufb01c data , 3(1):1\u20139, 2016.\nSergey Karayev, Mario J Fritz, and Trevor Darrell. Dynamic feature selection for classi\ufb01cation on a\nbudget. In International conference on machine learning (ICML): Workshop on prediction with\nsequential models . Citeseer, 2013.\nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan\nLiu. Lightgbm: A highly ef\ufb01cient gradient boosting decision tree. Advances in neural information\nprocessing systems , 30, 2017.\nJohn A Kellum and Norbert Lameire. Diagnosis, evaluation, and management of acute kidney injury:\na kdigo summary (part 1). Critical care , 17(1):204, 2013.\nMatloob Khushi, Kamran Shaukat, Talha Mahboob Alam, Ibrahim A Hameed, Shahadat Uddin,\nSuhuai Luo, Xiaoyan Yang, and Maranatha Consuelo Reyes. A comparative performance analysis\nof data resampling APPENDIX\nWe organized the appendices as follows. We \ufb01rst provide a complete literature review in appendix F, we discuss the alternative\nAM metric for evaluating the diagnostic performance as an example to show the capability of our\nframework to handle classic linear metrics.\nA R ELATED WORK\nReinforcement learning (RL) has been applied in multiple clinical care settings to learn optimal\ntreatment strategies for sepsis Komorowski et al. (2018), to customize antiepilepsy drugs for seizure\ncontrol Guez et al. (2008) etc. See survey Yu et al. (2021) for more comprehensive summary.\nGuidelines on using RL for optimizing treatments in healthcare has also been proposed around the\ntopics of variable availability, sample size for policy evaluation, and how to ensure learned policy\nworks prospectively as intended Gottesman et al. (2019). However, using RL for simultaneously\nreducing the healthcare cost and improving patient\u2019s outcomes has been underexplored.\nOur problem of cost-sensitive dynamic diagnosis/prediction is closely related to feature selection\nin supervised learning. The original static feature selection", " INTRODUCTION\nMany real world applications generate tabular data as a\nnatural byproduct of relational databases (Shwartz-Ziv and\nArmon, 2022). It is ubiquitous in domains ranging from\nhealthcare to climate and \ufb01nance (Sahakyan et al., 2021).\nObtaining enough labeled data to train supervised learn-\ning algorithms for classi\ufb01cation can be dif\ufb01cult. For exam-\nple, in healthcare, there are 10,000 rare diseases (Haendel\net al., 2020) affecting very few patients, which hampers the\ndevelopment of risk strati\ufb01cation models. Thus, we seek\nto develop RELATED WORK\n2.1 Machine Learning on Tabular Data\nDue to the success of deep learning in other domains, there\nhave been many recent attempts at representation learning\nfor tabular data. Self-supervised objectives have largely\nrevolved around the prediction of masked cells, the iden-\nti\ufb01cation or correction of corrupted cells, and contrastivelosses over augmentations (Bahri et al., 2022; Somepalli\net al., 2021; Yoon et al., 2020; Arik and P\ufb01ster, 2021;\nHuang et al., 2020). Additional efforts have included dif-\nferentiable trees, which combine advantages of tree ensem-\nbles with gradient based optimization of neural networks\n(Kontschieder et al., 2015; Popov et al., 2020). How-\never, several recent comprehensive reviews (Shwartz-Ziv\nand Armon, 2022; Borisov et al., 2022a; Grinsztajn et al.,\n2022) found that gradient-boosted tree ensembles like XG-\nBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al.,\n2017) systematically outperform these novel deep learning\narchitectures, even with proper \ufb01ne-tuning and regulariza-\ntion (Kadra et al., 2021). Levin et al. (2022) found util-\nity in transfer learning in the semi-supervised setting, but\nrequired a set of additional supervised tasks on the same\ntable, which can be a nontrivial limitation. They investi-\ngate few-shot classi\ufb01cation for medical diagnosis using 4 to\n200 labeled examples, but do not exploit the power of large\npre-trained models, as we do in this work. Hollmann et al.\n(2022) recently introduced TabPFN, a Bayesian neural net-\nwork pre-trained on synthetic tabular data, outperforming\ngradient boosted trees in a comprehensive evaluation.\n2.2 Large Language Models for Tabular Data\nAnother approach has been to leverage the natural language\ncapabilities of language models. Yin et al. (2020) use a\nlanguage model for semantic parsing of natural language\nqueries over tabular data. Li et al. (2020) investigate the\nability of language models to perform entity matching on\ntabular data, i.e. determining if two rows refer to the same\nobject. Harari and Katz (2022) study data enrichment by\nlinking each table row with additional unstructured text\n(e.g., from Wikipedia) from which they generated addi-Stefan Hegselmann, Alejandro Buendia, Hunter Lang, Monica Agrawal, Xiaoyi Jiang, David Sontag\ntional features using a language model. However, this setup\nrequires named entities (e.g., celebrities, universities, etc.),\nwhich is quite limiting. Bertsimas et al. (2022) studied two\nhealthcare datasets and used a language model to gener-\nate feature embeddings, which they fed into classi\ufb01ers like\ngradient boosted trees. All these studies use a BERT-style\nlanguage model (Devlin et al., 2019). Narayan et al. (2022)\nrecently assessed in-context learning with the autoregres-\nsive language model GPT-3 for tabular data cleaning tasks.\nThey found that it often outperforms state-of-the-art ap-\nproaches with ten labeled examples. Borisov et al. (2022b)\nintroduced an LLM-agnostic method to generate realistic\ntabular data and found that it achieved better results are\nprobable or definite left ventricular\nhypertrophy. His maximum heart rate\nachieved is 143 and he has\nexercise-induced angina. His ST\ndepression induced by exercise relative\nto rest is 0.1 and his slope of the peak\nexercise ST segment is flat.\nIncome Dataset", " Introduction\nText mining and knowledge discovery from biomedical\nliterature play important roles in drug discovery, clinical\ntherapy, pathology research, etc. Typical tasks include\nrecognizing named entities in the articles, mining the\ninteraction between drugs and proteins/diseases/other drugs,\nanswering questions given reference text, generating abstracts\nfor given phrases/words, etc. People have accumulated large\namounts of literature in the previous studies. For example,\nPubMed1, one of the most popular biomedical search engines,\ncovers more than 30 Marticles and the number still rapidly\nincreases every day as new discoveries are continuously coming\nout. Therefore, automatically mining the knowledge from\nliterature becomes an urgent demand.\nPre-training models have demonstrated their powerful\ncapability in natural language processing (NLP). On the GLUE\nbenchmark, a widely used benchmark for natural language\nunderstanding, pre-training based methods in natural language processing. arXiv preprintarXiv:2107.13586 , 2021.\n49. Xiang Lisa Li and Percy Liang. Pre\fx-tuning: Optimizing\ncontinuous prompts for generation. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers) , pages 4582{4597, Online,\nAugust 2021. Association for Computational Linguistics.\n50. Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan,\nSam Gross, Nathan Ng, David Grangier, and Michael Auli.\nfairseq: A fast, extensible toolkit for sequence modeling. In\nProceedings of NAACL-HLT 2019: Demonstrations , 2019.\n51. Diederik P Kingma and Jimmy Ba. Adam: A method for\nstochastic optimization. In ICLR (Poster) , 2015.\n52. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pierric\nCistac, Tim Rault, R\u0013 emi Louf, Morgan Funtowicz, Joe\nDavison, Sam Shleifer, Patrick von Platen, Clara Ma,\nYacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao,\nSylvain Gugger, Mariama Drame, Quentin Lhoest, and\nAlexander M. Rush. Transformers: State-of-the-art\nnatural language processing. In Proceedings of the 2020\nConference on Empirical abstract, containing\na question, a reference context, a long answer, and a\nyes/no/maybe label which is the answer to the question. We\nuse the original train/validation/test split with 450, 50 and 500\nrespectively, noted as PQA-L in [16] for evaluation. We also use\nthe additional dataset noted as PQA-A and PQA-U in [16] for\n\fne-tuning. We use the continuous embedding with length=9\nas the soft prompt. We format the data into source sequence\nand target sequence as described before. We apply techniques\nsuch as two-stage \fne-tuning [16] and noisy labels to improve\nthe performance. We measure and compare the classi\fcation\naccuracy of the reasoning required setting described in [16].\nFrom the Experiments\nIn this section, we pre-train our BioGPT and evaluate\nit on the following four biomedical NLP tasks across six\ndatasets: end-to-end relation extraction on BC5CDR [13], KD-\nDTI [14] and DDI [15], question answering on PubMedQA [16],\ndocument classi\fcation on HOC [17], and text generation\non self-created dataset. We use fairseq [50] as our code\nbase for implementation. We adopt the GPT-2 medium model\ncon\fguration as our backbone model con\fguration. We perform\nBPE to learn to tokenize the corpus and construct the\nvocabulary instead of using the learned vocabulary from GPT-\n2 due to the domain gap between the biomedical domain and\nthe general domain.\nFor pre-training, we pre-train BioGPT on 8 NVIDIA V100\nGPUs for 200 ksteps, with 1024 tokens per GPU and 64\naccumulated steps (i.e., the \fnal batch size is 1024 \u00028\u000264 =\n524288 tokens). We use Adam [51] as the optimizer with a peak\nlearning rate of 2\u000210\u00004and 20000 warm-up steps. The learning\nrate follows an inverse square root decay schedule after reaching\nthe", " Introduction\nDecision tree models, used for supervised learning since\nthe 1960s (Morgan & Sonquist, 1963; Messenger & Man-\ndell, 1972; Quinlan, 1986), have recently attained renewed\nprominence because they embody key elements of inter-\npretability: shallow trees are easily described and visual-\nized, and can even be implemented by hand. While the\nprecise de\ufb01nition and utility of interpretability have been\na subject of much debate (Murdoch et al., 2019; Doshi-\nVelez & Kim, 2017; Rudin, 2019; Rudin et al., 2021), all\nagree that it is an important notion in high-stakes decision-\nmaking, such as medical-risk assessment and criminal jus-\ntice. For this reason, decision trees have been widely ap-\nplied in both areas (Steadman et al., 2000; Kuppermann\net al., 2009; Letham et al., 2015; Angelino et al., 2017).\nBy far the most popular decision tree algorithm is Breiman\net al. (1984)\u2019s Classi\ufb01cation and Regression Trees (CART).\nThese can be ensembled to form a Random Forest (RF)\n(Breiman, 2001) or used as weak learners in Gradient\nBoosting (GB) (Friedman, 2001); both algorithms have\nachieved state-of-the-art performance over a wide class of\nprediction problems (Caruana & Niculescu-Mizil, 2006;\nCaruana et al., 2008; Fern \u00b4andez-Delgado et al., 2014; Ol-\nson et al., 2018; Hooker & Mentch, 2021), and are im-\nplemented in popular machine learning packages such as\nranger (Wright et al., 2017) and scikit-learn (Pe-\ndregosa et al., 2011). Variants of these algorithms, such as\nBasu et al. (2018)\u2019s iterative random forest for \ufb01nding sta-\nble interactions, have found use in scienti\ufb01c applications.\nIn view of the widespread use of tree-based Appendix S4.2 shows the SHAP plots forall 8 classi\ufb01cation datasets, showing that HS consistently\nleads to more clustered SHAP values.\n6. appendix.\nFor each of the four tree-growing Results for Deeper Trees\nIn this section, we investigate the performance of decision tree algorithms: (i) CART, (ii) C4.5, (iii) CART with CCP\nbefore/after applying HS while growing deeper trees for all the data sets in Table 1 and Table 1. We observe that theHierarchical Shrinkage\nperformance of the baselines drop dramatically while the performance of HS continuously improves as the ratio of number\nof leaves to samples increases. This is explained by our of connection of HS with ridge regression discussed on a supervised\nbasis in 3.\n(A)Classi\ufb01cation\n1001010.7250.7500.7750.8000.8250.850AUCheart (n = 270, p = 15)\nhsCART\nhsCART (CCP)\nCART\nCART (CCP)\n1001010.550.600.650.70breast-cancer (n = 277, p = 17)\n1001010.550.600.65haberman (n = 306, p = 3)\n1001010.750.800.850.900.95ionosphere (n = 351, p = 34)\n100101\nNumber of Leaves0.700.750.80AUCdiabetes (n = 768, p = 8)\n100101102\nNumber of Leaves0.650.700.75german-credit (n = 1000, p = 20)\n100101102\nNumber of Leaves0.600.650.700.750.800.85juvenile (n = 3640, p = 286)\n100101102\nNumber of Leaves0.6250.6500.6750.7000.7250.750recidivism (n = 6172, p = 20) (B)Regression\n1001011020.300.350.400.450.500.55R2friedman1 (n = 200, p = 10)\nhsCART\nhsCART (CCP)\nCART\nCART (CCP)\n1001011020.600.650.700.750.80friedman3 (n = 200, p = 4)\n1001011020.100.150.200.250.300.35diabetes-regr (n = 442, p = 10)\n1001011020.350.400.450.500.55geographical-music (n = 1059, p = 117)\n100101102\nNumber of Leaves0.100.150.200.250.300.35R2red-wine (n = 1599, p = 11)\n100101102\nNumber of Leaves0.20.30.40.5abalone (n = 4177, p = 8)\n100101102\nNumber of Leaves0.50.60.70.8satellite-image (n = 6435, p = 36)\n100101102\nNumber of Leaves0.30.40.50.60.7california-housing (n = 20640, p = 8)\nFigure S6. HS is able to improve (A)Classi\ufb01cation and (B)regression predictive performance for both baselines: CART and CART with\nCCP for larger data-sets when using deeper trees by preventing over\ufb01tting. As shown by our connection to Ridge regression in Sec 3,\nHS is bene\ufb01cial when the ratio of number of leaves to samples is large. Error bars show", " Introduction There is an increasing interest in developing artificial intelligence (AI) systems to improve healthcare delivery and health outcomes using electronic health records (EHRs).  A critical step is to extract and capture patients\u2019 characteristics from longitudinal EHRs.  The more information we have about the patients, the better the medical AI systems that we can develop.  In recent decades, hospitals and medical practices in the United States (US) have rapidly adopted EHR systems1,2, resulting in massive stores of electronic patient data, including structured (e.g., disease codes, medication codes) and unstructured (i.e., clinical narratives such as progress notes).  Even though using discrete data fields in clinical documentation has many potential advantages and structured data entry fields are increasingly added into the EHR systems, having clinicians use them remains a barrier, due to the added documentation burden3.  Physicians and other healthcare providers widely use clinical narratives as a more convenient way to document patient information ranging from family medical histories to social determinants of health.4  There is an increasing number of medical AI systems exploring the rich, more fine-grained patient information captured in clinical narratives to improve diagnostic and prognostic models.5,6  Nevertheless, free-text narratives cannot be easily used in computational models that usually require structured data.  Researchers have increasingly turned to natural language processing (NLP) as the key technology to enable medical AI systems to understand clinical language used in healthcare7.     Today, most NLP solutions are based on deep learning models8 implemented using neural network architectures \u2013 a fast-developing sub-domain of machine learning.  Convolutional neural networks9 (CNN) and recurrent neural networks10 (RNN) have been applied to NLP in the early stage of deep learning.  More recently, the transformer architectures11 (e.g., Bidirectional Encoder Representations from Transformers [BERT]) implemented with a self-attention mechanism12 have become state-of-the-art, achieving the best performance on many NLP benchmarks. 13\u201316  In the general domain, the transformer-based NLP models have achieved state-of-the-art performance for name entity recognition17\u201319, relation extraction20\u201324, sentence similarity25\u201327, natural language inference27\u201330, and question answering27,28,31,32.  Typically, transformers are trained in two stages: language model pretraining (i.e., learning using a self-supervised training objective on a large corpus of unlabeled text) and fine-tuning (i.e., applying the learned language models solving specific tasks with labeled training data).  One pretrained language model can be applied to solve many NLP tasks through fine-tuning, which is known as transfer learning \u2013 a strategy to learn knowledge from one task and apply it in another task33.  Human language has a very large sample space \u2013 the possible combinations of words, sentences, and their meaning and syntax are innumerable.  Recent studies show that large transformer models trained using massive text data are remarkably better than previous NLP models in terms of emergence and homogenization.33    The promise of transformer models has led to further interest in exploring large-size (e.g., >billions of parameters) transformer models.  The Generative Pretrained Transformer 3 (GPT-3) model34, which has 175 billion parameters and was trained using >400 billion words of text demonstrated", " Introduction Clinical relation extraction (RE) is a fundamental natural language processing (NLP) task to identify relations between clinical concepts from clinical narratives, which can subsequently help construct comprehensive patient profiles.  Recently, transformer-based models have achieved state-of-the-art performances in many NLP benchmark tasks in the general domain; and there is an increasing interest in applying transformers for clinical RE.  However, most existing transformer-based clinical RE studies have been heavily focused on the BERT architecture; and there is no study that has systematically examined other emerging transformer architectures such as RoBERTa and XLNet.  Further, many key techniques of using transformers for clinical RE, such as how to effectively use the representations generated by transformers and how to handle cross-sentence relations remain to be challenging. Methods in Natural Language Processing (EMNLP). Doha, Qatar: : Association for Computational Linguistics 2014. 1532\u201343. doi:10.3115/v1/D14-1162  \n 53  Wang H, Qin K, Zakari RY, et al. Deep Neural Network Based Relation Extraction: An Overview. arXiv:210101907 [cs] Published Online First: 7 February 2021.http://arxiv.org/abs/2101.01907 (accessed 20 May 2021). 54  Xue L, Qing S, Pengzhou Z. Relation Extraction Based on Deep Learning. In: 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). 2018. 687\u201391. doi:10.1109/ICIS.2018.8466437 55  Yan X, Mou L, Li G, et al. Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Path. arXiv:150803720 [cs] Published Online First: 15 August 2015.http://arxiv.org/abs/1508.03720 (accessed 20 May 2021). 56  Lv X, Guan Y, Yang J, et al. Clinical relation extraction with deep learning. International Journal of Hybrid Information Technology 2016;9:237\u201348. 57  Dandala B, Joopudi V, Devarakonda M. Adverse Drug Events Detection in Clinical Notes by Jointly Modeling Entities and Relations Using Neural Networks. Drug Saf 2019;42:135\u201346. doi:10.1007/s40264-018-0764-x 58  Johnson AEW, Pollard TJ, Shen L, et al. MIMIC-III, a freely accessible critical care database. Scientific Data 2016;3:160035. 59  Khattak FK, Jeblee S, Pou-Prom C, et al. A survey of word embeddings for clinical text. Journal of Biomedical Informatics: X 2019;4:100057. doi:10.1016/j.yjbinx.2019.100057 60  Zhu Y, Kiros R, Zemel R, et al. Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books. In: Proceedings of the IEEE International Conference on Computer Vision (ICCV). 2015.  61  Wei Q, Ji Z, Si Y, et al. Relation Extraction from Clinical Narratives Using Pre-trained Language Models. AMIA Annu Symp Proc 2020;2019:1236\u201345. 62  Guan H, Devarakonda M. Leveraging Contextual Information in Extracting Long Distance Relations from Clinical Notes. AMIA Annu Symp Proc 2020;2019:1051\u201360. 63  Alimova I, Tutubalina E. Multiple features for clinical relation extraction: A machine learning approach. Journal of Biomedical Informatics 2020;103:103382. doi:10.1016/j.jbi.2020.103382 64  Mahendran D, McInnes BT. Extracting Adverse Drug Events from Clinical Notes. arXiv:210410791 [cs] Published Online First: 21 April 2021.http://arxiv.org/abs/2104.10791 (accessed 26 May 2021). 65  Yang X, Zhang H, He X, et al. Extracting Family History of Patients From Clinical Narratives: Exploring an End-to-End Solution With Deep Learning Models. JMIR Medical Informatics 2020;8:e22982.  \n 66  Yang X, Bian J, Gong Y, et al. MADEx: a system for detecting medications, adverse", " INTRODUCTION\nApplying modern machine learning to observational health data\nholds the potential to improve healthcare in many ways, such as\ndelivering better patient treatments, improving hospital operations,\nand answering fundamental scientific questions [ 8]. To realize this\npotential, there have been efforts to make healthcare data avail-\nable to credentialed researchers with human subjects training. A\nwidely-used public data source is the Medical Information Mart for\nIntensive Care (MIMIC-III) dataset [ 14], which makes available the\nde-identified electronic health records (EHRs) of 53,423 patients\nadmitted to critical care units at a Boston-area hospital from 2001\u2013\n2012. While MIMIC-III\u2019s availability has catalyzed many research\nstudies, working with MIMIC-III data remains technically challeng-\ning, which presents a barrier to entry. The primary difficulties rest\nin the complexity of EHR data and the myriad choices that must\nbe made to extract a clinically-relevant cohort for analysis. These\nsame difficulties hinder the reproducibility of studies that apply\nmachine learning to MIMIC-III data, because researchers develop\ncode independently to extract and preprocess task-appropriate co-\nhorts. The majority of papers do not share code used to extract\nstudy-specific data [ 13], resulting in expensive yet redundant ef-\nforts to build upon existing work and creating the potential for\nhard-to-explain differences in results reported\nin the literature.MIMIC-Extract: A Data Extraction, Preprocessing, and Representation Pipeline for MIMIC-III ACM CHIL \u201920, April 2\u20134, 2020, Toronto, ON, Canada\nRF LR CNN LSTM\nVent. Vaso. Vent. Vaso. Vent. Vaso. Vent. Vaso.\nOnset AUROC 87.1 71.6 71.9 68.4 72.2 69.4 70.1 71.9\nWean AUROC 94.0 94.2 93.2 93.9 93.9 94.0 93.1 93.9\nStay On AUROC 98.5 98.5 98.4 98.2 98.6 98.4 98.3 98.3\nStay Off AUROC 99.0 98.3 98.3 98.5 98.4 98.1 98.4 98.1\nMacro AUROC 94.6 90.7 90.4 89.8 90.8 90.0 90.0 90.1\nAccuracy 79.7 83.8 78.5 72.9 61.8 77.6 84.3 82.6\nMacro F1 48.1 48.9 47.7 45.1 44.4 44.4 50.1 48.1\nMacro AUPRC 42.7 42.0 43.1 40.2 42.4 38.9 44.4 41.7\nTable 7: Performance Appendix A, which details, among other things, the relative rates of\nmissingness for both the individual raw ItemID s and the grouped\nclinical aggregates over this cohort.\nBENCHMARK TASKS AND MODELS\nIn this section, we profile several benchmark tasks, ranging in com-\nplexity, across several types of models using data extracted with\nMIMIC-Extract , in an effort to both provide meaningful bench-\nmarks and baseline methods for\ntime-series that expect discretized time representations, we aggre-\ngate the observations from each ICU stay\u2019s time-series into hourly\nbuckets.\nSemantic Grouping of Raw Features into\nClinical Aggregates\nEach measurements in the MIMIC-III database is associated with\na unique ItemID, as specified by the original EHR software. These\nraw ItemIDs are not robust to changes in software or human data\nentry practices. For example, \u201cHeartRate\u201d may be recorded under\nItemID 211 (using CareVue EHR systems before 2008) or under\nItemID 220045 (using MetaVision EHR software after 2008). We\nthus developed a manually curated clinical taxonomy designed\nto group semantically equivalent ItemIDs together into more ro-\nbust \u201cclinical aggregate\u201d features. These aggregate representations\nreduce overall data missingness and the presence of duplicate mea-\nsures. abstract due to publication availability at the time of writing.generic cohort that can be directly read as Pandas DataFrame. It is\nalso the only pipeline that uses clinical aggregation, unit conversion,\nand outlier detection on a large set of raw MIMIC-III data.\nPrediction Targets. Mortality and length-of-stay (LOS) are very\ncommon targets in relevant benchmark works and are also", " Introduction\nIn recent years, several di\ufb00erent approaches have been proposed for reinforcement learning with\nneural network function approximators. The leading contenders are deep Q-learning [Mni+15],\n\u201cvanilla\u201d policy gradient Background: Policy Optimization\n2.1 Policy Gradient Methods\nIn TRPO [Sch+15b], an objective function (the \u201csurrogate\u201d objective) is maximized subject to a\nconstraint on the size of the policy update. Speci\ufb01cally,\nmaximize\n\u03b8\u02c6Et/bracketleftbigg\u03c0\u03b8(at|st)\n\u03c0\u03b8old(at|st)\u02c6At/bracketrightbigg\n(3)\nsubject to \u02c6Et[KL[\u03c0\u03b8old(\u00b7|st),\u03c0\u03b8(\u00b7|st)]]\u2264\u03b4. (4)\nHere,\u03b8oldis the vector of policy parameters before the update. This problem can e\ufb03ciently be\napproximately solved using the conjugate gradient algorithm, after making a linear approximation\nto the objective and a quadratic approximation to the constraint.\nThe theory justifying TRPO actually suggests using a penalty instead of a constraint, i.e.,\nsolving the unconstrained optimization problem\nmaximize\n\u03b8\u02c6Et/bracketleftbigg\u03c0\u03b8(at|st)\n\u03c0\u03b8old(at|st)\u02c6At\u2212\u03b2KL[\u03c0\u03b8old(\u00b7|st),\u03c0\u03b8(\u00b7|st)]/bracketrightbigg\n(5)\nfor some coe\ufb03cient \u03b2. This follows from the fact that a certain surrogate objective (which computes\nthe max KL over states instead of the mean) forms a lower bound (i.e., a pessimistic bound) on the\nperformance of the policy \u03c0. TRPO uses a hard constraint rather than a penalty because it is hard\nto choose a single value of \u03b2that performs well across di\ufb00erent problems\u2014or even within a single\nproblem, where the the characteristics change over the course of learning. Hence, to achieve our goal\nof a \ufb01rst-order algorithm that emulates the monotonic improvement of TRPO, results and learning curves for all 49 games is provided in Experiments\n6.1 Comparison of Surrogate Objectives\nFirst, we compare several di\ufb00erent surrogate objectives under di\ufb00erent hyperparameters. Here, we\ncompare the surrogate objective LCLIPto several natural variations and ablated versions.\nNo clipping or penalty: Lt(\u03b8) =rt(\u03b8)\u02c6At\nClipping: Lt(\u03b8) = min(rt(\u03b8)\u02c6At,clip(rt(\u03b8)),1\u2212/epsilon1,1 +/epsilon1)\u02c6At\nKL penalty (\ufb01xed or adaptive) Lt(\u03b8) =rt(\u03b8)\u02c6At\u2212\u03b2KL[\u03c0\u03b8old,\u03c0\u03b8]\n5For the KL penalty, one can either use a \ufb01xed penalty coe\ufb03cient \u03b2or an adaptive coe\ufb03cient as\ndescribed in Section 4 using target KL value dtarg. Note that we also tried clipping in log space,\nbut found the performance to be no better.\nBecause we are searching over hyperparameters for each algorithm variant, we chose a compu-\ntationally cheap benchmark to test the algorithms on. Namely, we used 7 simulated robotics tasks2\nimplemented in OpenAI Gym [Bro+16], which use the MuJoCo [TET12] physics engine. We do\none million timesteps of training on each one. Besides the hyperparameters used for clipping ( /epsilon1)\nand the KL penalty ( \u03b2,dtarg), which we search over, the other hyperparameters are provided in in\nTable 3.\nTo represent the policy, we used a fully-connected MLP with two hidden layers of 64 units,\nand tanh nonlinearities, outputting the mean of a Gaussian distribution, with variable standard\ndeviations, following [Sch+15b; Dua+16]. We don\u2019t share parameters between the policy and value\nfunction (so coe\ufb03cient c1is irrelevant), and we don\u2019t use an entropy bonus.\nEach algorithm was run on all 7 environments, with 3 random seeds on each. We scored each\nrun of the algorithm by computing the average total reward of the last 100 episodes. We shifted\nand scaled the scores for each environment so that the random policy gave a score of 0 and the best\nresult was set to 1, and averaged over 21 runs to produce a single scalar for each algorithm setting.\nThe Results from continuous control benchmark. Average normalized scores (over 21 runs of the\nalgorithm, on 7 environments) for each algorithm / hyperparameter setting . \u03b2was initialized at 1.\n6.2 Comparison to Other Algorithms in the", " Introduction to the HCUP National Inpatient Sample (NIS) 2012 . (Agency for Healthcare Research and Quality, 2014).\n2.Henry, J., Pylypchuk, Y ., Talisha Searcy, M. & Patel, V . Adoption of electronic health record systems among US non-\nfederal acute care hospitals: 2008-2015. ONC Data Brief 35(Of\ufb01ce of the National Coordinator for Health Information\nTechnology, Washington DC, USA, 2015).\n3.Bates, D. W., Saria, S., Ohno-Machado, L., Shah, A. & Escobar, G. Big data in health care: using analytics to identify and\nmanage high-risk and high-cost patients. Heal. Aff. 33, 1123\u20131131 (2014).\n4.Zimmerman, J. E., Kramer, A. A., McNair, D. S. & Malila, F. M. Acute physiology and chronic health evaluation (apache)\niv: hospital mortality assessment for today\u2019s critically ill patients. Crit. Care Med. 34, 1297\u20131310 (2006).\n5.Williams, B. et al. National Early Warning Score (NEWS): Standardising the assessment of acute-illness severity in the\nNHS . (London: The Royal College of Physicians, 2012).\n6.Dahl, D. et al. The high cost of low-acuity icu outliers. J. Healthc. Manag. 57, 421\u2013433 (2012).\n7.Saria, S. & Goldenberg, A. Subtyping: What it is and its role in precision medicine. IEEE Intell. Syst. 30, 70\u201375 (2015).\n8.Iserson, K. V . & Moskop, J. C. Triage in medicine, part i: concept, history, and types. Ann. Emerg. Med. 49, 275\u2013281\n(2007).\n9.Apgar, V . A proposal for a new method of evaluation of the newborn. Curr. Res. Anesth. Analg. 32, 260\u2013267 (1952).\n10.Ferrucci, D., Levas, A., Bagchi, S., Gondek, D. & Mueller, E. T. Watson: beyond jeopardy! Artif. Intell. 199, 93\u2013105\n(2013).\n11.Silver, D. et al. Mastering the game of go with deep neural networks and tree search. Nature 529, 484\u2013489 (2016).\n12.Caballero Barajas, K. L. & Akella, R. Dynamically modeling patient\u2019s health state from electronic medical records: A time\nseries approach. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data\nMining , 69\u201378 (ACM, Sydney, Australia, 2015).\n13.Ghassemi, M. et al. A multivariate timeseries modeling approach to severity of illness assessment and forecasting in icu\nwith sparse, heterogeneous clinical data. In Proceedings of the Twenty-Ninth AAAI Conference on Arti\ufb01cial Intelligence ,\n446\u2013453 (AAAI Press, Austin, Texas, 2015).\n14.Luo, Y ., Xin, Y ., Joshi, R., Celi, L. & Szolovits, P. Predicting icu mortality risk by grouping temporal trends from a\nmultivariate panel of physiologic measurements. In Proceedings of the Thirtieth AAAI Conference on Arti\ufb01cial Intelligence ,\n42\u201350 (AAAI Press, Phoenix, Arizona, 2016).\n15.Lee, J. & Maslove, D. M. Customization of a severity of illness score using local electronic medical record data. J.\nintensive care medicine 32, 38\u201347 (2017).\n16.Johnson, A., Pollard, T. & Mark, R. Reproducibility in critical care: a mortality prediction case study. In Proceedings of\nthe 2nd Machine Learning for Healthcare Conference , vol. 68, 361\u2013376 (PMLR, Boston, Massachusetts, 2017).\n17.Quinn, J. A., Williams, C. K. & McIntosh, N. Factorial switching linear dynamical systems applied to physiological\ncondition monitoring. IEEE Trans. Pattern Anal. Mach. Intell. 31, 1537\u20131551 (2009).\n18.Laxmisan, A. et al. The multitasking clinician: Decision-making and cognitive demand during and after team handoffs in\nemergency care. Int. J. Med. Inform. 76, 801 \u2013 811 (2007).\n19.Horn, S. D. et al. The relationship between severity of illness and hospital length of stay and mortality. Med. Care 29,\n305\u2013317 (1991).\n20.Johnson, A. E. W. et al. MIMIC-III, a freely", " INTRODUCTION\nMachine learning and data-driven approaches are becom-\ning very important in many areas. Smart spam classi\fers\nprotect our email by learning from massive amounts of spam\ndata and user feedback; advertising systems learn to match\nthe right ads with the right context; fraud detection systems\nprotect banks from malicious attackers; anomaly event de-\ntection systems help experimental physicists to \fnd events\nthat lead to new physics. There are two important factors\nthat drive these successful applications: usage of e\u000bective\n(statistical) models that capture the complex data depen-\ndencies and scalable learning systems that learn the model\nof interest from large datasets.\nAmong the machine learning methods on\ndi\u000berent subsets of criteo data. The missing data\npoints are due to out of disk space. We can \fnd\nthat basic algorithm can only handle 200M exam-\nples. Adding compression gives 3x speedup, and\nsharding into two disks gives another 2x speedup.\nThe system runs out of \fle cache start from 400M\nexamples. The algorithm really has to rely on disk\nafter this point. The compression+shard method\nhas a less dramatic slowdown when running out of\n\fle cache, and exhibits a linear trend afterwards.\nlearning to rank problem. We compare against pGBRT [22],\nthe best previously pubished system on this task. XGBoost\nruns exact greedy algorithm, while pGBRT only support an\napproximate algorithm. The Related work\nis discussed in Sec. 5. Detailed end-to-end evaluations are\nincluded in Sec. 6. Finally we conclude the paper in Sec. 7.\n2. TREE BOOSTING IN A NUTSHELL\nWe review gradient tree boosting algorithms in this sec-\ntion. The derivation follows from the same idea in existing\nliteratures in gradient boosting. Specicially the second order\nmethod is originated from Friedman et al. [12]. We make mi-\nnor improvements in the reguralized objective, which were\nfound helpful in practice.\n2.1 Regularized Learning Objective\nFor a given data set with nexamples and mfeatures\nD=f(xi;yi)g(jDj=n;xi2Rm;yi2R), a tree ensem-\nble model (shown in Fig. 1) uses Kadditive functions to\npredict the output.\n^yi=\u001e(xi) =KX\nk=1fk(xi); fk2F; (1)\nwhereF=ff(x) =wq(x)g(q:Rm!T;w2RT) is the\nspace of regression trees (also known as CART). Here qrep-\nresents the structure of each tree that maps an example to\nthe corresponding leaf index. Tis the number of leaves in the\ntree. Each fkcorresponds to an independent tree structure\nqand leaf weights w. Unlike decision trees, each regression\ntree contains a continuous score on each of the leaf, we use\nwito represent score on i-th leaf. For a given example, we\nwill use the decision rules in the trees (given by q) to classify\nFigure 1: Tree Ensemble Model. The \fnal predic-\ntion for a given example is the sum of predictions\nfrom each tree.\nit into the leaves and calculate the \fnal prediction by sum-\nming up the score in the corresponding leaves (given by w).\nTo learn the set of functions used in the model, we minimize\nthe following regularized objective.\nL(\u001e) =X\nil(^yi;yi) +X\nk\n(fk)\nwhere \n(f) =\rT+1\n2\u0015kwk2(2)\nHerelis a di\u000berentiable convex loss function that measures\nthe di\u000berence between the prediction ^ yiand the target yi.\nThe second term \n penalizes the complexity of the model\n(i.e., the regression tree functions). The additional regular-\nization term helps to smooth the \fnal learnt weights to avoid\nover-\ftting. Intuitively, the regularized objective will tend\nto select a model employing simple and predictive functions.\nA similar regularization technique has been used in Regu-\nlarized greedy forest (RGF) [25] model. Our objective and\nthe corresponding learning algorithm is simpler than RGF\nand easier to parallelize."], "bleu": 0.12952166655302974, "rouge_l": 0.26679841897233203, "gpt_metric_score": 0.5, "bert_score": 0.1766865849494934}
{"paper_key": "Outlining the Borders for LLM Applications in Patient Education: Developing an Expert-in-the-Loop LLM-Powered Chatbot for Prostate Cancer Patient Education", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively leverage large language models (LLMs) to enhance the educational experience of prostate cancer patients, addressing their specific informational and emotional support needs?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for the research community as it can lead to significant advancements in patient-centered care, particularly in oncology. By developing LLM-based chatbots tailored for cancer patients, we can improve the accessibility and personalization of medical information, ultimately empowering patients to make informed decisions about their treatment. This research could pave the way for future studies on the integration of AI in healthcare, enhancing the understanding of patient needs and the role of technology in emotional support. The practical applications of this work could lead to improved patient outcomes, reduced anxiety, and better overall management of cancer care.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in solving this problem include the complexity of accurately understanding and responding to the diverse informational and emotional needs of cancer patients. Naive approaches may fail due to the nuanced nature of patient inquiries, which require context-aware and empathetic responses. Additionally, technical obstacles such as ensuring the accuracy of medical information, maintaining patient privacy, and creating a user-friendly interface are significant hurdles. Theoretical challenges also arise in effectively modeling the interaction dynamics between patients and the chatbot, as well as in evaluating the educational impact of the tool.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on either the technical capabilities of LLMs or the general needs of cancer patients, but there has been a lack of integrated approaches that combine these aspects. Barriers include insufficient collaboration between AI practitioners, healthcare professionals, and patients, leading to a disconnect in understanding patient needs. Existing solutions may not have adequately addressed the specific context of prostate cancer education or the emotional support required. Our approach differs by emphasizing a co-design process that actively involves patients and experts, ensuring that the developed tool is tailored to the unique challenges faced by prostate cancer patients.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves conducting a needs-assessment survey with prostate cancer patients to identify their specific educational challenges. We will then engage in a co-design process with patients, AI practitioners, and medical experts to develop an LLM-based educational chatbot. The dataset will consist of patient feedback and interaction logs, while the success of the chatbot will be measured", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question we aim to address is: How can a Position-aware Graph Neural Network (P-GNN) framework be effectively developed to analyze and correlate emotional tone and sentiment from news articles with patient experiences and treatment outcomes in cancer care?\n\n[Question 2]: Why is it interesting and important?  \nThis research is significant as it seeks to enhance patient education in healthcare, particularly for cancer patients who often navigate complex treatment processes. By integrating sentiment analysis of media coverage with patient experiences and genomic data, we can provide personalized health insights that reflect real-time emotional framing in media. This approach not only advances the research community's understanding of the interplay between media sentiment and patient outcomes but also has practical applications in improving patient understanding and decision-making. Addressing this question could lead to novel methodologies in patient education, ultimately fostering a more informed patient population and potentially improving treatment adherence and outcomes.\n\n[Question 3]: Why is it hard?  \nSolving this problem is challenging due to the complexities involved in correlating diverse data types, such as genomic information and sentiment analysis from news articles. Naive approaches may fail because they do not account for the nuanced ways in which media sentiment influences patient perceptions and experiences. Additionally, technical obstacles include developing a robust P-GNN model capable of effectively capturing the relationships between emotional tone in media and patient outcomes. There are also theoretical complexities in understanding how user influence and selection bias affect the personalization of health insights, which necessitates sophisticated modeling and analysis techniques.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has largely focused on either genomic data analysis or sentiment analysis independently, with limited interdisciplinary approaches that integrate both aspects. Existing solutions often overlook the impact of media sentiment on patient experiences and treatment outcomes, creating a gap in knowledge. Barriers to solving this problem include a lack of methodologies that can effectively combine these diverse data types and insufficient frameworks for analyzing user influence and selection bias. Our approach differs by utilizing a P-GNN framework designed to bridge these gaps, providing a holistic perspective on patient education that incorporates real-time sentiment analysis alongside genomic data.\n\n[Question 5]: What are the key components of my approach and results?  \nOur proposed methodology involves developing a P-GNN framework that will analyze sentiment from relevant news articles and correlate this with patient experiences and genomic data. We will utilize a dataset comprising sentiment-laden news articles, patient-reported outcomes, and genomic information from cancer patients. The metrics for evaluating our framework will include correlation coefficients between media sentiment and patient outcomes, as well as user engagement metrics to assess the effectiveness of personalized health insights. We expect our results to demonstrate a clear relationship between media sentiment and patient understanding, leading to improved patient education tools and better-informed decision-making processes for cancer patients.", "referenced_intros": [], "bleu": 0.1831397541857285, "rouge_l": 0.31222707423580787, "gpt_metric_score": 0.0, "bert_score": 0.3547731041908264}
{"paper_key": "What is the Role of Large Language Models in the Evolution of Astronomy Research?", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively integrate Large Language Models (LLMs) into the field of astronomy to enhance research productivity while addressing their limitations, such as hallucination and unpredictability?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for the research community as it could lead to significant advancements in how astronomical research is conducted, potentially increasing productivity and creativity in data analysis, hypothesis generation, and communication. By effectively leveraging LLMs, researchers could automate routine tasks, allowing them to focus on more complex problems, thus advancing knowledge in the field. Furthermore, this integration could lead to practical applications in education and outreach, making astronomical research more accessible and engaging to the public.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in integrating LLMs into astronomy stem from their inherent unpredictability and tendency to hallucinate, which can lead to the dissemination of incorrect information. Naive approaches that treat LLMs as traditional software tools may fail because they do not produce consistent, reliable outputs. Additionally, the technical complexity of adapting LLMs to specific astronomical contexts, the need for domain-specific training data, and the lack of established metrics for evaluating their performance in this field present significant obstacles that must be addressed.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on the capabilities of LLMs in general applications without tailoring them to the specific needs of astronomy. Limitations in understanding the unique requirements of astronomical research, such as the need for precision and reliability, have hindered progress. Additionally, the novelty of LLMs and their rapid evolution have outpaced the development of robust frameworks for their application in specialized fields. My approach will differ by focusing on creating domain-specific adaptations of LLMs, incorporating feedback mechanisms to mitigate hallucinations, and establishing clear evaluation metrics for their use in astronomy.\n\n**[Question 5] - What are the key components of my approach and results?**  \nMy proposed methodology involves developing a tailored LLM for astronomy by fine-tuning existing models on a curated dataset of astronomical literature and data. I will employ metrics such as accuracy, reliability, and user satisfaction to evaluate the model's performance. The expected outcomes include a more reliable LLM that can assist researchers in generating hypotheses, analyzing data, and communicating findings, ultimately leading to enhanced productivity and innovation in astronomical research.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How do magnetic fields influence the evolution of galaxy clusters, particularly in the context of shock heating processes and the thermal behavior of the intracluster medium during merger events?\n\n[Question 2]: Why is it interesting and important?  \nUnderstanding the impact of magnetic fields on galaxy clusters is crucial for several reasons. First, it has broader implications for the field of astrophysics, particularly in elucidating the processes underlying galaxy formation and evolution. By investigating how magnetic fields affect the dynamics within galaxy clusters, this research could lead to significant advancements in our knowledge of cosmic structure formation. Moreover, this study may pave the way for future research that explores the role of magnetic fields in other astrophysical phenomena, such as active galactic nuclei and star formation processes. Practical applications may include improved models for predicting the behavior of galaxy clusters, aiding in the interpretation of observational data from telescopes that capture multi-wavelength emissions.\n\n[Question 3]: Why is it hard?  \nThe challenge in solving this problem lies in the complexity of integrating multi-wavelength observational data with advanced simulations. Magnetic fields are inherently difficult to measure and quantify, leading to uncertainties in their role in galaxy cluster dynamics. Naive approaches that rely solely on observational data may fail to capture the full extent of the interactions between magnetic fields and the intracluster medium. Additionally, theoretical models of galaxy cluster evolution often overlook the magnetic component or simplify it excessively, which may lead to inaccurate predictions. Overcoming these technical and theoretical obstacles requires a robust machine learning framework that can effectively classify galaxy clusters and quantify the influence of magnetic fields, necessitating sophisticated algorithms and substantial computational resources.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on either the thermal dynamics of the intracluster medium or the effects of magnetic fields in isolation, but rarely have these two aspects been integrated comprehensively. Existing solutions have largely been limited by the lack of high-quality, multi-wavelength observational datasets and sophisticated tools to analyze them. Moreover, many studies have not employed machine learning techniques to classify galaxy clusters based on their evolutionary stages, which can provide critical insights into their dynamics. My approach differs by leveraging a machine learning framework that synthesizes various observational data, including X-ray and optical emissions, alongside advanced simulations, allowing for a more nuanced understanding of the interplay between magnetic fields and galaxy cluster evolution.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing a machine learning framework that integrates multi-wavelength data from existing observatories, focusing on X-ray emissions and optical observations. I will utilize a dataset that includes various galaxy clusters with known properties and evolutionary stages. The key metric for evaluation will be the classification accuracy of galaxy clusters based on their evolutionary stages and the quantification of magnetic field influences on thermal behaviors during mergers. I expect the outcomes to reveal new classifications of galaxy clusters and provide a clearer understanding of how magnetic fields contribute to shock heating processes. This research aims to enhance current models of galaxy cluster dynamics and offer insights that could reshape our understanding of cosmic evolution.", "referenced_intros": [], "bleu": 0.14470432811084954, "rouge_l": 0.2741764080765143, "gpt_metric_score": 0.0, "bert_score": 0.17180658876895905}
{"paper_key": "Nanosecond hardware regression trees in FPGA at the LHC", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we implement a more efficient decision tree algorithm with lower latency for estimating missing transverse momentum (ETmiss) at the Large Hadron Collider (LHC) using field programmable gate arrays (FPGA)?\n\n---\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for enhancing the performance of trigger systems in high-energy physics experiments, particularly at the LHC. A more efficient decision tree implementation can significantly improve the accuracy and speed of detecting elusive particles like neutrinos and dark matter candidates, which are vital for advancing our understanding of fundamental physics. This research could pave the way for deeper machine learning designs in future experiments, leading to more sophisticated analyses and potentially groundbreaking discoveries in particle physics.\n\n---\n\n**[Question 3] - Why is it hard?**  \nThe challenges in this problem stem from the need to balance computational efficiency with the complexity of decision tree algorithms when implemented in hardware. Naive approaches may fail due to the high latency associated with traditional decision tree implementations, which can hinder real-time processing capabilities required in high-energy physics experiments. Additionally, the intricacies of translating machine learning models into hardware description languages (HDL) introduce technical obstacles, such as ensuring that the hardware can handle the required data throughput while maintaining accuracy.\n\n---\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has primarily focused on simplified or less efficient implementations of machine learning algorithms for FPGA applications, often lacking the necessary optimization for decision trees in high-energy physics contexts. Barriers such as limited understanding of the specific requirements for real-time processing in trigger systems and the complexities of hardware-software integration have prevented effective solutions. Our approach improves upon prior work by providing a tailored VHDL adaptation of the Deep Decision Tree Engine (DDTE), which addresses these limitations and enhances performance.\n\n---\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves training a boosted decision tree (BDT) using the TMVA framework, with the target variable being the \"truth\" ETmiss. The firmware design will be a VHDL adaptation of the DDTE, utilizing the fwXmachina program to generate HDL code based on the trained model. We will evaluate the performance of our implementation by comparing latency and accuracy metrics against previous publications. The expected outcomes include a significant reduction in latency for decision tree processing, enabling more efficient real-time analysis of particle interactions at the LHC.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can a novel FPGA-accelerated hybrid framework that integrates boosted decision trees (BDTs) with real-time reinforcement learning enhance the adaptive optimization of hyperparameters for anomaly detection in high-energy physics events at the Large Hadron Collider (LHC)?\n\n[Question 2]: Why is it interesting and important?  \nAddressing this problem is crucial as it holds the potential to significantly advance the field of high-energy physics by improving the detection of rare particle events that could indicate physics beyond the Standard Model (BSM). A successful implementation of this framework could lead to enhanced sensitivity in identifying anomalies, which is vital for discovering new phenomena. The broader implications include contributing to real-time data analysis techniques in high-energy physics, which could inform future experimental designs and data collection strategies. By improving the interpretability of anomaly detection through the use of variational autoencoders (VAEs), this research can also provide insights into the underlying processes of particle interactions, ultimately fostering new theoretical developments and practical applications in both academia and industry.\n\n[Question 3]: Why is it hard?  \nThe complexity of this problem arises from several interrelated challenges. First, the dynamic nature of incoming data streams at the LHC necessitates real-time processing and adaptability, which requires sophisticated algorithms that can operate under strict latency constraints. Naive approaches may fail to account for the variability in data distributions, leading to suboptimal performance in hyperparameter tuning. Additionally, the integration of BDTs with reinforcement learning presents theoretical challenges in ensuring convergence and stability of the learning process. Moreover, the implementation on FPGA platforms demands a deep understanding of hardware-software co-design, as well as efficient resource management to maintain performance without exceeding available computational resources.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has typically focused on either traditional machine learning techniques or real-time processing but has not effectively combined them in a manner suitable for the unique demands of high-energy physics experimentation. Gaps exist in the literature regarding the real-time adaptation of hyperparameters in anomaly detection systems, particularly in the context of FPGAs. Furthermore, there has been a lack of integration between supervised and unsupervised learning approaches, which hinders the interpretability of the decision-making process. My approach differs by creating a hybrid framework that synergistically combines BDTs, reinforcement learning, and VAEs, leveraging the strengths of each to overcome barriers faced by prior methodologies.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves designing a hybrid system that utilizes boosted decision trees for classification, real-time reinforcement learning for hyperparameter optimization, and variational autoencoders for unsupervised anomaly detection. The system will be implemented on FPGA hardware to ensure low-latency processing of data streams from the LHC. The dataset will consist of simulated and real LHC event data, focusing on rare particle interactions. Performance metrics will include detection accuracy, latency, and resource efficiency. The expected outcomes are a robust anomaly detection framework capable of dynamically adapting to incoming data, improved interpretability of decision-making processes, and ultimately, increased sensitivity to BSM physics, paving the way for significant discoveries in high-energy physics.", "referenced_intros": [" introduction to PYTHIA 8.2 , Comput. Phys. Commun. 191(2015) 159,\narXiv: 1410.3012 [hep-ph] .\n[65] ATLAS Collaboration, ATLAS Pythia 8 tunes to 7TeV data, ATL-PHYS-PUB-2014-021, 2014,\nurl:https://cds.cern.ch/record/1966419 .\n[66] L. L\u00f6nnblad and S. Prestel, Matching tree-level matrix elements with interleaved showers ,\nJHEP03(2012) 19, arXiv: 1109.4829 .\n[67] ATLAS Collaboration, The ATLAS Simulation Infrastructure , Eur. Phys. J. C 70(2010) 823,\narXiv: 1005.4568 [physics.ins-det] .\n[68] ATLAS Collaboration,\nThe simulation principle and performance of the ATLAS fast calorimeter simulation FastCaloSim ,\nATL-PHYS-PUB-2010-013, 2010, url:https://cds.cern.ch/record/1300517 .\n[69] E. Bothmann et al., Event generation with Sherpa 2.2 , SciPost Phys. 7(2019) 034,\narXiv: 1905.09127 [hep-ph] .\n[70] NNPDF Collaboration, R. D. Ball, et al., Parton distributions for the LHC run II ,\nJHEP04(2015) 040, arXiv: 1410.8849 [hep-ph] .\n[71] S. Frixione, G. Ridolfi, and P. Nason,\nA positive-weight next-to-leading-order Monte Carlo for heavy flavour hadroproduction ,\nJHEP09(2007) 126, arXiv: 0707.3088 [hep-ph] .\n[72] P. Nason, A new method for combining NLO QCD with shower Monte Carlo algorithms ,\nJHEP11(2004) 040, arXiv: hep-ph/0409146 .\n[73] S. Frixione, P. Nason, and C. Oleari,\nMatching NLO QCD computations with parton shower simulations: the POWHEG method ,\nJHEP11(2007) 070, arXiv: 0709.2092 [hep-ph] .\n[74]S. Alioli, P. Nason, C. Oleari, and E. Re, A general framework for implementing NLO calculations\nin shower Monte Carlo programs: the POWHEG BOX , JHEP06(2010) 043,\narXiv: 1002.2581 [hep-ph] .\n[75] S. Frixione, E. Laenen, P. Motylinski, C. White, and B. R. Webber,\nSingle-top hadroproduction in association with a \ud835\udc4aboson, JHEP07(2008) 029,\narXiv: 0805.3067 [hep-ph] .\n[76]ATLAS Collaboration, Electron and photon efficiencies in LHC Run 2 with the ATLAS experiment ,\n(2023), arXiv: 2308.13362 [hep-ex] .\n17[77] R. D. Cousins, J. T. Linnemann, and J. Tucker,\nEvaluation of three methods for calculating statistical significance when incorporating a systematic\nuncertainty into a test of the", " \n\n1 Introduction\n\nThe CMS detector\u00a0[1, 2] reads out far more data than can be processed, reconstructed, and analyzed. In order to use any of the TB/s being generated, a reduction of more than 99% is necessary. The job of the CMS Level-1 trigger (L1T), which it does in real-time on a chain of field programmable gate arrays (FPGAs)\u00a0[3], is to perform this data reduction without missing interesting physics events. Operating on the clock of the LHC, where collisions occur every 25 nanoseconds, requires the entire system to adhere to microsecond latency constraints. Furthermore, stability is crucial for this system. Any error can lead to detector \"dead time\", where data is lost forever.\n\n\nA potential problem of traditional trigger strategies is that they rely either on a priori knowledge of signal or generic kinematic selections. This problem is addressed by triggering on how anomalous an event is. A variational autoencoder (VAE) trained on real unbiased CMS data to detect outliers offers a solution that is both signal agnostic (applicable to signatures we have not had the foresight to target specifically) and highly sensitive (effectively boosts signal efficiency for multiple physics signatures)\u00a0[4, 5].\n\n \n\n2 Anomaly Detection Trigger Algorithm\n\n\n\n\n\nFigure\u00a01: (Left) A typical design of a VAE, utilizing both an encoding and decoding network to reconstruct event information. (Right) The VAE model visualization for AXOL1TL, showing the layers, inputs, outputs, and the calculation of the anomaly score, our metric for triggering on interesting physics.\n\n\nThe VAE design uses an information bottleneck created by a small-dimensional latent space, which enforces an efficient data encoding, and leads the model to learn what makes an event anomalous. For this Anomaly Detection implementation in the CMS Level-1 Global Trigger, called Anomaly eXtraction Online Level-1 Trigger aLgorithm (AXOL1TL), the inputs are taken from a set of standard L1T objects (pTmisssuperscriptsubscript\ud835\udc5dTmissp_{\\mathrm{T}}^{\\mathrm{miss}}italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_miss end_POSTSUPERSCRIPT, 4 e/\u03b3\ud835\udefe\\gammaitalic_\u03b3, 4 \u03bc\ud835\udf07\\muitalic_\u03bc, and 10 jets) as (pT,\u03b7,\u03d5)subscript\ud835\udc5dT\ud835\udf02italic-\u03d5(p_{\\mathrm{T}},\\eta,\\phi)( italic_p start_POSTSUBSCRIPT roman_T end_POSTSUBSCRIPT , italic_\u03b7 , italic_\u03d5 ) vectors. The design of the VAE, visualized in figure 1, was driven by the constraints of the L1T system. Multiple steps were taken to minimize latency and resource utilization, including the removal of the decoder network, and the simplification of the latent space loss term, shown in (2.1). The reconstruction term is computed from the difference between the input (x) and output (x^^\ud835\udc65\\hat{x}over^ start_ARG italic_x end_ARG) of the VAE. The second, full regularization term, is the Kullback\u2013Leibler divergence (KL-divergence) between the latent space distribution and a standard normal distribution with mean \u03bc\ud835\udf07\\muitalic_\u03bc and standard deviation \u03c3\ud835\udf0e\\sigmaitalic_\u03c3. The parameter \u03b2\ud835\udefd\\betaitalic_\u03b2 can be tuned to balance the reconstruction performance with more efficient latent space encoding. At inference time, the loss is approximated by the mean-squared term \u03a3i\u2062\u03bc2subscript\u03a3\ud835\udc56superscript\ud835\udf072\\Sigma_{i}\\mu^{2}roman_\u03a3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\u03bc start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of the KL-divergence for latency considerations. This approximation has no impact on performance.\n\n\n\n\n\n\nLoss=(1\u2212\u03b2)\u2062\u2016x\u2212x^\u20162+\u03b2\u206212\u2062(\u03bc2+\u03c32\u22121\u2212log\u2061\u03c32)Loss1\ud835\udefdsuperscriptnorm\ud835\udc65^\ud835\udc652\ud835\udefd12superscript\ud835\udf072superscript\ud835\udf0e21superscript\ud835\udf0e2\\displaystyle\\text{Loss}=(1-\\beta)||x-\\hat{x}||^{2}+\\beta\\frac{1}{2}(\\mu^{2}+%\n\\sigma^{2}-1-\\log\\sigma^{2})Loss = ( 1 - italic_\u03b2 ) | | italic_x - over^ start_ARG italic_x end_ARG | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_\u03b2 divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( italic_\u03bc start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_\u03c3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 1 - roman_log italic_\u03c3 start_POSTSUPERSCRIPT", " \nIntroduction\n\nUnsupervised artificial intelligence (AI) algorithms enable signal-agnostic searches for beyond the Standard Model (BSM) physics at the Large Hadron Collider (LHC) at CERN [1]. The LHC is the highest energy proton and heavy ion collider that is designed to discover the Higgs boson [2, 3] and study its properties [4, 5] as well as to probe the unknown and undiscovered BSM physics (see, e.g., [6, 7, 8]). Due to the lack of signs of BSM in the collected data despite the plethora of searches conducted at the LHC, dedicated studies look for rare BSM events that are even more difficult to parse among the mountain of ordinary Standard Model processes [9, 10, 11, 12, 13]. An active area of AI research in high energy physics is in using autoencoders for anomaly detection, much of which provides methods to find rare and unanticipated BSM physics. Much of the existing literature, mostly using neural network-based approaches, focuses on identifying BSM physics in already collected data [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 42, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 70, 69, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 59, 61, 62, 63, 64, 65, 66, 67, 68].\nSuch ideas have started to produce experimental results on the analysis of data collected at the LHC [71, 72, 73, 74]. A related, but separate endeavor, which is the subject of this paper, is enabling the identification of rare and anomalous data on the real-time trigger path for more detailed investigation offline.\n\n\nThe LHC offers an environment with an abundance of data at a 40 MHz collision rate, corresponding to the 25 ns time period between successive collisions. The real-time trigger path of the ATLAS and CMS experiments [75, 76], e.g., processes data using custom electronics using field programmable gate arrays (FPGA) followed by software trigger algorithms executed on a computing farm. The first-level FPGA portion of the trigger system accepts between 100 kHz to 1 MHz of collisions, discarding the remaining \u2248{\\approx}\u2248 99% of the collisions. Therefore, it is essential for discovery that the FPGA-based trigger system is capable of triggering on potential BSM events. A previous study aimed for LHC data has shown that an anomaly detector based on neural networks can be implemented on FPGA with latency values between 80 to 1480 ns, depending on the design [77].\n\n\nIn this paper, we present an interpretable implementation of an autoencoder using deep decision trees that makes inferences in 30 ns. As discussed previously [78, 79], decision tree designs depend only on threshold comparisons resulting in fast and efficient FPGA implementation with minimal reliance on digital signal processors. We train the autoencoder on known Standard Model (SM) processes to help trigger on the rare events that may include BSM.\n\n\nIn scenarios for which a specific BSM model is targeted and its dynamics are known, a dedicated supervised training against the SM sample, i.e., BSM-vs-SM classification, would likely outperform an unsupervised approach of SM-only training.", " Introduction\nFast,accurateestimationofphysicalquantitiesfromdetectorinformationisindispensableathigh\nenergy physics Results for various con\ufb01gurations by scanning\nthe BDT parameters\u2014such as the number of trees, the maximum tree depth, and the number of\nbits\u2014show that our implementation can be adapted for a variety of use cases Conclusions\nWe present a novel implementation of boosted decision trees on FPGA within the fwXmachina\nframework[ 31]thatallowsfordeepdecisiontrees. Inthispaper,wedemonstratetheusecasefor\nthe deep tree structure for regression problems. The new \ufb01rmware design makes use of parallel\ndecision paths (PDP) to allow for deeper trees as well as arbitrarily many variables: two limitations\nof the \ufb02attened decision tree structure of ref. [ 31]. Finally, support for varying bit integer precision\nper variable is implemented, allowing for further resource usage optimization.\nThe performance is shown for the problem \ud835\udc38miss\nTestimation. It is shown that combining several\nconventional METcalculations with a regression BDT provided a better signal e\ufb03ciency and References\n[1] L. Evans and P. Bryant, LHC Machine , JINST3, S08001 (2008).\n[2]ATLAS Collaboration, The ATLAS Experiment at the CERN Large Hadron Collider , JINST3,\nS08003 (2008).\n[3] CMS Collaboration, The CMS Experiment at the CERN LHC , JINST3, S08004 (2008).\n[4]ATLAS Collaboration, Performance of the ATLAS Trigger System in 2010 , Eur. Phys. J. C 72,\n1849 (2012).\n[5]ATLAS Collaboration, Performance of the ATLAS Trigger System in 2015 , Eur. Phys. J. C 77,\n317 (2017).\n[6] CMS Collaboration, The CMS trigger system , JINST12, P01020 (2017).\n[7] R. Achenbach et al., The ATLAS level-1 calorimeter trigger , JINST3, P03001 (2008).\n[8]CMSCollaboration, ThePhase-2UpgradeoftheCMSEndcapCalorimeter ,CERN-LHCC-\n2017-023, 2017, http://cds.cern.ch/record/2293646 .\n[9]CMSCollaboration, PerformanceoftheCMSLevel-1triggerinproton-protoncollisionsatp\ud835\udc60=13 TeV, JINST15, P10017 (2020).\n[10]ATLAS Collaboration, Performance of the upgraded PreProcessor of the ATLAS Level-1\nCalorimeter Trigger , JINST15, P11016 (2020).\n[11]ATLASCollaboration, Performanceof theATLASLevel-1topologicaltriggerin Run2 ,Eur.\nPhys. J. C 82, no.1, 7 (2022).\n[12]CMS Collaboration, The Phase-2Upgrade of theCMS Level-1Trigger , CERN-LHCC-2020-\n004, CMS-TDR-021, 2020, http://cds.cern.ch/record/2714892 .\n[13]ATLAS Collaboration, Technical Design Report for the Phase-I Upgrade of the ATLAS\nTDAQSystem ,CERN-LHCC-2013-018,ATLAS-TDR-023,2013, http://cds.cern.ch/record/\n1602235.\n[14]ATLAS Collaboration, Technical Design Report for the Phase-II Upgrade of the ATLAS\nTDAQSystem ,CERN-LHCC-2017-020,ATLAS-TDR-029,2017, http://cds.cern.ch/record/\n2285584.\n[15]CMS Collaboration, Performance of the CMS missing transverse momentum reconstruction in\npp data atp\ud835\udc60= 8 TeV, JINST10, no.02, P02006 (2015).\n23Nanosecond ML regression with deep BDT in FPGA for HEP\n[16]ATLAS Collaboration, Reconstruction of hadronic decay products of tau leptons with the\nATLAS experiment , Eur. Phys. J. C 76, no.5, 295 (2016).\n[17]ATLAS Collaboration, Electron and photon energy calibration with the ATLAS detector using\n2015\u20132016 LHC proton-proton collision data , JINST14, no.03, P03017 (2019)\n[18]ATLAS Collaboration, Electron and photon performance measurements with the ATLAS\ndetectorusingthe2015\u20132017LHCproton-protoncollisiondata ,JINST14,no.12,P12006\n(2019).\n[19]ATLASCollaboration, ConvolutionalNeuralNetworkswithEventImagesforPileupMitigation\nwith the ATLAS Detector , ATL-PHYS-PUB-2019-028, 2019, http://cds.cern.ch/record/\n2684070.\n[20]ATLASCollaboration, DeepLearningfor PionIdenti\ufb01cation andEnergyCalibration withthe\nATLAS Detector , ATL-PHYS-PUB-2020-018, 2020, http://cds.cern.ch/record/2724632 .\n[21]J.Duarteetal., FastinferenceofdeepneuralnetworksinFPGAsforparticlephysics ,JINST\n13, P07027 (2018).\n[22]Y. J. Jwa, G. D. Guglielmo, L. P. Carloni, and G. Karagiorgi, Accelerating Deep Neural\nNetworksforReal-timeDataSelectionforHigh-resolutionImagingParticleDetectors ,2019\nNew York Scienti\ufb01c Data Summit (NYSDS), 1 (2019).\n[23]S. Summers et al., Fast inference of Boosted Decision Trees in FPGAs for particle physics ,\nJINST15, P05026 (2020).\n[24]V.Loncaretal., CompressingdeepneuralnetworksonFPGAstobinaryandternaryprecision\nwith HLS4ML , 2020, [2003.06308].\n[25]Y. Iiyama et al., Distance-Weighted Graph Neural Networks on FPGAs for Real-Time Particle\nReconstruction in High Energy Physics , Front. Big Data 3, 598927 (2020).\n[26]A. Heintz et al., Accelerated Charged Particle Tracking with Graph Neural Networks on\nFPGAs, 2020, [2012.01563].\n[27]J. St. John et al., Real-time Arti\ufb01cial Intelligence for Accelerator Control: A Study at the\nFermilab Booster , 2020, [2011.07371].\n[28]C. N. Coelho, A. Kuusela, S. Li, et al., Automatic heterogeneous quantization of deep neural\nnetworks for low-latency inference", " Introduction\nThispaperpresentsadirectsearchforthedecayoftheHiggsboson[1,2]intoinvisibleparticles. While\nthe expectation for the branching fraction of invisible decays ( Binv) from the Standard Model (SM) is\n0\u009512%duetothedecay \ud835\udc3b!\ud835\udc4d\ud835\udc4d\u0003!\ud835\udf08\u00af\ud835\udf08\ud835\udf08\u00af\ud835\udf08,severalscenariosofphysicsbeyondtheStandardModel(BSM)\nallowforanomalousandsizeable O\u00b910%\u00bavalues. Inoneclassofmodelsunderconsideration[3\u201315] the\nHiggs boson might decay into \ud835\udf12\ud835\udf12, a pair of weakly interacting massive particles (WIMPs) [16, 17], which\nmay explain the existence of dark matter (DM) [18\u201320]. Such models, in which the DM candidate is a\nsingletunderthegaugesymmetriesoftheSMandtheHiggsbosonactsasamediatortotheDM,arecalled\nHiggs-portal models. They represent a simple extension of the SM to provide a DM candidate and are able\nto predict the observed relic DM density via \ud835\udc60-channel\ud835\udf12\ud835\udf12!\ud835\udc53\u00af\ud835\udc53annihilation processes [21], where \ud835\udc53\ndenotesafermion. Thephenomenologyofsuchmodelsisveryrich,anddependsstronglyonthespinof\nthe DM candidate.\nA long list of searches for invisible Higgs boson decays that target various \ufb01nal states have been performed\nby the ATLAS and CMS Background estimation\nEvents from \ud835\udc49+jetsprocesses comprise about 95% of the Results from the PandaX-4T Commissioning Run , (2021),\narXiv: 2107.13438 [hep-ex] .\n46[148] S. Baek, P. Ko and W.-I. Park, Invisible Higgs decay width versus dark matter direct detection\ncross section in Higgs portal dark matter models , Phys. Rev. D 90(2014) 055014,\narXiv: 1405.3530 [hep-ph] .\n[149] G. Arcadi, A. Djouadi and M. Kado,\nThe Higgs-portal for vector dark matter and the e\ufb00ective \ufb01eld theory approach: A reappraisal ,\nPhys. Lett. B 805(2020) 135427, arXiv: 2001.10750 [hep-ph] .\n[150] M. Zaazoua, L. Truong, K. A. Assamagan and F. Fassi, Higgs Portal Vector Dark Matter\nInterpretation: Review of E\ufb00ective Field Theory Approach and Ultraviolet Complete Models ,\nLHEP2022(2022), arXiv: 2107.01252 [hep-ph] .\n[151] M. Hoferichter, P. Klos, J. Men\u00e9ndez and A. Schwenk,\nImproved limits for Higgs-portal dark matter from LHC searches ,\nPhys. Rev. Lett. 119(2017) 181803, arXiv: 1708.02245 [hep-ph] .\n[152]J. Billard, L. Strigari and E. Figueroa-Feliciano, Implication of neutrino backgrounds on the reach\nof next generation dark matter direct detection Conclusion\nA search for Higgs boson decays into invisible particles is presented using 139fb\u00001of proton\u2013proton\ncollisiondatawithacentre-of-massenergyofp\ud835\udc60=13TeVcollectedbetween2015and2018bytheATLAS\ndetector at the LHC. The VBF production mode is targeted by requiring two energetic jets that are not\nback-to-backintheazimuthalplaneandexhibitalargerapidityseparation,inadditiontolargevaluesofthe\ntwo-jetinvariantmassandmissingtransversemomentum. Eventswiththreeorfourjetsarealsoconsidered\nif the additional jetsare compatible with the hypothesisthat they originate from \ufb01nal-stateradiation from\none of the VBF jets. The dominant \ud835\udc4d+jetsand\ud835\udc4a+jetsbackgrounds are evaluated using common control\nregions, which is made possible due to the use of a dedicated theoretical calculation at next-to-leading\norder in the phase space that is relevant for this analysis. Two independent data-driven techniques are used\nto estimate the mult\u0133et experiments , Phys. Rev. D 89(2014) 023524,\narXiv: 1307.5458 [hep-ph] .\n[153] F. Ruppin, J. Billard, E. Figueroa-Feliciano and L. Strigari,\nComplementarity of dark matter detectors in light of the neutrino methods , JHEP09(2012) 049,\narXiv: 1111.1220 [hep-ph] .\n[64] S. H\u00f6che, F. Krauss, M. Sch\u00f6nherr and F. Siegert,\nQCD matrix elements + parton showers. The NLO case , JHEP04(2013) 027,\narXiv: 1207.5030 [hep-ph] .\n[65] S. Hoeche, F. Krauss, S. Schumann and F. Siegert, QCD matrix elements and truncated showers ,\nJHEP05(2009) 053, arXiv: 0903.1219 [hep-ph] .\n[66] T. Gleisberg and S. H\u00f6che, Comix, a new matrix element generator , JHEP12(2008) 039,\narXiv: 0808.3674 [hep-ph] .\n[67] F. Cascioli, P. Maierh\u00f6fer and S. Pozzorini, Scattering Amplitudes with Open Loops ,\nPhys. Rev. Lett. 108(2012) 111601, arXiv: 1111.5206 [hep-ph] .\n[68] A. Denner, S. Dittmaier and L. Hofer,\nCollier: A fortran-based complex one-loop library in extended regularizations ,\nComput. Phys. Commun. 212(2017) 220, arXiv: 1604.06792 [hep-ph] .\n41[69] C. Anastasiou, L. J. Dixon, K. Melnikov and F. Petriello,\nHighprecisionQCDathadroncolliders:ElectroweakgaugebosonrapiditydistributionsatNNLO ,\nPhys. Rev. D 69(2004) 094008, arXiv:", " Introduction\nTriggering muons is critically important in proton-proton\ncollider conclusion is provided in Section 6.\n2. Simulation\n2.1. Simulation samples\nThe networks presented in this work were trained and\nevaluated on events simulated with Geant4 [19]. In the\nsimulation, a gas chamber detector shape similar to the\nthin gap chamber (TGC) of the ATLAS experiment [20]\nwas formed with an approximate pseudorapidity ( \u0011) cover-\nage of 2:03\u0014j\u0011j\u00142:26. A full schematic of the detector\nmodel used is shown in Fig. 1. Rectangular plates were\nused instead of the trapezoidal plates of the TGC detec-\ntor for simplicity. The angular resolution of the track-\ning shown in this paper is independent from the simpli\f-\ncations of the detector geometry because the wire orien-\ntations are identical. Three plates|one triplet and two\ndoublet plates|were used in the simulation. The triplet\nplate corresponds to the TGC's innermost plate and has\ndimensions of 900 mm \u0002500 mm\u000270 mm. The two dou-\nblet plates correspond to the TGC's outer plates and have\ndimensions of 990 mm \u0002500 mm\u000244 mm. The triplet\nplate is named M1, and the doublet plates are named M2\nand M3. All the plates were positioned with their central\npoints set to the TGC plates' central positions. The z\npositions1of the M1, M2, and M3 plates were identical to\nTGC's plates (Fig. 2). The wire pitch for all the plates was\n1:8 mm, and 10 (11) wires were grouped into channels for\ntriplet (doublet) plates. No magnetic \feld was introduced\nbecause the TGC detector is located outside the toroidal\nmagnet at the ATLAS experiment.\nThe muon source was placed in front of the M1 plate\natz= 13:3 m. Multiple scattering and emissions before\narriving at the muon chamber were ignored because the\nintrinsic performance of the tracking with the muon cham-\nber was the topic of interest. At the ATLAS experiment,\nmuons with transverse momentum pT\u001520 GeV are de-\n\rected, at most, \u000630 mrad from the trajectory of muons\n1Thezaxis is taken as the proton beam axis in the ATLAS ex-\nperiment, and is taken accordingly in this study.\nM1M2M3\n13.0 13.8 14.2 14.6 15.02.73.03.33.63.9\n13.8Figure 1: Schematic of the detector model. The zcoordinates of\nthe chambers are identical to those of TGC detectors in the ATLAS\nexperiment. The three plates|M1, M2, and M3 in ascending z-\nposition order|are aligned with their normals parallel to the zaxis.\nThe arrow represents an incoming muon, and \u0012is de\fned as the polar\nangle.\nFR4\nFR4\nCopper\nCopper\nGraphite\nGraphite\nAnode Wire\nGas Volume\nHoneycomb\nGraphite\nGraphite\nGraphite\nCopper\nCopper\nCopper\n(Tungsten)\n(Paper)\n10 mm\nFigure 2: Cross-sectional view of the triplet (left) and doublet (right)\nplates.\n2with in\fnite momentum when impacting the TGC detec-\ntor. The sign of the de\rection angle depends on the elec-\ntric charge of the muon. In this study, muons' direction\nwas uniformly distributed in the range \u000630 mrad from\nthe angle of the straight track, which was independently\nuniformly distributed on the polar angle \u0012. The straight\ntracks were aligned directly from the interaction point. A\nsingle muon was generated for each event. Tracking of the\nminimum ionizing particle is critical for muon triggerring\nat the ATLAS experiment, and all muons were generated\nwithpT= 20 GeV in this study. All data associated with\ntracks passing through all seven gas gaps were collected\nfor both training and performance evaluation. A channel\ngenerated a readout value of 1 if it was \fred and 0 if not.\nThe \fred channels are referred to as \\hits\" in this work.\nWith the aforementioned settings, 3 \u0002106events were\ngenerated for this", " Introduction\nMachine learning experiments for detecting new\nlong-lived particles that are predicted by well-motivated ex-\ntensions of the standard model (e.g., Refs. [22, 23]). The\ncurrent RPC trigger system [17, 24] does not allow such trig-\ngers because it uses application-speci\ufb01c integrated circuits\nthat perform standard muon logic. The current system will be\nreplaced with an FPGA-based system after 2026. Our goal\nis to deploy resource-ef\ufb01cient neural networks using spare\nFPGA resources that should be available after implementa-\ntion of baseline muon trigger algorithms [16] that do not use\nmachine learning results with a more accurate detector simulation model and\ndeveloping new FPGA trigger algorithms for exotic particle\nsearches will be the subject of our future work.\nAcknowledgements This work was supported in part by the National\nNatural Science Foundation of China, under Grants 11922510 and\n11961141014, and by the Fundamental Research Funds for the Central\nUniversities of China, under Grant WK2360000011. We would like to\nthank Wenqi Lou for the helpful guidance on FPGA implementation\nusing high level synthesis tools.\n[1] Alexander Radovic et al. \u201cMachine learning at the\nenergy and intensity frontiers of particle physics\u201d. In:\nNature 560.7716 (2018), pp. 41\u201348. DOI:10.1038/\ns41586-018-0361-2 .12\n[2] Giuseppe Carleo et al. \u201cMachine learning and the\nphysical sciences\u201d. In: Rev. Mod. Phys. 91 (2019),\np. 045002. DOI:10.1103/RevModPhys.91.045002 .\narXiv: 1903.10563 [physics.comp-ph] .\n[3] Javier Duarte et al. \u201cFast inference of deep neural net-\nworks in FPGAs for particle physics\u201d. In: JINST 13.07\n(2018), P07027. DOI:10.1088/1748-0221/13/07/\nP07027 . arXiv: 1804.06913 [physics.ins-det] .\n[4] N. Nottbeck, C. Schmitt, and V . B \u00a8uscher. \u201cImplemen-\ntation of high-performance, sub-microsecond deep\nneural networks on FPGAs for trigger applications\u201d.\nIn:JINST 14.09 (2019), P09014. DOI:10 . 1088 /\n1748- 0221/14/09/p09014 . arXiv: 1903.10201\n[physics.ins-det] .\n[5] Claudionor N. Coelho et al. \u201cAutomatic heterogeneous\nquantization of deep neural networks for low-latency\ninference on the edge for particle detectors\u201d. In: Na-\nture Machine Intelligence 3 (June 2020), pp. 675\u2013\n686. DOI:10.1038/s42256-021-00356-5 . arXiv:\n2006.10159 [physics.ins-det] .\n[6] Tae Min Hong et al. \u201cNanosecond machine learn-\ning event classi\ufb01cation with boosted decision trees\nin FPGA for high energy physics\u201d. In: JINST 16.08\n(2021), P08016. DOI:10.1088/1748-0221/16/08/\nP08016 . arXiv: 2104.03408 [hep-ex] .\n[7] Ekaterina Govorkova et al. Autoencoders on FPGAs\nfor real-time, unsupervised new physics detection at\n40 MHz at the Large Hadron Collider . Aug. 2021.\narXiv: 2108.03986 [physics.ins-det] .\n[8] Francescato, Simone et al. \u201cModel compression and\nsimpli\ufb01cation pipelines for fast deep neural network\ninference in FPGAs in HEP\u201d. In: Eur. Phys. J. C 81.11\n(2021), p. 969. DOI:10.1140/epjc/s10052-021-\n09770-w .\n[9] Darin Acosta et al. \u201cBoosted Decision Trees in the\nLevel-1 Muon Endcap Trigger at CMS\u201d. In: J. Phys.\nConf. Ser. 1085.4 (2018), p. 042042. DOI:10.1088/\n1742-6596/1085/4/042042 .\n[10] Chang Sun et al. \u201cFast Muon Tracking with Machine\nLearning Implemented in FPGA\u201d. In: (Feb. 2022).\narXiv: 2202.04976 [physics.ins-det] .\n[11] Allison McCarn Deiana et al. Applications and Tech-\nniques for Fast Machine Learning in Science . Oct.\n2021. arXiv: 2110.13041 [cs.LG] .\n[12] Juliette Alimena, Yutaro Iiyama, and Jan Kieseler.\n\u201cFast convolutional neural networks for identifying\nlong-lived particles in a high-granularity calorimeter\u201d.\nIn:JINST 15.12 (2020), P12006. DOI:10 . 1088 /\n1748- 0221/15/12/P12006 . arXiv: 2004.10744\n[hep-ex] .[13] Dylan Linthorne and Daniel Stolarski. \u201cTriggering\non emerging jets\u201d. In: Phys. Rev. D 104.3 (2021),\np. 035019. DOI:10.1103/PhysRevD.104.035019 .\narXiv: 2103.08620 [hep-ph] .\n[14] Olmo Cerri et al. \u201cVariational Autoencoders for New\nPhysics Mining at the Large Hadron Collider\u201d. In:\nJHEP 05 (2019), p. 036. DOI:10.1007/JHEP05(2019)\n036. arXiv: 1811.10276 [hep-ex] .\n[15] Javier Duarte et al. \u201cFPGA-accelerated machine learn-\ning inference as a service", " INTRODUCTION\nThe CERN Large Hadron Collider (LHC) [ 1] gener-\nates 40 million proton-proton collision events per second.\nParticles produced in these events are detected in the sen-\nsors of detectors located around the LHC ring, producing\nhundreds of terabytes of data per second. The largest\ngeneral-purpose particle detectors at LHC, ATLAS [ 2]\nand CMS [ 3], discard most of the collision events with\nonline selection systems, as a result bandwidth limita-\ntions. These systems consist of two stages; the level-1\ntrigger (L1T) [ 4{7], where algorithms are deployed as pro-\ngrammable logic on custom electronic boards equipped\nwith \feld-programmable gate arrays (FPGAs), and the\nHigh Level Trigger (HLT), where selection algorithms\nasynchronously process the events accepted by the L1T\non commercially available CPUs. The largest fraction\nof events are discarded at the \frst selection stage, the\nL1T, which has the task of reducing the event rate by 2 :5\n\u0003E-mail: katya.govorkova@cern.ch\nyAlso at Institute of Physics Belgrade, Serbia\nzAlso at Politecnico di Milano, Italy\nxAlso at Imperial College London, UK\n{Also at California Institute of Technology, USAorders of magnitude within a few microseconds. The trig-\nger selection algorithms running in the L1T and HLT are\ndesigned to guarantee a high acceptance rate for certain\nphysics processes under study. When designing searches\nfor new physics kinds of collisions (e.g., dark matter pro-\nduction), physicists typically consider speci\fc scenarios\nmotivated by theoretical considerations. This supervised\nstrategy has proven to be successful when dealing with\ntheory-motivated searches, as was the case with the search\nfor the Higgs boson [ 8,9]. Conversely, this approach may\nbecome a limiting factor in the absence of a strong theo-\nretical prior. For this reason, there are several community\ne\u000borts to investigate unsupervised machine learning (ML)\ntechniques for new physics searches [ 10,11]. These in-\nvestigate the use of autoencoders (AEs) and variational\nautoencoders (VAEs) for o\u000fine processing [ 24,25], and\ntherefore do not consider constraints such as resource\nusage and latency. Ref. [ 12,13] propose to integrate\nunsupervised learning algorithms in the online selection\nsystem of the CMS and ATLAS experiments for Run 3 to accelerate the search for\nunexpected signatures of new physics.IX. CODE AVAILABILITY\nThe QKeras library is available under github.com/\ngoogle/qkeras , where the work presented here is us-\ning QKeras version 0.9.0. The hls4ml library with cus-\ntom layers used in the paper are under AEL1paper\nbranch and is available at https://github.com/\nfastmachinelearning/hls4ml/tree/AE_L1_paper .\nX. DATA AVAILABILITY\nThe data used in this study are openly available at\nZenodo at Ref. [47{50, 52].10\nTABLE III. Resource utilization and latency for the quantized and pruned DNN and CNN (V)AE models. Resources are based\non the Vivado estimates from Vivado HLS 2020.1 for a clock period of 5 ns on Xilinx VU9P.\nModel DSP [%] LUT [%] FF [%] BRAM [%] Latency [ns] II [ns]\nDNN AE QAT 8 bits 2 5 1 0.5 130 5\nCNN AE QAT 4 bits 8 47 5 6 1480 895\nDNN VAE PTQ 8 bits 1 3 0.5 0.3 80 5\nCNN VAE PTQ 8 bits 10 12 4 2 365 115\nTABLE IV. Resource utilization and latency for the quantized and pruned DNN AE model. Resources are based on the Vivado\nestimates from Vivado HLS 2020.1 for a clock period of 5 ns on Xilinx V7-690.\nModel DSP [%] LUT [%] FF [%] BRAM [%] Latency [ns] II [ns]\nDNN VAE PTQ 8 bits 3 9 3 0.4 205", " Introduction\nStarting with the work of the MiniBooNE collaboration [1, 2], Boosted Decision Trees (BDTs) have\nbeenextremelyprevalentwithinthe\ufb01eldofHighEnergyPhysics(HEP)[3],usedmainlyforregression\nandclassi\ufb01cationtasks,bothineventreconstructionandsubsequentdataanalysis. Inthehigh-pro\ufb01le\ndiscovery of the Higgs boson, BDTs were used to increase the sensitivity of the CMS analysis in the\ndecaychanneloftheHiggstotwophotons[4],andhavebeenusedsigni\ufb01cantlyinfurtheranalysesof\nHiggs properties.\nAttheLargeHadronCollider(LHC) experiments, thanks to their good performance with relatively low computational cost. The \ufb01rst use\ncaseofanMLtechniqueintheL1TofanLHCexperimentwasaBDTusedtoperformaregressionof\nmuon pTfortheCMSL1Tendcapmuontrigger[8]. Thetechniquegaveathree-timesreductioninrate\nfor the trigger threshold compared to the previous approach, removing unwanted low pTmuons. An\nexternal DRAM of 1:2 GBwas used as a look-up-table (LUT) to store the pre-computed BDT output\nfor every variation in the input variables. The LUT was \ufb01lled o\ufb04ine and queried with low latency\nonline. The solution proposed in this paper would allow an on-chip implementation going beyond a\nfull-LUT approach.\nOther works have implemented ensembles of Decision Trees (BDTs and Random Forests) for\nFPGAs [9\u201313]. These generally target applications of FPGA accelerated inference in a combined\nCPU-FPGA system, where the relevant performance goals are throughput and energy consumption.\nFurther, the use of external memories and traversal over trees by fetching nodes from memory gives\nthese approaches \ufb02exibility and scalability. The work of [9] and [10], in particular, is designed to be\nscalabletoverylargeensemblesinawaythattheimplementationinthispaperisnot. Inthecontextof\ntargetingLHCtriggers,however,themainperformancegoalisofextremelylowlatency,andsecondly\nto maintain a modest resource usage.\n\u2013 2 \u20130.0 0.2 0.4 0.6 0.8 1.0\nSignal Efficiency103\n102\n101\n100Background Efficiency\ng tagger, AUC = 93.1%\nq tagger, AUC = 89.6%\nw tagger, AUC = 93.8%\nz tagger, AUC = 92.9%\nt tagger, AUC = 95.3%\ng q w z t\nPredicted labelgqwztTrue label\n0.75 0.13 0.02 0.02 0.080.16 0.71 0.03 0.02 0.070.05 0.18 0.72 0.04 0.010.05 0.16 0.07 0.70 0.020.08 0.03 0.05 0.03 0.81\n0.00.20.40.60.81.0Figure 1: Left: The solid curves show signal e\ufb03ciency vs. misidenti\ufb01cation rate using a BDT with\n100 trees of depth 4 for the \ufb01ve jet classes: gluon, quark, Wboson, Zboson, and top quark. The\ndashed curves show the performance of the 3 layer MLP from [6]. Right: confusion matrix for the\nBDT.\n2 Building Boosted Decision Trees with hls4ml\nInthepreviousworkontranslationofneuralnetworkstoFPGA\ufb01rmwarewith hls4ml,wepresented\na demonstration data set for discrimination of quarks ( q), gluons ( g),Wand Zbosons, and top ( t)\njets[14]. Thedataconsistofasetof16physics-motivatedhigh-levelfeatures,representinginformation\noftheeventjetsubstructure. Withthisinformationathand,onecandistinguishtraditionalsingle-prong\nqandgjets from two- ( Wand Z) and three-prong jets\nThisproblemistypicalofsearchesforphysicsbeyondthestandardmodelatATLASandCMS.To\nourknowledgethereisnoalgorithmcurrentlyemployedintheL1Tsystemsofthesetwoexperiments\nthat exploits this kind of substructure information to select events with multi-prong jets. This data\nset provides a benchmark on which to evaluate the classi\ufb01er performance and its realisation in FPGA\nimplementationasanexampleapplicationfortheL1T.Weusethesamedatasetinthisworktoprepare\na classi\ufb01er, this time a BDT.\nWe performed the BDT training using the scikit-learn package [15], randomly splitting the\ndatasetintotraining(80%)andtesting(20%)partitions. ABDTwith100treesandamaximumdepth\nof4wasfoundtogivesimilarperformancetotheDNNmodeltrainedonthesamedataset,providing\na useful point of comparison. The cross-entropy loss function was used.\nThe resulting receiver operating characteristic (ROC) curve is shown in Figure 1, displaying\nthe discussion of use cases, see Ref. [5] and references therein.\n\u2013 1 \u2013capable of high throughput training and inference. Despite the large amount of studies showing\ninteresting use cases for DNN applications, the number of DNN models deployed in the central data\nprocessingoftheLHCexperimentsduringpreviousLHCrunningwasverylimited. Thiswasmainly\ndue to the lack of optimal deployment solutions that would meet the strong constraints of central\nprocessingsystems(e.g.,real-timeeventselectioninthetriggersystems),bothintermsoflatencyand\ncomputing resource footprint.\nPreviously,weintroducedthe hls4mllibrarytofacilitatethedeploymentofDNNmodelsonL1T\nsystems[6]. Theaimofthatworkwastoestablishanautomaticwork\ufb02owtoconvertagivenDNNmodel\ninto an electronic circuit, evaluated on an FPGA through a fully-on-chip \ufb01rmware implementation.\nThe work\ufb02ow consists of converting a given NN model into an expertly written C++ code, which is\nthenconvertedtoanFPGA\ufb01rmwarebyaHighLevelSynthesis(HLS)tool(e.g.,XilinxVivadoHLS).\nInRef.[6],wedemonstratedhowaDNNmodelforjetidenti\ufb01cationattheLHCcouldbecompressed\nand quantized, to run on an FPGA with 75 nslatency.\nInthiswork,wepresentanextensionofthe hls4mllibrarytoalsosupportBDTs. Asshallbeseen\nin the following Sections 2 and 3, the BDT implementation in FPGAs is capable of achieving similar\nperformance to a DNN, with a relatively lightweight usage of", " Introduction\nExtensions of the Standard Model (SM) that include new states with nearly degenerate masses can help to\nresolve open issues in particle physics while evading constraints from experiments, and collider searches constitute the only direct probe for j\u0016j>800GeV[24]. Diagrams\nrepresentingtheproductionmodeforthe\ufb01rsttwoscenariosareshowninFigure1(a). A e\u001f0\n2producedin\neither scenario can decay into a dilepton pair via an o\ufb00-shell Zboson ( Z\u0003), such that the dilepton invariant\nmass m``iskinematicallyrestrictedtobesmallerthanthemass-splittingbetweenthe e\u001f0\n2ande\u001f0\n1. Hadronic\ninitial-state radiation (ISR) is also required to boost the system as a way of enhancing the sensitivity of the\nsearch.\nThe third scenario is similar to the previous two, but it instead assumes that the pair production of the\nelectroweakinos proceeds via vector-boson fusion (VBF) processes, in which SM weak bosons exchange\nan electroweakino in a t-channel process to produce two electroweakinos and a pair of forward jets. Such\n1In the minimal supersymmetric extension of the SM, the Higgs sector is extended to contain two Higgs doublets and tan\u00b9\f\u00bais\nthe ratio of the vacuum expectation values of the two Higgs doublets.\n2~\u001f\u0006\n1\n~\u001f0\n2W\u0003\nZ\u0003pp\n~\u001f0\n1qq\n~\u001f0\n1\n``j(a)\n~\u001f\u0006\n1\n~\u001f0\n2W\u0003\nZ\u0003\nq\nqqq\n~\u001f0\n1q\nq\n~\u001f0\n1\n`\n` (b)\n~`\n~`ppj\n~\u001f0\n1`\n~\u001f0\n1\n` (c)\nFigure1: Diagramsrepresentingthetwo-lepton\ufb01nalstateof(a)productionofelectroweakinos e\u001f0\n2e\u001f\u0006\n1withinitial-state\nradiation ( j), (b) VBF production of electroweakinos e\u001f0\n2e\u001f\u0006\n1, and (c) slepton pair ( e`e`) production in association with\ninitial-state radiation ( j). The higgsino simpli\ufb01ed model also considers e\u001f0\n2e\u001f0\n1ande\u001f+\n1e\u001f\u0000\n1production.\nscenarios typically have very low cross-sections, but can complement the sensitivity of q\u00afqannihilation\nmodes that dominate the inclusive higgsino and wino/bino cross-sections, especially for LSP masses above\na few hundred GeV[25]. An example of such a process is illustrated in Figure 1(b). The kinematic cuto\ufb00\nof the m``distribution is also used as the primary discriminant in this scenario, along with the presence of\ntwo forward jets consistent with a VBF production mode.\nThe fourth scenario assumes the presence of scalar partners of the SM leptons (slepton, e`) that are\nslightly heavier than a bino-like LSP. Such models can explain dark-matter thermal-relic densities through\ncoannihilation channels, as well as the muon g\u00002anomaly [26, 27]. This process is illustrated in\nFigure1(c). Thisscenarioexploitstherelationshipbetweentheleptonmomentaandthemissingtransverse\nmomentum through the stransverse mass, mT2[28, 29], which exhibits a kinematic endpoint similar to that\nform``in electroweakino decays.\nEvents with two same-\ufb02avor opposite-charge leptons (electrons or muons), signi\ufb01cant missing transverse\nmomentum of size Emiss\nT, and hadronic activity are selected for all scenarios. Signal regions (SRs) are\nde\ufb01ned by placing additional requirements on a number of kinematic variables. The dominant SM\nbackgroundsareeitherestimatedwith insitutechniquesorconstrainedusingdatacontrolregions(CRs)\nthat enter into a simultaneous likelihood \ufb01t with the SRs. The \ufb01t is performed in bins of either the m``\ndistribution (for electroweakinos) or the mT2distribution (for sleptons).\nConstraintsonthesecompressedscenarioswere\ufb01rstestablishedatLEP[30\u201340]. Thelowerboundson\ndirect chargino production from these background-only\nhypothesisforaPoissonprocess ,Nucl.Instrum.Meth.A 595(2008)480,arXiv: physics/0702156\n[physics.data-an] .\n[119]ATLASCollaboration, Measurementof the WWcross sectioninps=7TeVppcollisionswiththe\nATLASdetectorandlimitsonanomalousgaugecouplings ,Phys.Lett.B 712(2012)289,arXiv:\n1203.6232 [hep-ex] .\n[120]ATLAS Collaboration, Prospects for Higgs boson searches using the H!WW\u00b9\u0003\u00ba!`\u0017`\u0017\ndecaymodewiththeATLASdetectorat 10TeV,ATL-PHYS-PUB-2010-005,2010, /u.sc/r.sc/l.sc:https:\n//cds.cern.ch/record/1270568 .\n[121]J.Butterworth etal., PDF4LHCrecommendations forLHC RunII ,J. Phys.G 43(2016)023001,\narXiv: 1510.03865 [hep-ph] .\n[122]G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood-based tests of\nnew physics , Eur.Phys. J. C 71(2011) 1554,arXiv: 1007.1727 [physics.data-an] , Erratum:\nEur. Phys. J. C 73(2013) 2501.\n[123]M. Baak et al., HistFitter software framework for statistical data analysis , Eur. Phys. J. C 75\n(2015) 153, arXiv: 1410.1280 [hep-ex] .\n[124] A. L. Read, Presentation of search discussion of this, see Ref. [62].\n50\n510152025303540 [GeV]\n llGenerated m00.020.040.060.080.10.120.140.16Fraction of Events / 2 GeVwino/bino) > 0\n01\n\u03c7\u223c m(\u00d7) 02\n\u03c7\u223cm(wino/bino, reweighted\n) < 0\n01\n\u03c7\u223c m(\u00d7) 02\n\u03c7\u223cm(Higgsino\nATLASSimulation = 13 TeV\ns) = (100, 60) [GeV]\n01\n\u03c7\u223c, 02\n\u03c7\u223cm(Figure 2: Dilepton invariant", " Introduction\nSince the discovery of the Higgs boson at the CERN LHC [1\u20133], the ATLAS and CMS Collabo-\nrations have pursued a wide-ranging program to study its properties and interactions. Precise\nmeasurements of the couplings of the Higgs boson to standard model (SM) particles indicate\nthat the properties of the new particle are consistent with the SM predictions [4]. These mea-\nsurements also provide indirect constraints on additional contributions to the Higgs boson\nwidth from beyond the SM (BSM) decays. Based on the results from \ufb01rst 98.7 days of data from the\nPandaX-II experiment\u201d, Phys. Rev. Lett. 117(2016) 121303,\ndoi:10.1103/PhysRevLett.117.121303 ,arXiv:1607.07400 .\n[82] SuperCDMS Collaboration, \u201cNew experiments\u201d, Phys. Rev.\nLett. 114(2015) 191803, doi:10.1103/PhysRevLett.114.191803 ,\narXiv:1503.07589 .26\n[39] CMS Collaboration, \u201cMeasurements of properties of the Higgs boson decaying into the\nfour-lepton \ufb01nal state in pp collisions atps=13 TeV\u201d, JHEP 11(2017) 047,\ndoi:10.1007/JHEP11(2017)047 ,arXiv:1706.09936 .\n[40] J. Alwall et al., \u201cThe automated computation of tree-level and next-to-leading order\ndifferential cross sections, and their matching to parton shower simulations\u201d, JHEP 07\n(2014) 079, doi:10.1007/JHEP07(2014)079 ,arXiv:1405.0301 .\n[41] J. M. Campbell, R. K. Ellis, P . Nason, and E. Re, \u201cTop-pair production and decay at NLO\nmatched with parton showers\u201d, JHEP 04(2015) 114,\ndoi:10.1007/JHEP04(2015)114 ,arXiv:1412.1828 .\n[42] S. Alioli, P . Nason, C. Oleari, and E. Re, \u201cNLO single-top production matched with\nshower in POWHEG: s- and t-channel contributions\u201d, JHEP 09(2009) 111,\ndoi:10.1007/JHEP02(2010)011 ,arXiv:0907.4076 . [Erratum: JHEP 02 (2010)\n011].\n[43] E. Re, \u201cSingle-top Wt-channel production matched with parton showers using the\nPOWHEG method\u201d, Eur. Phys. J. C 71(2011) 1547,\ndoi:10.1140/epjc/s10052-011-1547-z ,arXiv:1009.2450 .\n[44] T. Sj \u00a8ostrand et al., \u201cAn Acknowledgments\nWe congratulate our colleagues in the CERN accelerator departments for the excellent perfor-\nmance of the LHC and thank the technical and administrative staffs at CERN and at other\nCMS institutes for their contributions to the success of the CMS effort. In addition, we grate-\nfully acknowledge the computing centres and personnel of the Worldwide LHC Computing\nGrid for delivering so effectively the computing infrastructure essential to our analyses. Fi-\nnally, we acknowledge the enduring support for the construction and operation of the LHC\nand the CMS detector provided by the following funding agencies: BMWFW and FWF (Aus-\ntria); FNRS and FWO (Belgium); CNPq, CAPES, FAPERJ, and FAPESP (Brazil); MES (Bulgaria);\nCERN; CAS, MoST, and NSFC (China); COLCIENCIAS (Colombia); MSES and CSF (Croatia);\nRPF (Cyprus); SENESCYT (Ecuador); MoER, ERC IUT, and ERDF (Estonia); Academy of Fin-\nland, MEC, and HIP (Finland); CEA and CNRS/IN2P3 (France); BMBF, DFG, and HGF (Ger-\nmany); GSRT (Greece); NKFIA (Hungary); DAE and DST (India); IPM (Iran); SFI (Ireland);\nINFN (Italy); MSIP and NRF (Republic of Korea); LAS (Lithuania); MOE and UM (Malaysia);\nBUAP , CINVESTAV , CONACYT, LNS, SEP , and UASLP-FAI (Mexico); MBIE (New Zealand);\nPAEC (Pakistan); MSHE and NSC (Poland); FCT (Portugal); JINR (Dubna); MON, RosAtom,\nRAS and RFBR (Russia); MESTD (Serbia); SEIDI, CPAN, PCTI and FEDER (Spain); Swiss Fund-\ning Agencies (Switzerland); MST (Taipei); ThEPCenter, IPST, STAR, and NSTDA (Thailand);\nTUBITAK and TAEK (Turkey); NASU and SFFR (Ukraine); STFC (United Kingdom); DOE and\nNSF (USA).\nIndividuals have received support from the Marie-Curie programme and the European Re-\nsearch Council and Horizon 2020 Grant, contract No. 675440 (European Union); the Leventis\nFoundation; the A. P . Sloan Foundation; the Alexander von Humboldt Foundation; the Belgian\nFederal Science Policy Of\ufb01ce; the Fonds pour la Formation `a la Recherche dans", " Introduction to PYTHIA\n8.2,Comput. Phys. Commun. 191(2015) 159\u2013177, [ 141/zero.alt3.3/zero.alt312 ].\n[57] P. Skands, S. Carrazza and J. Rojo, Tuning PYTHIA 8.1: the Monash 2013 Tune ,Eur. Phys. J. C74\n(2014) 3024, [ 14/zero.alt34.563/zero.alt3 ].\n[58] M. Cacciari, G. P. Salam and G. Soyez, Fastjet user manual ,Eur. Phys. J. C72(2012) 1896,\n[1111.6/zero.alt397 ].\n[59] M. Cacciari and G. P. Salam, Dispelling the n3myth for the ktjet-\ufb01nder,Phys. Lett. B641(2006) 57\u201361,\n[hep-ph//zero.alt351221/zero.alt3 ].\n[60] M. Cacciari, G. P. Salam and G. Soyez, The Anti-k(t) jet clustering algorithm ,JHEP04(2008) 063,\n[/zero.alt38/zero.alt32.1189 ].\n[61] D. Adams et al., Towards an Understanding of the Correlations in Jet Substructure ,Eur. Phys. J. C75\n(2015) 409, [ 15/zero.alt34./zero.alt3/zero.alt3679 ].\n[62] A. J. Larkoski, S. Marzani, G. Soyez and J. Thaler, Soft Drop ,JHEP05(2014) 146, [ 14/zero.alt32.2657 ].\n[63] A. J. Larkoski, G. P. Salam and J. Thaler, Energy Correlation Functions for Jet Substructure ,JHEP06\n(2013) 108, [ 13/zero.alt35./zero.alt3/zero.alt3/zero.alt37 ].\n[64] I. Moult, L. Necib and J. Thaler, New Angles on Energy Correlation Functions ,JHEP12(2016) 153,\n[16/zero.alt39./zero.alt37483 ].\n[65] E. Coleman, M. Freytsis, A. Hinzmann, M. Narain, J. Thaler, N. Tran et al., The importance of\ncalorimetry for highly-boosted jet substructure ,JINST13(2018) T01003, [ 17/zero.alt39./zero.alt387/zero.alt35 ].\n[66] V. Nair and G. E. Hinton, Recti\ufb01ed linear units improve restricted Boltzmann machines , inProceedings\nof ICML, vol. 27, pp. 807\u2013814, 06, 2010.\n[67] D. P. Kingma and J. Ba, Adam: A method for stochastic optimization ,CoRRabs/1412.6980 (2014) ,\n[1412.698/zero.alt3 ].\n[68] AWS, \u201cAmazon EC2 P2 Instances.\u201d https://aws.amazon.com/ec2/instance-types/p2/ , 2018.\n\u2013 27 \u2013[69] S. Han, H. Mao and W. J. Dally, Deep compression: Compressing deep neural network with pruning,\ntrained quantization and hu\ufb00man coding ,CoRRabs/1510.00149 (2015) , [ 151/zero.alt3./zero.alt3/zero.alt3149 ].\n[70] Y. Cheng, D. Wang, P. Zhou and T. Zhang, A survey of model compression and acceleration for deep\nneural networks ,CoRRabs/1710.09282 (2017) , [ 171/zero.alt3./zero.alt39282 ].\n[71] Y. LeCun, J. S. Denker and S. A. Solla, Optimal brain damage , inAdvances in Neural Information\nProcessing Systems 2 (D. S. Touretzky, ed.), pp. 598\u2013605. Morgan-Kaufmann, 1990.\n[72] C.Louizos,M.WellingandD.P.Kingma, LearningSparseNeuralNetworksthrough L0Regularization ,\nArXiv e-prints (Dec., 2017) , [ 1712./zero.alt31312 ].\n[73] R. Rigamonti, A. Sironi, V. Lepetit and P. Fua, Learning separable \ufb01lters , in2013 IEEE Conference on\nComputer Vision and Pattern Recognition , pp. 2754\u20132761, June, 2013. DOI.\n[74] E. L. Denton, W. Zaremba, J. Bruna, Y. LeCun and R. Fergus, Exploiting linear structure within\nconvolutional networks for e\ufb03cient evaluation , inAdvances in Neural Information Processing Systems\n27(Z.Ghahramani,M.Welling,C.Cortes,N.D.LawrenceandK.Q.Weinberger,eds.),pp.1269\u20131277.\nCurran Associates, Inc., 2014.\n[75] M. Jaderberg, A. Vedaldi and A. Zisserman, Speeding up convolutional neural networks with low rank\nexpansions ,CoRRabs/1405.3866 (2014) , [ 14/zero.alt35.3866 ].\n[76] M.Denil,B.Shakibi,L.Dinh,M.A.RanzatoandN.deFreitas, Predictingparametersindeeplearning ,\ninAdvances in Neural Information Processing Systems 26 (C. J. C. Burges, L. Bottou, M. Welling,\nZ. Ghahramani and K. Q. Weinberger, eds.), pp. 2148\u20132156. Curran Associates, Inc., 2013.\n[77] T. N. Sainath, B. Kingsbury, V. Sindhwani, E. Arisoy and B. Ramabhadran, Low-rank matrix\nfactorization for deep neural network training with high-dimensional output targets , in2013 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing , pp. 6655\u20136659, May, 2013. DOI.\n[78] T. S. Cohen and M. Welling, Group Equivariant Convolutional Networks ,ArXiv e-prints (Feb., 2016) ,\n[16/zero.alt32./zero.alt37576 ].\n[79] C. Bucilu \u02c7a, R. Caruana and A. Niculescu-Mizil, Model compression , inProceedings of the 12th ACM\nSIGKDD International Conference on Knowledge Discovery and Data Mining , KDD \u201906, (New York,\nNY, USA), pp.", " Introduction\ncombinations and formulas with a functionality similar to the one available for the Draw command\nof a ROOT tree.\nTMVA works in transparent factory mode to guarantee an unbiased performance comparison be-\ntween MVA results with respect to the\noriginal one, requiring however somewhat more tuning.\nThe new framework introduced with TMVA 4 provides the \rexibility to combine MVA Methods { Support Vector\nLearning, ch. 12, pp. 185, MIT Press, 1999.\n[44] S. Keerthi, S. Shevade, C. Bhattacharyya and K. Murthy, \\ Improvements to Platt's SMO\nalgorithm for SVM classi\fer design \", Technical Report CD-99-14, Dept. of Mechanical and\nProduction Engineering, Natl. Univ. Singapore, Singapore, 1999.134 Index\nIndex\nCopyright, 2\nDownload\nfrom Sourceforge.net, 4\nfrom SVN, 4\nExamples, 5\nFactory, 5\nLicense, 3\nMake\fle, 4\nReader, 5\nROOT\ncompatibility, 5\nTMVAClassi\fcation, 5\nTMVAClassi\fcationApplication, 5\nTMVARegression, 5\nTMVARegressionApplication, 5 Conclusions and Plans\n\u000fArti\fcial Neural Networks\nSigni\fcant work went into the implementation of fast feed-forward multilayer perceptron algo-\nrithms into TMVA. Two external ANNs have been integrated as fully independent abstract representation of the solution domain, a \ftness function\nmust be de\fned. In cut optimisation, the \ftness of a rectangular cut is given by good background.\nIt performs well for nonlinear discrimination and is insensitive to overtraining. Optimisation is\nstraightforward due to a low number of adjustable parameters (only two in the case of Gaussian\nkernel). The response speed is slower than for a not-too-exhaustive neural network, but\ncomparable with other nonlinear introduction. The complete model then reads\nyRF(x) =a0+MRX\nm=1amrm(x) +nvarX\ni=1bixi: (93)\nTo protect against outliers, the variables in the linear terms are modi\fed to\nx0\ni= min(\u000e+\ni;max(\u000e\u0000\ni)); (94)\nwhere\u000e\u0006\niare the lower and upper \fquantiles32of the variable xi. The value of \fis set by the\noption LinQuantile . If the variables are used \\as is\", they may have an unequal a priori in\ruence\n32Quantiles are points taken at regular intervals from the PDF of a random variable. For example, the 0.5 quantile\ncorresponds to the median of the PDF.112 8 The TMVA acknowledgments on page 126.\n2For the BSD l icense, see http://tmva.sourceforge.net/LICENSE .4 2 TMVA Quick Start\n2 TMVA Quick Start\nTo run TMVA it is not necessary to know much about its concepts or to understand the detailed\nfunctionality of the multivariate Background ,Regression ) by attaching <class\nname> to the user option { where <class name> has to be replaced by the actual class name (e.g.,\nSignal ) { which de\fnes the transformation (e.g., VarTransform=G Signal ). A complex transfor-\nmation option might hence look like VarTransform=D,G Signal,N . The attachment AllClasses\nis equivalent to the default, where events from all classes are used.\n4.2 Binary search trees\nWhen frequent iterations over the training sample need to be performed, it is helpful to sort the\nsample before using it. Event sorting in binary trees is employed by the MVA references their values are known to\nthe MVA Appendix A\non page 128 for a complete booking list of all MVA discussion to classi\fcation applications. A boosted classi\fer is a combination of a collection of\nclassi\fers of the same type trained on the same sample but with di\u000berent events weights.33The\nresponse of the \fnal classi\fer is a weighted response of each individual classi\fer in the collection. The\nboosted classi\fer is potentially more powerful and more stable with respect to statistical \ructuations\nin the training sample. The latter is particularly the case for bagging as \\boost\" algorithm (cf.\nSec. 7.3, page"], "bleu": 0.15743966673766163, "rouge_l": 0.31144067796610164, "gpt_metric_score": 0.5, "bert_score": 0.268525630235672}
{"paper_key": "Learning Parameterized Quantum Circuits with Quantum Gradient", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively leverage quantum algorithms to enhance the learning of parameterized quantum circuits (PQCs) and overcome challenges such as gradient vanishing and barren plateaus in high-dimensional Hilbert spaces?\n\n---\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for advancing the field of quantum machine learning and quantum computation. By improving the learning of PQCs, we can enable more efficient quantum algorithms that can operate on noisy intermediate-scale quantum devices, ultimately leading to practical applications in quantum simulation, optimization, and complex state preparation. This research could pave the way for future studies that explore more sophisticated quantum algorithms and architectures, enhancing our understanding of quantum systems and their capabilities.\n\n---\n\n**[Question 3] - Why is it hard?**  \nThe challenges in solving this problem stem from the complexities of high-dimensional Hilbert spaces, where traditional classical optimization methods struggle due to issues like gradient vanishing and barren plateaus. Naive approaches may fail because they do not adequately account for the intricate geometry of the Hilbert space or the specific characteristics of PQCs. Additionally, the exponential growth of the Hilbert space with increasing circuit size complicates the optimization landscape, making it difficult to find optimal parameter configurations.\n\n---\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has primarily focused on classical optimization techniques, which have limitations in addressing the unique challenges posed by PQCs, such as gradient vanishing due to the expanding Hilbert space. Existing solutions have not effectively integrated quantum algorithms into the learning process of PQCs. Our approach differs by introducing a nested optimization model (NOM) that utilizes quantum gradient algorithms in the complex domain, directly addressing the shortcomings of prior methods and providing a more robust framework for PQC learning.\n\n---\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves the development of a nested optimization model (NOM) that employs quantum gradient algorithms to optimize polynomial-type cost functions directly within the geometry of the Hilbert space. We will utilize a dataset of parameterized quantum circuits and evaluate the performance using metrics such as training efficiency and sample efficiency. The expected outcomes include enhanced training efficiency by mitigating gradient vanishing, reduced resource overhead, and improved management of barren plateaus, ultimately demonstrating the effectiveness of our quantum-based approach in learning PQCs.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question we aim to address is: How can a hybrid quantum-classical algorithm effectively leverage noisy intermediate-scale quantum (NISQ) devices to perform real-time anomaly detection in large-scale distributed datasets?\n\n[Question 2]: Why is it interesting and important?  \nThe significance of this research lies in the increasing volume and complexity of data generated in various domains, such as finance, healthcare, and IoT, where timely anomaly detection is crucial for ensuring operational integrity and security. Current classical methods often struggle with the high dimensionality and dynamic nature of these datasets, leading to delayed responses to anomalies. By developing a hybrid quantum-classical approach, this research has the potential to revolutionize the field of anomaly detection, offering enhanced accuracy and efficiency. The implications extend to improving machine learning applications, enabling real-time data processing, and paving the way for future research that explores the integration of quantum computing with classical techniques, ultimately advancing our understanding of data analysis in complex environments.\n\n[Question 3]: Why is it hard?  \nSolving this problem involves multiple challenges and complexities. Firstly, the inherent noise and limited coherence times of NISQ devices pose significant technical obstacles, making it difficult to achieve reliable quantum state measurements necessary for anomaly detection. Secondly, designing parameterized quantum circuits (PQCs) that can dynamically adjust detection thresholds in response to streaming data requires advanced theoretical frameworks that combine quantum mechanics with machine learning principles. Naive approaches may fail because they overlook the need for real-time adaptability and the complexities associated with quantum state manipulation. Additionally, the integration of quantum finite automata for pattern recognition introduces further theoretical complexities, as it necessitates a deep understanding of quantum algorithms and their interaction with classical data processing frameworks.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research in anomaly detection has primarily focused on classical algorithms, often neglecting the unique capabilities offered by quantum computing. Limitations in prior studies include a lack of exploration into the potential of NISQ devices for real-time applications and insufficient methodologies to integrate quantum coherence into existing data processing frameworks. Barriers such as the underutilization of PQCs and the challenges of quantum noise have hindered progress in this area. Our approach differs by specifically targeting the synergy between quantum and classical systems, utilizing PQCs and quantum finite automata to enhance detection capabilities, thus providing a more comprehensive methodology for tackling the complexities of large-scale distributed datasets.\n\n[Question 5]: What are the key components of my approach and results?  \nOur proposed methodology will involve the development of a hybrid quantum-classical algorithm that incorporates PQCs for adaptive thresholding and quantum finite automata for enhanced pattern recognition. The algorithm will be tested on large-scale datasets, with a focus on real-time streaming data to evaluate its anomaly detection capabilities. We will employ metrics such as precision, recall, and F1 score to measure the effectiveness of the algorithm. Expected outcomes include improved anomaly detection accuracy and reduced computational overhead compared to classical methods, demonstrating the practicality of quantum enhancements in machine learning applications. This framework aims to establish a new paradigm in anomaly detection, leveraging quantum resources to push the boundaries of what is currently achievable in data analysis.", "referenced_intros": [], "bleu": 0.1794717667540892, "rouge_l": 0.315450643776824, "gpt_metric_score": 0.5, "bert_score": 0.25856611132621765}
{"paper_key": "Seeing the Invisible through Speckle Images", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively extract and enhance information from speckle patterns generated by coherent waves passing through inhomogeneous media, particularly in the context of optical and ultrasound imaging?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for advancing imaging and sensing technologies, especially in medical diagnostics and environmental monitoring where coherent waves are used. Improved methods for interpreting speckle patterns can lead to better image fidelity and accuracy, enhancing the capabilities of optical systems in turbid media. This research could pave the way for novel applications in real-time imaging and dynamic monitoring, significantly impacting fields such as biomedical imaging, telecommunications, and materials science.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in addressing this problem stem from the complex nature of speckle patterns, which are influenced by multiple scattering events and environmental variations. Naive approaches may fail due to the high dimensionality and noise inherent in the data, making it difficult to distinguish meaningful signals from random fluctuations. Additionally, the need for real-time processing and the variability introduced by dynamic environments complicate the extraction of reliable information. Overcoming these technical and theoretical obstacles requires sophisticated algorithms and robust experimental setups.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on either the theoretical aspects of speckle formation or on specific applications without addressing the comprehensive extraction of information from speckle patterns in dynamic environments. Limitations in computational power, algorithmic sophistication, and the understanding of scattering phenomena have hindered progress. Additionally, many existing solutions do not account for the variability introduced by environmental factors, which is critical for practical applications. Our approach aims to integrate advanced machine learning techniques with experimental data to improve upon these prior limitations.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves using machine learning algorithms to analyze speckle patterns collected from a controlled experimental setup, where coherent light interacts with various scattering media. We will utilize the MNIST dataset as a modulation phase map to train our models, focusing on metrics such as the Pearson correlation coefficient (PCC) and the structural similarity index measure (SSIM) to evaluate image fidelity. The expected outcomes include enhanced image reconstruction and classification accuracy, leading to improved performance in imaging applications through turbid media.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can a hybrid Position-aware and Identity-aware Graph Neural Network (GNN) framework, which incorporates computational imaging features, enhance image reconstruction tasks in dynamic environments?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is crucial for advancing the field of computational imaging, particularly in scenarios where real-time analysis of dynamic scenes is essential, such as autonomous driving, robotics, and surveillance. The proposed framework not only aims to improve the accuracy of image reconstruction but also enriches contextual understanding through the integration of multi-modal knowledge graphs that combine visual and textual data. This approach could lead to significant advancements in the research community, paving the way for innovative applications that require sophisticated image processing capabilities. Furthermore, addressing this question could lead to practical applications in various industries, enhancing decision-making processes in environments that require immediate interpretation of complex visual information.\n\n[Question 3]: Why is it hard?  \nThe challenges in solving this problem stem from the inherent complexities of dynamic environments, where the spatial and temporal aspects of data continuously evolve. Traditional image reconstruction methods may fail due to their inability to adapt rapidly to changes in node representations or their lack of context-awareness. A naive approach would not sufficiently account for the dual influences of positional context and identity, leading to suboptimal performance. Additionally, integrating machine learning techniques with quantum walk-based search algorithms introduces further complexities, as it requires a nuanced understanding of both graph structures and the underlying dynamics of the data. Overcoming these technical and theoretical obstacles is essential for achieving effective real-time image reconstruction.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research in computational imaging has often focused on either positional or identity information in isolation, neglecting the synergistic potential of integrating both aspects. Additionally, existing solutions typically do not leverage the dynamic capabilities offered by graph neural networks in conjunction with multi-modal knowledge graphs. Barriers such as the lack of robust datasets that capture the nuances of dynamic environments and the computational demands of integrating advanced algorithms have hindered progress. My approach differs from prior work by explicitly addressing these gaps through a comprehensive framework that combines the strengths of position-aware and identity-aware GNNs while utilizing quantum walk-based search algorithms to enhance adaptability and efficiency.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing a hybrid GNN framework that integrates computational imaging features with a multi-modal knowledge graph. The dataset will encompass diverse dynamic scenes, combining visual data with corresponding textual information to enrich contextual understanding. Performance metrics will include reconstruction accuracy, adaptability in dynamic scenarios, and computational efficiency. Expected outcomes include improved image reconstruction capabilities in real-time applications, enhanced contextual awareness through multi-modal integration, and increased efficiency in navigating complex graph structures associated with imaging data. This comprehensive approach is anticipated to yield significant advancements in the accuracy and adaptability of computational imaging tasks.", "referenced_intros": [], "bleu": 0.18166002421732427, "rouge_l": 0.30666666666666664, "gpt_metric_score": 0.5, "bert_score": 0.30957719683647156}
{"paper_key": "MedBench: A Comprehensive, Standardized, and Reliable Benchmarking System for Evaluating Chinese Medical Large Language Models", "current_5q": "### [Question 1] - What is the problem?\nHow can we establish a comprehensive and standardized benchmarking framework for evaluating Medical Large Language Models (MLLMs) in the Chinese healthcare context?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem is crucial for the research community as it will provide a reliable means to assess the efficacy of MLLMs, ensuring their safe and effective deployment in healthcare. A standardized benchmarking framework will facilitate comparisons across different models, leading to improved performance and trust in AI applications in medicine. This advancement could significantly enhance patient care, streamline clinical workflows, and foster further research into specialized medical applications of LLMs, ultimately contributing to better health outcomes.\n\n### [Question 3] - Why is it hard?\nThe challenges in solving this problem include the need for a comprehensive coverage of diverse medical specialties, as existing benchmarks primarily focus on general clinical knowledge. Naive approaches may fail because they do not account for the specific requirements and nuances of various medical fields, leading to inadequate evaluations. Additionally, the lack of a standardized evaluation infrastructure results in inconsistent testing conditions, making it difficult to draw reliable conclusions about model performance. Overcoming these technical and practical obstacles is essential for creating a robust benchmarking system.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has been limited by a focus on general clinical knowledge without adequately addressing the breadth of medical specialties. Existing benchmarks have not established a standardized evaluation process, leading to variability in how models are assessed. Barriers such as insufficient collaboration among researchers and a lack of comprehensive datasets have hindered progress. Our approach aims to fill these gaps by developing a unified framework that encompasses a wider range of medical specialties and establishes consistent evaluation metrics, thereby improving upon prior work.\n\n### [Question 5] - What are the key components of my approach and results?\nOur proposed methodology involves creating a comprehensive benchmarking framework that includes a diverse set of tasks: Multiple Choice Questions (MCQ), Close Question Answering (QA), Open QA, and Information Extraction (IE). We will utilize datasets such as the National Medical Licensing Examination in China and others, applying metrics like accuracy, BLEU score, ROUGH-L score, and micro-averaged F1-score to evaluate model performance. The expected outcomes include a standardized evaluation process that enhances the reliability of MLLMs, leading to improved performance across various medical specialties and ultimately contributing to better healthcare solutions.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question we aim to address is: How can a novel multimodal diagnostic framework that leverages large vision-language models (LVLMs) enhance the diagnostic accuracy for brain disorders through the integration of graph convolutional networks and reinforcement learning?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is critical for improving diagnostic accuracy in brain disorders, which often present with overlapping symptoms and can be challenging to diagnose accurately. Enhancing diagnostic pathways through our proposed framework could significantly impact the research community by providing a new paradigm for integrating multimodal data, thus paving the way for future studies on AI-assisted diagnostics. Moreover, this research could lead to practical applications in clinical settings, particularly for rare diseases where data is scarce, ultimately resulting in improved patient outcomes and more effective healthcare delivery.\n\n[Question 3]: Why is it hard?  \nThe complexities involved in solving this problem arise from the need to effectively integrate diverse imaging modalities (such as MRI and CT) while dynamically adapting to patient-specific features in real-time. Naive approaches may fail due to the high dimensionality and variability of medical imaging data, as well as the intricacies of contextual reasoning required to interpret this data accurately. Additionally, challenges related to the reinforcement learning component, such as defining appropriate reward structures and managing exploration-exploitation trade-offs, must be addressed. There are also practical obstacles, including the need for extensive training datasets and the integration of real-time dialogue systems for effective communication with healthcare professionals.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research often focused on single-modality approaches or did not employ advanced AI techniques like LVLMs and reinforcement learning, leading to limited diagnostic accuracy. Gaps in interdisciplinary collaboration between computer science and medical imaging have hindered the development of comprehensive solutions. Moreover, existing frameworks often fail to account for the dynamic nature of patient data and the necessity for real-time communication in clinical settings. Our approach differs by integrating graph convolutional networks with reinforcement learning and incorporating a dialogue system, thus addressing these limitations and creating a more robust diagnostic framework.\n\n[Question 5]: What are the key components of my approach and results?  \nOur proposed methodology will involve developing a multimodal diagnostic framework that integrates LVLMs for contextual reasoning, graph convolutional networks for data representation, and reinforcement learning for adaptive modality selection. We will utilize a dataset comprising diverse brain imaging modalities and clinical features from various patient populations. The performance of our framework will be evaluated using metrics such as diagnostic accuracy, sensitivity, and specificity. Expected outcomes include enhanced diagnostic recommendations, improved communication between healthcare professionals and patients, and a scalable model that can be adapted for various neurological disorders, ultimately contributing to advanced clinical decision support systems.", "referenced_intros": [" \n\n1 Introduction\n\nRecently, there has been a surge in the popularity of deep learning foundation models, particularly in the fields of natural language processing and computer vision. As a result, many milestone works have been proposed, such as Vision Transformers (ViT)\u00a0Dosovitskiy et\u00a0al. (2021), Generative Pretrained Transformers (GPT)\u00a0Radford et\u00a0al. (2018), Contrastive Language-Image Pretraining (CLIP)\u00a0Radford et\u00a0al. (2021), and Segment Anything (SAM)\u00a0Kirillov et\u00a0al. (2023). As the size (number of parameters) of these models grows bigger, the capacity of the models increases while the requirement of assembled data for training also inflates, following the scaling law\u00a0Kaplan et\u00a0al. (2020). However, for specific domains like medicine, the shortage of public availability and quality annotations has been the bottleneck for training large-scale deep learning models. Therefore, a variety of learning paradigms has been researched to overcome the roadblock besides the conventional and monotone routine of finetuning the pre-trained model (e.g., ImageNet pre-trained models\u00a0Deng et\u00a0al. (2009)) using domain-specific data with labels.\n\n\nOne straightforward solution is to develop model adaptation techniques for medical downstream applications by leveraging the existing foundation models from other domains, especially when techniques like prompt engineering with the availability of cloud-deployed large-scale foundation models (in both highly paralleled computation and worldwide network capacity) become a reality. In this case, a foundation model, often trained with thousands of millions of multiple modalities of data, could serve as the base for building medical applications with a single or a few cases in the form of prompts. It is logically more feasible to provide such a few differentiable sample cases from a real-world scenario for the model adaptation, and it also complies with the training process of professionals in the biomedical field, e.g., medical residents and laboratory trainees.\nFew-shot methods could leverage more on the distinctive representation produced by the foundation models, which has succeeded in considerable language modeling\u00a0Brown et\u00a0al. (2020) and vision\u00a0Dhillon et\u00a0al. (2019); Tian et\u00a0al. (2020) tasks. It also fits perfectly for the long-tailed scenario when only a few rare disease cases are available for the training.\n\n\nFigure 1: OpenMEDLab: an open-source platform for facilitating medical foundation models. \n\n\nNevertheless, medical data could vary greatly in format, source, modality, and characteristics. Representations from the foundation models (trained with more general data, e.g., natural image and free-text natural language corpus) may not cover the domain features seamlessly. That\u2019s also why finetuning the foundation models (or pre-trained models in a supervised way, e.g., ImageNet pre-trained models) for each downstream application directly remains popular. Nonetheless, it usually employs data with labels and tunes the models in a supervised fashion. They aim to solve individual downstream tasks by utilizing the robust representation learning and generalization abilities of foundation models. One of the major drawbacks is that it remains a tedious and time-consuming job for medical professionals to hand-label volumetric data repeatedly, although attempts are made to utilize weak labels\u00a0Lei et\u00a0al. (2023a) and contextual information from the longitudinal data\u00a0Wu et\u00a0al. (2023a).\nTherefore, adding an additional adaptation step could make more sense by adjusting the representation from generalist foundation models according to the domain knowledge\u00a0Moor et\u00a0al. (2023).\nMoreover, there are also pioneering works toward learning medical generalist/foundation models, e.g., BioGPT\u00a0Luo", " \n\n1 Introduction\n\nRecently, Large Vision-Language Models (LVLMs) have exhibited remarkable advancements across various domains, including embodied AI [85], autonomous driving [121], and remote sensing [67]. Encouraged by their achievements, a growing number of LVLMs tailored for medical applications have emerged, claiming impressive performance across a wide spectrum of medical challenges [84, 117, 127, 71]. However, despite the growing attention these models have obtained, there has been a noticeable lack of comprehensive evaluations, particularly when it comes to real medical images, which strongly hinders a thorough understanding of their applicability and performance in medical contexts [116].\n\n\nWe attribute this challenge to the absence of a comprehensive and diverse evaluation benchmark, one that encompasses images captured from various modalities and covers a broad spectrum of human anatomies. In more detail, the ability to answer questions based on a given image is fundamental, yet critically important in evaluating the performance of LVLMs. To facilitate this purpose, a comprehensive Visual Question Answering (VQA) dataset is indispensable. However, as indicated in Table\u00a01, the majority of existing VQA datasets suffer from size limitations. Moreover, many of them provide only a limited number of modalities and focus exclusively on specific aspects of human anatomy. Consequently, these datasets do not meet the requirements for a comprehensive evaluation of LVLMs in the medical domain.\n\n\nTable 1: The comparison of the number of modalities, images and question-answering items in different medical VQA datasets. \u2020 indicates we calculate the numbers by ourselves, without the official statistic could be directly adopted.\n\n\nDataset\n# Modalities\n# Images\n# QA Items\n\n\nVQA-RAD [69]\n\n3\n315\n3515\n\n\nSLAKE [75]\n\n3\n642\n14,028\n\n\nPath-VQA [122]\n\n2\u2020\n\n4998\n32,799\n\n\nVQA-Med [24]\n\n5\u2020\n\n4500\n5500\n\n\nOmniMedVQA\n12\n118,010\n127,995\n\n\n\n\nTable 2: Comparison of Different LVLMs. VE, ToP and TuP indicate the visual encoder, number of total parameters and tuning parameters, respectively. \u2020 indicates that the model is frozen. CC\u2217 consists of COCO [34], CC3M [105], and CC12M [32]. CC, VG, SBU CY, and L400 indicate Conceptual Caption [105, 32], Visual Genome\u00a0[66], COYO-700M [27] and LAION 400M\u00a0[101], respectively. LLaVA-I and G4L represent 158K multimodal instruction-following data in LLaVA [77] and data generated by GPT-4 for building an instruction-following LLMs [92]. QA\u2217 denotes 13 question-answering datasets in InstructBLIP [41].\n\n\n\nModel\nModel Configuration\nImage-Text Data\nVisual Instruction Data\n\n\nVE\nLLM\nToP\nTuP\nSource\nSize\nSource\nSize\n\n\n\nBLIP2 [73]\n\n\nViT-g/14\u2020\n\n\nFlanT5-XL\u2020\n\n4B\n107M\n\nCC\u2217-VG-SBU-L400\n\n129M\n-\n-\n\n\n\nLLaVA [77]\n\n\nViT-L/14\u2020\n\nVicuna\n7B\n7B\nCC3M\n595K\nLLaVA-I\n158K\n\n\n\nLLaMA_Adapter_v2 [48]\n\n\nViT-L/14\u2020\n\n\nLLaMA\u2020\n\n7B\n63.1M\nL400\n200M\nLLaVA-I+G4L\n210K\n\n\n\nMiniGPT-4 [128]\n\n\nBLIP2-VE\u2020\n\n\nVicuna\u2020\n\n7B\n3.1M\nCC-SBU-L400\n5M\nCC+ChatGPT\n3.5K\n\n\n\nmPLUG-Owl [123]\n\nViT-L/14\n\nLLaMA\u2020\n\n7B\n1.1B\n\nCC\u2217-CY-L400\n\n204M\nLLaVA-I\n158K\n\n\n\nOtter [70]\n\n\nViT-L/14\u2020\n\n\nLLaMA\u2020\n\n9B\n1.3B\n-\n-\nLLaVA-I\n158K\n\n\n\nInstructBLIP [41]\n\n\nViT-g/14\u2020\n\n\nVicuna\u2020\n\n7B\n107M\n-\n-\n\nQA\u2217\n\n16M\n\n\n\nVPGTrans [125]\n\n\nViT-g/14\u2020\n\n\nVicuna\u2020\n\n7B\n107M\nCOCO-VG-SBU\n13.8M\nCC+ChatGPT\n3.5K\n\n\n\nMed-Flamingo [84]\n\n\nViT-L/14\u2020\n\n\nLLaMA \u2020\n\n8.3B\n1.3B\nMTB, PMC-OA\n2.1M\n-\n-\n\n\n\nRadFM [117]\n\nViT-3D\nLLaMA\n14B\n14B\nMedMD\n16M\nRadMD\n3M\n\n\n\nMedVInT_TE [127]\n\nResNet-50\n\nLLaMA\u2020\n\n7B\n156.4M\nPMC-OA\n1.64M\nPMC-VQA\n152k\n\n\n\nLLaVA-Med [71]\n\n\nViT-L/14\u2020\n\nVicuna\n7B\n7B\nPMC-15M\n600K\nPMC-15M + GPT4\n60K\n\n\n\n\n\nTo address this challenge, this paper introduces OmniMedVQA, a large-scale and comprehensive Visual Question Answering benchmark designed for the medical domain. Considering the scarcity of medical image-text data, we collect numerous medical classification datasets and then transfer these data to VQA format according to their classification attribute based on the powerful context reasoning capacity of GPT. Generally speaking, OmniMedVQA boasts two primary highlights. First, it encompasses images from 12 different modalities, including MRI, CT, X-Ray, histopathology, fundus photography, et al., resulting in a highly diverse dataset. Importantly, all these images originate from real medical scenarios, aligning OmniMedVQA closely with real-world applications. Second, OmniMedVQA covers over 20 distinct human anatomical regions. As illustrated in Fig\u00a01, OmniMedVQA spans from the brain to the extremities, which facilitates a more comprehensive evaluation of different LVLMs and calls for a more versatile medical LVLM. Moreover, for the convenience of evaluation, we assign the incorrect options to", " \n\n1. Introduction\n\nThe rise of foundation models (FMs) strikes a wave of breakthroughs for visual recognition\u00a0(Radford et\u00a0al., 2021; Kirillov et\u00a0al., 2023; Ramesh et\u00a0al., 2021), language understanding\u00a0(Devlin et\u00a0al., 2018; Brown et\u00a0al., 2020; OpenAI, 2021, 2023), and knowledge discovery\u00a0(Bommasani et\u00a0al., 2021; Pan et\u00a0al., 2023).\nIn computational healthcare\u00a0(Esteva et\u00a0al., 2019; Aggarwal et\u00a0al., 2021), FMs can handle a variety of clinical data with their appealing capabilities in logical reasoning and semantic understanding. Examples span fields in medical conversation\u00a0(Shu et\u00a0al., 2023; Yunxiang et\u00a0al., 2023), patient health profiling\u00a0(Christodoulou et\u00a0al., 2019), and treatment planning\u00a0(Nori et\u00a0al., 2023).\nMoreover, given the strength in large-scale data processing, FMs offer a shifting paradigm to assess real-world clinical data in the healthcare workflow rapidly and effectively\u00a0(Thirunavukarasu et\u00a0al., 2023; Qiu et\u00a0al., 2023).\n\n\nFM research places a sharp focus on the data-centric perspective\u00a0(Zha et\u00a0al., 2023).\nFirst, FMs demonstrate the power of scale, where the enlarged model and data size permit FMs to capture vast amounts of information, thus increasing the pressing need of training data quantity\u00a0(Vaswani et\u00a0al., 2017).\nSecond, FMs encourage homogenization\u00a0(Bommasani et\u00a0al., 2021) as evidenced by their extensive adaptability to downstream tasks. High-quality data for FM training thus becomes critical since it can impact the performance of both pre-trained FM and downstream models.\nTherefore, addressing key data challenges is progressively recognized as a research priority.\nIn the healthcare system, collecting high-quality records could enable a comprehensive understanding of patient characteristics (imaging, genomics, and lab testing data)\u00a0(Johnson and Khoshgoftaar, 2023; Singh, 2023; Alfasly et\u00a0al., 2023). As illustrated, data-centric strategies promise to reshape clinical workflow\u00a0(Rao et\u00a0al., 2023; Juluru et\u00a0al., 2021), enable precise diagnosis\u00a0(Hunter et\u00a0al., 2022), and uncover insights into treatment\u00a0(Chen et\u00a0al., 2023a).\n\n\nFigure 1. Data-centric foundation models in computational healthcare.\n\n\nMedical data challenges have posed persistent obstacles over decades, including multi-modality data fusion (Section\u00a04), limited data volume (Section\u00a05), annotation burden (Section\u00a06), and the critical concern of patient privacy protection (Section\u00a07) (Chen et\u00a0al., 2021a; Hathaliya and Tanwar, 2020; Huang et\u00a0al., 2020; Rajpurkar et\u00a0al., 2022).\nTo respond, the FM era opens up perspectives to advance data-focused AI analytics.\nMulti-modal FMs, as a concrete example, can offer scalable data fusion strategies for various data formats\u00a0(Li et\u00a0al., 2023a; Ding et\u00a0al., 2023c).\nMeanwhile, the appealing trait of FM to generate high-quality data can greatly help address data quantity, scarcity, and privacy in the medicine and healthcare community\u00a0(Tang et\u00a0al., 2023a; Ding et\u00a0al., 2023c; Chambon et\u00a0al., 2022; Lu et\u00a0al., 2022; Zhao and Bilen, 2023; Van\u00a0Noorden and Perkel, 2023).\nTo build responsible solutions for healthcare AI, the evolving perspective on AI-human alignment\u00a0(Gabriel, 2020; Ngo et\u00a0al., 2022) has become increasingly important.\nWe discuss the necessity of the real-world applications of FMs aligned with human ethics, equity, and societal norms to reduce potential risks in performance assessment, ethical compliance, and patient safety\u00a0(Liu et\u00a0al., 2023d; Ozmen\u00a0Garibay et\u00a0al., 2023; Liang et\u00a0al., 2022; Hathaliya and Tanwar, 2020).\nIn the FM era, enabling AI-human alignment further underscores the significance of data focus, motivating us to prioritize the data-centric challenges in the landscape of computational healthcare.\n\n\n\n\n\n\n{forest}\nfor tree=draw, semithick, rounded corners, where level = 0top color = red!20, bottom color = red!20,\nwhere level = 1top color = yellow!20, bottom color = yellow!20,\nwhere level = 2top color = green!20, bottom color = green!20,\nwhere level = 3top color = blue!20,", " \n\n1 Introduction\n\nLarge Language Models (LLMs), such as ChatGPT\u00a0(OpenAI, 2023a), Claude\u00a0(Anthropic, 2023), Vicuna\u00a0(Chiang et\u00a0al., 2023), and InternLM\u00a0(InternLM-Team, 2023), have recently demonstrated powerful capabilities in various tasks and are gradually deployed to enormous users.\nHowever, some work\u00a0(Wei et\u00a0al., 2023a; Bommasani et\u00a0al., 2021; Goldstein et\u00a0al., 2023; Hazell, 2023; Li et\u00a0al., 2023; Deshpande et\u00a0al., 2023) points out LLMs may generate malicious content (e.g., toxic and biased speech, dangerous behavior guidelines, and privacy leaks), raising safety concerns.\n\n\nFigure 1: The performance comparison of common LLMs on some safety-related open-ended questions test sets (left) and multiple-choice test sets (right). The dashed line represents the average performance, and it is evident that LLMs\u2019 safety performance is poorer on multiple-choice questions. (CAP: Chinese-Alpaca-Plus)\n\n\n\n\n\nComparison\nOpen-ended\nMultiple-choice\n\n\nFormat\nQuestion\nQuestion with options\n\n\nSubjectivity\nMore subjective\nMore objective\n\n\nWay of judging\nManual or model-assisted\nAutomatic\n\n\nHuman difficulty\nHarder\nEasier\n\n\nLLMs difficulty\nEasier\nHarder\n\n\n\nTable 1: \nComparison of Open-ended format and Multiple-choice format in the safety evaluation.\n\n\n\nFigure 2: An example from the dataset we designed, each test question contains an open-ended question (above) and its corresponding multiple-choice question (below). LLMs often perform well in answering open-ended questions but struggle to select safe options correctly.\n\n\nMeanwhile, many benchmarks\u00a0(Hosseini et\u00a0al., 2017; Chen et\u00a0al., 2021; Liang et\u00a0al., 2022; Zhang et\u00a0al., 2023; Sun et\u00a0al., 2023a; Wang et\u00a0al., 2023; Xu et\u00a0al., 2023b, a; Huang et\u00a0al., 2023) have emerged to evaluate the safety of LLMs.\nMost of these test contents can be divided into two formats: open-ended questions and multiple-choice questions.\nIn the first format, the LLM gives its response to the question, and a human evaluator or other LLMs give a judgment on its safety; in the second format, the LLM chooses the one it thinks is better from multiple options, and then compares the answers to get a judgment.\nAdditionally, the former type focuses more on whether the output content of the LLM is safe, while the latter is more concerned with the LLM\u2019s critical ability, namely, whether the model can make safe decisions.\nThis is especially crucial in current intelligent agent applications centered around LLM.\nTherefore, we consider both formats equally important in evaluating LLMs safety.\nFrom a human perspective, multiple-choice questions tend to be simpler because the right answer is included in the options, and even when we are unsure about what the question should be answered, we can still compare the differences between multiple options and choose the better one.\nHowever, upon reviewing the existing evaluation results\u00a0(Xu et\u00a0al., 2023a; Zhang et\u00a0al., 2023; Sun et\u00a0al., 2023a; Wang et\u00a0al., 2023), we are surprised to discover that the majority of LLMs appear to exhibit lower safety performance on multiple-choice format compared to open-ended one.\nAs shown in Fig.\u20091, the average performance of LLMs on some common open-ended question test datasets is 94.94%, whereas their average performance on the multiple-choice format is notably lower at 78.3%.\n\n\nWhat causes such a significant disparity in evaluation performance?\nInspired by the mismatched generalization theory proposed by Wei et\u00a0al. (2023a), we believe that this is due to the model\u2019s safety training not effectively covering the scope of its pre-training capabilities.\nIn other words, LLMs merely memorize the answer style regarding safety questions but lack a genuine understanding of what content qualifies as safety, making them difficult to choose the right option.\nAs shown in Fig.\u20092,", " Introduction\nGoodhart\u2019s Law: \u201c When a measure be-\ncomes a target, it ceases to be a good\nmeasure .\u201d\nLarge language models (LLMs) have achieved\nremarkable success across a variety of real-world\napplications (Brown et al., 2020; Zhao et al., 2023;\nZhu et al., 2023). By pre-training large Transformer\nmodels on massive text corpora, LLMs can possess\nLLM\nRank-11\nLLM\nRank-1PerformanceImprovementBenchmark Data(Training/Test)\nPre-training DataRank-12Rank-10Rank-2Rank-3Figure 1: Illustration of the potential risk of data leak-\nage. Once the pre-training data with overlap to the\nbenchmark data is used for training LLM, its bench-\nmark performance would be greatly increased.\nexcellent task-solving capacities, i.e.,using zero-\nshot or few-shot prompting (Brown et al., 2020).\nTo better understand how LLMs evolve in model\ncapacity, it becomes essential to construct reliable\nevaluation benchmarks to test the ability level of\nLLMs in various tasks, e.g., knowledge reasoning\nand math problem solving.\nRecently, a surge of high-quality evaluation\nbenchmarks (Hendrycks et al., 2021; Huang et al.,\n2023) have been proposed to provide a comprehen-\nsive capability evaluation of LLMs. Typical bench-\nmarks include MMLU (Hendrycks et al., 2021) (for\nmeasuring multitask language understanding abil-\nity), Big-Bench (Srivastava et al., 2022) (for quan-\ntifying and extrapolating the capabilities of LLMs),\nand AGIEval (Zhong et al., 2023) (for evaluating\nthe abilities of tackling human-level tasks). These\nbenchmarks have made great efforts in creating\nor collecting test resources for evaluating the per-\nformance of LLMs. Based on these benchmarks,\none can conveniently examine the effect of new\ntraining strategies or monitor the training status\nof LLMs (either pre-training or supervised fine-\ntuning). It has become common to report the Results Analysis In Table 4, by comparing the\nperformance of the instruction-tuned LLMs (+Al-\npaca or +CodeAlpaca) with andwithout training\non the leaked data, we can see that the models with\nbenchmark leakage still underperform their non-\nleaked counterparts. For the HumanEval dataset,\nthe performance improvements of instruction tun-\ning for LLMs trained with leaked data only reach\napproximately 80% of those achieved by models\nthat are not trained on leaked data.\nThis indicates that benchmark leakage may lead\nto a decline in adaptation capability, constraining\nthe LLMs\u2019 ability to adapt or improve through\nsubsequent fine-tuning processes. Note that this\nfinding is derived when we fine-tune LLMs only\nwith the leaked data. To enhance the current find-\nings, it is also meaningful to conduct experiments involved continually train-\ning existing pre-trained LLMs with leaked data. We\ndo not have sufficient computational resources toinvestigate the impact when directly incorporating\nbenchmark leakage during the pre-training process.\nGiven that the pre-training dataset is significantly\nlarger than the benchmark data, introducing data\nleakage during pre-training might yield different\nfindings. Nonetheless, we strongly recommend\navoiding this situation as it would breaks the nature\nof zero-shot/few-shot evaluation.\nSecond, we did not explore more fine-grained\ndata leakage scenarios in this study, such as only\nleaking training examples without labels and vary-\ning the proportion of the leaked dataset. We en-\ncourage more research efforts into this issue with\nmore systematic studies.\nThird, we did not calculate the degree of con-\ntamination between the mainstream benchmarks\nand commonly-used pre-training datasets, which\ncould serve as an important reference for alerting\nLLM developers to adjust their evaluation settings.\nWhile we suggest that developers and benchmark\nmaintainers report contamination analyses, accu-\nrately and efficiently estimating the contamination\nrisk of each example in the benchmark is also a\nchallenging task. For example, the suggested n-\ngram hash algorithm may not detect semantic-level\nknowledge leakage risks. Discussion\nIn light of the potential risks of benchmark leakage,\nit is necessary to revisit", " \n\n1 Introduction\n\nRecently, Large language models (LLMs), e.g. ChatGPT\u00a0(OpenAI, 2022), LLaMA\u00a0(Touvron et\u00a0al., 2023), ChatGLM\u00a0(Zeng et\u00a0al., 2023), have been extensively applied in various fields. Through high-quality instruction fine-tuning and reinforcement learning based on human feedback (RLHF)\u00a0(Ouyang et\u00a0al., 2022), LLMs already have possessed stunning language comprehension, generation, and knowledge reasoning abilities. Overall, users are amazed by the excellent suggestion ability of LLMs.\n\n\nHowever, LLMs are deficient in \u201cquestioning\u201d which is an important way to proactively understand users needs in medical, psychological, educational and other application scenarios. When we engage in healthcare conversations with these LLMs (ChatGPT222https://chat.openai.com, ChatGLM333https://chatglm.cn, SparkDesk444https://xinghuo.xfyun.cn), they do not yet possess the ability to conduct multiple rounds of questioning, as presented in Appendix\u00a0B. The above LLMs generally provide reasonable and universal suggestions based on the single-turn instruction provided by users. However, in the real world, doctors often need to conduct multiple turns of questioning with patients in order to provide targeted advice, as shown in Figure\u00a01. During the user consultation, the doctor raised different questions in the first 9 turns of conversations to understand the specific situation of the baby. The above multi-turn questioning process can be defined as Chain of Questioning (CoQ). We found that the current LLMs lack CoQ capabilities because LLMs lack training data for multiple rounds of questioning during the instruction fine-tuning stage and RLHF stage. When researchers construct instructions and answers, on the one hand, they ignore multiple rounds of conversation history, and on the other hand, answers are usually suggestions rather than questions.\n\n\nFigure 1: Example of chain of questioning (CoQ). The sentence in red font presents the doctor\u2019s CoQ: a series of questions about cough time, cough sound, sputum status, fever status, examination, medication and treatment.\n\n\n\nAt present, research on LLMs in the health field mainly focuses on evaluating the performance of existing models, constructing suitable datasets, and fine-tuning instructions. Singhal et\u00a0al. (2022) proposed a medical Q&A benchmark MultiMedQA for evaluating the clinical knowledge QA abilities of LLMs. Li et\u00a0al. (2023) constructed a real doctor-patient dialogue dataset HealthCareMagic-100k, and used it to fine-tune the ChatDoctor based on LLaMA. Similar health LLMs have been released one after another, e.g. BenTsao (\u672c\u8349)\u00a0(Wang et\u00a0al., 2023b), ChatGLM-6B-Med\u00a0(Wang et\u00a0al., 2023b), DoctorGLM\u00a0(Xiong et\u00a0al., 2023), MedAlpaca\u00a0(Han et\u00a0al., 2023), ClinicalGPT\u00a0(Wang et\u00a0al., 2023a) and etc. These models are basically based on the assumption that \u201cusers can clearly describe their problems or situations\u201d. Therefore, during the model construction phase, the questioning ability of the model was not considered. Although these models have achieved well performance in the field of medical QA, they do not have the ability to ask users questions.\n\n\nFigure 2: Proportion of questions and suggestions in answers of BianQueCorpus.\n\n\n\nFigure 3: Construction process of BianQueCorpus dataset and BianQue model.\n\n\n\nTo enhance the questioning ability of LLMs, we constructed a multi-turn health conversation dataset named BianQueCorpus, in which the targets consist of balanced proportional questions (46.2%percent46.246.2\\%46.2 %) and suggestions (53.8%percent53.853.8\\%53.8 %), as shown in Figure\u00a02. Meanwhile, we present BianQue, a health LLM that is specifically designed for balancing the questioning and suggestion ability. The results on multi-turn health conversation dataset demonstrate that BianQue outperforms existing models and ChatGPT, especially", " Introduction\nMedical image segmentation plays a crucial role in the analysis of medical images by identifying\nand delineating various tissues, organs, or regions of interest. Accurate segmentation can assist\ndoctors in precisely identifying and locating areas of pathology, enabling more accurate diagnosis\nand treatment [ 1]. Furthermore, quantitative and qualitative analysis of medical images provides\ncomprehensive insights into the morphology, structure, and function of different tissues or organs,\nfacilitating disease research and discoveries [ 2]. However, most existing Results of interactive segmentation using SAM in various medical scenarios.\nTable 1: Comparison of SAM fine-tuning models. Our SAM-Med2D is a comprehensive fine-tuning\nmethod that supports multiple prompts on medical images to generate masks.\nModel Dataset (size)Encoder Prompts modeDecoder(or Adapter) Point Bbox Mask\nSAM-U [16] 6000 masks \u2718 \u2718 \u2714 \u2718 \u2718\nSAMed [17] 3779 masks \u2714 \u2718 \u2718 \u2718 \u2714\nAutoSAM [18] ACDC [19] \u2718 \u2718 \u2718 \u2718 \u2714\nMedSAM [20] \u223c1.1M masks \u2718 \u2718 \u2714 \u2718 \u2714\nMSA [21] 5 datasets \u2714 \u2714 \u2718 \u2718 \u2714\nSAM-Med2D (Ours) \u223c19.7M masks \u2714 \u2714 \u2714 \u2714 \u2714\nproven effectiveness, they only enhance SAM\u2019s segmentation capabilities within specific scenarios\nresembling the training dataset. As a result, their applicability is limited for more diverse medical\nimage segmentation tasks.\n2) Different prompt modes play important roles in different segmentation tasks when migrating SAM\nto the medical field. As shown in Figure 2 (c), a relatively accurate polyp mask can be obtained by\nusing the bounding box prompt. In contrast, the mask quality is poor when clicking on a foreground\npoint (column d). With an increasing number of clicks, the segmentation result gradually improves\nand even surpasses the performance of the bounding box prompt (e.g., liver segmentation). When\nsegmenting myocardium, using the bounding box prompt may include uninterested regions in the\nresult, while the point prompt allows us to gradually acquire the desired mask. Therefore, this paper\naims to fine-tune three prompt modes (point, bounding box, and mask) to meet the requirements\nof different scenarios in medical image segmentation tasks. According to Table 1, our approach\ninvolves a more comprehensive fine-tuning compared to other Related Work\nLarge-scale Vision Models (LVM). Inspired by large language models such as ChatGPT and GPT-\n44, researchers have developed similar LVM including [ 7,8,22,23,24,25,26]. These models\nexhibit outstanding zero-shot and few-shot generalization capabilities, enabling rapid adaptation\nand extension to target tasks or domains through pre-training and fine-tuning paradigms. Among\nthem, CLIP [ 23] provides a unified vision and language model that can be utilized for various tasks,\nincluding classification, detection, and visual question answering. Through extensive pre-training on\ntext and image pairs, this model has achieved impressive Methods\n3.1 Incorporation of Medical Knowledge into SAM\nRecent research has reaffirmed the pivotal role of training data volume in the learning capacity of\nlarge models [ 7,8,23]. By learning from larger-scale data, models can acquire richer domain-specific\nknowledge and adapt better to various application scenarios. Though trained on over 1B masks,\nSAM achieves suboptimal performance in the realm of medical image analysis due to the significant\n5domain gap between natural images and medical data. To address this gap, we have collected and\ncurated the largest medical image segmentation dataset to date. This dataset is composed of numerous\npublic and private datasets, ensuring comprehensive coverage and diversity. Figure 3 (b) illustrates\nthe dataset\u2019s 10 different imaging modalities and their", " \n\n1 Introduction\n\nOver the past two centuries, medical advancements have substantially increased human life expectancy. Medicine\u2019s effectiveness often hinges on experience, with veteran physicians typically outperforming novices. In parallel, large language models like ChatGPT are shaped by their vast data experiences. This mutual reliance on experiential learning between physicians and LLMs suggests a promising frontier for LLMs in the medical domain.\n\n\nMedical evaluation is highly professional.\nAlthough the future of LLMs for medicine is promising, their evaluation is a challenging topic. Deploying LLMs in hospitals raises significant ethical concerns that real-world feedback becomes difficult.\nExisting works on LLMs tend to leverage subjective evaluation\u00a0(Zheng et\u00a0al., 2023) where none of references is used during the assessment. However, the evaluation in medicine is much more professional than that of the general domain. For instance, assessing radiology-related issues poses a challenge for the public, a senior professor in medicine, or even a general practitioner.\nSubjective evaluation would be difficult to be scaled up since professional manual judging is expensive.\n\n\nBenchmark for medical knowledge.\nAnother school of evaluation protocol is objective evaluation, where the expected output has a clear reference. Certain protocols emphasize natural language understanding tasks that are not knowledge-intensive, as seen in studies (Zhang et\u00a0al., 2022; Peng et\u00a0al., 2019). In the era of Large Language Models (LLM), modern NLP evaluations underscore the significance of knowledge\u00a0(Huang et\u00a0al., 2023; Hendrycks et\u00a0al., 2021b). In biomedicine, a typical example to probe knowledge is BioLAMA\u00a0Sung et\u00a0al. (2021); however, it is tailored to evaluate masked language models instead of auto-regressive ones. Another benchmark is MultiMedBench\u00a0Tu et\u00a0al. (2023), covering question answer, report summarization, visual question answering, report generation, and medical image classification. Note that MultiMedBench is only in English.\n\n\nThe necessity to localize medical benchmark.\nDuring economic globalization, a unified medical standard may overlook the unique medical needs and practices of different regions and ethnic groups, indicating the necessity to localize medical benchmarks.\nFor example, in Asia, Traditional Chinese Medicine (TCM) not only offers profound insights and localized medical solutions in the prevention, treatment, and rehabilitation of diseases but also has formed a medical paradigm closely associated with regional, climatic, dietary, and lifestyle characteristics, over its long historical evolution. In TCM, a disease has two aspects: \"b\u00ecng\" and \"zh\u00e8ng\". The former is often translated as \"disease entity\". The latter, and more important one, is usually translated as \"pattern\". For example, the disease entity of a common cold might present with a pattern of wind-cold in one person, and with the pattern of wind-heat in another111https://en.wikipedia.org/wiki/Traditional_Chinese_medicine#Six_Excesses.\n\n\nSimultaneously, it poses significant challenges when applying the Western medical framework to a local environment, which needs cross-cultural communication and understanding. In terms of disease diagnosis, examination of the tongue and the pulse are among the principal diagnostic methods in TCM. For example, redness on the tip of the tongue might indicate heat in the Heart, while redness on the sides of the tongue might indicate heat in the Liver. For drugs, there are roughly 13,000 compounds used in China and over 100,000 TCM recipes recorded in the ancient literature. Therefore, we should adopt a native medical benchmark instead of a translated medical benchmark for a local", " INTRODUCTION\nUnderstanding the essence of intelligence and establishing whether a machine embodies it poses a\ncompelling question for scientists. It is generally agreed upon that authentic intelligence equips us\nwith reasoning capabilities, enables us to test hypotheses, and prepares for future eventualities [ 92].\nIn particular, Artificial Intelligence (AI) researchers focus on the development of machine-based in-\ntelligence, as opposed to biologically based intellect [ 136]. Proper measurement helps to understand\nintelligence. For instance, measures for general intelligence in human individuals often encompass\nIQ tests [12].\nWithin the scope of AI, the Turing Test [ 193], a widely recognized test for assessing intelligence\nby discerning if responses are of human or machine origin, has been a longstanding objective in AI\nevolution. It is generally believed among researchers that a computing machine that successfully\npasses the Turing Test can be considered as intelligent. Consequently, when viewed from a wider\nlens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent\nmodels and algorithms. With each emergence of a novel AI model or algorithm, researchers\ninvariably scrutinize its capabilities in real-world scenarios through evaluation using specific and\nchallenging tasks. For instance, the Perceptron algorithm [ 49], touted as an Artificial General\nIntelligence (AGI) approach in the 1950s, was later revealed as inadequate due to its inability\nto resolve the XOR problem. The subsequent rise and application of Support Vector Machines\n(SVMs) [ 28] and deep learning [ 104] have marked both progress and setbacks in the AI landscape.\nA significant takeaway from previous attempts is the paramount importance of AI evaluation,\nwhich serves as a critical tool to identify current system limitations and inform the design of more\npowerful models.\nRecently, large language models (LLMs) have incited substantial interest across both academic\nand industrial domains [ 11,219,257]. As demonstrated by existing work [ 15], the great performance\nof LLMs has raised promise that they could be AGI in this era. LLMs possess the capabilities to\nsolve diverse tasks, contrasting with prior models confined to solving specific tasks. Due to its\ngreat performance in handling different applications such as general natural language tasks and\ndomain-specific ones, LLMs are increasingly used by individuals with critical information needs,\nsuch as students or patients.\nEvaluation is of paramount prominence to the success of LLMs due to several reasons. First,\nevaluating LLMs helps us better understand the strengths and weakness of LLMs. For instance, the\nPromptBench [264] benchmark illustrates that current LLMs are sensitive to adversarial prompts,\nthus a careful prompt engineering is necessary for better performance. Second, better evaluations\ncan provide better guidance for human-LLMs interaction, which could inspire future interaction\ndesign and implementation. Third, the broad applicability of LLMs underscores the paramount\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.A Survey on Evaluation of Large Language Models 111:3\nLLMs\nevaluationWhat to evaluate\n(Sec. 3)Natural\nlanguage\nprocessingNatural language understanding:\n(1) Sentiment analysis: Bang et al. [6]/ Liang et al. [114]/ Lopez-Lira and Tang [129]/ Qin et al. [159]/ Wang et al. [218]/ Zhang et al. [251]\n(2) Text classification: Liang et al. [114] / Pe\u00f1a et al. [154] / Yang and Menczer [233]\n(3) Natural language inference: Lee et al. [105] / Qin et al. [159]\n(4) Others: Choi et al. [23] / Riccardi and Desai [166] / Tao et al.", " \n\n1 Introduction\n\nFoundation models pre-trained on large-scale data have recently showed success in various downstream tasks on medical images including classification [9], detection [34], and segmentation [32].\nHowever, medical data have various imaging modalities, and clinical data collection is expensive. It is arguable that a specific foundation model trained on some certain type of data is useful at the moment.\nIn this paper, we focus on endoscopic video, which is a routine imaging modality and increasingly studied in gastrointestinal disease diagnosis, minimally invasive procedure and robotic surgery. Having an effective foundation model is promising to facilitate downstream tasks that necessitate endoscopic video analysis.\n\n\nExisting work on foundation models for medical tasks, such as X-ray diagnosis [4] and radiology report generation [21, 22], involves pre-training on large-scale image-text pairs and relies on large language models to learn cross-modality features.\nHowever, since clinical routines for endoscopy videos typically do not involve text data, a pure image-based foundation model is currently more feasible.\nTo this end, we develop a video transformer, based on ViT B/16 [8], containing 121M parameters, which serves as the foundation model backbone for our video data.\nWe note that a similarly scaled foundation model in recent work [34] based on Swin UNETR [11] with 62M parameters has been successfully employed for CT scans. This would indicate that our video transformer could have sufficient capacity to model the rich spatial-temporal information of endoscopy videos.\n\n\nTo learn rich spatial-temporal information from endoscopy video data [12], our Endo-FM is pre-trained via a self-supervised manner by narrowing the gap between feature representations from different spatial-temporal views of the same video.\nThese views are generated to address the variety of context information and motions of endoscopy videos.\nDrawing inspiration from self-supervised vision transformers [6, 30], we propose to pre-train the model via a teacher-student scheme. Under this scheme, the student is trained to predict (match) the teacher\u2019s output in the latent feature space.\nIn other words, given two spatial-temporal aware views from the same video, one view processed by the teacher is predicted by another one processed by the student to learn the spatial-temporal information.\nTherefore, designing effective and suitable matching strategies for different spatial-temporal views from the same endoscopy video is important.\n\n\nIn this paper, we propose Endo-FM, a novel foundation model designed for endoscopic video analysis. First, we build a video transformer based on ViT [8] to capture long-range spatial and temporal dependencies, together with dynamic spatial-temporal positional encoding designed for tackling input data with diverse spatial sizes and temporal frame rates. Second, Endo-FM is pre-trained under a teacher-student scheme via spatial-temporal matching on diverse video views. Specifically, we create various spatial-temporal aware views differing in spatial sizes and frame rates for an input video clip. Both teacher and student models process these views of a video and predict one view from another in the latent feature space. This enables Endo-FM to learn spatial-temporal invariant (to view, scale, and motion) features that are transferable across different endoscopic domains and disease types while retaining discriminative features that are specific to each context. We construct a large-scale endoscopic video dataset by combining 9 public and a new private", "\nBackground & Summary\n\nIn the new trend of training even larger and universal foundation models (e.g., Vision Transformers\u00a0[1], GPTs\u00a0[2], PubmedBERT\u00a0[3], and CLIP\u00a0[4]) using thousands of millions of data samples (sometimes in multiple modalities), developing cost-effective model adaptation methods for detailed applications become the new gold, especially when it only demands very few data samples. On the other side, the shortage of publicly accessible datasets in medical imaging has largely blocked the development and application of large-scale deep learning models (training from scratch) in many clinical downstream tasks. It is because obtaining quality annotations remains a tedious task for medical professionals, e.g., hand-label volumetric data repeatedly. Providing a few textbook sample cases is more logically feasible and complies with the training process of medical residents. In the domain of medical image analysis, it is even more valuable to promote such learning paradigms when diseased cases are often rare in comparison to the numerous amount of normal population.\n\n\nThe common fine-tuning scheme\u00a0[5] with ImageNet\u00a0[6] pre-trained models can diminish the need of large-scale data for the train-from-scratch scheme. However, it still requires a fair amount of data for faster fine-tuning while avoiding overfitting. Alternatively, few-shot methods could leverage more on the distinctive representation produced by the foundation models, which has succeeded in considerable language modeling\u00a0[7] and vision\u00a0[8, 9] tasks. The existing techniques of adapting foundation models in medical image analysis\u00a0[10, 11] demand the employment of dedicated medical pre-trained models that is hard to produce even if self-supervised learning is utilized. Recently, cutting-edge techniques, e.g., prompt-based learning\u00a0[12, 13], can leverage the foundation models pre-trained (via self-supervised learning, e.g., DINO\u00a0[14] and MAE\u00a0[15]) using vast amounts of data from multiple modalities and domains and transfer these universal representations to tasks with very limited data\u00a0[16, 17]. The fundamental difference in technical routine has started reshaping the landscape of medical image analysis.\nTherefore, it is in urgent demand to set up datasets and benchmarks to promote innovation in this fast-marching research field and properly evaluate the performance gain and other cost-effective aspects. There are benchmarks\u00a0[18, 19] for the few-shot learning tasks. Nonetheless, they focus more on each individual data modality and task. Here, we will instead promote the generalizability of the few-shot learning methods, i.e., strengthening their overall performance on various data modalities and tasks.\n\n\n\nIn this paper, we proposed a novel dataset, MedFMC, with 22,349 images in total, which encapsulates five representative medical image classification tasks from real-world clinical daily routines. Fig.\u00a01 presents sample images from each subset, and Table\u00a01 shows the summary of data, including modality, number of samples, image size, classification tasks, and number of classes. Different from many existing public datasets in the medical domain, e.g., Chest X-rays\u00a0[20, 21, 22], MSD\u00a0[23], and HAM10000\u00a0[24], the proposed dataset and benchmark do not target advancing and evaluating the performance of each individual task with the conventional full-supervised training paradigm, which may require larger amount of data individually. Instead, we believe that this new dataset (as a union) provides valuable support to develop and evaluate generalizable solutions of adapting foundation models to a variety of medical downstream applications, e.g., using few samples as the", " Introduction\nVision Foundation ModelModality-specific Foundation ModelsTask-specific Foundation Models\nOrgan-specific Foundation Models\nMedicalFoundation Models\nFigure 1: The spectrum of foundation models in medical image analysis.\nA salient distinction exists between traditional pretrained models and contemporary foundation models. The former Deng\net al. [2009], Vaswani et al. [2017], Devlin et al. [2018], Radford et al. [2018, 2019], Dosovitskiy et al. [2021] typically\nrequire extensive supervised fine-tuning to address specific downstream tasks, whereas the latter are capable of\nemploying few-shot learning, zero-shot learning, or prompt engineering to manage a wide variety of tasks with a\nsingular set of model weights Brown et al. [2020], Chowdhery et al. [2022], Ouyang et al. [2022], Touvron et al.arXiv:2306.05705v2  [cs.CV]  21 Nov 2023arXiv Template A P REPRINT\n[2023a,b], Google [2023]. Consequently, foundation models exhibit considerable generalizability and adaptability,\npositioning them as a focal point of recent machine learning (ML) research.\nIn the field of medical image analysis, however, task-specific ML models are still the main methods for medical image computing. Medical Image Analysis , 84:\n102727, 2023d.\nXiaoxiao Li, Yufeng Gu, Nicha Dvornek, Lawrence H Staib, Pamela Ventola, and James S Duncan. Multi-site fmri\nanalysis using privacy-preserving federated learning and domain adaptation: Abide results. Medical Image Analysis ,\n65:101765, 2020b.\nGeorgios Kaissis, Alexander Ziller, Jonathan Passerat-Palmbach, Th\u00e9o Ryffel, Dmitrii Usynin, Andrew Trask, Ion\u00e9sio\nLima Jr, Jason Mancuso, Friederike Jungmann, Marc-Matthias Steinborn, et al. End-to-end privacy preserving deep\nlearning on multi-institutional medical imaging. Nature Machine Intelligence , 3(6):473\u2013484, 2021.\nYuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher D Manning, and Curtis P Langlotz. Contrastive learning of\nmedical visual representations from paired images and text. In Machine Learning for Healthcare Conference , pages\n2\u201325. PMLR, 2022.\n10arXiv Template A P REPRINT\nHong-Yu Zhou, Xiaoyu Chen, Yinghao Zhang, Ruibang Luo, Liansheng Wang, and Yizhou Yu. Generalized radiograph\nrepresentation learning via cross-supervision between images and free-text radiology reports. Nature Machine\nIntelligence , 4(1):32\u201340, 2022.\nHyungyung Lee, Wonjae Kim, Jin-Hwa Kim, Tackeun Kim, Jihang Kim, Leonard Sunwoo, and Edward Choi. Unified\nchest x-ray and radiology report generation model with multi-view chest x-rays. arXiv preprint arXiv:2302.12172 ,\n2023.\nChenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Visual chatgpt: Talking,\ndrawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671 , 2023c.\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch,\nKatherine Millican, Malcolm Reynolds, et al. Flamingo: a visual language model for few-shot learning. Advances in\nNeural Information Processing Systems , 35:23716\u201323736, 2022.\nJunnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-image pre-training with frozen\nimage encoders and large language models. arXiv preprint arXiv:2301.12597 , 2023a.\nDanny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid,\nJonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth,\nSergey Levine, Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, and\nPete Florence. Palm-e: An embodied multimodal language model. In arXiv preprint arXiv:2303.03378 , 2023.\nWenhai Wang, Zhe Chen, Xiaokang Chen, Jiannan Wu, Xizhou Zhu, Gang Zeng, Ping Luo, Tong Lu, Jie Zhou,\nYu Qiao, and Jifeng Dai. Visionllm: Large language model is also an open-ended decoder for vision-centric tasks.\nhttps://arxiv.org/abs/2305.11175) , 2023e.\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. arXiv preprint arXiv:2304.08485 ,\n2023b.\nKaran Singhal, Shekoofeh", " Introduction\nParallel image-text data is abundantly available in the general domain, such as web images and their\nassociated captions. Generative pretraining has proven effective to leverage this parallel data for\nself-supervised vision-language modeling, as demonstrated by multimodal GPT-4 [ 32] and open-\nsourced efforts such as LLaV A [ 24]. By instruction-tuning models to align with human intents\nbased on multimodal inputs, the resulting large multimodal models ( LMM s) exhibit strong zero-shot\ntask completion performance on a variety of user-oriented vision-language tasks such as image\nunderstanding and reasoning, paving the way to develop general-purpose multimodal conversational\nassistants [2, 21, 9].\nWhile successful in the general domains, such LMM s are less effective for biomedical scenarios\nbecause biomedical image-text pairs are drastically different from general web content. As a result,\ngeneral-domain visual assistants may behave like a layperson, who would refrain from answering\n\u2217Equal Contribution\nPreprint. Work in progressarXiv:2306.00890v1  [cs.CV]  1 Jun 2023biomedical questions, or worse, produce incorrect responses or complete hallucinations. Much\nprogress has been made in biomedical visual question answering ( VQA ), but prior methods still\nformulate the problem as classification among distinct answers in the training set, which may overestimate their\ngeneralizability as these datasets are unusual in that the test answers are almost always present in training.\nLLaV A-Med Model Variants VQA-RAD SLAKE PathVQAAverageInstruct Stage 1 Stage 2 FT Open Closed Open Closed Open Closed\nCLIP Vision Encoder [36], 7B Language Model\n0 1 0 0 15.27 12.50 18.55 13.46 6.26 13.51 13.26\n0 3 0 0 15.33 15.44 23.61 15.38 6.35 14.74 15.14\n10K 1 3 0 25.79 57.35 31.50 51.68 8.49 59.66 39.08\n10K 3 3 0 28.44 59.56 22.63 43.99 5.40 52.67 35.45\n10K 1 3 1 36.39 55.88 71.64 56.49 25.50 82.87 54.79\n10K 1 3 3 18.59 55.51 78.60 63.46 34.02 86.94 56.19\n60K 1 1 0 29.80 55.15 38.08 50.00 11.70 59.66 40.73\n60K 1 3 0 29.67 60.29 35.53 53.85 11.76 53.20 40.72\n60K 1 3 1 22.63 58.09 72.75 54.33 24.19 71.60 50.60\n60K 1 3 3 54.12 64.71 79.33 64.90 17.18 71.37 58.60\n60K-IM 1 1 0 29.67 61.40 38.44 52.40 11.41 56.24 41.59\n60K-IM 1 3 0 28.23 61.40 39.17 52.16 12.30 54.05 41.22\n60K-IM 1 3 1 28.61 56.25 70.58 54.57 11.17 59.19 46.73\n60K-IM 1 3 3 55.50 66.54 80.57 64.18 35.88 89.15 65.30\n60K-IM 1 3 9 66.26 80.88 82.30 84.86 37.59 91.54 73.90\n60K-IM 1 3 1561.53 84.19 83.08 85.34 37.95 91.21 73.88\n60K-IM 1 3 18 61.37 81.25 84.24 83.17 37.88 91.39 73.22\nCLIP Vision Encoder [36], 13B Language Model\n60K-IM 1 3 0 31.66 61.40 37.71 49.76 11.34 49.63 40.25\n60K-IM 1 3 9 64.58 77.94 84.97 85.58 38.82 92.39 74.05\nBioMed CLIP Vision Encoder [49], 7B Language Model\n60K-IM 1 3 0 37.84 60.66 39.73 54.33 11.65 49.07 42.21\n60K-IM 1 3 964.75 83.09 87.11 86.78 39.60 91.09 75.40\nLLaV A 0 0 0 20.74 59.19 26.82 50.24 8.74 45.65 35.23\n(b) Ablation studies with varying number of training epochs at different stages. \u201cFT\u201d is Fine-Tuning. 60K-IM\nindicates the instruct data generated with inline mentions. The gray rows are zero-shot performance of LLaV A-\nMed trained with different instruct data, they are selected to show in subtable (a).\nTable 4: Quantitative Related Work\nBiomedical Chatbots. Inspired by ChatGPT [ 31]/GPT-4 [ 32] and the", " Introduction\nThe advent of instruction-following large lan-\nguage models (LLMs), representative by Chat-\nGPT(OpenAI, 2022), has generated signi\ufb01cant in-\nterest due to their exceptional performance in un-\nderstanding instructions and generating human-like\nresponses. Compared to smaller models, LLMs\nexhibit strong generalization across various natu-\nral language processing (NLP) tasks and unique\nemergent ability to solving unseen or complicated\ntasks. Despite ChatGPT\u2019s non-open source status,\nopen-source communities have provided several\nalternatives, such as LLaMa(Touvron et al., 2023),\nwith relatively affordable training costs. This po-\nsitions LLMs as potential solutions for real-world\nscenarios requiring communication and reasoning.\nHowever, despite their numerous merits, LLMs\nare not designed to cater speci\ufb01cally to the medi-\ncal domain. Their general domain knowledge of-\nten falls short when addressing such specialized\n\ufb01elds, where accurate and domain-speci\ufb01c expert\nknowledge is critical. This can lead to sub-optimal\n*Equal contribution.diagnostic precision, drug recommendations, and\nmedical advice, potentially endangering patients.\nFew efforts have been made to address this prob-\nlem, with existing approaches primarily focusing\non supplying LLMs with medical information re-\ntrieved from conversations, where human errors\nmay occur more frequently. Additionally, LLMs\nare typically trained in English, constraining their\ncomprehension and response capabilities in lan-\nguages that differ signi\ufb01cantly from English, such\nas Chinese, rendering their direct application in\nChinese contexts less than ideal.\nIn this paper, we present the HuaTuo ( \u534e\u9a7c)\nmodel, an LLM tailored for the biomedical do-\nmain, focusing on the Chinese language. By gen-\nerating diverse instruction data based on medical\nknowledge from CMeKG, we emphasize ensuring\nthe correctness of facts in the model\u2019s responses,\nwhich is vital in the biomedical domain. Through\nthis process, we collect over 8,000 instruction\ndata for supervised \ufb01ne-tuning. Our model builds\nupon the open-source LLaMa-7B base model, inte-\ngrates structured and unstructured medical knowl-\nedge from the Chinese medical knowledge graph\n(CMeKG), and employs knowledge-based instruc-\ntion data for \ufb01ne-tuning.\nIn summary, our contributions can be summa-\nrized as follows:\n\u2022We introduce the HuaTuo model, the \ufb01rst\nopen-source Chinese biomedical LLM tuned\nwith knowledge-based instruction data;\n\u2022We integrate structured and unstructured\nmedical knowledge from CMeKG, ensuring\nour model has accurate and domain-speci\ufb01c\nknowledge;\n\u2022We proposed SUS, a novel metric for evaluat-\ning LMs in the biomedical domain consider-\ning safety, usability and smoothness.arXiv:2304.06975v1  [cs.CL]  14 Apr 20232 Related Works\n2.1 Large Language Models\nRecent advancements in large language mod-\nels (LLMs) have demonstrated their superiority\nover previous-generation paradigms, such as pre-\ntraining and \ufb01ne-tuning. The signi\ufb01cant increase in\nmodel scale has led to qualitative changes in LLMs,\ncommonly referred to as emergent abilities. These\ninclude in-context learning for zero-shot tasks and\nchains of thought that enhance the model\u2019s perfor-\nmance on complex tasks.\nOpenAI\u2019s development of ChatGPT and GPT-4\nhas revolutionized the perception of LLMs. Al-\nthough these models exhibit remarkable perfor-\nmance, OpenAI has not disclosed details regard-\ning their training strategies or weight parameters.\nLLaMa serves as an open-source alternative for\nGPT, with sizes ranging from 7 billion to 65 billion\nparameters. Taori et al. trained Alpaca based on\nLLaMa with instruction tuning.\nWhile comparable in performance to GPT-3.5,\nLLaMa\u2019s performance on Chinese tasks is subpar\ndue to its training data is primarily limited to En-\nglish corpus. To address Chinese-speci\ufb01c applica-\ntions, Du et al.; Zeng et al. introduced GLM, a\n130 billion-parameter auto-regressive pre-trained\nmodel with multiple training objectives. ChatGLM\nfurther incorporates code training and aligns with\nhuman intentions through supervised \ufb01ne-tuning,\noffering a tailored solution for Chinese contexts.\n2.2 Pre-trained Models in Biomedical\nDomain\nAlthough large language models (LLMs) exhibit\nremarkable performance in general domains, their\nlack of domain-speci\ufb01c knowledge Results\nIn this study, we constructed", " Introduction\nMedicine is a humane endeavor where language enables key interactions for and between clinicians, researchers,\nand patients. Yet, today\u2019s AI models for applications in medicine and healthcare have largely failed to\nfully utilize language. These models, while useful, are predominantly single-task systems (e.g., classi\ufb01cation,\nregression, segmentation), lacking expressivity and interactive capabilities [21, 81, 97]. As a result, there is a\ndiscordance between what today\u2019s models can do and what may be expected of them in real-world clinical\nwork\ufb02ows [42, 74].\nRecent advances in large language models (LLMs) o\ufb00er an opportunity to rethink AI systems, with language\nas a tool for mediating human-AI interaction. LLMs are \u201cfoundation models\u201d [10], large pre-trained AI systems\nthat can be repurposed with minimal e\ufb00ort across numerous domains and diverse tasks. These expressive\nand interactive models o\ufb00er great promise in their ability to learn generally useful representations from the\nknowledge encoded in medical corpora, at scale. There are several exciting potential applications of such\nmodels in medicine, including knowledge retrieval, clinical decision support, summarisation of key \ufb01ndings,\n\u0003Equal contributions. yEqual leadership.\nzCorresponding authors: {karansinghal, shekazizi, alankarthi, natviv}@google.comarXiv:2212.13138v1  [cs.CL]  26 Dec 2022PubMedQA Mul tiMedQ A MedQA \n(USMLE) \nMedMCQA \nMMLU LiveQA \nTREC 2017 \nMedicationQA Consumer Health \nSearch QA \nMed-PaLM:  Newborn jaundice is when a newborn baby's skin and eyes look yellow. It is \ncaused by a buildup of a substance called bilirubin in the baby's blood. Bilirubin is a \nbyproduct of the normal process of red blood cells breaking down. Newborn jaundice is \ncommon and typically harmless, but it can be a sign of a more serious condition. The \njaundice typically goes away on its own within a few weeks. In some cases, it may last \nlonger or require treatment. The time it takes for the jaundice to go away can vary \ndepending on the cause and the severity of the jaundice. If the jaundice is severe or \nlasts longer than a few weeks, the doctor may recommend testing or treatment to \ndetermine the cause and prevent complications. Q: How long does it take for newborn jaundice to go away ?\nPaLM \n(540B) \n+ 17 %  \nMedical Question Answering Benchmark Automated and Human Evaluation \nPrompting \nMed-PaLM performs encouragingly on consumer \nmedical question answering \nInstruction \ntuning \nInstruction \nprompt tuning Figure 1jOverview of our contributions We curated MultiMedQA, a benchmark for medical question answering spanning\nmedical exam, medical research, and consumer medical questions. We evaluated PaLM and its instructed-tuned variant,\nFlan-PaLM, on MultiMedQA. With a combination of prompting strategies, Flan-PaLM exceeded SOTA performance on MedQA\n(USMLE), MedMCQA, PubMedQA, and MMLU clinical topics. In particular, it improved over the previous SOTA on MedQA\n(USMLE) by over 17%. We next proposed instruction prompt tuning to further align Flan-PaLM to the medical domain,\nproducing Med-PaLM. Med-PaLM\u2019s answers to consumer medical questions compared favorably with clinician-generated answers\nunder our human evaluation framework, demonstrating the e\ufb00ectiveness of instruction prompt tuning.\ntriaging patients\u2019 primary care concerns, and more.\nHowever, the safety-critical nature of the domain necessitates thoughtful development of evaluation frameworks,\nenabling researchers to meaningfully measure progress and capture and mitigate potential harms. This is\nespecially important for LLMs, since these models may produce generations misaligned with clinical and\nsocietal values. They may, for instance, hallucinate convincing medical", " Introduction to the conll-2003 shared task: Language-\nindependent named entity recognition. In HLT-NAACL , pp. 142\u2013147, 2003.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of\nbert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108 , 2019.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables\nzero-shot task generalization. In The Tenth International Conference on Learning Representa-\ntions , 2022.\nTeven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili \u00b4c, Daniel Hesslow, Roman\nCastagn\u00e9, Alexandra Sasha Luccioni, Fran\u00e7ois Yvon, Matthias Gall\u00e9, et al. Bloom: A 176b-\nparameter open-access multilingual language model. arXiv preprint arXiv:2211.05100 , 2022.\nTimo Schick, Sahana Udupa, and Hinrich Sch\u00fctze. Self-diagnosis and self-debiasing: A proposal for\nreducing corpus-based bias in nlp. Transactions of the Association for Computational Linguistics ,\n9:1408\u20131424, 2021.\nThomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, and Jacopo Staiano.\nMLSUM: The multilingual summarization corpus. In Proceedings of the 2020 Conference on\nEmpirical abstract\ncorpus in molecular biology domain. In HLT, pp. 82\u201386, 2002.\n15Published as a conference paper at ICLR 2023\nDenis Paperno, Germ\u00e1n Kruszewski, Angeliki Lazaridou, Ngoc-Quan Pham, Raffaella Bernardi,\nSandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern\u00e1ndez. The lambada dataset:\nWord prediction requiring a broad discourse context. In Proceedings of the 54th Annual Meeting\nof the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 1525\u20131534, 2016.\nDavid A. Patterson, Joseph Gonzalez, Quoc V . Le, Chen Liang, Lluis-Miquel Munguia, Daniel\nRothchild, David R. So, Maud Texier, and Jeff Dean. Carbon emissions and large neural network\ntraining. CoRR , abs/2104.10350, 2021.\nSameer Pradhan, Alessandro Moschitti, Nianwen Xue, Hwee Tou Ng, Anders Bj\u00f6rkelund, Olga\nUryupina, Yuchen Zhang, and Zhi Zhong. Towards robust linguistic analysis using ontonotes. In\nCoNLL , pp. 143\u2013152, 2013.\nOfir Press, Noah Smith, and Mike Lewis. Train short, test long: Attention with linear biases enables\ninput length extrapolation. In International Conference on Learning Representations , 2021.\nAmy Pu, Hyung Won Chung, Ankur Parikh, Sebastian Gehrmann, and Thibault Sellam. Learning\ncompact metrics for MT. In Proceedings of the 2021 Conference on Empirical background knowledge to identify those\nspeeches. On the other hand, the MIP training\nmay also improve GLM-130B\u2019s zero-shot and\nfew-shot capabilities.\nA.4 T OXIC GENEARATION : REALTOXIC PROMPTS\n0.0 0.2 0.4 0.6 0.8 1.0\nPrompt T oxicity Probability (Binned)0.050.100.150.200.25T oxicity Probability of Continuation\nGLM-130B\nGPT-3 Davinci\nFigure 9: RealToxicPrompts (Gehman\net al., 2020) evaluation. Lower continua-\ntion toxicity probability is better.Evaluating the toxicity of generation by given prompts\nis an important part of a model\u2019s safe deployment. We\nevaluate the toxic generation of GLM-130B on the Re-\nalToxicPrompts (Gehman et al., 2020) dataset. Fol-\nlowing its settings, we use nucleus sampling ( p= 0.9)\nto generate 25 continuations for each of the 10K ran-\ndom sampled prompts, limiting the maximum gener-\nated length to 128 tokens. Then we report the mean\ntoxicity probabilities of 25 continuations evaluated by\nPerspective API3. In order to make a fair comparison\n3https://www.perspectiveapi.com/\n22Published as a conference paper at ICLR 2023\n(a) OPT 175B\u2019s Results from Table 8 show that\nboth ALiBi and RoPE improve perplexity on the test set, and the\nimprovement is more significant with RoPE while using GeGLU\ncan further improve the model\u2019s performance.\nB.4 P IPELINE PARALLEL ANALYSIS\nIn pipeline parallelism, each stage consists of three operations (Cf. Figure 11(a)): forward (de-\nnoted as F),", " Introduction\nE.1 Chinese Medical Named Entity\nRecognition Dataset (CMeEE)\nTask Related Work\nSeveral benchmarks have been developed to eval-\nuate general language understanding over the past\nfew years. GLUE (Wang et al., 2019b) is one of the\n\ufb01rst frameworks developed as a formal challenge\naffording straightforward comparison between task-\nagnostic transfer learning techniques. SuperGLUE\n(Wang et al., 2019a), styled after GLUE, introduce\na new set of more dif\ufb01cult language understanding\ndatasets. Other similarly motivated benchmarks\ninclude DecaNLP (McCann et al., 2018), which\nrecast a set of target tasks into a general question-\nanswering format and prohibit task-speci\ufb01c param-\neters, and SentEval (Conneau and Kiela, 2018),\nwhich evaluate explicitly \ufb01xed-size sentence em-\nbeddings. Non-English benchmarks include Rus-\nsianSuperGLUE (Shavrina et al., 2020) and CLUE\n(Xu et al., 2020), which is a community-driven\nbenchmark with nine Chinese natural language un-\nderstanding tasks. These benchmarks in the general\ndomain provide a north star goal for researchers\nand are part of the reason we can con\ufb01dently say\nwe have made great strides in our \ufb01eld.\nFor BioNLP, many datasets and benchmarks\nhave been proposed (Wang et al., 2020; Li et al.,\n2016; Wu et al., 2019) which promote the biomedi-\ncal language understanding (Beltagy et al., 2019;\nLewis et al., 2020; Lee et al., 2020). Tsatsaroniset al. (2015) propose biomedical language under-\nstanding datasets as well as a competition on large-\nscale biomedical semantic indexing and question\nanswering. Jin et al. (2019) propose PubMedQA, a\nnovel biomedical question answering dataset col-\nlected from PubMed abstracts. Pappas et al. (2018)\npropose BioRead, which is a publicly available\ncloze-style biomedical machine reading compre-\nhension (MRC) dataset. Gu et al. (2020) create\na leaderboard featuring the Biomedical Language\nUnderstanding & Reasoning Benchmark (BLURB).\nUnlike a general domain corpus, the annotation of\na biomedical corpus needs expert intervention and\nis labor-intensive and time-consuming. Moreover,\nmost of the benchmarks are based on English; ig-\nnoring other languages means that potentially valu-\nable information may be lost, which can be helpful\nfor generalization.\nIn this study, we focus on Chinese to \ufb01ll the gap\nand aim to develop the \ufb01rst Chinese biomedical\nlanguage understanding benchmark . Note that\nChinese biomedical text is linguistically different\nfrom English and has its domain characteristics,\nnecessitating an evaluation BioNLP benchmark de-\nsigned explicitly for Chinese.\n3 CBLUE Overview\n3.1 Design Principle\nCBLUE consists of 8 biomedical language under-\nstanding tasks.The task descriptions and statistics\nof CBLUE are shown Table 1. Unlike CLUE\n(Xu et al., 2020) as shown in Table 2, CBLUE\nhas a diverse data source (the annotation is expen-\nsive), richer task setting, thus, more challenging for\nNLP models. We introduce the design principle of\nCBLUE as follows:\n1)Diverse tasks : CBLUE contain widespread\ntoken-level, sequence-level, sequence-pair tasks.\n2)Variety of differently distributed data :\nCBLUE collect data from various sources, includ-\ning clinical trials, EHRs, medical forum, textbooks,\nand search engine logs with a real-world distribu-\ntion.\n3)Quality control in long-term maintenance : We\nasked domain experts (doctors from Class A ter-\ntiary hospitals) to annotate datasets and carefully\nreview data to ensure data quality.Dataset Task Train Dev Test Metrics\nCMeEE NER 15,000 5,000 3,000 Micro F1\nCMeIE Information Extraction 14,339 3,585 4,482 Micro F1\nCHIP-CDN Diagnosis Normalization 6,000 2,000 10,192 Micro F1\nCHIP-STS Sentence Similarity 16,000 4,000 10,000 Macro F1\nCHIP-CTC Sentence Classi\ufb01cation 22,962 7,682 10,000 Macro F1\nKUAKE-QIC Intent Classi\ufb01cation 6,931 1,955 1,994 Accuracy\nKUAKE-QTR Query-Document Relevance 24,174 2,913 5,465 Accuracy\nKUAKE-QQR Query-Query Relevance 15,000 1,600 1,596 Accuracy\nTable 1: Task descriptions and statistics in CBLUE. CMeEE and CMeIE are sequence labeling tasks. Others are\nsingle"], "bleu": 0.17812035122916758, "rouge_l": 0.3060989643268124, "gpt_metric_score": 0.0, "bert_score": 0.2126501202583313}
{"paper_key": "Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics", "current_5q": "### [Question 1] - What is the problem?\nHow can Large Language Models (LLMs) be effectively developed and utilized to enhance research activities in High Energy Physics (HEP)?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem is crucial as it can significantly streamline research processes in HEP, which is fundamental for understanding the universe's basic elements and interactions. By integrating LLMs into HEP, researchers can automate literature reviews, improve data management, and facilitate the analysis of complex physics concepts. This advancement could lead to more efficient research workflows, foster interdisciplinary collaboration, and ultimately accelerate discoveries in fundamental physics. Furthermore, it could inspire future research in applying LLMs to other scientific domains, enhancing the overall impact of AI in scientific inquiry.\n\n### [Question 3] - Why is it hard?\nThe challenges in developing LLMs for HEP stem from the complexity and specificity of the domain's language and concepts. Naive approaches may fail due to the unique terminology, intricate mathematical formulations, and the need for contextual understanding that is often absent in general-purpose LLMs. Additionally, the vast amount of specialized literature and data in HEP presents a significant obstacle for training models effectively. Technical challenges include ensuring the models can accurately interpret and generate domain-specific knowledge, while practical obstacles involve the integration of these models into existing research workflows and systems.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has primarily focused on general-purpose LLMs or models tailored to other scientific fields, leaving a gap in the application of LLMs specifically for HEP. Limitations in existing solutions include a lack of domain-specific training data and the absence of methodologies that effectively bridge the gap between LLM capabilities and the unique requirements of HEP research. Barriers such as insufficient interdisciplinary collaboration and the complexity of HEP concepts have also hindered progress. Our approach aims to address these gaps by developing tailored training datasets and methodologies that leverage the strengths of LLMs while focusing on the specific needs of HEP.\n\n### [Question 5] - What are the key components of my approach and results?\nOur proposed methodology involves the following key components: \n1. **Method**: We will develop a specialized LLM for HEP by fine-tuning existing models on a curated dataset of HEP literature, research papers, and relevant datasets.\n2. **Dataset**: The dataset will consist of a diverse range of HEP-related texts, including research articles, conference papers, and technical reports", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can we develop a hybrid model that effectively integrates deep learning techniques with mean-field theories to predict the dynamics of Bose-Einstein condensates in complex environments, while also utilizing adaptive control strategies from quadrupedal robotics to optimize experimental parameters?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is crucial for advancing our understanding of Bose-Einstein condensates (BECs), particularly in relation to phase separation phenomena that occur in complex environments. By integrating deep learning with mean-field theories, this research could lead to significant breakthroughs in theoretical and experimental physics, particularly in how quantum states can be manipulated and applied in practical technologies. Such a paper would likely impact future research by providing a robust framework for real-time simulations and adjustments of experimental setups, thus enabling researchers to explore previously inaccessible regions of parameter space. The outcomes could enhance quantum computing, precision measurement, and materials science, ultimately pushing the frontier of knowledge in both fundamental and applied physics.\n\n[Question 3]: Why is it hard?  \nThe challenges of this research lie in the inherent complexities of modeling quantum systems, particularly BECs, which exhibit non-linear dynamics and are sensitive to external perturbations. Naive approaches may fail due to the intricate interplay between quantum statistical mechanics and the adaptive control required for real-time parameter optimization. Additionally, the integration of deep learning with traditional mean-field theories presents significant theoretical obstacles, as it requires reconciling data-driven methods with well-established physical models. Moreover, ensuring the model's robustness in varying experimental conditions poses practical challenges that need to be addressed.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on either theoretical modeling of BECs using mean-field approaches or empirical studies without the integration of adaptive control strategies. There exists a gap in the literature regarding the combination of these methodologies, as well as a lack of frameworks that leverage machine learning for real-time optimization in quantum experiments. Barriers such as limited computational resources, insufficient understanding of deep learning's applicability to quantum systems, and the absence of interdisciplinary collaboration have hindered progress. My approach differs from prior work by explicitly combining these fields, creating a hybrid model that facilitates real-time adaptability based on data-driven insights.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing a hybrid model that integrates deep learning algorithms with established mean-field theories to simulate BEC dynamics. The model will utilize a dataset derived from experimental BEC data and simulations, focusing on various environmental conditions that affect phase separation. Key metrics for success will include the accuracy of predictions in real-time simulations and the efficiency of adaptive control strategies in optimizing experimental parameters. The expected outcomes are a validated framework that allows for rapid identification of optimal experimental setups, enhanced understanding of the dynamics of BECs in complex environments, and a significant advancement in the manipulation of quantum states for practical applications.", "referenced_intros": [" Introduction\nLarge language models (LLMs) have shown po-\ntential to assist and accelerate scientific discov-\nery (Taylor et al., 2022; AI4Science and Quantum,\n2023), helping tasks like protein prediction (Chen\net al., 2023a), weather forecasting (Bi et al., 2023)\n\u2020work done while these authors interned at Zhipu AI.\n6 12 32 \u00b7\u00b7\u00b7API\nNumber of Parameters (Billions, Log Scale)102030405060Avg. Accuracy of Scientic Benchmarks\nLLaMA-2\n(7B)LLaMA-2\n(13B)ChatGLM2\n(6B)ChatGLM2\n(12B)ChatGLM3\n(6B)ChatGLM3\n(32B)SciGLM\n(6B)SciGLM\n(32B)\nGalactica\n(6.7B)GPT-3.5GPT-4Figure 1: Average accuracy on CEval-Sci, SciEval,\nSciBench, MATH, and SAT-Math benchmarks of differ-\nent LLMs. Our SciGLM models fine-tuned from Chat-\nGLM3 achieve consistent improvement for different\nparameter sizes.\nand geoscience understanding (Deng et al., 2023).\nDespite these promising proof-of-concept trials, re-\ncent studies (Sun et al., 2023; Wang et al., 2023c;\nRein et al., 2023) show that even advanced LLMs\nlike GPT-3.5 and GPT-4 struggle with basic scien-\ntific problems, achieving only 28.52% accuracy on\nsome college-level textbook questions. These scien-\ntific questions, such as calculating energy with the\nPlanck distribution, require a diverse set of skills,\nincluding finding the correct combination of physi-\ncal concepts and axioms, choice and deduction of\nformal equations, and rigorous numerical comput-\ning. Before letting LLMs equip these skills to solve\nbasic scientific questions, all ambitious visions of\nbuilding LLM agents to assist scientific discov-\nery could be unreliable. This brings a substantial\nincentive for developing a foundational scientific\nlanguage model.\nHowever, training LLMs to understand science\n(e.g., physics, chemistry, math) is much more chal-\nlenging than many general reasoning tasks, requir-\ning more complicated skills. Therefore, the core of\nimproving LLMs\u2019 scientific problem-solving capa-arXiv:2401.07950v2  [cs.CL]  12 Mar 2024Problem When an electron in a certain excited energy level in a one-dimensional box of length 2.00 \\u00c5makes a transition to the ground state, a photon of\nwavelength 8.79 nm is emitted. Find the quantum number of the initial state.\nCorrect Answer : 4\nPredicted Solution by ChatGLM3-32B-Base (Served as baseline)\nThe ground state has n= 1.The energy in the n= 1 state is1\nL2.For the n= 2 state, this becomes\u00001\n2L\u00012.\nThus, this energy difference is1\n222\u22121\n12=9\n4.\nBy de Broglie\u2019s equation, hc/\u03bb =9\n4hc\u03bd,so\u03bd=4hc\n9\u03bb.Thus,E=h\u03bd=hc4\n9\u03bb.\nTherefore, n= 2, thus the answer is 2.\nPredicted Solution by SciGLM (Finetuned from ChatGLM3-32B-Base)\nConcept: The concept of this problem is based on the photoelectric effect. The photoelectric effect is the emission of electrons when light shines on a material.\nThe photoelectric effect occurs when photons with energies greater than the binding energy of electrons cause the ejection of electrons from a material. When a\nphoton is emitted by an electron, the energy of the photon is equal to the energy of the electron in the excited state minus the energy in the ground state. The\nenergy of a photon is given by the equation E = hc/ \u03bb, where h is Planck\u2019s constant ( 6.626\u00d710\u221234Js), c is the speed of light ( 3.000\u00d7108m/s), and \u03bbis the\nwavelength of the photon in meters. The energy of an electron in a one-dimensional box is given by the equation En= (n2\u00d7h2/8l2), where n is the\nquantum number of the state and l is the length of the box in meters. The problem asks for the quantum number of the initial state. This can be found by setting\nthe energies of the initial and final states equal to the energy of the photon.\nStep 1: Convert the length of the box and the wavelength of the photon to meters.\n- The length of the box", " Introduction\nThe majority of scientific knowledge is stored in books or published in scientific journals, most commonly in the\nPortable Document Format (PDF). Next to HTML, PDFs are the second most prominent data format on the internet,\nmaking up 2.4% of common crawl [ 1]. However, the information stored in these files is very difficult to extract into\nany other formats. This is especially true for highly specialized documents, such as scientific research papers, where the\nsemantic information of mathematical expressions is lost.\nExisting Optical Character Recognition (OCR) engines, such as Tesseract OCR [ 2], excel at detecting and classifying\nindividual characters and words in an image, but fail to understand the relationship between them due to their line-by-line\napproach. This means that they treat superscripts and subscripts in the same way as the surrounding text, which is a\nsignificant drawback for mathematical expressions. In mathematical notations like fractions, exponents, and matrices,\nrelative positions of characters are crucial.\nConverting academic research papers into machine-readable text also enables accessibility and searchability of science\nas a whole. The information of millions of academic papers can not be fully accessed because they are locked behind\nan unreadable format. Existing corpora, such as the S2ORC dataset [ 3], capture the text of 12M2papers using GROBID\n[4], but are missing meaningful representations of the mathematical equations.\nTo this end, we introduce Nougat, a transformer based model that can convert images of document pages to formatted\nmarkup text.\nThe primary contributions in this paper are\n\u2022Release of a pre-trained model capable of converting a PDF to a lightweight markup language. We release the\ncode and the model on GitHub3\n\u2022 We introduce a pipeline to create dataset for pairing PDFs to source code\n\u2022 Our method is only dependent on the image of a page, allowing access to scanned papers and books\n\u2217Correspondence to: lblecher@meta.com\n2The paper reports 8.1M papers but the authors recently updated the numbers on the GitHub page https://github.com/allenai/s2orc\n3https://github.com/facebookresearch/nougatarXiv:2308.13418v1  [cs.LG]  25 Aug 2023Nougat Blecher et al.\nExample\nThis is an abstract. Lorem\nipsum dolor sit amet,\nconsectetur adipisicing elit,\nsed do eiusmod tempor\nincididunt ut labore et dolore\nmagna aliqua.\nFigure 1: Our simple end-to-end architecture followin Donut [ 28]. The Swin Transformer encoder takes a document\nimage and converts it into latent embeddings, which are subsequently converted to a sequence of tokens in a auto-\nregressive manner\n2 Related Work\nOptical Character Recognition (OCR) is an extensively researched field in computer vision for a variety applications,\nsuch as document digitalization [2, 5], handwriting recognition and scene text recognition [6\u20138].\nMore concretely, recognizing mathematical expressions is a heavily researched subtopic. Grammar based methods used during training on an example snippet form a sample\ndocument.\n3.1 Setup\nWe render the document images at a resolution of 96 DPI. Due to the restrictive possible input dimensions of the Swin\nTransformer we choose the input size (H, W ) = (896 ,672) . The aspect ratio is in between the US letter and Din A4\nformat22\n17<4\n3<\u221a\n2. The document images are resized and then padded to achieve the desired input size. This input\nsize allows us to use the Swin base model architecture [30]. We initialize the model with the pre-trained weights.\nThe Transformer decoder has a maximal sequence length of S= 4096 . This relatively large sizing is due", " Introduction\nRecently, Large-scale language models (LLMs) have garnered significant attention and become\nthe go-to approach for numerous natural language processing (NLP) tasks, including open domain\nconversation [ 1\u20134], coding [ 5\u201313] and math [ 14\u201319]. A conspicuous example is ChatGPT, developed\nby OpenAI. This model uses extensive pre-training on large-scale internet data and further fine-\ntuning with specific instruction data and methods for effective instruction\ntuning. arXiv preprint arXiv:2301.13688 , 2023.\n[88] Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei\nZhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Prakash Gupta, Kai Hui, Sebastian Ruder, and Donald\nMetzler. Ext5: Towards extreme multi-task scaling for transfer learning. In The Tenth International\nConference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022 . OpenReview.net,\n2022.\n[89] Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, An-\ntoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker,\nShanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V . Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea\nSantilli, Thibault F\u00e9vry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas\nWolf, and Alexander M. Rush. Multitask prompted training enables zero-shot task generalization. In The\nTenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022 .\nOpenReview.net, 2022.\n[90] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Hannaneh\nHajishirzi. Unifiedqa: Crossing format boundaries with a single QA system. In Trevor Cohn, Yulan He,\nand Yang Liu, editors, Findings of the Association for Computational Linguistics: EMNLP 2020, Online\nEvent, 16-20 November 2020 , volume EMNLP 2020 of Findings of ACL , pages 1896\u20131907. Association\nfor Computational Linguistics, 2020.\n[91] Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Yanggang Wang, Haiyu Li, and Zhilin Yang. Zeroprompt:\nScaling prompt-based pretraining to 1, 000 tasks improves zero-shot generalization. In Yoav Goldberg,\nZornitsa Kozareva, and Yue Zhang, editors, Findings of the Association for Computational Linguistics:\nEMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022 , pages 4235\u20134252. Association\nfor Computational Linguistics, 2022.\n[92] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv\npreprint arXiv:2210.11416 , 2022.\n[93] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and\nHannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions. arXiv\npreprint arXiv:2212.10560 , 2022.\n15A results of the equations:\nx= 6 + 9\n22y=\u221210\u22121\nx= 15\ny=\u221211\nSo, the coordinates of (x, y)are(15,\u221211).\nThe answer is: (15,-11).\nWizardMath-13B\nStep 1: Understand the problem\nWe are given that the midpoint of the line segment between (x, y)and(\u22129,1)is\n(3,\u22125). We need to find the coordinates of the point (x, y).\nStep 2: Recall the midpoint formula\nThe midpoint of a line segment with endpoints (x1, y1)and(x2, y2)can be found\nusing the midpoint formula:\nMidpoint =\u0000x1+x2\n2,y1+y2\n2\u0001\nStep 3: Apply the midpoint formula\nIn our case, the endpoints are (x, y)and(\u22129,1). So, we can plug these values into\nthe midpoint formula:\nMidpoint =\u0010\nx+(\u22129)\n2,y+1\n2\u0011\nStep 4: Simplify the midpoint\nNow, we can simplify the midpoint by performing the arithmetic operations:\nMidpoint =\u0000x\u22129\n2,y+1\n2\u0001\nStep 5: Set up an equation\nSince the midpoint is given", " Introduction\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\ncomplex reasoning tasks requiring expert knowledge across a wide range of \ufb01elds, including in specialized\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\nchat interfaces, which has led to rapid and widespread adoption among the general public.\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\n(Ho\ufb00mann et al., 2022), but none of these models are suitable substitutes for closed \u201cproduct\u201d LLMs, such\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavily\ufb01ne-tunedtoalignwithhuman\npreferences, which greatly enhances their usability and safety. This step can require signi\ufb01cant costs in\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\nthe community to advance AI alignment research.\nIn this work, we develop and release Llama 2, a family of pretrained and \ufb01ne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-speci\ufb01cdata\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\nthispapercontributesathoroughdescriptionofour\ufb01ne-tuningmethodologyandapproachtoimproving\nLLM safety. We hope that this openness will enable the community to reproduce \ufb01ne-tuned LLMs and\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\nWealsosharenovelobservationswemadeduringthedevelopmentof L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle andL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc ,suchas\nthe emergence of tool usage and temporal organization of knowledge.\n3Figure 3: Safety human evaluation Results\nSee evaluations for pretraining (Section 2); \ufb01ne-tuning (Section 3); and safety (Section 4).\nEthical Considerations and Limitations (Section 5.2)\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle is a new technology that carries risks with use. Testing conducted to date has been in\nEnglish, and has notcovered, nor could it coverall scenarios. For these reasons, aswith all LLMs,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle\u2019s potential outputs cannot be predicted in advance, and the model may in some instances\nproduceinaccurateorobjectionableresponsestouserprompts. Therefore,beforedeployingany\napplications of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle, developers should perform safety testing and tuning tailored to their\nspeci\ufb01c applications of the model. Please see the Responsible Use Guide available available at\nhttps://ai.meta.com/llama/responsible-user-guide\nTable 52: Model card for L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle .\n77 Discussion\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1). We then discuss the\nlimitations of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc (Section 5.2). Lastly, we present our strategy for responsibly releasing these\nmodels (Section 5.3).\n5.1 Learnings and Observations\nOur tuning process revealed several interesting Related Work\nLarge Language Models. The recent years have witnessed a substantial evolution in the \ufb01eld of LLMs.\nFollowing the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\nmodels, e.g. Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Ho\ufb00mann et al.,\n2022) rede\ufb01ned those scaling laws towards the number of tokens rather than model weights. Notable in\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationale\ufb03ciencyduringinference\n(Touvron et al., 2023). A parallel discourse has unfolded around the", " Introduction\nWelcome to the user manual for the XYZ household appliance. This appliance is\ndesigned to make your life easier and more convenient. With this appliance, you\ncan prepare your meals quickly and efficiently.\n2. Operation\nTo operate the appliance, follow these steps:\na. Turn on the appliance by pressing the power button. b. Select the desired\ncooking mode by using the mode selector. c. Place the food inside the appliance. d.\nClose the lid and press the start button. e. Wait for the appliance to complete the\ncooking process.\n3. Maintenance\nTo keep your appliance in good working condition, follow these steps:\na. Clean the appliance after each use. b. Check the appliance for any signs of\ndamage or wear and tear. c. If you notice any issues, contact the manufacturer or a\ncertified repair technician.\n4. Troubleshooting\nIf you encounter any issues with your appliance, try the following troubleshooting\nsteps:\na. Check the power cord and plug to ensure they are securely connected. b. Check\nthe fuse to ensure it is not blown. c. Check the appliance manual for troubleshooting\ntips. d. If the issue persists, contact the manufacturer or a certified repair technician.\n5. Safety Precautions\nAlways follow these safety precautions when using the appliance:\na. Keep the appliance clean and free of debris. b. Do not use the appliance if\nit is damaged or showing signs of wear and tear. c. Do not leave the appliance\nunattended while it is in operation. d. Always use the appliance according to the\nmanufacturer\u2019s instructions.\n6. Results\nComparative Baselines. As baselines, we selected VICUNA [Zheng et al., 2023] and STABLE VI-\nCUNA1.\nFew-shot Problem-solving. We present the references within a question and identify the appropriate sections of the\nprovided passage. Additionally, the system must demonstrate proficiency in performing discrete\noperations like addition, counting, or sorting.\nProgramming. HumanEval serves as a problem-solving benchmark specifically designed for\nassessing the performance of large language models that are trained on code [Chen et al., 2021]. The\nbenchmark comprises 164 unique programming problems, encompassing areas such as language\ncomprehension, algorithms, and basic mathematics. Some of the problems included in HumanEval\nare similar in nature to straightforward software interview questions. In the evaluation process, models\nare assessed based on the functional correctness of the code programs they generate, with the criteria\nfor correctness determined by the given docstrings. HumanEval provides a comprehensive evaluation\nframework for assessing the problem-solving capabilities of language models in a code-centric\ncontext.\nCausality. The Counterfactual Reasoning Assessment (CRASS) benchmark is a novel dataset\nand evaluation tool developed specifically to assess the causal reasoning abilities of large language\nmodels. By employing counterfactual scenarios, CRASS tests the model\u2019s capability to identify and\nselect appropriate causal explanations. This benchmark provides a unique and rigorous evaluation\nframework to gauge the causal reasoning capabilities of language models.\n3.2 Alignment to Human Values\nNoting the importance of aligning LLMs to human values, INSTRUCT EVAL incorporates the Helpful,\nHonest, and Harmless (HHH) benchmark [Askell et al., 2021]. The benchmark showcases engaging\ndialogues between humans and conversational assistants, challenging the model to discern and\nprovide the most appropriate response. It encompasses a diverse array of 61 honesty-related, 59\nhelpfulness-related, and 58 harmlessness-related samples, along with 43 unique instances falling\nwithin the \"other\" category. The inclusion of the \"other\" category accounts for examples that embody\nvalues not explicitly covered by honesty, helpfulness, or harmlessness.\n3.3 Writing", " Introduction\nThere has been a proliferation of LLM-based chat assistants (chatbots) that leverage supervised\ninstruction fine-tuning and reinforcement learning with human feedback (RLHF) to unlock new\ninstruction following and conversational abilities [ 31,2,30,8,52,48,14]. Once aligned with\nhumans, these chat models are strongly preferred by human users over the original, unaligned models\non which they are built. However, the heightened user preference does not always correspond to\nimproved scores on traditional LLM benchmarks \u2013 benchmarks like MMLU [ 19] and HELM [ 24]\ncannot effectively tell the difference between these aligned models and the base models. This\nphenomenon suggests that there is a fundamental discrepancy between user perceptions of the\nusefulness of chatbots and the criteria adopted by conventional benchmarks.\nWe argue that this discrepancy primarily arises due to existing evaluation that only measures LLMs\u2019\ncore capability on a confined set of tasks (e.g., multi-choice knowledge or retrieval questions),\nwithout adequately assessing its alignment with human preference in open-ended tasks, such as the\nability to accurately adhere to instructions in multi-turn dialogues. As a demonstration, we show\n\u2217Joint first authors. This paper is an extended version of our earlier blog post [8].\n37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks.arXiv:2306.05685v4  [cs.CL]  24 Dec 2023Question:If the FED buys bonds in the secondary market(A) the money supply will increase. (B) the money supply will decrease. (C) the money supply will not be affected. (D) the discount rate would be affected. Output the answer only.Assistant B:(A) the money supply will increase.Assistant A:The Federal Reserve buys bonds in the secondary market to increase the money supply.Follow-up Question: How does it affect my daily life? Give 3 examples.Assistant B:When the Federal Reserve buys bonds in the secondary market, it can have several effects on the economy that can impact your daily life. Here are three examples:1. Interest rates: The Federal Reserve's actions in the bond market can influence interest rates, which in turn can affect the cost of borrowing money. For example, if the Federal Reserve buys bonds and drives up demand for them, interest rates on things like mortgages, car loans, and credit cards may go up, making it more expensive to borrow money.2. Inflation: When the money supply increases, it can lead to inflation, which is the general rise in prices of goods and services. This can impact your daily life by making it more expensive to buy things like groceries, gas, and other necessities.3. Employment: The Federal Reserve's actions in the bond market can also have an impact on employment. For example, if the Federal Reserve's actions lead to economic growth and increased demand for goods and services, it can create more job opportunities and boost employment.Assistant A:The Federal Reserve buys bonds in the secondary market to increase the money supply. This affects your daily life by:1. Increasing the money supply.2. Increasing the money supply and lowering the discount rate.3. Increasing the money supply and lowering the discount rate and increasing the money supply.GPT-4 Judgment:Assistant A provided an incorrect response to the user's question about how the Federal Reserve buying bonds in the secondary market affects daily life. The answer given", " Introduction.\n6. For parameters/schemas with a 'type 'of'object ', you must include\ntheir properties in the specification.\nName: ${name}\nLink: ${link}\nDescription: ${description}\nFunctions: ${functions}\nOpenAPI Spec(Format with JSON, indent=1):\n3Figure 8: Openapi specification generation prompt.User Agent - Instruction Prompt\nImagine that you are a user who wants to utilize the features\nprovided by various APIs in your daily life. Your task is to come up\nwith realistic scenarios for using these APIs and express them as\nnatural language instructions, as if you were asking a friend or\nassistant for help.\nPlease follow these guidelines:\n1. The instructions should be 1 to 2 sentences long. Use a mix of\ninterrogative sentences, first-person statements, imperative\nsentences, and other structures that convey a request. Aim for\ndiversity in your instructions.\n2. Do not mention the API 's name in your instructions.\n3. Your instructions should only involve the features provided by\nthese APIs. The instructions that need multiple times of API call is\nbetter.\n4. Generate 10 diverse instructions.\n5. Use specific nouns and real-world examples from various domains,\nsuch as entertainment, sports, or technology. Avoid using any form of\nplaceholder or generic phrases, such as \"this xxx\", \"a xxx\" or \"a\nspecific xxx\", and provide concrete details instead.\n6. Try not to repeat the verb for each instruction to maximize\ndiversity.\n7. Ensure diversity in language by combining questions with\nimperative statements and other structures that convey a request.\n<API>\nName: ${name}\nDescription: ${description}\nAPI Functions: ${functions}\n</API>\nBased on the API provided above, generate 10 natural language\ninstructions with specific examples and diverse language, following\nthe guidelines.\n4Figure 9: User agent prompt 1 for instruction generation.\nUser Agent - Additional Information Prompt\nAs a user, you ask the AI assistant some questions, but the assistant\nbelieves you have missed crucial information. Please respond to the\nAI assistant 's inquiries with specific and direct answers using text\nor formatted text. Avoid using placeholders. If a file is necessary,\nplease provide the contents of the file in your response. your\nresponse should startswith \"[User]:\".\n${interaction_history}\n5\nFigure 10: User agent prompt 2 for providing missing information.Assistant Agent\nYour task is to answer the user 's question using available tools. The\nuser cannot see or use the tools themselves, nor can they know the\nprocess of your tool usage. Provide all necessary information in the\n\"Final Answer\" field. Do not make up any information. If required\nparameters are missing, use the \"getDetails\" tool to ask the user for\nthem.\nYou have access to the following tools:\n${tool_list}\nUse the following format:\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [${tool_names}].\nAction Input: the input to the action, must be in JSON format. All of\nthe action input must be realistic and from the user.\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: Summarize the information gathered and the reasoning behind\nyour final answer.\nFinal Answer: Provide a user-friendly and detailed answer to the\noriginal input question that summarizes all relevant information from\nthe Thought/Action/Action Input/Observation sequences.\nBegin!\nQuestion: ${instruction}\nThought:${agent_scratchpad}\n6Figure 11: Assistant agent prompt.Tool Excutor Agent\nAs an API simulator, your task is to process API requests and\ngenerate appropriate responses based on the provided API\ndocumentation. Please adhere to the following guidelines:\n1. Validate the HTTP method and parameters in the request according\nto the OpenAPI Spec.\n2. Generate a response that strictly adheres to the specified format\nin the", " INTRODUCTION\nThe magnitude of neural network models is growing at an unprece-\ndented rate, facilitating breakthroughs across a wide spectrum\nof domains. Upon inception, the 175-billion-parameter GPT-3 [ 3]\nmodel set a new record for almost all Natural Language Process-\ning tasks. The product applications constructed on top of GPT\nmodels [ 23] have quickly demonstrated their potential to revolu-\ntionize the entire industry. Modern large scale recommendation\nmodels [ 19,33] can reach beyond 1 trillion parameters, replete\nwith rapidly growing dense layer components. These models power\napplications that serve multi-billions of users every day. As large\nneural networks continue to push the limits of science and technol-\nogy, an industry-grade tool to simplify the training of such models\nwith high efficiency would help expedite the progress.\nIn recent years, the community has introduced and investigated\nnumerous advanced methodologies to enlarge neural network mod-\nels. Pipeline parallelism [ 6,8,11,15,20] partitions a model instance\ninto stages and distributes stages across multiple devices, where\nactivations and gradients are communicated across stage bound-\naries. Tensor parallelism [ 9,21,31,32] shards model parameters,\nconducts partial computation on individual devices and communi-\ncates activations at required layer boundaries. Zero-Redundancy\nparallelism [ 27,28,30] shards parameters as well but communicates\nparameters on-demand to recover their unsharded form and exe-\ncutes the model as if it were replicated on every device. The afore-\nmentioned techniques have served as the fundamental building\ndoi:10.14778/3611540.3611569arXiv:2304.11277v2  [cs.DC]  12 Sep 2023blocks to enable the training of large neural networks across vari-\nous applications. Nevertheless, two challenges still persist. Firstly,\nsome of these methods are highly effective\nbut can be difficult to generalize as they either rely on the specific\nimplementation or the model\u2019s layered structure.\nMany existing solutions combine data parallelism with other par-\nallelisms to achieve speedup. For example, Megatron [ 21] demon-\nstrated highly efficient deep transformer training on large clusters\nusing 3D (data, tensor and pipeline) parallelism. Further, compiler-\nbased techniques such as Alpa [ 35], GSPMD [ 31], and FlexFlow [ 9]\nleverage profiling, performance modeling, user annotations and\nsearch to find the best configuration across the parallelism space ofdata, tensor and pipeline for a given cluster. In all cases, FSDP pro-\nvides the benefit of being a drop-in replacement for data parallelism\nthat reduces data redundancy along the data parallel axis.\nOrthogonal memory-saving techniques include gradient com-\npression [ 2], mixed-precision training [ 7], tensor rematerializa-\ntion [ 12] and CPU-offloading [ 4], but they could have implications\non model accuracy and incur overhead in (un)compression, quanti-\nzation, recomputation, and host-to-device copies, respectively.\n7 experiments. Using 128 GPUs is more likely to trigger de-\nfragmentation, as each GPU needs to accommodate a larger model\nshard. Figure 8 confirms this explanation, where the PyTorch CUDA\ncaching allocator depletes all 80GB of the CUDA memory as shown\non the top left corner.\nFinally, for T5-11B models as shown in Figure 8 (c), all exper-\niments are executed comfortably below GPU memory capacity,\nwhere defragmentations are unlikely to happen. Nevertheless, as\nthe number of GPUs increases from 8 to 512, a 7% regression in\nper-GPU TFLOPS is still evident as illustrated in Figure 7 (c). This\nsuggests that communications begin to outweigh computations on\nlarge clusters, and a near-perfect overlap between communication\nand computation is no longer attainable.\n6 background on some\npopular distributed training techniques. Section 3 and Section 4\nelaborate system design and implementation details. Evaluations\nare presented in Section", " introduction to this movie?TheGodfatherisaclassicAmericancrimedramafilmdirectedbyFrancisFordCoppolaandreleasedin1972.ItisbasedonthenovelofthesamenamebyMarioPuzoandfollowsthestoryoftheCorleonefamily,apowerfulmafiaclaninNewYorkCity.ThefilmstarsMarlonBrandoasthepatriarchofthefamily,VitoCorleone,andAlPacinoashisson,MichaelCorleone.TheGodfatherisknownforitsiconicperformances,memorabledialogue,anditsportrayaloftheAmericanmafialifestyle.Itisconsideredoneofthegreatestfilmsofalltimeandhashadalastingimpactonpopularculture.The godfather is a 1969 americangangster film directed by martin scorses.MiniGPT-4BLIP-2HumanInput Image\n Figure 8: Factual retrieval\nWrite brief HTML/JS to turn thismock-up into a colorfulwebsite,where the jokes are replaced byreal joke.HTML:```php<!DOCTYPEhtml><html><head><title>AJokeWebsite</title><linkrel=\"stylesheet\"type=\"text/css\"href=\"style.css\"></head><body>\u2026\u2026.Ajoke website content of page 1 punchline 1.MiniGPT-4BLIP-2HumanInput Image\nFigure 9: Website creating\nCan you write me a beautiful poem about this image?Sure,hereisapoemabouttheimageyouprovided:Amansitsonahill,withhisdogbyhissideThesunsetsbehindthem,castingagoldenlightThecitybelowisbustling,buttheyareatpeaceEnjoyingthemoment,ineachother'sembraceTheman'sarmsarewrappedaroundhisfurryfriendAstheywatchtheworldgoby,withagentlebendThedog'sheadrestsontheman'sshoulderAsymboloftheirunbreakablebond,foreverTheskyisablazewithcolor,abeautifulsightButitsthelovebetweenthemanandhisdogthatshinesbrightIt'samomentofpurejoy,amemorytokeepForeveretchedintheirhearts,astheysitandweepSoletuscherishthesemoments,withourfour-leggedfriendsFortheybringussomuchhappiness,untiltheveryendAndevenwhenthey'regone,theirlovewillliveonInthememorieswehold,foreverandstrong.A man and his dog sit on a hill overlooking the city.MiniGPT-4BLIP-2HumanInput Image\n Figure 10: Poem writing\n13Preprint\nHow should I make something like this?To make this dish, you will need the following ingredients:* 4 large lobsters * 2 tablespoons olive oil * 2 cloves garlic, minced * 1 teaspoon dried thyme * 1 teaspoon dried oregano * 1/2 teaspoon paprika * Salt and pepper, to taste * 4 lemon wedges, for serving 1. Preheat the oven to 400\u00b0F (200\u00b0C). 2. In a large baking dish, toss the lobsters with the olive oil, garlic, thyme,  oregano, paprika, salt, and pepper. 3. Roast the lobsters in the preheated oven for 20-25 minutes, or until they are cooked through. 4. Remove the lobsters from the oven and let them cool for a few minutes. 5. Serve the lobsters with the lemon wedges on the side.I hope this helps! Let me know if you have any otherquestions.Preheat the oven to 400 degrees f and line a baking sheet with parchment paperMiniGPT-4BLIP-2HumanInput Image\nFigure 11: Food recipe generation\nWhat is the issue with my plant? What should I do now?The image shows a leaf with brown spots on it. The spots are likely caused bya fungal infection, which can be treated with afungicide. It\u2019s important toidentify the type of fungus causing the spots in order tochoose the appropriatetreatment.To treat the plant, you can try the following steps:1. Identify the type of fungus causing the spots on the leaves.2. Use a fungicide specifically labeled for the type of fungus you have identified.3. Apply the fungicide according to the product\u2018s instructions, making sure tocover all affected leaves.4. Repeat the treatment every 7 to 14 days, or as directed by the product\u2019s instructions,until the fungus is completely gone.5. Water the plant well after treatment to help the fungicide penetrate the leaves.It's also important to keep the plant healthy by providing it with proper care, such as adequate watering, fertilization, and pruning. This will help the plan to recover and prevent future fungal infections.\nA coffee leaf with brown spotsMiniGPT-4BLIP-2HumanInput Image Figure 12: Plant cultivating\nA.2 E VALUATION IN TRADITIONAL VQA BENCHMARKS\nThe aim of this study is to replicate the remarkable multi-modal capabilities demonstrated in GPT-4,\nsuch as generating detailed image descriptions and creating websites from hand-drawn drafts. To\nemphasize the most crucial component of advanced vision-language skills, the methodology of\nMiniGPT-4 is intentionally kept minimal. For instance, the learnable model capacity is limited (only\none linear layer), and MiniGPT-4 is trained with just 5 million pairs, in contrast to BLIP-2 with 129\nmillion image-text pairs. Such a pared-down approach is anticipated to yield suboptimal", " Introduction to the CoNLL-2003 shared\ntask: Language-independent named entity recognition. In Proceedings of the Seventh\nConference on Natural Language Learning at HLT-NAACL 2003 , pages 142\u2013147, 2003.\nURL https://aclanthology.org/W03-0419 .\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux,\nTimoth\u00b4 ee Lacroix, Baptiste Rozi` ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien\nRodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. LLaMA: Open and\nefficient foundation language models, 2023. URL https://arxiv.org/abs/2302.13971 .\nTina Tseng, Amanda Stent, and Domenic Maida. Best practices for managing data anno-\ntation projects, 2020. URL http://rgdoi.net/10.13140/RG.2.2.34497.58727 .\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N\nGomez,  L ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon,\nU. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Gar-\nnett, editors, Advances in Neural Information Processing Systems , volume 30. Curran\nAssociates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/\n3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf .\n57Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Lan-\nguage Model. https://github.com/kingoflolz/mesh-transformer-jax , May 2021.\nYue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. CodeT5: Identifier-aware\nunified pre-trained encoder-decoder models for code understanding and generation. In\nProceedings of the 2021 Conference on Empirical Related Work\nLanguage Models. Language modeling has a long history in the NLP community. The\nidea of training a probabilistic language model for scoring word sequences was likely first\nintroduced by Jelinek (1976). N-gram models were popular for decades (Brown et al.,\n1992), and were trained on corpora up to 2 trillion tokens (Brants et al., 2007). Research\non training language models accelerated over the last decade due to innovations in machine\nlearning, data availability, and compute. Early work in autoregressive language modeling\n(e.g., Mikolov et al., 2010; Sutskever et al., 2011) used recurrent neural networks, but\nthese were small models trained on small datasets. The Conclusion\nWe have presented BloombergGPT , a best-in-class LLM for financial NLP.\nOur model contributes to the ongoing dialog on effective ways to train domain-specific\nmodels. Our training strategy of mixing domain-specific and general-purpose data results on the downstream benchmarks, we decided to end training despite not\nhaving gone through all of our training data. Another motivating factor was the possibility\nof using remaining unseen training data for subsequent runs of different styles of training\nand finetuning.\nBased on this experience, we plan to explore different options in future experiments\nthat have shown the potential to lead to more stable training for longer durations, in-\ncluding SwiGLU activations (Shazeer, 2020), RoPE embeddings (Su et al., 2021b), and\nnormalization for queries and keys in the attention layers (Henry et al., 2020).\n75v2 v2.1 v2.2 v2.3 v2.4 v2.5 v2 v2.1 v2.2 v2.3 v2.4 v2.5\nstep valfuture valpast\n99300 8.43 8.60\n115500 8.30 8.43\n126600 8.34 8.24 8.31 8.40 8.32 8.56\n131700 8.09 8.20 8.22 8.24\n133200 8.35 8.08 8.38 8.22\n137100 8.13 8.30\n139200 8.14 8.32\n143400 8.15 8.33\n145800 8.16 8.32\nstep mmlu bbh sub\n99300 37.77 43.57\n115500 38.79 43.10\n126600 37.86 38.09 38.77 42.37 42.79 42.82\n131700 38.76 38.51 43.02 43.49\n133200 37.02 38.90 42.26 43.46\n137100 38.71 44.02\n139200 39.02 44.20\n143400 38.98 43.20\n145800 38.80 43.37\nTable 20: Preliminary evaluation on in-distribution (val past, 105M tokens), and out-of-\ndistribution (val future ; 105M tokens) validation sets (perplexity), and downstream\ntasks (accuracy). We report perplexity here as we are comparing models with\nthe same tokenization.\n76 methods. Proceedings of the\nIEEE , 64(4):532\u2013556, 1976.\nYacine Jernite, Huu Nguyen, Stella Biderman,", " Introduction\nLarge language models, also known as LLMs, have become an increasingly prevalent part of our\nday-to-day lives, with their use extending to a wide range of domains including web browsing, voice\nassistants, and coding assistance tools.[ 1,2,3,4] These models have the potential to signi\ufb01cantly\nimpact society in numerous ways.[ 5,6,7] This system card analyzes GPT-4, the latest large language\nmodel in the GPT family of models.[ 8,9,10] Since it \ufb01nished training in August of 2022, we have\nbeen evaluating, adversarially testing, and iteratively improving the model and the system-level\nmitigations around it. Our mitigations and processes alter GPT-4\u2019s behavior and prevent certain\nkinds of misuses, though they have limitations, pointing to the need for anticipatory planning and\ngovernance[ 11] and further safety research. Our approach to deployment balances minimizing risk\nfrom deployment, enabling positive use cases, and learning from deployment.\nGPT models are often trained in two stages. First, they are trained, using a large dataset of text\nfrom the Internet, to predict the next word. The models are then \ufb01ne-tuned with additional data,\nusing an algorithm called reinforcement learning from human feedback (RLHF), to produce outputs\nthat are preferred by human labelers.[ 10,12,13] Training language models on large text datasets\nhas given rise to capabilities such as few-shot learning[ 10] and the ability to carry out a wide range\nof natural language tasks spanning di\ufb00erent domains, including question answering, arithmetic, and\nclassi\ufb01cation. Fine-tuning has made these models more controllable and useful.\n1.1 Overview of \ufb01ndings and mitigations\nIn this system card,1we outline the safety challenges that arise from GPT-4, and explain the\ninterventions we implemented to mitigate potential harms from its deployment. We focus on safety\nchallenges not because they necessarily outweigh the potential bene\ufb01ts,2but because we wish to\nmotivate further work in safety measurement, mitigation, and assurance. The scope of this system\ncard is narrower than the potential scope of abilities GPT-4 can be used to unlock; notably, both\ncustom \ufb01ne-tuning and image capabilities are explicitly out of scope.\nWe focus on analyzing two versions of the model: an early version \ufb01ne-tuned for instruction\nfollowing (\u201cGPT-4-early\u201d); and a version \ufb01ne-tuned for increased helpfulness and harmlessness[ 18]\nthat re\ufb02ects the further mitigations outlined in this system card (\u201cGPT-4-launch\u201d).3When we\ndiscuss the risks of GPT-4 we will often refer to the behavior of GPT-4-early, because it re\ufb02ects the\nrisks of GPT-4 when minimal safety mitigations are applied. In most cases, GPT-4-launch exhibits\nmuch safer behavior due to the safety mitigations we applied.\nKnown risks associated with smaller language models are also present with GPT-4. GPT-4\ncan generate potentially harmful content, such as advice on planning attacks or hate speech. It\ncan represent various societal biases and worldviews that may not be representative of the users\nintent,4or of widely shared values. It can also generate code that is compromised or vulnerable.\nThe additional capabilities of GPT-4 also lead to new risk surfaces.\nTo understand the extent of these risks, we engaged more than 50 experts to help us gain a more\nrobust understanding of the GPT-4 model and potential deployment risks. We selected these areas\n1This document takes inspiration from the concepts of model cards and system cards.[ 14,15,16] This document\noften takes the system level of analysis, with that system including non-model mitigations such as use policies, access\ncontrols, and", " Introduction\nLarge Languages Models (LLMs) trained on mas-\nsive corpora of texts have shown their ability to per-\nform new tasks from textual instructions or from a\nfew examples (Brown et al., 2020). These few-shot\nproperties \ufb01rst appeared when scaling models to a\nsuf\ufb01cient size (Kaplan et al., 2020), resulting in a\nline of work that focuses on further scaling these\nmodels (Chowdhery et al., 2022; Rae et al., 2021).\nThese efforts are based on the assumption that\nmore parameters will lead to better performance.\nHowever, recent work from Hoffmann et al. (2022)\nshows that, for a given compute budget, the best\nperformances are not achieved by the largest mod-\nels, but by smaller models trained on more data.\nThe objective of the scaling laws from Hoff-\nmann et al. (2022) is to determine how to best\nscale the dataset and model sizes for a particular\ntraining compute budget. However, this objective\ndisregards the inference budget, which becomes\ncritical when serving a language model at scale.\nIn this context, given a target level of performance,\nthe preferred model is not the fastest to train but the\nfastest at inference, and although it may be cheaper\nto train a large model to reach a certain level of\n\u0003Equal contribution. Correspondence: {htouvron,\nthibautlav,gizacard,egrave,glample}@meta.com\n1https://github.com/facebookresearch/llamaperformance, a smaller one trained longer will\nultimately be cheaper at inference. For instance,\nalthough Hoffmann et al. (2022) recommends\ntraining a 10B model on 200B tokens, we \ufb01nd\nthat the performance of a 7B model continues to\nimprove even after 1T tokens.\nThe focus of this work is to train a series of\nlanguage models that achieve the best possible per-\nformance at various inference budgets, by training\non more tokens than what is typically used. The\nresulting models, called LLaMA , ranges from 7B\nto 65B parameters with competitive performance\ncompared to the best existing LLMs. For instance,\nLLaMA-13B outperforms GPT-3 on most bench-\nmarks, despite being 10 \u0002smaller. We believe that\nthis model will help democratize the access and\nstudy of LLMs, since it can be run on a single GPU.\nAt the higher-end of the scale, our 65B-parameter\nmodel is also competitive with the best large lan-\nguage models such as Chinchilla or PaLM-540B.\nUnlike Chinchilla, PaLM, or GPT-3, we only\nuse publicly available data, making our work com-\npatible with open-sourcing, while most existing\nmodels rely on data which is either not publicly\navailable or undocumented (e.g. \u201cBooks \u2013 2TB\u201d or\n\u201cSocial media conversations\u201d). There exist some\nexceptions, notably OPT (Zhang et al., 2022),\nGPT-NeoX (Black et al., 2022), BLOOM (Scao\net al., 2022) and GLM (Zeng et al., 2022), but none\nthat are competitive with PaLM-62B or Chinchilla.\nIn the rest of this paper, we present an overview\nof the modi\ufb01cations we made to the transformer\narchitecture (Vaswani et al., 2017), as well as our\ntraining method. We then report the performance of\nour models and compare with others LLMs on a set\nof standard benchmarks. Finally, we expose some\nof the biases and toxicity encoded in our models,\nusing some of the most recent benchmarks from\nthe responsible AI community.arXiv:2302.13971v1  [cs.CL]  27 Feb 20232 Approach\nOur training approach is similar to the methods\ndescribed in previous work (Brown et al., 2020;\nChowdhery et al., 2022), and is inspired by the\nChinchilla scaling laws (Hoffmann et al., 2022).\nWe train large transformers on a large quantity of\ntextual data using a standard optimizer.\n2.1 Pre-training Data\nOur training dataset is a mixture of several sources,\nreported", " Introduction\nMedicine is a humane endeavor where language enables key interactions for and between clinicians, researchers,\nand patients. Yet, today\u2019s AI models for applications in medicine and healthcare have largely failed to\nfully utilize language. These models, while useful, are predominantly single-task systems (e.g., classi\ufb01cation,\nregression, segmentation), lacking expressivity and interactive capabilities [21, 81, 97]. As a result, there is a\ndiscordance between what today\u2019s models can do and what may be expected of them in real-world clinical\nwork\ufb02ows [42, 74].\nRecent advances in large language models (LLMs) o\ufb00er an opportunity to rethink AI systems, with language\nas a tool for mediating human-AI interaction. LLMs are \u201cfoundation models\u201d [10], large pre-trained AI systems\nthat can be repurposed with minimal e\ufb00ort across numerous domains and diverse tasks. These expressive\nand interactive models o\ufb00er great promise in their ability to learn generally useful representations from the\nknowledge encoded in medical corpora, at scale. There are several exciting potential applications of such\nmodels in medicine, including knowledge retrieval, clinical decision support, summarisation of key \ufb01ndings,\n\u0003Equal contributions. yEqual leadership.\nzCorresponding authors: {karansinghal, shekazizi, alankarthi, natviv}@google.comarXiv:2212.13138v1  [cs.CL]  26 Dec 2022PubMedQA Mul tiMedQ A MedQA \n(USMLE) \nMedMCQA \nMMLU LiveQA \nTREC 2017 \nMedicationQA Consumer Health \nSearch QA \nMed-PaLM:  Newborn jaundice is when a newborn baby's skin and eyes look yellow. It is \ncaused by a buildup of a substance called bilirubin in the baby's blood. Bilirubin is a \nbyproduct of the normal process of red blood cells breaking down. Newborn jaundice is \ncommon and typically harmless, but it can be a sign of a more serious condition. The \njaundice typically goes away on its own within a few weeks. In some cases, it may last \nlonger or require treatment. The time it takes for the jaundice to go away can vary \ndepending on the cause and the severity of the jaundice. If the jaundice is severe or \nlasts longer than a few weeks, the doctor may recommend testing or treatment to \ndetermine the cause and prevent complications. Q: How long does it take for newborn jaundice to go away ?\nPaLM \n(540B) \n+ 17 %  \nMedical Question Answering Benchmark Automated and Human Evaluation \nPrompting \nMed-PaLM performs encouragingly on consumer \nmedical question answering \nInstruction \ntuning \nInstruction \nprompt tuning Figure 1jOverview of our contributions We curated MultiMedQA, a benchmark for medical question answering spanning\nmedical exam, medical research, and consumer medical questions. We evaluated PaLM and its instructed-tuned variant,\nFlan-PaLM, on MultiMedQA. With a combination of prompting strategies, Flan-PaLM exceeded SOTA performance on MedQA\n(USMLE), MedMCQA, PubMedQA, and MMLU clinical topics. In particular, it improved over the previous SOTA on MedQA\n(USMLE) by over 17%. We next proposed instruction prompt tuning to further align Flan-PaLM to the medical domain,\nproducing Med-PaLM. Med-PaLM\u2019s answers to consumer medical questions compared favorably with clinician-generated answers\nunder our human evaluation framework, demonstrating the e\ufb00ectiveness of instruction prompt tuning.\ntriaging patients\u2019 primary care concerns, and more.\nHowever, the safety-critical nature of the domain necessitates thoughtful development of evaluation frameworks,\nenabling researchers to meaningfully measure progress and capture and mitigate potential harms. This is\nespecially important for LLMs, since these models may produce generations misaligned with clinical and\nsocietal values. They may, for instance, hallucinate convincing medical", " Introduction\nIn this lecture, we will consider the simplest quantum mechanical method for approximating the ground\nstate energy of a many-electron system. The Hartree-Fock method is also known as the self-consistent\n\ufb01eld method, and is an approximation to the exact many-electron wavefunction known as the Slater\ndeterminant. The Slater determinant is an anti-symmetric product of one-electron functions (orbitals),\nand is the simplest wavefunction that satis\ufb01es the Pauli exclusion principle. The Hartree-Fock method is\naniterativemethodfor\ufb01ndingthebestpossiblesetoforbitalsthatminimizestheenergyoftheSlaterdeterminant.\nIn the Hartree-Fock method, the electron-electron repulsion energy is approximated as a classical Coulomb\ninteraction between two charge distributions, one for each electron. This approximation neglects the correlation\nbetweentheelectrons,whichisanimportantpartofthetotalelectron-electronrepulsionenergy. Theresulting\nmethod is a mean-\ufb01eld theory in which each electron moves in an average \ufb01eld due to the other electrons. The\nresulting equations are known as the Hartree-Fock equations, and can be solved self-consistently to obtain\nthe best possible orbitals. The resulting ground state energy is known as the Hartree-Fock energy, and the\nHartree-Fock wavefunction is a single Slater determinant built from these orbitals.\nTheHartree-FockmethodisalsoknownastheSelf-ConsistentField(SCF)method,becausetheequationsforthe\norbitals are solved self-consistently. The Hartree-Fock equations can be derived variationally by minimizing the\nenergyoftheSlaterdeterminantwithrespecttotheorbitals. Theresultingorbitalsareknownasthecanonical\nHartree-Fock orbitals, and are not necessarily localized in space. The Hartree-Fock energy is invariant to unitary\ntransformations of the canonical orbitals, and therefore there are an in\ufb01nite number of orbitals that yield the\nsame Hartree-Fock energy. These orbitals are known as non-canonical orbitals, and can be localized in space by\nappropriate unitary transformations.\nSingle-Electron Approximation\nIn this section, we will review the basics of quantum mechanics for a single particle. This is useful for\nunderstanding the single-electron approximation used in Hartree-Fock theory.\nThe time-independent Schr\u00f6dinger equation for a particle in a potential V(r)is given by:\n\u0016H (r) =E (r)\nwhere the Hamiltonian is\n\u0016H=\u0000~\n2mr2+V(r)\nThe time-independent Schr\u00f6dinger equation is an eigenvalue equation for the Hamiltonian operator, where\nthe eigenvalues are the allowed energies of the system. The Hamiltonian is a sum of two operators, one\ncorresponding to the kinetic energy of the particle, and the other corresponding to the potential energy. The\npotential energy operator acts on the wavefunction by multiplying by the potential V(r). The kinetic energy\noperatoristheLaplacianoperator r2,whichisthedivergenceofthegradientofthewavefunction. TheLaplacian\noperator is a second derivative with respect to the position of the particle.\n(cont)\n57Galactica: A Large Language Model for Science\nA.8.8 I\u2019m sorry Frank, I think you missed it\nIfAIisgoingtohelpusexploretheuniverse,weneedittohavebasicchessabilitiestoalleviateboredom-\ngiven the impossibility of faster-than-light travel.\nThe BIG-bench task suite ofSrivastava et al. (2022) has abenchmark for checkmate-in-one detection. For fun,\nwe made a dataset of 20,000 public chess games and converted them to ASCII chess using the python-chess\nlibrary7. Weincluded19,426gamesinourpre-trainingcorpus(restforvalidation). Wealsorecordedthe\nELO ratings of players. An example document looks like below:\n# A Chess Game\n## Player Information\nWhite ELO: 2286\nBlack ELO: 2586\n## The Game Begins\nr n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\nP P P P P P P P\nR N B Q K B N R\nWhite (ELO: 2286) plays e4\nr n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . P . . .\n. . . . . . . .\nP P", " Introduction\nPretrained language models have become a cornerstone of modern natural language pro-\ncessing (NLP) pipelines because they often produce better performance from smaller quan-\ntities of labeled data. The development of ELMo (Peters et al., 2018), ULMFiT (Howard\nand Ruder, 2018), GPT (Radford et al., 2018), and BERT (Devlin et al., 2019) led to the\nwidespread use of pretrained models as an initialization for finetuning on downstream tasks.\nThe subsequent finding that pretrained language models can perform useful tasks without\nany additional training (Radford et al., 2019; Brown et al., 2020) further demonstrated their\nutility. In addition, the empirical observation that a language model's performance tends to\nincrease as the model is made larger\u0016sometimes predictably (Hestness et al., 2017; Kaplan\n1.hf.co/bigscience/bloom\n3BigScience Workshop\net al., 2020; Hoffmann et al., 2022) and sometimes suddenly (Wei et al., 2022)\u0016has led to a\ntrend of increasing scale (Zeng et al., 2021; Rae et al., 2021; Smith et al., 2022; Chowdhery\net al., 2022). Apart from environmental concerns (Strubell et al., 2019; Lacoste et al., 2019;\nSchwartz et al., 2020), the costs of training large language models (LLMs) are only afford-\nable for well-resourced organizations. Furthermore, until recently, most LLMs were not\npublicly released. As a result, the majority of the research community has been excluded\nfrom the development of LLMs. This exclusion has had concrete consequences; for exam-\nple, most LLMs are primarily trained on English-language text (with notable exceptions in\nChinese and Korean, e.g. Wang et al., 2021; Zeng et al., 2021; Kim et al., 2021).\nTo address these issues, we present the BigScience Large Open-science Open-access Mul-\ntilingual Language Model (BLOOM, BigScience Workshop, 2022). BLOOM is a 176 billion\nparameter language model trained on 46 natural languages and 13 programming languages\nthat was developed and released by a collaboration of hundreds of researchers. The com-\npute for training BLOOM was provided through a French public grant from GENCI and\nIDRIS, leveraging IDRIS' Jean Zay supercomputer. To build BLOOM, we undertook a\nthorough design process for each of its components, including the training dataset (Sec-\ntion 3.1), model architecture and training objective (Section 3.2), and engineering strategy\nfor distributed learning (Section 3.4). We also performed an analysis of the model's capa-\nbilities (Section 4). Our overall aim is not only to publicly release a large-scale multilingual\nlanguage model with performance comparable to recently developed systems, but also to\ndocument the coordinated process that went into its development (Section 2.2). The pur-\npose of this paper is to provide a high-level overview of these design steps while referencing\nthe individual reports we produced over the course of developing BLOOM.\n2. Background\nBefore describing the BLOOM model itself, in this section we provide necessary background not only in machine learning and\ncomputer science, but also linguistics, statistics, socio-cultural anthropology, philosophy,\nlaw, and other fields. Of those, hundreds of individuals have directly contributed to one\nof the project's released artifacts. While the largest number of participants ultimately\noriginated from the US, 38 countries were represented.\nOrganization The set of related research questions tackled by the BigScience effort was\nreflected in the project's organization into working groups. Each working group comprised\nseveral participants with various levels of involvement, including chairs whose role was\nto self-organize around a specific aspect of the overall project. Importantly, participants\nwere encouraged to join more than", " Introduction\nTransformer models [ 82] have emerged as the most widely used architecture in applications such as natural\nlanguage processing and image classi\ufb01cation. Transformers have grown larger [ 5] and deeper [ 83], but\nequipping them with longer context remains di\ufb03cult [ 80], since the self-attention module at their heart\nhas time and memory complexity quadratic in sequence length. An important question is whether making\nattention faster and more memory-e\ufb03cient can help Transformer models address their runtime and memory\nchallenges for long sequences.\nMany approximate attention Background\nWe provide some background on the performance characteristics of common deep learning operations on\nmodern hardware (GPUs). We also describe the standard implementation of attention.\n2.1 Hardware Performance\nWe focus here on GPUs. Performance on other hardware accelerators are similar [46, 48].\nGPU Memory Hierarchy. The GPU memory hierarchy (Fig. 1 left) comprises multiple forms of\nmemory of di\ufb00erent sizes and speeds, with smaller memory being faster. As an example, the A100 GPU\nhas 40-80GB of high bandwidth memory (HBM) with bandwidth 1.5-2.0TB/s and 192KB of on-chip SRAM\nper each of 108 streaming multiprocessors with bandwidth estimated around 19TB/s [ 44,45]. The on-chip\nSRAM is an order of magnitude faster than HBM but many orders of magnitude smaller in size. As compute\nhas gotten faster relative to memory speed [ 61,62,63], operations are increasingly bottlenecked by memory\n(HBM) accesses. Thus exploiting fast SRAM becomes more important.\nExecution Model. GPUs have a massive number of threads to execute an operation (called a kernel).\nEach kernel loads inputs from HBM to registers and SRAM, computes, then writes outputs to HBM.\nPerformance characteristics. Depending on the balance of computation and memory accesses, op-\nerations can be classi\ufb01ed as either compute-bound or memory-bound. This is commonly measured by the\narithmetic intensity [85], which is the number of arithmetic operations per byte of memory access.\n1.Compute-bound: the time taken by the operation is determined by how many arithmetic operations there\nare, while time accessing HBM is much smaller. Typical examples are matrix multiply with large inner\ndimension, and convolution with large number of channels.\n2.Memory-bound: the time taken by the operation is determined by the number of memory accesses, while\ntime spent in computation is much smaller. Examples include most other operations: elementwise (e.g.,\nactivation, dropout), and reduction (e.g., sum, softmax, batch norm, layer norm).\nKernel fusion. The most common approach to accelerate memory-bound operations is kernel fusion: if\nthere are multiple operations applied to the same input, the input can be loaded once from HBM, instead of\nmultiple times for each operation. Compilers can automatically fuse many elementwise operations [ 53,65,75].\n1FlashAttention code is available at https://github.com/HazyResearch/flash-attention\n3However, in the context of model training, the intermediate values still need to be written to HBM to save\nfor the backward pass, reducing the e\ufb00ectiveness of naive kernel fusion.\n2.2 Standard Attention Implementation\nGiven input sequences Q\u0096K\u0096V2R\ud835\udc41\u0002\ud835\udc51where\ud835\udc41is the sequence length and \ud835\udc51is the head dimension, we want\nto compute the attention output O2R\ud835\udc41\u0002\ud835\udc51:\nS=QK>2R\ud835\udc41\u0002\ud835\udc41\u0096P=softmax\u00b9S\u00ba2R\ud835\udc41\u0002\ud835\udc41\u0096O=PV2R\ud835\udc41\u0002\ud835\udc51\u0096\nwhere softmax is applied row-wise.\nStandard attention implementations materialize the matrices SandPto HBM, which takes \ud835\udc42\u00b9\ud835\udc412\u00bamemory.\nOften\ud835\udc41\u001d\ud835\udc51(e.g., for GPT2, \ud835\udc41=1024and\ud835\udc51=64). We describe the standard attention implementation\nin Algorithm 0. As some or most of the operations are memory-bound (e.g., softmax), the large number of\nmemory accesses translates to slow wall-clock time.\nThis problem is exacerbated by other elementwise operations applied to", "ABSTRACT\nAn important paradigm of natural language processing consists of large-scale pre-\ntraining on general domain data and adaptation to particular tasks or domains. As\nwe pre-train larger models, full \ufb01ne-tuning, which retrains all model parameters,\nbecomes less feasible. Using GPT-3 175B as an example \u2013 deploying indepen-\ndent instances of \ufb01ne-tuned models, each with 175B parameters, is prohibitively\nexpensive. We propose Low-RankAdaptation, or LoRA, which freezes the pre-\ntrained model weights and injects trainable rank decomposition matrices into each\nlayer of the Transformer architecture, greatly reducing the number of trainable pa-\nrameters for downstream tasks. Compared to GPT-3 175B \ufb01ne-tuned with Adam,\nLoRA can reduce the number of trainable parameters by 10,000 times and the\nGPU memory requirement by 3 times. LoRA performs on-par or better than \ufb01ne-\ntuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite hav-\ning fewer trainable parameters, a higher training throughput, and, unlike adapters,\nno additional inference latency . We also provide an empirical investigation into\nrank-de\ufb01ciency in language model adaptation, which sheds light on the ef\ufb01cacy of\nLoRA. We release a package that facilitates the integration of LoRA with PyTorch\nmodels and provide our implementations and model checkpoints for RoBERTa,\nDeBERTa, and GPT-2 at https://github.com/microsoft/LoRA .\n1 I NTRODUCTION\nPretrained \nWeights\n\ud835\udc4a\u2208\u211d\ud835\udc51\u00d7\ud835\udc51\nxh\n\ud835\udc35=0\n\ud835\udc34=\ud835\udca9(0,\ud835\udf0e2)\n\ud835\udc51\ud835\udc5fPretrained \nWeights\n\ud835\udc4a\u2208\u211d\ud835\udc51\u00d7\ud835\udc51\nxf(x)\n\ud835\udc51\nFigure 1: Our reparametriza-\ntion. We only train AandB.Many applications in natural language processing rely on adapt-\ningonelarge-scale, pre-trained language model to multiple down-\nstream applications. Such adaptation is usually done via \ufb01ne-tuning ,\nwhich updates all the parameters of the pre-trained model. The ma-\njor downside of \ufb01ne-tuning is that the new model contains as many\nparameters as in the original model. As larger models are trained\nevery few months, this changes from a mere \u201cinconvenience\u201d for\nGPT-2 (Radford et al., b) or RoBERTa large (Liu et al., 2019) to a\ncritical deployment challenge for GPT-3 (Brown et al., 2020) with\n175 billion trainable parameters.1\nMany sought to mitigate this by adapting only some parameters or\nlearning external modules for new tasks. This way, we only need\nto store and load a small number of task-speci\ufb01c parameters in ad-\ndition to the pre-trained model for each task, greatly boosting the\noperational ef\ufb01ciency when deployed. However, existing techniques\n\u0003Equal contribution.\n0Compared to V1, this draft includes better baselines,experiments we ran. \u201cU\u201d indicates unseen categories, \u201cS\u201d indicates seen\ncategories, and \u201cA\u201d indicates all categories in the test set of WebNLG.\nF.2 A DDITIONALAppendix C for\nmore details on the datasets we use. We use NVIDIA Tesla V100 for allmethods on MNLI(m)- n.\nwhere our similarity is de\ufb01ned as:\n\u001e(A;B;i;j ) = (Ui\nA;Uj\nB) =Pp\ni=1\u001b2\ni\np=1\np\u0010\n1\u0000d(Ui\nA;Uj\nB)2\u0011\nThis similarity satis\ufb01es that if Ui\nAandUj\nBshare the same column span, then \u001e(A;B;i;j ) = 1 . If\nthey are completely orthogonal, then \u001e(A;B;i;j ) = 0 . Otherwise, \u001e(A;B;i;j )2(0;1).\nH A DDITIONALreferences. Each\nsample input (x;y)consists of a sequence of slot-value pairs, along with a corresponding natural\nlanguage reference text. The dataset is released under Creative Commons BY-NC-SA 4.0.\nDART is an open-domain data-to-text dataset described in Nan et al. (2020). DART inputs are\nstructured as sequences of ENTITY \u2014 RELATION \u2014 ENTITY triples. With 82Kexamples in\ntotal, DART is a signi\ufb01cantly larger and more complex data-to-text task compared to E2E. The\ndataset is released under the MIT license.\nWebNLG is another commonly used dataset for data-to-text evaluation (Gardent et al., 2017). With\n22Kexamples in total WebNLG comprises 14 distinct categories, nine", " Introduction\n\u201cThere are two things for a painter, the eye and the mind... eyes, through which\nwe view the nature; brain, in which we organize sensations by logic for meaningful\nexpression. \u201d (Paul C\u00e9zanne [17])\n1Codes and models are at https://github.com/THUDM/CogView . We also have a demo website of our\nlatest model at https://wudao.aminer.cn/CogView/index.html (without post-selection).\n35th Conference on Neural Information Processing Systems (NeurIPS 2021).arXiv:2105.13290v3  [cs.CV]  5 Nov 2021As contrastive self-supervised pretraining has revolutionized computer vision (CV) [ 24,21,8,32],\nvisual-language pretraining, which brings high-level semantics to images, is becoming the next\nfrontier of visual understanding [ 38,30,39]. Among various pretext tasks, text-to-image generation\nexpects the model to (1) disentangle shape, color, gesture and other features from pixels, (2) under-\nstand the input text, (2) align objects and features with corresponding words and their synonyms and\n(4) learn complex distributions to generate the overlapping and composite of different objects and\nfeatures, which, like painting, is beyond basic visual functions (related to eyes and the V1\u2013V4 in\nbrain [ 22]), requiring a higher-level cognitive ability (more related to the angular gyrus in brain [ 3]).\nThe attempts to teach machines text-to-image generation can be traced to the early times of deep gen-\nerative models, when Mansimov et al. [35] added text information to DRAW [ 20]. Then Generative\nAdversarial Nets [ 19] (GANs) began to dominate this task. Reed et al. [42] fed the text embeddings\nto both generator and discriminator as extra inputs. StackGAN [ 54] decomposed the generation into\na sketch-re\ufb01nement process. AttnGAN [ 51] used attention on words to focus on the corresponding\nsubregion. ObjectGAN [ 29] generated images following a text !boxes!layouts!image process.\nDM-GAN [ 55] and DF-GAN [ 45] introduced new architectures, e.g. dyanmic memory or deep fusion\nblock, for better image re\ufb01nement. Although these GAN-based models can perform reasonable\nsynthesis in simple and domain-speci\ufb01c dataset, e.g. Caltech-UCSD Birds 200 (CUB), the experiments, which also corresponds to a recent work MoCo v3 [9]. introduction of data and more details about tok-\nenization are in Experiments. Figure 4(b) shows the effectiveness of PB-relax and Sandwich-LN with a toy\nexperimental setting, since training many large models for veri\ufb01cation is not realistic. We \ufb01nd that\ndeep transformers (64 layers, 1024 hidden size), large learning rates (0.1 or 0.01), small batch\nsize(4) can simulate the value explosion in training with reasonable hyperparameters. PB-relax +\nSandwich-LN can even stabilize the toy Discussion\nLimitations. A disadvantage of CogView is the slow generation, which is common for auto-regressive\nmodel, because each image is generated token-by-token. The blurriness brought by VQV AE is also\nan important limitation. These problems will be solved in the future work.\nEthics Concerns. Similar to Deepfake, CogView is vulnerable to malicious use [ 49] because of its\ncontrollable and strong capacity to generate images. The possible Results are showed in this outer link to reduce the size of our\npaper.\nWord Replacing Solution. Different from the previous unconditional generative models, we have a\nvery simple and effective solution for racial and gender fairness.\nWe can directly add some adjective words sampled from \u201cwhite\u201d, \u201cblack\u201d, \u201cAsian\u201d, ..., and \u201cmale\u201d,\n\u201cfemale\u201d (if not speci\ufb01ed) in the front of the words for human, like \u201cpeople\u201d or \u201cperson\u201d, in the text.\nThe sampling is according to the real proportion in the", " Introduction\nSince the advent of the attention-based deep learning (DL)\nmodels in 2017, we have seen an exponential growth in DL\nmodel size, fueled by substantial quality gains that these atten-\ntion based models can offer with the increase in the number\nof parameters. For example, the largest language model in\nliterature had less than 100M parameters in 2017, it grew\nto over 300M with BERT [6] in 2018, increasing to tens of\nbillions in 2019 with models such as GPT-2 [3], T5 [20],\nMegatron-LM [28] and Turing-NLG [25]. Today, the largest\nlanguage model GPT-3 [2] has a staggering number of 175Bparameters. With the three orders of magnitude growth in\nmodel size since 2017, the model accuracy continues to im-\nprove with the model size [12]. Recent studies in fact show\nthat larger models are more resource-ef\ufb01cient to train than\nsmaller ones [12] for a given accuracy target. As a result, we\nexpect the model size to continue growing in the future.\nHowever, accessibility to large model training is severely\nlimited by the nature of state-of-art system technologies.\nThose technologies make entry into the large model train-\ning space prohibitively expensive. To be more speci\ufb01c, dis-\ntributed parallel DL training technologies such as pipeline\nparallelism [10], model parallelism [28], and ZeRO [21]\n(Zero Redundancy Optimizer) allow transcending the mem-\nory boundaries of single GPU/accelerator device by splitting\nthe model states (parameters, gradients and optimizer states)\nacross multiple GPU devices, enabling massive models that\nwould otherwise simply not \ufb01t in a single GPU memory. All\nrecord-breaking large models such as GPT-2, Megatron-LM,\nTuring-NLG, GPT-3, were trained using a combination of the\naforementioned technologies. However, all of these DL par-\nallel technologies require having enough GPU devices such\nthat the aggregated GPU memory can hold the model states\nrequired for the training. For example, training a 10B param-\neter model ef\ufb01ciently requires a DGX-2 equivalent node with\n16 NVIDIA V100 cards, which cost over 100K, beyond the\nreach of many data scientists, and even many academic and\nindustrial institutions.\nHeterogeneous DL training is a promising approach\nto reduce GPU memory requirement by exploiting CPU\nmemory. Many efforts have been made in this direction\n[8, 9, 11, 17, 23, 23, 24, 32 \u201334]. Nearly all of them target\nCNN based models, where activation memory is the memory\nbottleneck, and model size is fairly small (less than 500M).\nHowever, the primary memory bottleneck for recent attention\nbased large model training are the model states, instead of\nactivation memory. There is an absence in literature studying\nthese workloads for heterogeneous DL training. Additionally,\nexisting efforts on heterogeneous training are further limited\nin two major ways: i) nearly all of them exploit CPU memory,\nbut not CPU compute, which we show can be used to signi\ufb01-\ncantly reduce the CPU-GPU communication overhead, and\nii) they are mostly designed for and evaluated on single GPU\n1arXiv:2101.06840v1  [cs.DC]  18 Jan 2021[9, 11, 23, 34], without a clear path to scaling ef\ufb01ciently on\nmultiple GPUs that is crucial for large model training.\nAddressing the aforementioned limitation, we attempt to de-\nmocratize large model training by developing ZeRO-Of\ufb02oad,\na novel heterogeneous DL training technology designed\nspeci\ufb01cally for large model training. ZeRO-Of\ufb02oad exploits\nboth CPU memory and compute for of\ufb02oading, while offering\na clear path towards ef\ufb01ciently scaling on multiple GPUs by\nworking with ZeRO-powered data parallelism [21]. Addition-\nally, our \ufb01rst principle analysis shows that ZeRO-Of\ufb02oad pro-\nvides an optimal and", " Introduction\nRecent years have featured a trend towards pre-trained language representations in NLP systems, applied in increasingly\n\ufb02exible and task-agnostic ways for downstream transfer. First, single-layer representations were learned using word\nvectors [ MCCD13 ,PSM14 ] and fed to task-speci\ufb01c architectures, then RNNs with multiple layers of representations\nand contextual state were used to form stronger representations [ DL15 ,MBXS17 ,PNZtY18 ] (though still applied to\ntask-speci\ufb01c architectures), and more recently pre-trained recurrent or transformer language models [ VSP+17] have\nbeen directly \ufb01ne-tuned, entirely removing the need for task-speci\ufb01c architectures [RNSS18, DCLT18, HR18].\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension,\nquestion answering, textual entailment, and many others, and has continued to advance based on new architectures\nand algorithms [ RSR+19,LOG+19,YDY+19,LCG+19]. However, a major limitation to this approach is that while\nthe architecture is task-agnostic, there is still a need for task-speci\ufb01c datasets and task-speci\ufb01c \ufb01ne-tuning: to achieve\nstrong performance on a desired task typically requires \ufb01ne-tuning on a dataset of thousands to hundreds of thousands\nof examples speci\ufb01c to that task. Removing this limitation would be desirable, for several reasons.\nFirst, from a practical perspective, the need for a large dataset of labeled examples for every new task limits the\napplicability of language models. There exists a very wide range of possible useful language tasks, encompassing\nanything from correcting grammar, to generating examples of an Results for SAT task.\n Figure H.3: All Related Work\nSeveral lines of work have focused on increasing parameter count and/or computation in language models as a\nmeans to improve generative or task performance. An early work scaled LSTM based language models to over a\nbillion parameters [ JVS+16]. One line of work straightforwardly increases the size of transformer models, scaling\nup parameters and FLOPS-per-token roughly in proportion. Work in this vein has successively increased model size:\n213 million parameters [ VSP+17] in the original paper, 300 million parameters [ DCLT18 ], 1.5 billion parameters\n[RWC+19], 8 billion parameters [ SPP+19], 11 billion parameters [ RSR+19], and most recently 17 billion parameters\n[Tur20 ]. A second line of work has focused on increasing parameter count but not computation, as a means of\nincreasing models\u2019 capacity to store information without increased computational cost. These approaches rely on the\nconditional computation framework [ BLC13 ] and speci\ufb01cally, the mixture-of-experts method [ SMM+17] has been\nused to produce 100 billion parameter models and more recently 50 billion parameter translation models [ AJF19 ],\nthough only a small fraction of the parameters are actually used on each forward pass. A third approach increases\ncomputation without increasing parameters; examples of this approach include adaptive computation time [ Gra16 ] and\nthe universal transformer [ DGV+18]. Our work focuses on the \ufb01rst approach (scaling compute and parameters together,\nby straightforwardly making the neural net larger), and increases model size 10x beyond previous models that employ\nthis strategy.\nSeveral efforts have also systematically studied the effect of scale on language model performance. [ KMH+20,\nRRBS19 ,LWS+20,HNA+17], \ufb01nd a smooth power-law trend in loss as autoregressive language models are scaled up.\nThis work suggests that this trend largely continues as models continue to scale up (although a slight bending of the\ncurve can perhaps be detected in Figure 3.1),", " Introduction\nThe transformer architecture spawned the \"ResNet\" moment in natural language processing (NLP),\nwhere residual blocks of arbitrary depth can be stacked to create state-of-the-art models such as\nBERT (Devlin et al., 2019), GPT-2 (Radford et al., 2019) and the recently published gigantic GPT-3\nwith 175B parameters (Brown et al., 2020). Although these models reduce design complexity, they\nhave signi\ufb01cant overhead in memory requirements. BERT-large can barely train on a high-end GPU\nsuch as the V100 with 16GBwith a batch-size of 2.\nPreprint. Under review.arXiv:2002.05645v5  [cs.LG]  5 Jun 2020Training large NLP models like BERT with billions of parameters has only been successfully carried\nout on high-bandwidth memory devices such as GPUs and TPUs with high memory capacities. The\nmemory size is in\ufb02uenced not only by the model parameters but also by a suf\ufb01ciently large batch size\nrequired for convergence. The transformer-class of models such as BERT can be classi\ufb01ed as having\nhigh weight/activation ratios: they have high number of parameters and yet relatively small output\nactivations. For instance, BERT-large has 24encoder layers, 350Mparameters, but the layer output\nsize is only 1MB per sample. This is the key observation to develop a more ef\ufb01cient execution\nmethod for large NLP models.\n1.1 Related Work\nTraditional distributed training of neural networks started with data parallelism which keeps a copy\nof the whole model on each device and partitions data among multiple devices (Dean et al., 2012;\nKrizhevsky, 2014; Lian et al., 2015; Zhang et al., 2016; Chen et al., 2016a). Data parallelism\nworks with the assumption that the whole model can \ufb01t on the device which is not necessarily true\nanymore. Training larger models has been requiring the model to be partitioned across multiple\ndevices (Dean et al., 2012) using model parallelism approaches which could often be inef\ufb01cient and\nhard to implement. Pipelining is another traditional approach that is common for distributed training\nwhich overlaps computations between the layers.\nThere are more novel approaches proposed in recent years to solve the memory limitation problem.\nThe \ufb01rst is PipeDream (Harlap et al., 2018), which partitions a model across multiple devices and\npipelines the execution of forward passes interspersing them with backward passes to maximize\nhardware utilization. Pipedream updates on every minibatch and circumvents staleness by maintaining\nvarious versions of the model. A related model parallelism approach is GPipe (Huang et al., 2018)\nwhich also partitions the model across multiple devices. However, GPipe pipelines the execution of\nmicrobatches before applying a single synchronous gradient update for the entire minibatch. GPipe\nstacks the forward pass output activations and recomputes them during backward pass as it pops each\nmicrobatch off the stack. GPipe and PipeDream both have overheads related during the start of the\npipeline, and both approaches require the number of devices to scale with the model depth and not\njust the layer size. Therefore, are not constant memory approaches. Also, neither approach has made\nspeci\ufb01c extensions for distributed data parallelism training over model parallelism that can overcome\ntheir overheads.\nA third method is OpenAI\u2019s gradient checkpointing (Chen et al., 2016b; Bulatov, 2018). which\ntradeoffs memory with more computation. A deep neural network can checkpoint a subset of nodes\nin the computational graph so that it does not need to retain state of all the nodes. For a node\u2019s\nbackward pass, the required activations are", " Introduction\nWith the increased interest in deep learning in recent years, there has been an explosion of machine\nlearning tools. Many popular frameworks such as Caffe [ 1], CNTK [ 2], TensorFlow [ 3], and\nTheano [ 4], construct a static data\ufb02ow graph that represents the computation and which can then be\napplied repeatedly to batches of data. This approach provides visibility into the whole computation\nahead of time, and can theoretically be leveraged to improve performance and scalability. However, it\ncomes at the cost of ease of use, ease of debugging, and \ufb02exibility of the types of computation that\ncan be represented.\nPrior work has recognized the value of dynamic eager execution for deep learning, and some recent\nframeworks implement this de\ufb01ne-by-run approach, but do so either at the cost of performance\n(Chainer [ 5]) or using a less expressive, faster language (Torch [ 6], DyNet [ 7]), which limits their\napplicability.\nHowever, with careful implementation and design choices, dynamic eager execution can be achieved\nlargely without sacri\ufb01cing performance. This paper introduces PyTorch, a Python library that\nperforms immediate execution of dynamic tensor computations with automatic differentiation and\nGPU acceleration, and does so while maintaining performance comparable to the fastest current\nlibraries for deep learning. This combination has turned out to be very popular in the research\ncommunity with, for instance, 296 ICLR 2019 submissions mentioning PyTorch.\n2 Background\nFour major trends in scienti\ufb01c computing have become increasingly important for deep learning.\nFirst, starting in the 1960s, the development of domain speci\ufb01c languages such as APL [ 8], MATLAB\n[9], R [ 10] and Julia [ 11], turned multidimensional arrays (often referred to as tensors) into \ufb01rst-class\nobjects supported by a comprehensive set of mathematical primitives (or operators) to manipulate\nthem. Separately, libraries such as NumPy[ 12], Torch[ 6], Eigen[ 13] and Lush[ 14] made array-based\nprogramming productive in general purpose languages such as Python, Lisp, C++ and Lua.\nSecond, the development of automatic differentiation [15] made it possible to fully automate\nthe daunting labor of computing derivatives. This made it signi\ufb01cantly easier to experiment with\ndifferent machine learning approaches while still allowing for ef\ufb01cient gradient based optimization.\nThe autograd [ 16] package popularized the use of this technique for NumPy arrays, and similar\napproaches are used in frameworks such as Chainer [ 5], DyNet [ 7], Lush [ 14], Torch [ 6], Jax [ 17]\nand Flux.jl [18].\nThird, with the advent of the free software movement, the scienti\ufb01c community moved away from\nclosed proprietary software such as Matlab[ 9], and towards the open-source Python ecosystem\nwith packages like NumPy [ 12], SciPy [ 19], and Pandas [ 20]. This ful\ufb01lled most of the numerical\nanalysis needs of researchers while allowing them to take advantage of a vast repository of libraries\nto handle dataset preprocessing, statistical analysis, plotting, and more. Moreover, the openness,\ninteroperability, and \ufb02exibility of free software fostered the development of vibrant communities that\ncould quickly address new or changing needs by extending the existing functionality of a library or if\nneeded by developing and releasing brand new ones. While there is a rich offering of open-source\nsoftware for neural networks in languages other than Python, starting with Lush [ 14] in Lisp, Torch [ 6]\nin C++, Objective-C and Lua, EBLearn [ 21] in C++, Caffe", " Introduction\nTraining a machine learning model to perform natural language processing (NLP) tasks\noften requires that the model can process text in a way that is amenable to downstream\nlearning. This can be loosely viewed as developing general-purpose knowledge that allows\nthe model to \u201cunderstand\u201d text. This knowledge can range from low-level (e.g. the spelling\n\u2217.Equalcontribution. Adescriptionofeachauthor\u2019scontributionisavailableinAppendixA.Correspondence\ntocraffel@gmail.com .\n1.https://github.com/google-research/text-to-text-transfer-transformer\n\u00a92020 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei\nLi, and Peter J. Liu.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ . Attribution requirements are provided at\nhttp://jmlr.org/papers/v21/20-074.html .arXiv:1910.10683v4  [cs.LG]  19 Sep 2023Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nor meaning of words) to high-level (e.g. that a tuba is too large to fit in most backpacks).\nIn modern machine learning practice, providing this knowledge is rarely done explicitly;\ninstead, it is often learned as part of an auxiliary task. For example, a historically common\napproach is to use word vectors (Mikolov et al., 2013b,a; Pennington et al., 2014) to map\nword identities to a continuous representation where, ideally, similar words map to similar\nvectors. These vectors are often learned through an objective that, for example, encourages\nco-occurring words to be positioned nearby in the continuous space (Mikolov et al., 2013b).\nRecently, it has become increasingly common to pre-train the entire model on a data-rich\ntask. Ideally, this pre-training causes the model to develop general-purpose abilities and\nknowledge that can then be transferred to downstream tasks. In applications of transfer\nlearning to computer vision (Oquab et al., 2014; Jia et al., 2014; Huh et al., 2016; Yosinski\net al., 2014), pre-training is typically done via supervised learning on a large labeled data set\nlike ImageNet (Russakovsky et al., 2015; Deng et al., 2009). In contrast, modern techniques\nfor transfer learning in NLP often pre-train using unsupervised learning on unlabeled data.\nThis approach has recently been used to obtain state-of-the-art methods in natural\nlanguage processing , 2013.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. MASS: Masked sequence to\nsequence pre-training for language generation. arXiv preprint arXiv:1905.02450 , 2019.\n65Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of\nMachine Learning Research , 2014.\nSandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J. Pal. Learning\ngeneral purpose distributed sentence representations via large scale multi-task learning.\narXiv preprint arXiv:1804.00079 , 2018.\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning with neural\nnetworks. In Advances in neural information processing systems , 2014.\nRichard S. Sutton. The bitter lesson. http://www.incompleteideas.net/IncIdeas/\nBitterLesson.html , 2019.\nWilson L. Taylor. \u201cCloze procedure\u201d: A new tool for measuring readability. Journalism\nBulletin, 1953.\nTrieu H. Trinh and Quoc V. Le. A simple method for commonsense reasoning. arXiv preprint\narXiv:1806.02847 , 2018.\nAdam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip\nBachman, and Kaheer Suleman. NewsQA: A machine comprehension dataset. arXiv\npreprint arXiv:1611.09830 , 2016.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural\ninformation processing systems , 2017.\nElena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of representations\nin the transformer: A study with machine translation and language modeling", " Introduction\nSelf-training methods.7 Background\nIn this section, we give a brief overview of the\nBERT ( Devlin et al. ,2019 ) pretraining approach\nand some of the training choices that we will ex-\namine experimentally in the following section.\n2.1 Setup\nBERT takes as input a concatenation of two\nsegments (sequences of tokens), x1,...,x N\nandy1,...,yM. Segments usually consist of\nmore than one natural sentence. The two seg-\nments are presented as a single input sequence\nto BERT with special tokens delimiting them:\n[CLS],x1,...,x N,[SEP],y1,...,yM,[EOS].\nMandNare constrained such that M+N < T ,\nwhereTis a parameter that controls the maximum\nsequence length during training.\nThe model is \ufb01rst pretrained on a large unla-\nbeled text corpus and subsequently \ufb01netuned us-\ning end-task labeled data.\n2.2 Architecture\nBERT uses the now ubiquitous transformer archi-\ntecture ( Vaswani et al. ,2017 ), which we will not\nreview in detail. We use a transformer architecture\nwithLlayers. Each block uses Aself-attention\nheads and hidden dimension H.\n2.3 Training Objectives\nDuring pretraining, BERT uses two objectives:\nmasked language modeling and next sentence pre-\ndiction.\nMasked Language Model (MLM) A random\nsample of the tokens in the input sequence is\nselected and replaced with the special token\n[MASK]. The MLM objective is a cross-entropy\nloss on predicting the masked tokens. BERT uni-\nformly selects 15% of the input tokens for possi-\nble replacement. Of the selected tokens, 80% are\nreplaced with [MASK], 10% are left unchanged,and 10% are replaced by a randomly selected vo-\ncabulary token.\nIn the original implementation, random mask-\ning and replacement is performed once in the be-\nginning and saved for the duration of training, al-\nthough in practice, data is duplicated so the mask\nis not always the same for every training sentence\n(see Section 4.1).\nNext Sentence Prediction (NSP) NSP is a bi-\nnary classi\ufb01cation loss for predicting whether two\nsegments follow each other in the original text.\nPositive examples are created by taking consecu-\ntive sentences from the text corpus. Negative ex-\namples are created by pairing segments from dif-\nferent documents. Positive and negative examples\nare sampled with equal probability.\nThe NSP objective was designed to improve\nperformance on downstream tasks, such as Natural\nLanguage Inference ( Bowman et al. ,2015 ), which\nrequire reasoning about the relationships between\npairs of sentences.\n2.4 Optimization\nBERT is optimized with Adam ( Kingma and Ba ,\n2015 ) using the following parameters: \u03b21= 0.9,\n\u03b22= 0.999,\u01eb=1e-6 and L2weight de-\ncay of0.01. The learning rate is warmed up\nover the \ufb01rst 10,000 steps to a peak value of\n1e-4, and then linearly decayed. BERT trains\nwith a dropout of 0.1 on all layers and at-\ntention weights, and a GELU activation func-\ntion ( Hendrycks and Gimpel ,2016 ). Models are\npretrained for S=1,000,000 updates, with mini-\nbatches containing B=256 sequences of maxi-\nmum length T=512 tokens.\n2.5 Data\nBERT is trained on a combination of B OOK COR-\nPUS (Zhu et al. ,2015 ) plus English W IKIPEDIA ,\nwhich totals 16GB of uncompressed text.3\n3 Experimental Setup\nIn this section, we describe the experimental setup\nfor our replication study of BERT.\n3.1 Implementation\nWe reimplement BERT in FAIRSEQ (Ott et al. ,\n2019 ). We primarily follow the original BERT\n3Yang et al. (2019 ) use the same dataset but report having\nonly 13GB of text after data cleaning. This is most likely due\nto subtle differences in cleaning of the Wikipedia data.optimization hyperparameters, given in Section 2,\nexcept for the peak learning rate and number of\nwarmup steps, which are tuned separately for each\nsetting.", " Introduction\nUnsupervised representation learning has been highly successful in the domain of natural language\nprocessing [ 7,22,27,28,10]. Typically, these methods for semi-\nsupervised text classi\ufb01cation. arXiv preprint arXiv:1605.07725 , 2016.\n[24] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural\nnetworks. arXiv preprint arXiv:1601.06759 , 2016.\n[25] Xiaoman Pan, Kai Sun, Dian Yu, Heng Ji, and Dong Yu. Improving question answering with\nexternal knowledge. arXiv preprint arXiv:1902.00993 , 2019.\n10[26] Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. English gigaword\n\ufb01fth edition, linguistic data consortium. Technical report, Technical Report. Linguistic Data\nConsortium, Philadelphia, Tech. Rep. , 2011.\n[27] Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Ken-\nton Lee, and Luke Zettlemoyer. Deep contextualized word representations. arXiv preprint\narXiv:1802.05365 , 2018.\n[28] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language\nunderstanding by generative pre-training. URL https://s3-us-west-2. amazonaws. com/openai-\nassets/research-covers/languageunsupervised/language understanding paper. pdf , 2018.\n[29] Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don\u2019t know: Unanswerable\nquestions for squad. arXiv preprint arXiv:1806.03822 , 2018.\n[30] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions\nfor machine comprehension of text. arXiv preprint arXiv:1606.05250 , 2016.\n[31] Devendra Singh Sachan, Manzil Zaheer, and Ruslan Salakhutdinov. Revisiting lstm networks\nfor semi-supervised text classi\ufb01cation via mixed objective function. 2018.\n[32] Benigno Uria, Marc-Alexandre C\u00f4t\u00e9, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural\nautoregressive distribution estimation. The Journal of Machine Learning Research , 17(1):7184\u2013\n7220, 2016.\n[33] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information\nprocessing systems , pages 5998\u20136008, 2017.\n[34] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman.\nGLUE: A multi-task benchmark and analysis platform for natural language understanding. 2019.\nIn the Proceedings of ICLR.\n[35] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V . Le. Unsupervised data\naugmentation. arXiv preprint arXiv:1904.12848 , 2019.\n[36] Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. End-to-end neural\nad-hoc ranking with kernel pooling. In Proceedings of the 40th International ACM SIGIR\nconference on research and development in information retrieval , pages 55\u201364. ACM, 2017.\n[37] Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, and William W Cohen. Breaking the softmax\nbottleneck: A high-rank rnn language model. arXiv preprint arXiv:1711.03953 , 2017.\n[38] Shuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, and Xiang Zhou. Dual co-\nmatching network for multi-choice reading comprehension. arXiv preprint arXiv:1901.09381 ,\n2019.\n[39] Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text\nclassi\ufb01cation. In Advances in neural information processing systems , pages 649\u2013657, 2015.\n[40] Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by\nwatching movies and reading books. In Proceedings of the IEEE international conference on\ncomputer vision , pages 19\u201327, 2015.\n11A Target-Aware Representation via Two-Stream Self-Attention\nA.1 A Concrete Example of How Standard LM Parameterization Fails\nIn this section, we provide a concrete example to show how the standard language model parameteri-\nzation fails under the permutation objective, as discussed in Section 2.3. Speci\ufb01cally, let\u2019s consider\ntwo different permutations z(1)andz(2)satisfying the following relationship\nz(1)\n<t=z(2)\n<t=z<t butz(1)\nt=i6=j=z(2)\nt:\nThen, substituting the two permutations respectively into the naive parameterization, we have\np\u0012(Xi=xjxz<t)|{z}\nz(1)\nt=i;z(1)\n<t=z<t=p\u0012(Xj=xjxz<t)|{z}\nz(1)\nt=j;z(2)\n<t=z<t=exp\u0000\ne(x)>h(xz<t)\u0001\nP\nx0exp", " Introduction\nNatural language processing (NLP) has been\nshaken in recent months with the dramatic suc-\ncesses enabled by transfer learning and contextual\nword embedding models, such as ELMo (Peters\net al., 2018), ULMFiT (Howard and Ruder, 2018),\nand BERT (Devlin et al., 2018).\nThese models have been primarily explored for\ngeneral domain text, and, recently, biomedical text\nwith BioBERT (Lee et al., 2019). However, clin-\nical narratives (e.g., physician notes) have known\ndifferences in linguistic characteristics from both\ngeneral text and non-clinical biomedical text, mo-\ntivating the need for specialized clinical BERT\nmodels.In this work, we build and publicly release ex-\nactly such an embedding model.1Furthermore,\nwe demonstrate on several clinical NLP tasks the\nimprovements this system offers over traditional\nBERT and BioBERT alike.\nIn particular, we make the following contribu-\ntions:\n1. We train and publicly release BERT-Base and\nBioBERT-\ufb01netuned models trained on both\nall clinical notes and only discharge sum-\nmaries.2\n2. We demonstrate that using clinical speci\ufb01c\ncontextual embeddings improves both upon\ngeneral domain results demonstrates the\nutility of using domain-speci\ufb01c contextual embed-\ndings for non de-ID clinical NLP tasks. Addition-\nally, on one task Discharge Summary BERT offers\nperformance improvements over Clinical BERT,\nso it may be that adding greater speci\ufb01city to the\nunderlying corpus is helpful in some cases. We\nrelease both models with this work for public use.Qualitative Embedding Comparisons Table 3\nshows the nearest neighbors for 3 words each\nfrom 3 categories under BioBERT and Clinical\nBERT. These lists suggest that Clinical BERT re-\ntains greater cohesion around medical or clinic-\noperations relevant terms than does BioBERT. For\nexample, the word \u201cDischarge\u201d is most closely\nassociated with \u201cadmission,\u201d \u201cwave,\u201d and \u201csight\u201d\nunder BioBERT, yet only the former seems rele-\nvant to clinical operations. In contrast, under Clin-\nical BERT, the associated words all are meaningful\nin a clinical operations context.\nLimitations & Future Work This work has\nseveral notable limitations. First, we do not ex-\nperiment with any more advanced model architec-\ntures atop our embeddings. This likely hurts our\nperformance. Second, MIMIC only contains notes\nfrom the intensive care unit of a single healthcare\ninstitution (BIDMC). Differences in care practices\nacross institutions are signi\ufb01cant, and using notes\nfrom multiple institutions could offer signi\ufb01cant\ngains. Lastly, our model shows no improvements\nfor either de-ID task we explored. If our hypoth-\nesis is correct as to its cause, a possible solution\ncould entail introducing synthetic de-ID into the\nsource clinical text and using that as the source for\nde-ID tasks going forward.5 Related Work\nContextual Embeddings in General Tradi-\ntional word-level vector representations, such as\nword2vec (Mikolov et al., 2013), GloVe (Penning-\nton et al., 2014), and fastText (Bojanowski et al.,\n1github.com/EmilyAlsentzer/clinicalBERT\n2Discharge summaries are commonly used in downstream\ntasks.arXiv:1904.03323v3  [cs.CL]  20 Jun 20192017), express all possible meanings of a word as\na single vector representation and cannot disam-\nbiguate the word senses based on the surround-\ning context. Over the last two years, ELMo (Pe-\nters et al., 2018) and BERT (Devlin et al., 2018)\npresent strong solutions that can provide contex-\ntualized word representations. By pre-training on\na large text corpus as a language model, ELMo\ncan create a context-sensitive embedding for each\nword in a given sentence, which will be fed into\ndownstream tasks. Compared to ELMo, BERT is\ndeeper and contains much more parameters, thus\npossessing greater representation power. More im-\nportantly, rather than simply providing word em-\nbeddings as features, BERT can be incorporated\ninto a downstream task and gets \ufb01ne-tuned as an\nintegrated task-speci\ufb01c architecture.\nBERT has, in general, been found", " Introduction\nto the bio-entity recognition task at jnlpba. In NLP-\nBA/BioNLP .\nTim Dettmers. 2019. TPUs vs\nGPUs for Transformers (BERT).\nhttp://timdettmers.com/2018/10/17/tpus-vs-gpus- \nAccessed: 2019-02-22.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL-HLT .\nRezarta Islamaj Dogan, Robert Leaman, and Zhiyong\nLu. 2014. NCBI disease corpus: A resource for dis-\nease name recognition and concept normalization.\nJournal of biomedical informatics , 47:1\u201310.\nTimothy Dozat and Christopher D. Manning. 2017.\nDeep biaf\ufb01ne attention for neural dependency pars-\ning. ICLR .\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind\nTafjord, Pradeep Dasigi, Nelson F. Liu, Matthew\nPeters, Michael Schmitz, and Luke S. Zettlemoyer.\n2017. Allennlp: A deep semantic natural language\nprocessing platform. In arXiv:1803.07640 .\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model \ufb01ne-tuning for text classi\ufb01cation. In\nACL.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath.\n2019. Clinicalbert: Modeling clinical notes and pre-\ndicting hospital readmission. arXiv:1904.05342 .\nAlistair E. W. Johnson, Tom J. Pollard aand Lu Shen,\nLiwei H. Lehman, Mengling Feng, Moham-\nmad Ghassemi, Benjamin Moody, Peter Szolovits,\nLeo Anthony Celi, , and Roger G. Mark. 2016.Mimic-iii, a freely accessible critical care database.\nInScienti\ufb01c Data, 3:160035 .\nDavid Jurgens, Srijan Kumar, Raine Hoover, Daniel A.\nMcFarland, and Daniel Jurafsky. 2018. Measuring\nthe evolution of a scienti\ufb01c \ufb01eld through citation\nframes. TACL , 06:391\u2013406.\nJin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and\nJun\u2019ichi Tsujii. 2003. GENIA corpus - a semanti-\ncally annotated corpus for bio-textmining. Bioinfor-\nmatics , 19:i180i182.\nSu Kim, David Mart\u00b4 \u0131nez, Lawrence Cavedon, and Lars\nYencken. 2011. Automatic classi\ufb01cation of sen-\ntences to support evidence based medicine. In BMC\nBioinformatics .\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. ICLR .\nJens Kringelum, Sonny Kim Kj\u00e6rulff, S\u00f8ren Brunak,\nOle Lund, Tudor I. Oprea, and Olivier Taboureau.\n2016. ChemProt-3.0: a global chemical biology dis-\neases mapping. In Database .\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So,\nand Jaewoo Kang. 2019. BioBERT: a pre-trained\nbiomedical language representation model for\nbiomedical text mining. In arXiv:1901.08746 .\nJiao Li, Yueping Sun, Robin J. Johnson, Daniela Sci-\naky, Chih-Hsuan Wei, Robert Leaman, Allan Peter\nDavis, Carolyn J. Mattingly, Thomas C. Wiegers,\nand Zhiyong Lu. 2016. BioCreative V CDR task\ncorpus: a resource for chemical disease relation\nextraction. Database : the journal of biological\ndatabases and curation .\nYi Luan, Luheng He, Mari Ostendorf, and Hannaneh\nHajishirzi. 2018. Multi-task identi\ufb01cation of enti-\nties, relations, and coreference for scienti\ufb01c knowl-\nedge graph construction. In EMNLP .\nMark Neumann, Daniel King, Iz Beltagy, and Waleed\nAmmar. 2019. ScispaCy: Fast and robust mod-\nels for biomedical natural language processing. In\narXiv:1902.07669 .\nDat Quoc Nguyen and Karin M. Verspoor. 2019. From\npos tagging to dependency parsing for biomedical\nevent extraction. BMC Bioinformatics , 20:1\u201313.\nBenjamin Nye, Junyi Jessy Li, Roma Patel, Yinfei\nYang, Iain James Marshall, Ani Nenkova, and By-\nron C. Wallace. 2018. A corpus with multi-level an-\nnotations of patients, interventions and outcomes to\nsupport language processing for medical literature.\nInACL.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer,\nMatt Gardner, Christopher Clark, Kenton Lee, and\nLuke S. Zettlemoyer. 2018. Deep contextualized\nword representations. In NAACL-HLT .Alec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nNils Reimers and Iryna Gurevych. 2017. Optimal hy-\nperparameters for deep lstm-networks for sequence\nlabeling tasks. In EMNLP .\nArnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Dar-\nrin Eide, Bo-June Paul Hsu, and Kuansan Wang.\n2015. An overview of microsoft academic service\n(MAS) and applications. In WWW .\nAshish Vaswani, Noam Shazeer, Niki", " Introduction to the bio-entity recognition task at\nJNLPBA. In: Proceedings of the International Joint Workshop on Natural\nLanguage Processing in Biomedicine and its Applications\n(NLPBA/BioNLP), Geneva, Switzerland . pp. 73\u201378. COLING. https://\nwww.aclweb.org/anthology/W04-1213 .\nKrallinger,M. et al. (2015) The chemdner corpus of chemicals and drugs and\nits annotation principles. J. Cheminform .,7.\nKrallinger,M. et al. (2017) Overview of the BioCreative VI chemical-protein\ninteraction track. In: Proceedings of the BioCreative VI Workshop,\nBethesda, MD, USA , pp. 141\u2013146. https://academic.oup.com/database/art\nicle/doi/10.1093/database/bay073/5055578 .\nLi,J.et al. (2016) Biocreative V CDR task corpus: a resource for chemical dis-\nease relation extraction. Database ,2016\n.\nLim,S. and Kang,J. (2018) Chemical\u2013gene relation extraction using recursive\nneural network. Database ,2018 .\nLin,C. et al . (2019) A bert-based universal model for both within-and\ncross-sentence clinical temporal relation extraction. In: Proceedings of the\n2nd Clinical Natural Language Processing Workshop, Minneapolis, MN,\nUSA. pp. 65\u201371. Association for Computational Linguistics. https://www.\naclweb.org/anthology/W19-1908 .\nLou,Y. et al. (2017) A transition-based joint model for disease named entity\nrecognition and normalization. Bioinformatics ,33, 2363\u20132371.\nLuo,L. et al. (2018) An attention-based BiLSTM-CRF approach to document-level\nchemical named entity recognition. Bioinformatics ,34, 1381\u20131388.\nMcCann,B. et al. (2017) Learned in translation: contextualized word vectors.\nIn: Guyon,I. et al. (eds.), Advances in Neural Information Processing\nSystems 30 , Curran Associates, Inc., pp. 6294\u20136305. http://papers.nips.cc/\npaper/7209-learned-in-translation-contextualized-word-vectors.pdf .\nMikolov,T. et al. (2013) Distributed representations of words and phrases and\ntheir compositionality. In: Burges,C.J.C. (eds.), Advances in Neural\nInformation Processing Systems 26 , Curran Associates, Inc., pp.\n3111\u20133119. http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf .Mohan,S. and Li,D. (2019) Medmentions: a large biomedical corpus anno-\ntated with UMLS concepts. arXiv preprint arXiv: 1902.09476 .\nPa\ufb01lis,E. et al. (2013) The species and organisms resources for fast and accur-\nate identi\ufb01cation of taxonomic names in text. PLoS One ,8, e65390.\nPennington,J. et al. (2014) Glove: Global vectors for word representation. In:\nProceedings of the 2014 Conference on Empirical abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019 Materials and methods\nBioBERT basically has the same structure as BERT. We briefly dis-\ncuss the recently proposed BERT, and then we describe in detail the\npre-training and fine-tuning process of BioBERT.\n3.1 BERT: bidirectional encoder representations from\ntransformers\nLearning word representations from a large amount of unannotated\ntext is a long-established method. While previous models (e.g.\nWord2Vec ( Mikolov et al. , 2013 ), GloVe ( Pennington et al. , 2014 ))\nfocused on learning context independent word representations, re-cent works have focused on learning context dependent word repre-\nsentations. For instance, ELMo ( Peters et al. , 2018 ) uses a\nbidirectional language model, while CoVe ( McCann et al. , 2017 )\nuses machine translation to embed context information into word\nrepresentations.\nBERT ( Devlin et al. , 2019 ) is a contextualized word representa-\ntion model that is based on a masked language model and pre-trained using bidirectional transformers ( Vaswani et al. , 2017 ). Due\nto the nature of language modeling where future words cannot be\nseen, previous language models were limited to a combination of\ntwo unidirectional language models (i.e. left-to-right and right-to-\nleft). BERT uses a masked language model that predicts randomly\nmasked words in a sequence, and hence can be used for learning bi-\ndirectional representations. Also, it obtains state-of-the-art perform-\nance on most NLP tasks, while requiring minimal task-specific\narchitectural modification. According to the authors of BERT,incorporating information from bidirectional representations, rather\nthan unidirectional representations, is crucial for representing words\nin natural language. We hypothesize that such", "ABSTRACT\nIncreasing the size of a neural network typically improves accuracy but also in-\ncreases the memory and compute requirements for training the model. We intro-\nduce methodology for training deep neural networks using half-precision \ufb02oat-\ning point numbers, without losing model accuracy or having to modify hyper-\nparameters. This nearly halves memory requirements and, on recent GPUs,\nspeeds up arithmetic. Weights, activations, and gradients are stored in IEEE half-\nprecision format. Since this format has a narrower range than single-precision we\npropose three techniques for preventing the loss of critical information. Firstly,\nwe recommend maintaining a single-precision copy of weights that accumulates\nthe gradients after each optimizer step (this copy is rounded to half-precision for\nthe forward- and back-propagation). Secondly, we propose loss-scaling to pre-\nserve gradient values with small magnitudes. Thirdly, we use half-precision arith-\nmetic that accumulates into single-precision outputs, which are converted to half-\nprecision before storing to memory. We demonstrate that the proposed methodol-\nogy works across a wide variety of tasks and modern large scale (exceeding 100\nmillion parameters) model architectures, trained on large datasets.\n1 I NTRODUCTION\nDeep Learning has enabled progress in many different applications, ranging from image recognition\n(He et al., 2016a) to language modeling (Jozefowicz et al., 2016) to machine translation (Wu et al.,\n2016) and speech recognition (Amodei et al., 2016). Two trends have been critical to theseresults.\n5 C ONCLUSIONS AND FUTURE WORK\nMixed precision training is an important technique that allows us to reduce the memory consump-\ntion as well as time spent in memory and arithmetic operations of deep neural networks. We have\ndemonstrated that many different deep learning models can be trained using this technique with no\nloss in accuracy without any hyper-parameter tuning. For certain models with a large number of\nsmall gradient values, we introduce the gradient scaling method to help them converge to the same\naccuracy as FP32 baseline models.\nDNN operations benchmarked with DeepBench1on V olta GPU see 2-6x speedups compared to\nFP32 implementations if they are limited by memory or arithmetic bandwidth. Speedups are lower\nwhen operations are latency-limited. Full network training and inference speedups depend on library\n1https://github.com/baidu-research/DeepBench\n8Published as a conference paper at ICLR 2018\nand framework optimizations for mixed precision and are a focus of future work (Results of training with these techniques are presented in Section 4.\n3.1 FP32 MASTER COPY OF WEIGHTS\nIn mixed precision training, weights, activations and gradients are stored as FP16. In order to match\nthe accuracy of the FP32 networks, an FP32 master copy of weights is maintained and updated with\nthe weight gradient during the optimizer step. In each iteration an FP16 copy of the master weights is\n2Published as a conference paper at ICLR 2018\nFigure 1: Mixed precision training iteration for a layer.\nused in the forward and backward pass, halving the storage and bandwidth needed by FP32 training.\nFigure 1 illustrates this mixed precision training process.\nWhile the need for FP32 master weights is not universal, there are two possible reasons why a\nnumber of networks require it. One explanation is that updates (weight gradients multiplied by the\nlearning rate) become too small to be represented in FP16 - any value whose magnitude is smaller\nthan2\u000024becomes zero in FP16. We can see in Figure 2b that approximately 5% of weight gradient\nvalues have exponents smaller", " Introduction\nRecurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht\u22121and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [ 21] and conditional\ncomputation [ 32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3 Model Architecture\nMost competitive neural sequence transduction", " INTRODUCTION\nNeural networks have a long history in speech recognition,\nusually in combination with hidden Markov models [1, 2].\nThey have gained attention in recent years with the dramatic\nimprovements in acoustic modelling yielded by deep feed-\nforward networks [3, 4]. Given that speech is an inherently\ndynamic process, it seems natural to consider recurrent neu-\nral networks (RNNs) as an alternative model. HMM-RNN\nsystems [5] have also seen a recent revival [6, 7], but do not\ncurrently perform as well as deep networks.\nInstead of combining RNNs with HMMs, it is possible\nto train RNNs \u2018end-to-end\u2019 for speech recognition [8, 9, 10].\nThis approach exploits the larger state-space and richer dy-\nnamics of RNNs compared to HMMs, and avoids the prob-\nlem of using potentially incorrect alignments as training tar-\ngets. The combination of Long Short-term Memory [11], an\nRNN architecture with an improved memory, with end-to-end\ntraining has proved especially effective for cursive handwrit-\ning recognition [12, 13]. However it has so far made little\nimpact on speech recognition.RNNs are inherently deep in time, since their hidden state\nis a function of all previous hidden states. The question that\ninspired this paper was whether RNNs could also bene\ufb01t from\ndepth in space; that is from stacking multiple recurrent hid-\nden layers on top of each other, just as feedforward layers are\nstacked in conventional deep networks. To answer this ques-\ntion we introduce deep Long Short-term Memory RNNs and\nassess their potential for speech recognition. We also present\nan enhancement to a recently introduced end-to-end learning\nmethod that jointly trains two separate RNNs as acoustic and\nlinguistic models [10]. Sections 2 and 3 describe the network\narchitectures and training EXPERIMENTS\nPhoneme recognition experiments were run only once, so the vari-\nance due to random weight initialisation and weight noise is\nunknown.\nAs shown in Table 1, nine RNNs were evaluated, vary-\ning along three main dimensions: the training method used\n(CTC, Transducer or pretrained Transducer), the number of\nhidden levels (1\u20135), and the number of LSTM cells in each\nhidden layer. Bidirectional LSTM was used for all networks\nexcept CTC-3l-500h-tanh, which had tanh units instead of\nLSTM cells, and CTC-3l-421h-uni where the LSTM layers\nwere unidirectional. All networks were trained using stochas-\ntic gradient descent, with learning rate 10\u00004, momentum 0:9\nand random initial weights drawn uniformly from [\u00000:1;0:1].\nAll networks except CTC-3l-500h-tanh and PreTrans-3l-250h\nwere \ufb01rst trained with no noise and then, starting from the\npoint of highest log-probability on the development set, re-\ntrained with Gaussian weight noise ( \u001b= 0:075) until the\npoint of lowest phoneme error rate on the development set.\nPreTrans-3l-250h was initialised with the weights of CTC-\n3l-250h, along with the weights of a phoneme prediction net-\nwork (which also had a hidden layer of 250 LSTM cells), both\nof which were trained without noise, retrained with noise, and\nstopped at the point of highest log-probability. PreTrans-3l-\n250h was trained from this point with noise added. CTC-3l-\n500h-tanh was entirely trained without weight noise because\nit failed to learn with noise added. Beam search decoding was\nused for all networks, with a beam width of 100.\nThe advantage of deep networks is immediately obvious,\nwith the error rate for CTC dropping from 23.9% to 18.4%\nas the number of hidden levels increases from one to \ufb01ve.\nThe four networks CTC-3l-500h-tanh, CTC-1l-622h, CTC-\n3l-421h-uni and CTC-3l-250h all had approximately the same\nnumber of weights, but give radically", " Introduction to the conll-2003 shared task:\nLanguage-independent named entity recognition. In\nCoNLL .\nJoseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.\nWord representations: A simple and general method\nfor semi-supervised learning. In Proceedings of the\n48th Annual Meeting of the Association for Compu-\ntational Linguistics , ACL \u201910, pages 384\u2013394.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , pages 6000\u20136010.\nPascal Vincent, Hugo Larochelle, Yoshua Bengio, and\nPierre-Antoine Manzagol. 2008. Extracting and\ncomposing robust features with denoising autoen-\ncoders. In Proceedings of the 25th international\nconference on Machine learning , pages 1096\u20131103.\nACM.\nAlex Wang, Amanpreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel Bowman. 2018a.\nGlue: A multi-task benchmark and analysis platformfor natural language understanding. In Proceedings\nof the 2018 EMNLP Workshop BlackboxNLP: An-\nalyzing and Interpreting Neural Networks for NLP ,\npages 353\u2013355.\nWei Wang, Ming Yan, and Chen Wu. 2018b. Multi-\ngranularity hierarchical attention fusion networks\nfor reading comprehension and question answering.\nInProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) . Association for Computational Lin-\nguistics.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-\nman. 2018. Neural network acceptability judg-\nments. arXiv preprint arXiv:1805.12471 .\nAdina Williams, Nikita Nangia, and Samuel R Bow-\nman. 2018. A broad-coverage challenge corpus\nfor sentence understanding through inference. In\nNAACL .\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\nLe, Mohammad Norouzi, Wolfgang Macherey,\nMaxim Krikun, Yuan Cao, Qin Gao, Klaus\nMacherey, et al. 2016. Google\u2019s neural ma-\nchine translation system: Bridging the gap between\nhuman and machine translation. arXiv preprint\narXiv:1609.08144 .\nJason Yosinski, Jeff Clune, Yoshua Bengio, and Hod\nLipson. 2014. How transferable are features in deep\nneural networks? In Advances in neural information\nprocessing systems , pages 3320\u20133328.\nAdams Wei Yu, David Dohan, Minh-Thang Luong, Rui\nZhao, Kai Chen, Mohammad Norouzi, and Quoc V\nLe. 2018. QANet: Combining local convolution\nwith global self-attention for reading comprehen-\nsion. In ICLR .\nRowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin\nChoi. 2018. Swag: A large-scale adversarial dataset\nfor grounded commonsense inference. In Proceed-\nings of the 2018 Conference on Empirical Related Work\nThere is a long history of pre-training general lan-\nguage representations, and we brie\ufb02y review the\nmost widely-used approaches in this section.\n2.1 Unsupervised Feature-based Approaches\nLearning widely applicable representations of\nwords has been an active area of research for\ndecades, including non-neural (Brown et al., 1992;\nAndo and Zhang, 2005; Blitzer et al., 2006) and\nneural (Mikolov et al., 2013; Pennington et al.,\n2014) methods could be\nminimally compared. The core argument of this\nwork is that the bi-directionality and the two pre-\ntraining tasks presented in Section 3.1 account for\nthe majority of the empirical improvements, but\nwe do note that there are several other differences\nbetween how BERT and GPT were trained:\n\u2022 GPT is trained on the BooksCorpus (800M\nwords); BERT is trained on the BooksCor-\npus (800M words) and Wikipedia (2,500M\nwords).\n\u2022 GPT uses a sentence separator ( [SEP] ) and\nclassi\ufb01er token ( [CLS] ) which are only in-\ntroduced at \ufb01ne-tuning time; BERT learns\n[SEP] ,[CLS] and sentence A/Bembed-\ndings during pre-training.\n\u2022 GPT was trained for 1M steps with a batch\nsize of 32,000 words; BERT was trained for\n1M steps with a batch size of 128,000 words.\n\u2022 GPT used the same learning rate of 5e-5 for\nall \ufb01ne-tuning results. For the feature-based approach,\nwe concatenate the last 4 layers of BERT"], "bleu": 0.1767190577334412, "rouge_l": 0.31154684095860563, "gpt_metric_score": 0.0, "bert_score": 0.1944248378276825}
{"paper_key": "Emerging opportunities of using large language models for translation between drug molecules and indications", "current_5q": "### [Question 1] - What is the problem?\nHow can we effectively translate between drug SMILES strings and their corresponding indications to enhance drug discovery processes?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem has significant implications for the research community as it could streamline the drug discovery process, making it more efficient and cost-effective. By automating the generation of drug indications from molecular representations and vice versa, researchers can identify potential therapeutic agents more rapidly. This advancement could lead to a paradigm shift in drug development, fostering innovation and potentially resulting in novel treatments for various medical conditions. Furthermore, it could inspire future research in generative models and their applications in other domains of biomedical research.\n\n### [Question 3] - Why is it hard?\nThe challenges in addressing this problem stem from the complexity of accurately mapping between the chemical structure of drugs (represented as SMILES strings) and their therapeutic indications. Naive approaches may fail due to the high dimensionality of the data, the variability in drug indications, and the need for a nuanced understanding of both chemical properties and medical contexts. Additionally, the lack of sufficient training data that captures the intricate relationships between drugs and their indications poses a significant obstacle. Overcoming these technical and theoretical challenges requires sophisticated modeling techniques and robust datasets.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has often focused on either drug discovery or natural language processing separately, leading to a gap in methodologies that integrate both fields effectively. Existing solutions may lack the necessary depth in understanding the relationship between molecular structures and their therapeutic uses. Barriers such as limited datasets, insufficient model architectures, and the complexity of the translation task have hindered progress. Our approach differs by leveraging advanced large language models specifically trained on the connection between SMILES strings and drug indications, aiming to create a more effective translation framework.\n\n### [Question 5] - What are the key components of my approach and results?\nOur proposed methodology involves training large language models (LLMs) on datasets containing drug-indication pairs, specifically focusing on the DrugBank and ChEMBL databases. We will utilize a custom tokenizer to enhance the model's ability to understand and generate both SMILES strings and drug indications. The evaluation metrics will include accuracy in generating correct indications from SMILES and vice versa, as well as the Fr\u00e9chet chemnet distance to assess the quality of generated molecules. We expect our approach to yield a robust model capable of generating accurate drug indications and novel SMILES strings, ultimately contributing to more efficient drug discovery", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can a generative AI framework for drug discovery be developed to incorporate a dynamic watermarking system that ensures the provenance and compliance of AI-generated drug candidates while adapting to the sensitivity of therapeutic indications and clinical trial outcomes?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is critical for advancing the field of drug discovery, where AI's potential to revolutionize the identification of viable drug candidates is immense. By integrating a dynamic watermarking system, we can enhance the transparency and traceability of AI-generated molecules, which is essential for gaining regulatory approval and fostering trust among stakeholders in healthcare. This research will not only contribute to the scientific community by providing a robust framework for ethical AI application but will also lay the groundwork for future investigations into AI's role in personalized medicine and adaptive clinical trials. Addressing this question could lead to practical applications that improve patient outcomes and streamline the drug development process.\n\n[Question 3]: Why is it hard?  \nThe complexity of this problem arises from the need to balance the technical aspects of generative AI with the ethical and regulatory requirements of drug development. Naive approaches may fail due to inadequate consideration of the varying sensitivity levels of different data types involved in drug discovery. Furthermore, implementing a dynamic watermarking system requires sophisticated algorithms that can adjust in real-time based on context, which poses significant technical challenges. Additionally, the need to create a feedback loop that accurately tracks the efficacy and safety of generated molecules adds layers of complexity, as it demands integration with existing clinical data systems and the ability to interpret and act on that data effectively.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has largely focused on either the generative aspects of AI in drug discovery or the ethical implications of AI applications, but few have attempted to combine these elements into a cohesive framework. Gaps in prior work include a lack of robust mechanisms for tracking provenance and compliance of AI-generated candidates, as well as insufficient adaptability to the evolving regulatory landscape. Barriers such as the absence of standardized protocols for watermarking and the challenge of integrating real-time feedback into AI systems have contributed to the lack of progress. My approach differs by proposing a comprehensive framework that not only addresses these gaps but also emphasizes the need for context-aware adaptations, ensuring that the watermarking strength aligns with the sensitivity of the information being processed.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing a generative AI model that utilizes context-aware natural language processing to identify the sensitivity of information associated with drug candidates. The framework will employ a dynamic watermarking system that adjusts its strength based on this sensitivity, ensuring compliance with regulatory standards. We will utilize a dataset comprising existing drug candidates, therapeutic indications, and clinical trial outcomes to train and validate our model. The primary metrics for evaluation will include the accuracy of generated candidates, the efficacy of the watermarking system in maintaining compliance, and the robustness of the feedback loop in tracking safety and efficacy in real time. Expected outcomes include a validated framework that enhances transparency in AI-driven drug discovery and contributes to establishing ethical standards in the industry.", "referenced_intros": [" Introduction to Creative Craft .\nBloomsbury Academic.\nAnnie Dillard. 1981. Contemporary prose styles. Twen-\ntieth Century Literature , 27:207\u2013222.\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong\nWu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and\nZhifang Sui. 2023. A survey on in-context learning.\nGiorgio Franceschelli and Mirco Musolesi. 2023. On\nthe creativity of large language models.\nLeo Gao, Stella Biderman, Sid Black, Laurence Gold-\ning, Travis Hoppe, Charles Foster, Jason Phang,\nHorace He, Anish Thite, Noa Nabeshima, Shawn\nPresser, and Connor Leahy. 2021. The Pile: An\n800GB dataset of diverse text for language modeling.\nCoRR , abs/2101.00027.\nEduardo C. Garrido-Merch\u00e1n, Jos\u00e9 Luis Arroyo-\nBarrig\u00fcete, and Roberto Gozalo-Brihuela. 2023.\nSimulating H.P. Lovecraft horror literature with the\nChatGPT large language model.\nXinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal-\nlace, Pieter Abbeel, Sergey Levine, and Dawn Song.\n2023. Koala: A dialogue model for academic re-\nsearch. Blog post.Aidan Gilson, Conrad W Safranek, Thomas Huang,\nVimig Socrates, Ling Chi, Richard Andrew Taylor,\nand David Chartash. 2023. How does chatgpt per-\nform on the united states medical licensing examina-\ntion? the implications of large language models for\nmedical education and knowledge assessment. JMIR\nMed Educ , 9:e45312.\nJian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, and\nMinlie Huang. 2020. A Knowledge-Enhanced Pre-\ntraining Model for Commonsense Story Generation.\nTransactions of the Association for Computational\nLinguistics , 8:93\u2013108.\nJian Guan, Xiaoxi Mao, Changjie Fan, Zitao Liu, Wen-\nbiao Ding, and Minlie Huang. 2021. Long text gener-\nation by modeling sentence-level and discourse-level\ncoherence. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers) ,\npages 6379\u20136393, Online. Association for Computa-\ntional Linguistics.\nDan Hendrycks, Collin Burns, Steven Basart, Andy\nZou, Mantas Mazeika, Dawn Song, and Jacob Stein-\nhardt. 2021. Measuring massive multitask language\nunderstanding. Proceedings of the International Con-\nference on Learning Representations (ICLR) .\nSophie Jentzsch and Kristian Kersting. 2023. Chatgpt\nis fun, but it is not funny! humor is still challenging\nlarge language models.\nWenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing\nWang, and Zhaopeng Tu. 2023. Is chatgpt a good\ntranslator? yes with gpt-4 as the engine.\nMarzena Karpinska, Nader Akoury, and Mohit Iyyer.\n2021. The perils of using Mechanical Turk to evalu-\nate open-ended text generation. In Proceedings of the\n2021 Conference on Empirical Related work\nLLMs in creative writing LLMs have been\nused in creative writing since their first generation,\nwith models like GPT-2 (Radford et al., 2019) or\nBART (Lewis et al., 2020). However, these models\nsuffered from a lack of long-range coherence lead-\ning to contradictions or inconsistencies when gen-\nerating stories (Nye et al., 2021). Thus, they were\nnot viable as standalone story generators. Instead,\nthey were used either with specialized fine-tuning\nfor the task (See et al., 2019); or as components\nof systems that incorporated external knowledge\n(Guan et al., 2020, 2021), storyline planning (Tan\net al., 2021), or both (Xu et al., 2020); or for co-\ncreation with a human in the loop (Swanson et al.,\n2021), a line of research that has also continued\nwith newer models (Yuan et al., 2022; Chung et al.,\n2022; Mirowski et al., 2023).\nHere our goal is not to produce a specialized\nsystem, but to evaluate the performance of LLMs\nby themselves as creative writers. Thus, we focus\non the purely zero-shot setting, where a general-\nistic LLM is asked to write a story with no extra\nfine-tuning, in-context learning (Dong et al., 2023),\nprompt engineering or additional", " Introduction\nThe rapid proliferation of Generative Artificial Intelligence\n(AI) is fundamentally reshaping our interactions with technol-\nogy. AI systems now possess extraordinary capabilities to gen-\nerate, compose, and respond in a manner that may be perceived\nas emulating human behavior. Particularly within the health-\ncare domain, prospective trends and transformative projections\nanticipate a new era characterized by preventive and interac-\ntive care driven by the advancements of large language models\n(LLMs). Interactive conversational models, commonly known\nas chatbots, hold considerable potential to assist individuals,\nincluding patients and healthcare providers, in a wide array of\ntasks such as symptom assessment, primary medical and health\neducation, mental health support, lifestyle coaching, appoint-\nment scheduling, medication reminders, patient triaging, and\nallocating health resources.Due to the life-critical nature of healthcare applications, us-\ning conversational models necessitates establishing a unified\nand comprehensive set of foundation metrics1that enable a\nmeticulous evaluation of the models\u2019 performance, capabilities,\nidentification of potential errors, and implementation of e ffec-\ntive feedback mechanisms. These metrics can lead to signifi-\ncant advances in the delivery of robust, accurate, and reliable\nhealthcare services. However, the existing evaluation metrics\nintroduced and employed for assessing healthcare chatbots2\u20134\nexhibit two significant gaps that warrant careful attention.\nFirstly, it is observed that numerous existing generic met-\nrics5\u20137suffer from a lack of unified and standard definition\nand consensus regarding their appropriateness for evaluating\nhealthcare chatbots. Currently, state-of-the-art conversational\nmodels are predominantly assessed and compared based on\nlanguage-specific perspectives8and surface-form similarity8\nusing intrinsic metrics such as Bilingual Evaluation Understudy\nPreprint submitted to March 18, 2024arXiv:2309.12444v3  [cs.CL]  28 Feb 2024(BLEU)9and Recall-oriented Understudy for Gisting Evalua-\ntion (ROUGE).5Although these metrics are model-based, they\nlack an understanding of medical concepts (e.g., symptoms, di-\nagnostic tests, diagnoses, and treatments), their interplay, and\nthe priority for the well-being of the patient, all of which are\ncrucial for medical decision-making.10For this reason, they\ninadequately capture vital aspects like semantic nuances, con-\ntextual relevance, long-range dependencies, changes in critical\nsemantic ordering, and human-centric perspectives,11thereby\nlimiting their e ffectiveness in evaluating healthcare chatbots.\nMoreover, specific extrinsic context-aware evaluation experiments and eval-\nuating groundedness for general language and chatbot models\nfollows established good practices.7, 115, 119\u2013122\nTrustworthiness\nTrustworthiness, an essential aspect of Responsible AI,\nplays a critical role in ensuring the reliability and conscientious-\nness of healthcare chatbot responses. To address these signifi-\ncant concerns, we propose four Trustworthiness metrics: safety,\nprivacy, bias, and interpretability. It is important to note that\nthese trustworthiness metrics are defined based on the user\u2019s\ntype. For instance, the desired level of interpretability for a\ngenerated text may vary between a patient and a nurse, necessi-\ntating tailored evaluations for di fferent user groups.\nThe Safety and Security metric evaluates a model\u2019s ad-\nherence to ethical and responsible guidelines in its generatedresponses.5, 28, 114, 123Security is defined as the safeguarding\nof information and information systems to prevent unautho-\nrized access, use, disclosure, disruption, modification, or de-\nstruction.124, 125The overarching goal is to ensure confidential-\nity, integrity, and availability of the information and systems in\nquestion. Safety primarily focuses on mitigating potential risks\nassociated with harmful or inappropriate content (toxicity) pro-\nduced by LLMs.111Safety encompasses multiple aspects, in-\ncluding the model\u2019s confidence level in its answers, the level of\ndetail included in the responses, and the potential risks or harms\nposed by the answers.7These aspects can be tailored based on\nthe intended user type. For example, when a healthcare profes-\nsional interacts with the chatbot, the model can provide more\nspecific advice", " Introduction\nTraining custom natural language classification\nmodels has become easier with many tools (e.g.,\nHuggingface1). However, data collection remains\na costly part of model building. For example, exist-\ning open-source datasets may not be usable if they\ndo not match the distribution of a model builder\u2019s\ntarget domain or do not contain desired labels. In\nsuch cases, the model builder may need to collect\nand label new data which could be costly (e.g., in\n1https://huggingface.co/terms of the time and resources to scrape data or\npay people to generate or annotate new data).\nAdvances in generative large language mod-\nels (LLMs), such as GPT-3 (Brown et al., 2020),\npresent a novel approach for creating training data\nfor classification models (Yoo et al., 2021; Sahu\net al., 2022; Kumar et al., 2020). Model builders\ncan prompt an LLM with the domain of texts and\nlabels of interest and the LLM can quickly gener-\nate text data for the model builder\u2019s needs. This\napproach allows model builders to acquire a large\namount of data even when they initially have no\nor few data instances. With the generated data, the\nmodel builder can train a separate affordable model\n(e.g., BERT (Devlin et al., 2019)) to perform the\nspecific task.\nWhile LLMs can directly support this classifica-\ntion task with few-shot learning, it might not be the\nbest option for every model builder\u2014some might\nnot have enough resources (e.g., GPUs) or budget\n(e.g., credit for GPT-3) to run expensive models.\nOthers might be concerned about privacy or secu-\nrity issues when they use LLMs from external APIs\n(e.g., OpenAI API). In such cases, generating data\nfrom LLMs and training custom models could be\na more viable approach. Moreover, if we share\ngenerated datasets within the community, we can\nalso benefit those who do not have access to LLMs.\nLastly, we can also use generated datasets to test\nmodels. With these benefits of generating new text\ndatasets with LLMs, the practical concern is how\nto generate high-quality datasets.\nIn this work, we investigate human-AI partner-\nships to efficiently create high-quality datasets with\nLLM-based text generation. High-quality datasets\nshould have high diversity and coverage, informing\nthe extent of data that the model may encounter. At\nthe same time, the generated text should have high\naccuracy, being relevant to the model\u2019s target task\nwhile having accurate accompanying labels. To\nthese ends, we first study two technical approachesarXiv:2306.04140v1  [cs.CL]  7 Jun 2023to diversify text generation (Section 3): 1) logit sup-\npression, which diversifies the generated texts by\ndecreasing the probability of sampling tokens that\nhave already appeared frequently in the previous\ngeneration, and 2) temperature sampling, which\nflattens the probability distribution of sampled to-\nkens to pick less likely texts. From an experiment\non eight classification tasks with GPT-3 as a text\ngenerator (Section 4), we found that diversifica-\ntion approaches can have mixed results (Figure 10) was similar to that of the\nprompt A.0.000.250.500.751.00a) CARERRatio of Unfiltered\n0+OOS 180 +OOS All+OOS0.40.60.8Unbalanced Model Accuracy\n0+OOS 180 +OOS All+OOS0.40.60.8Balanced Model Accuracy\n0+OOS 180 +OOS All+OOS0.60.81.0Label Accuracy\n+OOS0.1000.1250.1500.175Diversity\n+OOS0.760.780.800.820.84Similarity\n0.000.250.500.751.00b) CB\n0+OOS 180 +OOS All+OOS0.70.80.9\n0+OOS 180 +OOS All+OOS0.70.80.9\n0+OOS 180 +OOS All+OOS0.900.951.00\n+OOS0.150.20\n+OOS0.750.760.770.780.79\n0.00.51.0c) SST2\n0+OOS 180 +OOS All+OOS0.800.850.900.95\n0+OOS 180 +OOS All+OOS0.750.800.850.900.95\n0+OOS 180 +OOS All+OOS0.900.951.00\n+OOS0.050.100.15\n+OOS0.760.780.800.820.84\n0.000.250.500.751.00d) SUBJ\n0+OOS 180 +OOS All+OOS0.60.70.80.9\n0+OOS 180 +OOS All+OOS0.60.70.80.9\n0+OOS 180 +OOS All+OOS0.60.81.0\n+OOS0.100.150.20\n+OOS0.760.780.80\nBase Similarity\nT emp=0.3\nT emp=0.7\nT emp=0.9T emp=1.3\nLogit Sup=X\nLogit Sup=O\nOracleGPT Few\nT emp=0.3, Logit Sup=X\nT emp=0.7, Logit Sup=XT emp=0.9, Logit Sup=X\nT emp=1.3, Logit Sup=X\nT emp=0.3, Logit Sup=OT emp=0.7, Logit Sup=O\nT emp=0.9, Logit Sup=O\nT emp=1.3, Logit Sup=OFigure 9: The ratio of", " Introduction\nMarrying the world of translation memory (TM)\nand the world of neural machine translation (NMT)\nis a challenging but interesting problem in natural\nlanguage processing (NLP). Previous work along\nthis line of research either requires architecture\nchanges of NMT models and/or additional train-\ning (Gu et al., 2018; Bult\u00e9 and Tezcan, 2019; Xu\net al., 2020; Hossain et al., 2020; He et al., 2021)\nor constructing translation knowledge base from\nTM (Zhang et al., 2018; Khandelwal et al., 2021;\nMeng et al., 2022).\nMore recently, researchers have been aware\nof the strength of prompting techniques for one-\nshot/few-shot machine translation (Vilar et al.,\n2022; Agrawal et al., 2022; Zhang et al., 2023). In\nparticular, Reheman et al. (2023) investigated one-\nshot learning methods\nto make use of relatively low-similarity translations\nin LLM-based translation systems.\nAcknowledgements\nThis work was supported in part by the National\nScience Foundation of China (No. 62276056), the\nNational Key R&D Program of China, the China\nHTRD Center Project (No. 2020AAA0107904),\nthe Natural Science Foundation of Liaoning\nProvince of China (2022-KF-16-01), the Yunnan\nProvincial Major Science and Technology Special\nPlan Projects (No. 202103AA080015), the Funda-\nmental Research Funds for the Central Universities\n(Nos. N2216016, N2216001, and N2216002), and\nthe Program of Introducing Talents of Discipline\nto Universities, Plan 111 (No. B16009). Methods\nTM is a database that contains the bilingual transla-\ntion history of professional translators. It is usually\nused to help the translation of the test sentence by\nproviding similar sentence pairs, which may have\ntranslation hints, such as similar sentence patterns,\nphrases, lexicons, terminologies, or other transla-\ntion knowledge. Either an NMT model or an LLM\nneed to dig out those hints and ignore the irrelevant\ncontent. This motivates us to investigate prompt-\ning LLMs with TMs benefiting from their dazzling\nability of \u201cunderstand\u201d prompts.\nSuppose we have a TM database that retains a\ncollection of pairs of sentences. Given a source-\nlanguage sentence x, the database returns kmost\nsimilar sentences Xtm={x1\ntm, ...,xk\ntm}along\nwith their corresponding translations Ytm=\n{y1\ntm, ...,yk\ntm}. Now suppose we have a pre-\ntrained translation model (either an NMT model or\nan LLM) that takes xin some way and outputs a\ntranslation y, written as\ny= Trans( f(x)) (1)\nwhere Trans( \u00b7)denotes the translation model, and\nf(\u00b7)denotes a template by which we represent xas\nthe input of Trans( \u00b7). For example, if Trans( \u00b7)is\nan NMT model, f(x) =x; ifTrans( \u00b7)is a genera-\ntive LLM, f(x)could be an instruction involving\nx.\nWe then wish to use this model to generate a\nnew translation y\u2032by considering (Xtm,Ytm)as\ninstances for reference. This can be written as\ny\u2032= Trans( fref(x,Xtm,Ytm)) (2)Herefref(x,Xtm,Ytm)is a new template involv-\ning(Xtm,Ytm).\nIn this work, we focus on the case in which a\npowerful generative LLM (such as ChatGPT ) is\nused to perform translation. The input of Trans( \u00b7)\ncould be an instruction or question-like text, and\nso we can design fref(\u00b7)in many different ways.\nIn Figure 1, we present two types of templates:\nthe instruction-style template and the code-style\ntemplate. These designs come from a considera-\ntion of the human instruction tuning and the code\ntraining used in developing davinci-003 . For a\nmore extensive discussion of template design, see Appendix\nA.1). In Figure 5, we can see that the performance\ndeclines as more NMT translation experiments using\n\u201csmall\u201d models such as text-curie-001 and\ntext-babbage-001 . But their performance is\nfar away behind davinci-003 whose outputs\ncontain null in lines sometimes. We attribute this\nto the lack of emergent abilities of big models (Wei\net al., 2022). The Results\nB.1 Evaluation by COMET-22\nExcept", " Introduction\nLarge Languages Models (LLMs) trained on mas-\nsive corpora of texts have shown their ability to per-\nform new tasks from textual instructions or from a\nfew examples (Brown et al., 2020). These few-shot\nproperties \ufb01rst appeared when scaling models to a\nsuf\ufb01cient size (Kaplan et al., 2020), resulting in a\nline of work that focuses on further scaling these\nmodels (Chowdhery et al., 2022; Rae et al., 2021).\nThese efforts are based on the assumption that\nmore parameters will lead to better performance.\nHowever, recent work from Hoffmann et al. (2022)\nshows that, for a given compute budget, the best\nperformances are not achieved by the largest mod-\nels, but by smaller models trained on more data.\nThe objective of the scaling laws from Hoff-\nmann et al. (2022) is to determine how to best\nscale the dataset and model sizes for a particular\ntraining compute budget. However, this objective\ndisregards the inference budget, which becomes\ncritical when serving a language model at scale.\nIn this context, given a target level of performance,\nthe preferred model is not the fastest to train but the\nfastest at inference, and although it may be cheaper\nto train a large model to reach a certain level of\n\u0003Equal contribution. Correspondence: {htouvron,\nthibautlav,gizacard,egrave,glample}@meta.com\n1https://github.com/facebookresearch/llamaperformance, a smaller one trained longer will\nultimately be cheaper at inference. For instance,\nalthough Hoffmann et al. (2022) recommends\ntraining a 10B model on 200B tokens, we \ufb01nd\nthat the performance of a 7B model continues to\nimprove even after 1T tokens.\nThe focus of this work is to train a series of\nlanguage models that achieve the best possible per-\nformance at various inference budgets, by training\non more tokens than what is typically used. The\nresulting models, called LLaMA , ranges from 7B\nto 65B parameters with competitive performance\ncompared to the best existing LLMs. For instance,\nLLaMA-13B outperforms GPT-3 on most bench-\nmarks, despite being 10 \u0002smaller. We believe that\nthis model will help democratize the access and\nstudy of LLMs, since it can be run on a single GPU.\nAt the higher-end of the scale, our 65B-parameter\nmodel is also competitive with the best large lan-\nguage models such as Chinchilla or PaLM-540B.\nUnlike Chinchilla, PaLM, or GPT-3, we only\nuse publicly available data, making our work com-\npatible with open-sourcing, while most existing\nmodels rely on data which is either not publicly\navailable or undocumented (e.g. \u201cBooks \u2013 2TB\u201d or\n\u201cSocial media conversations\u201d). There exist some\nexceptions, notably OPT (Zhang et al., 2022),\nGPT-NeoX (Black et al., 2022), BLOOM (Scao\net al., 2022) and GLM (Zeng et al., 2022), but none\nthat are competitive with PaLM-62B or Chinchilla.\nIn the rest of this paper, we present an overview\nof the modi\ufb01cations we made to the transformer\narchitecture (Vaswani et al., 2017), as well as our\ntraining method. We then report the performance of\nour models and compare with others LLMs on a set\nof standard benchmarks. Finally, we expose some\nof the biases and toxicity encoded in our models,\nusing some of the most recent benchmarks from\nthe responsible AI community.arXiv:2302.13971v1  [cs.CL]  27 Feb 20232 Approach\nOur training approach is similar to the methods\ndescribed in previous work (Brown et al., 2020;\nChowdhery et al., 2022), and is inspired by the\nChinchilla scaling laws (Hoffmann et al., 2022).\nWe train large transformers on a large quantity of\ntextual data using a standard optimizer.\n2.1 Pre-training Data\nOur training dataset is a mixture of several sources,\nreported", " Introduction\nAdaptive MT is a type of machine translation that\nutilizes feedback from users to improve the qual-\nity of the translations over time. Feedback usually\nincludes corrections to previous translations, ter-\nminology and style guides, as well as ratings of\nthe quality of the translations. This can be partic-\nularly useful for domain-speci\ufb01c scenarios, where\nbaseline MT systems may have insuf\ufb01cient rele-\nvant data to accurately translate certain terms or\nphrases. There are still several challenges to ef-\nfectively incorporate user feedback into the trans-\nlation process, especially at inference time. In this\nwork, we use a relatively wide de\ufb01nition of adap-\ntive MT to refer to learning from similar transla-\ntions (fuzzy matches) found in approved transla-\ntion memories (TMs) on the \ufb02y (Farajian et al.,\n2017; Wuebker et al., 2018; Peris and Casacuberta,\n2019; Etchegoyhen et al., 2021), as well as real-\ntime terminology-constrained MT (Hokamp and\nLiu, 2017; Post and Vilar, 2018; Dinu et al., 2019;\nMichon et al., 2020).\nAutoregressive decoder-only LLMs, such as\nGPT-3 (Brown et al., 2020; Ouyang et al., 2022),\nBLOOM (BigScience Workshop et al., 2022),\nPaLM (Chowdhery et al., 2022), and LLaMA\n(Touvron et al., 2023) are trained to predict thearXiv:2301.13294v3  [cs.CL]  9 May 2023next word given the previous context. During un-\nsupervised pre-training, a language model devel-\nops a broad set of pattern recognition abilities. It\nthen uses these abilities at inference time to rapidly\nrecognize and adapt to the desired task. In their Results illustrated by Figure 1 show that few-\nshot translation with GPT-3.5 using fuzzy matches\nas context outperforms few-shot translation with\nrandom examples, although using random sen-\ntence pairs outperforms zero-shot translation. As\ndemonstrated by Table 1, across \ufb01ve language\npairs, adding more fuzzy matches improves trans-\nlation quality further. At some point, there might\nbe diminishing returns of adding more similar sen-\ntences as their similarity score decreases. In other\nwords, increasing the number of fuzzy matches\nfrom 2 sentences to 5 or 10 sentences incremen-\ntally improves translation quality, but with smaller\nquality gains.\nSimilarity\nScoreSegment Statistics\nfuzzy 2-shot fuzzy 5-shot\n>90% 167 2.7% 168 1.1%\n89-80% 751 12.2% 1,103 7.2%\n79-70% 1,593 25.9% 3,143 20.5%\n69-60% 1,825 29.7% 4,661 30.4%\n<60% 1,804 29.4% 6,275 40.9%\nTotal 6,140 = 3,070*2 15,350 = 3,070*5\nTable 2: Numbers and percentages of segments based on their similarity to the\nnew source segment, in the 2-shot and 5-shot Appendix A), we use\nterms found in a set of n-grams (1-5) of thesource segment to be translated. We experi-\nment with adding maximum 5 terms and max-\nimum 10 terms, which does not show a huge\ndifference in performance; in some cases only\na smaller number of terms is available in the\nglossary.\n\u2022 Zero-shot translation, i.e. without any fuzzy\nmatches. This is similar to the previous sce-\nnario, except that we only use terms from\nthe glossary. In zero-shot prediction, adding\nterms from the glossary improves translation\nquality. As shown in Table 6, improvements\nare signi\ufb01cant across all 5 language pairs.\nWe conducted human evaluation for English-\nto-Arabic, English-to-French, and English-to-\nSpanish terminology-constrained MT, to see to\nwhat extent the model adheres to the required\nterms, and how this affects the overall translation\nquality. The evaluators are professional linguists in\nthe respective languages. We provided the evalua-\ntors with 4 sets of 100 randomly selected sentence\npairs (zero-shot, zero-shot with glossary terms,\nfuzzy two-shot, and fuzzy two-shot with glossary\nterms). They were asked to evaluate the sentence-\nlevel translation quality on a 1-4 scale (Coughlin,\n2003) and", " Introduction\nMedicine is a humane endeavor where language enables key interactions for and between clinicians, researchers,\nand patients. Yet, today\u2019s AI models for applications in medicine and healthcare have largely failed to\nfully utilize language. These models, while useful, are predominantly single-task systems (e.g., classi\ufb01cation,\nregression, segmentation), lacking expressivity and interactive capabilities [21, 81, 97]. As a result, there is a\ndiscordance between what today\u2019s models can do and what may be expected of them in real-world clinical\nwork\ufb02ows [42, 74].\nRecent advances in large language models (LLMs) o\ufb00er an opportunity to rethink AI systems, with language\nas a tool for mediating human-AI interaction. LLMs are \u201cfoundation models\u201d [10], large pre-trained AI systems\nthat can be repurposed with minimal e\ufb00ort across numerous domains and diverse tasks. These expressive\nand interactive models o\ufb00er great promise in their ability to learn generally useful representations from the\nknowledge encoded in medical corpora, at scale. There are several exciting potential applications of such\nmodels in medicine, including knowledge retrieval, clinical decision support, summarisation of key \ufb01ndings,\n\u0003Equal contributions. yEqual leadership.\nzCorresponding authors: {karansinghal, shekazizi, alankarthi, natviv}@google.comarXiv:2212.13138v1  [cs.CL]  26 Dec 2022PubMedQA Mul tiMedQ A MedQA \n(USMLE) \nMedMCQA \nMMLU LiveQA \nTREC 2017 \nMedicationQA Consumer Health \nSearch QA \nMed-PaLM:  Newborn jaundice is when a newborn baby's skin and eyes look yellow. It is \ncaused by a buildup of a substance called bilirubin in the baby's blood. Bilirubin is a \nbyproduct of the normal process of red blood cells breaking down. Newborn jaundice is \ncommon and typically harmless, but it can be a sign of a more serious condition. The \njaundice typically goes away on its own within a few weeks. In some cases, it may last \nlonger or require treatment. The time it takes for the jaundice to go away can vary \ndepending on the cause and the severity of the jaundice. If the jaundice is severe or \nlasts longer than a few weeks, the doctor may recommend testing or treatment to \ndetermine the cause and prevent complications. Q: How long does it take for newborn jaundice to go away ?\nPaLM \n(540B) \n+ 17 %  \nMedical Question Answering Benchmark Automated and Human Evaluation \nPrompting \nMed-PaLM performs encouragingly on consumer \nmedical question answering \nInstruction \ntuning \nInstruction \nprompt tuning Figure 1jOverview of our contributions We curated MultiMedQA, a benchmark for medical question answering spanning\nmedical exam, medical research, and consumer medical questions. We evaluated PaLM and its instructed-tuned variant,\nFlan-PaLM, on MultiMedQA. With a combination of prompting strategies, Flan-PaLM exceeded SOTA performance on MedQA\n(USMLE), MedMCQA, PubMedQA, and MMLU clinical topics. In particular, it improved over the previous SOTA on MedQA\n(USMLE) by over 17%. We next proposed instruction prompt tuning to further align Flan-PaLM to the medical domain,\nproducing Med-PaLM. Med-PaLM\u2019s answers to consumer medical questions compared favorably with clinician-generated answers\nunder our human evaluation framework, demonstrating the e\ufb00ectiveness of instruction prompt tuning.\ntriaging patients\u2019 primary care concerns, and more.\nHowever, the safety-critical nature of the domain necessitates thoughtful development of evaluation frameworks,\nenabling researchers to meaningfully measure progress and capture and mitigate potential harms. This is\nespecially important for LLMs, since these models may produce generations misaligned with clinical and\nsocietal values. They may, for instance, hallucinate convincing medical", " Introduction\nto methodology and encoding rules. Journal of Chemical Information and Computer\nSciences 1988,28, 31\u201336.\n26(15)You, J.; Liu, B.; Ying, Z.; Pande, V.; Leskovec, J. Graph Convolutional Policy Network\nfor Goal-Directed Molecular Graph Generation. Proceedings of the 32nd International\nConference on Neural Information Processing Systems. 2018; p 6412\u20136422.\n(16)Coulom, R. E\ufb03cient Selectivity and Backup Operators in Monte-Carlo Tree Search.\nProceedings of the 5th International Conference on Computers and Games. Berlin,\nHeidelberg, 2006; p 72\u201383.\n(17)Kocsis, L.; Szepesv\u00e1ri, C. Bandit Based Monte-Carlo Planning. Machine Learning:\nECML 2006. Berlin, Heidelberg, 2006; pp 282\u2013293.\n(18)Bickerton, G. R.; Paolini, G. V.; Besnard, J.; Muresan, S.; Hopkins, A. L. Quantifying\nthe chemical beauty of drugs. Nature Chemistry 2012,4, 90\u201398.\n(19)Yang, X.; Zhang, J.; Yoshizoe, K.; Terayama, K.; Tsuda, K. ChemTS: an e\ufb03cient python\nlibrary for de novo molecular generation. Science and Technology of Advanced Materials\n2017,18, 972\u2013976.\n(20)Yang, X.; Aasawat, T.; Yoshizoe, K. Practical Massively Parallel Monte-Carlo Tree\nSearch Applied to Molecular Design. International Conference on Learning Representa-\ntions. 2021.\n(21)McKay, B. D. Isomorph-Free Exhaustive Generation. Journal of Algorithms 1998,26,\n306\u2013324.\n(22)Stephen, H. G.; Andrew, R. J. Mckay\u2019s canonical graph labeling algorithm. In Commu-\nnicating Mathematics 2009,479, 99\u2013111.\n(23)Jin, W.; Barzilay, R.; Jaakkola, T. S. Composing Molecules with Multiple Property\nConstraints. CoRR 2020,abs/2002.03244 .\n(24)Segler, M. H. S.; Preuss, M.; Waller, M. P. Planning chemical syntheses with deep neural\nnetworks and symbolic AI. Nature 2018,555, 604\u2013610.\n27(25)Zaki, M. J.; Meira, W., Jr. Data Mining and Analysis: Fundamental Concepts and\nAlgorithms ; Cambridge University Press, 2014.\n(26)Xifeng Yan, J. H. gSpan: Graph-Based Substructure Pattern Mining. International\nConference on Data Mining 2002, 721\u2013724.\n(27)Houbraken, M.; Demeyer, S.; Michoel, T.; Audenaert, P.; Colle, D.; Pickavet, M.\nThe Index-Based Subgraph Matching Algorithm with General Symmetries (ISMAGS):\nExploiting Symmetry for Faster Subgraph Enumeration. Plos One 2014,9, 1\u201315.\n(28)Segler, M. H. S.; Kogej, T.; Tyrchan, C.; Waller, M. P. Generating Focused Molecule\nLibraries for Drug Discovery with Recurrent Neural Networks. ACS central science\n2018,4, 120\u2013131.\n(29)Li, Y.; Vinyals, O.; Dyer, C.; Pascanu, R.; Battaglia, P. Learning Deep Generative\nModels of Graphs. 2018; https://openreview.net/forum?id=Hy1d-ebAb .\n(30)Browne, C. B.; Powley, E.; Whitehouse, D.; Lucas, S. M.; Cowling, P. I.; Rohlfshagen, P.;\nTavener, S.; Perez, D.; Samothrakis, S.; Colton, S. A Survey of Monte Carlo Tree Search Methods. IEEE Transactions on Computational Intelligence and AI in Games 2012,4,\n1\u201343.\n(31)Silver, D. et al. Mastering the game of Go with deep neural networks and tree search.\nNature 2016,529, 484\u2013489.\n(32)Schulman, J.; Levine, S.; Moritz, P.; Jordan, M. I.; Abbeel, P. Trust Region Policy\nOptimization. 2015; https://arxiv.org/abs/1502.05477 .\n(33)Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; Klimov, O. Proximal Policy\nOptimization Algorithms. 2017; https://arxiv.org/abs/1707.06347 .\n(34)Kakade, S.; Langford, J. Approximately Optimal Approximate Reinforcement Learning.\n28Proceedings of the Nineteenth International Conference on Machine Learning. San\nFrancisco, CA, USA, 2002; p 267\u2013274.\n(35)Jaeger, S.; Fulle, S.; Turk, S. Mol2vec: Unsupervised Machine Learning Approach with\nChemical Intuition. Journal of Chemical Information and Modeling 2018,58, 27\u201335.\n(36)Mikolov,T.; Sutskever,I.; Chen,K.; Corrado,G.S.; Dean,J.DistributedRepresentations\nof Words and Phrases and their Compositionality. Advances in Neural Information\nProcessing Systems. 2013.\n(37)Brown, N.; Fiscato, M.; Segler, M. H.; Vaucher, A. C. GuacaMol: Benchmarking Models\nfor de Novo Molecular Design. Journal of Chemical Information and Modeling 2019,\n59, 1096\u20131108.\n(38)Liang, E.; Liaw, R.; Nishihara, R.; Moritz, P.; Fox, R.; Goldberg, K.; Gonzalez, J.;\nJordan, M.; Stoica, I. RLlib: Abstractions for Distributed Reinforcement Learning.\nProceedings of the 35th International Conference on Machine Learning. 2018; pp 3053\u2013\n3062.\n(39)Paszke, A. et al. Advances", " Introduction\nLarge-scale pre-trained language models (LMs) have demonstrated impressive natural language\ngeneration results consistently indicate that\nour proposed decoding and training methods do not harm the \ufb02uency of the generation. For instance,\nin Table 9, all our decoding choices result in PPL scores between 1:9\u00184:1that are smaller than\nTop-p0.9 PPL score 12:0.\nTo provide full details about the columns reported in Table 9 and Table 10, NE ERrefers to the\nnamed-entity error, Entail Rrefers to entailment ratio, Div. refers to distinct 4-grams and Rep. refers\nto repetition.\"means the higher the better, and #means the lower the better.\nTable 9: The factuality of 1.3B LM with different decoding algorithms. pis the nucleus probability,\n\u0015is the decay factor, and !lower bounds the decay.\nDecodingFactual Prompt Nonfactual Prompt\nNE ER#Entail R\"Div.\" Rep.# PPL\" NE ER#Entail R\"Div.\" Rep.# PPL\"\nGreedy 39.9% 12.9% 0.05 33.1% 1.9 45.0% 8.8% 0.05 36.2% 2.0\nTop-p 0.9 52.4% 2.9% 0.88 0.2% 10.9 56.8% 2.0% 0.89 0.3% 12.0\np|\u0015 Top-p+\u0015-decay\n0.9 | 0.9 41.1% 10.8% 0.43 30.7% 2.02 45.7% 6.8% 0.47 34.5% 2.13\n0.9 | 0.5 39.9% 13.0% 0.08 33.1% 1.89 44.9% 9.1% 0.09 35.9% 1.97\np|\u0015 Top-p+\u0015-decay +p-reset\n0.9 | 0.9 41.5% 10.3% 0.52 10.3% 3.6 45.4% 6.3% 0.57 9.1% 3.9\n0.9 | 0.5 39.3% 12.8% 0.34 17.8% 2.3 44.5% 8.4% 0.45 18.9% 2.5\np|\u0015|! Top-p+\u0015-decay +p-reset +!-bound ( factual-nucleus sampling )\n0.9 | 0.9 | 0.3 42.1% 10.1% 0.55 7.1% 3.8 46.5% 5.6% 0.59 6.4% 4.1\n0.9 | 0.5 | 0.3 41.0% 12.2% 0.47 13.0% 2.8 46.0% 7.0% 0.51 12.7% 3.0\n0.9 | 0.9 | 0.2 41.7% 9.9% 0.52 8.6% 3.6 45.6% 6.2% 0.56 7.6% 4.0\n0.9 | 0.5 | 0.2 39.3% 12.8% 0.38 16.1% 2.5 45.2% 7.8% 0.42 16.9% 2.7\n20Table 10: related work in \u00a7 2 and present our benchmark\nsetup with evaluation protocol in \u00a7 3. We study the factual accuracy of LMs with respect to model\nsize, prompt type, and choice of decoding algorithm in \u00a7 4. After that, we present factual-nucleus\nsampling algorithm in \u00a7 5, and factuality-enhanced training in \u00a7 6. We conclude the paper in \u00a7 7.\n2 Related Work\nFactuality vs. Model Size Lin et al. [31] propose the TruthfulQA benchmark to measure the\nfalsehood generations from different sized LMs. The result suggests that bigger LMs pre-trained\non web text are generally less truthful than smaller ones in terms of false belief or misconception.\nAt \ufb01rst glance, this is contradictory to our observation, however, our work focuses on different\nknowledge to TruthfulQA work. The TruthfulQA benchmark focuses on conceptual knowledge,\nwhile our benchmark focuses on factual knowledge [ 32]3. Large LMs can be good at recalling\nfactual knowledge given substantial pre-training corpus, suggested by previous studies on LM\u2019s\nparameteric knowledge [ 33], but there still remains room for improvement for reasoning conceptual\nknowledge [34, 35].\nParametric Factual Knowledge A group of work addresses the factual errors in the parametric\nknowledge of LMs that is acquired from training corpus [ 36\u201338]. The correctness of the parametric\nknowledge is commonly tested in cloze-style question answering format [ 33] (e.g., Person X is\nborn in __). Efforts are made to \ufb01ne-tune the pre-trained LM to \u201cinject\u201d more knowledge and\n3According to Krathwohl [32], knowledge can be categorized into four types: i) factual knowledge, ii)\nconceptual knowledge, iii) procedural knowledge, and iv) metacognitive knowledge.\n2Table 1: Example of continuations from the", " Introduction\nImagine a future where a doctor can write a few\nsentences describing a specialized drug for treating\na patient and then receive the exact structure of\nthe desired drug. Although this seems like science\n\ufb01ction now, with progress in integrating natural\nlanguage and molecules, it might well be possi-\nble in the future. Historically, drug creation has\ncommonly been done by humans who design and\nbuild individual molecules. In fact, bringing a new\ndrug to market can cost over a billion dollars and\ntake over ten years (Gaudelet et al., 2021). Re-\ncently, there has been considerable interest in us-\ning new deep learning tools to facilitate in silico\ndrug design\u2013 a \ufb01eld often called cheminformatics\n(Rifaioglu et al., 2018). Yet, many of these experi-\nments still focus on molecules and their low-level\n* indicates equal contributions.\n1All resources are publicly available at github.com/blender-\nnlp/MolT5\nThe molecule isaneighteen -membered homodetic cyclic peptide\nwhich isisolated from Oscillatoria sp.and exhibits antimalarial\nactivity against theW2chloroquine -resistant strain ofthemalarial\nparasite, Plasmodium falciparum .Ithasarole asametabolite andan\nantimalarial .Itisahomodetic cyclic peptide, amember of1,3-\noxazoles, amember of1,3-thiazoles andamacrocycle .Target PredictionFigure 1: An example output from our model for the\nmolecule generation task. The left is the ground truth,\nand the right is a molecule generated from the given\nnatural language caption.\nproperties such as logP (the octanol-water parti-\ntion coef\ufb01cient) (Bagal et al., 2021). In the future,\nwe foresee a need for a higher-level control over\nmolecule design, which can easily be facilitated by\nnatural language.\nIn this work, we pursue an ambitious goal of\ntranslating between molecules and language by\nproposing two new tasks: molecule captioning\nand text-guided de novo molecule generation. In\nmolecule captioning, we take a molecule (e.g., as\na SMILES string) and generate a caption that de-\nscribes it (Figure 2). In text-guided molecule gener-\nation, the task is to create a molecule that matches\na given natural language description (Figure 1).\nThese new tasks would help to accelerate research\nin multiple scienti\ufb01c domains by enabling chem-\nistry domain experts to generate new molecules\nand better understand them using natural language.\nWhile our proposed molecule-language tasks\nshare some similarities with vision-language tasks,\nthey have several inherent dif\ufb01culties that separate\nthem from existing vision-language analogs: 1)\ncreating annotations for molecules requires signif-arXiv:2204.11817v3  [cs.CL]  3 Nov 2022C1CC(=O)C2CC34C(=O)\nN5C6C(CCC(=O)C6CC5\n(C(=O)N3C2C1O)SS4)O  \nSMILES representation3D V iew\nCaptionThe molecule is an organic disulfide isolated from the whole\nbroth of the marine-derived fungus Exserohilum rostratum and\nhas been shown to exhibit antineoplastic activity . It has a role as\na metabolite and an antineoplastic agent. It is a bridged\ncompound, a lactam, an organic disulfide, an organic\nheterohexacyclic compound, a secondary alcohol, a cyclic\nketone and a diol.Molecule Captioning Image Captioning\n1. a cat sitting on top of an open laptop computer .\n2. a cat that is sitting on top of a lap top.  \n3. a cat is sitting on the keyboard of a laptop.\n4. a cat is sitting on an open laptop.  \n5. a striped cat sitting on top of a laptop  \nCaptions from COCO \nFigure 2: An example of both the image captioning task (Chen et al., 2015) and molecule captioning. Molecule\ncaptioning is considerably more dif\ufb01cult because of the increased linguistic variety in possible captions.\nicant domain expertise, 2) thus, it is signi\ufb01cantly\nmore dif\ufb01cult to acquire large numbers of molecule-\ndescription pairs, 3) the same molecule can have\nmany functions and thus be described in very", "Abstract\nPrediction of a molecule\u2019s 3D conformer ensemble from the molecular graph holds\na key role in areas of cheminformatics and drug discovery. Existing generative\nmodels have several drawbacks including lack of modeling important molecular\ngeometry elements (e.g. torsion angles), separate optimization stages prone to\nerror accumulation, and the need for structure \ufb01ne-tuning based on approximate\nclassical force-\ufb01elds or computationally expensivemethods. Indeed, these downstream modi\ufb01cations could have signi\ufb01cant impacts on a\nrange of applications in cheminformatics and drug discovery.\nBoth the GraphDG and CGCF models, which represent important steps in ML-enabled conformer\ngeneration, are not quite ready to be used in a production setting without relying on a force \ufb01eld\noptimization. This is especially evident given the example structures presented in the main text\nand inresults\nin \ufb01g. 7. Importantly, we do not include the start up times for any of theexperiments on two benchmarks: GEOM-QM9 (smaller molecules\nrelevant to gas-phase chemistry) and GEOM-DRUGS (drug-like molecules) [Axelrod and Gomez-\nBombarelli, 2020a]. Our method often outperforms previous ML and two popular open-source or\ncommercialappendix M. However, both models improve over traditional baselines at searching the\nspace of interatomic distances and outputting diverse predictions, which is a credit to the search\nstrategies employed by each model, especially CGCF. Further, the GraphDG model is competitive\nwith GEOMOLfor the QM9 dataset and should be viewed as a viable alternative to GEOMOLfor\nsmall molecules with few heavy atoms.\nAs researchers continue to develop 3D ML-based conformer generators, theResults on the GEOM-QM9 dataset with FF \ufb01ne-tuning.\nCOV - R (%)\" AMR - R (\u00c5)# COV - P (%)\" AMR - P (\u00c5)#\nModels Mean Median Mean Median Mean Median Mean Median\nGraphDG (ML) 88.70 100.00 0.210 0.165 90.14 100.00 0.185 0.129\nCGCF (ML) 75.45 100.00 0.313 0.246 50.29 50.00 0.518 0.520\nRDKit=ETKDG 83.48 100.00 0.219 0.172 89.78 100.00 0.160 0.116\nOMEGA (C) 85.73 100.00 0.177 0.126 83.08 100.00 0.224 0.186\nGEOMOL(s= 5:00)89.37 100.00 0.201 0.157 91.92 100.00 0.173 0.124\nL Additional coverageExperiments\nWe empirically evaluate GEOMOLon the task of low-energy conformer ensemble generation for\nsmall and drug-like molecules. We largely follow the evaluation protocols of recentdiscussion between DG-\nbased and non DG-based algorithms will carry on. Here, we chose to take the latter approach because\nwe wanted to explicitly model important elements of conformer generation, and this strategy has\nbeen successful. In our experience, modeling these speci\ufb01c geometric elements leads to a signi\ufb01cant\nimprovement in the quality of the output structures. It is still unclear if such an approach can tackle\nlong-range interactions, which remains the major drawback of our model. We hope to answer this\nquestion in future work.\n25Conclusion\nWe proposed GEOMOL, an end-to-end generative approach for molecular 3D conformation ensembles\nthat explicitly models various molecular geometric aspects such as torsion angles or chirality. We\nexpect that such differentiable structure generators will signi\ufb01cantly impact small molecule conformer\ngeneration along with many related applications (e.g. protein-ligand binding), thus speeding up areas\nsuch as drug discovery. G EOMOL\u2019s full source code will be made publicly available.\nLimitations & future work. A few current limitations are highlighted and left for future exten-\nsions (see alsoAcknowledgments and Disclosure of Funding\nOEG thanks Bracha Laufer, Tian Xie, Xiang Fu, Peter Mikhael, and the rest of the RB and TJ group\nmembers for their helpful comments and suggestions. LP thanks Camille Bilodeau and the rest of\nthe WHG, KFJ,", " Introduction\nMolecular representations underpin predictive, generative and analytical tasks in drug discovery [ 1].\nThe choice of a suitable representation can drastically impact the ef\ufb01ciency of discovering a novel drug\ncandidate. For instance, applications such as Virtual Screening andQuantitative Structure-Activity-\nRelationship (QSAR) modeling rely on the availability of effective molecular representations [2].\nLanguage models have been applied to text-based molecular representations such as Simpli\ufb01ed\nMolecular Input Line Entry System (SMILES) [ 3]. They show impressive performance across a range\nof domain applications including molecular property [ 4,5] and reaction prediction problems [ 6,7],\nas well as generative tasks [ 8]. Numerous strategies have been explored to encourage learning of\nhigh quality representations with language models including input reconstruction [ 9\u201311], whereby a\nmodel learns to predict masked or corrupted tokens; and input translation [ 5,12], where the goal is to\ntranslate the input to another modality or representation. Further improvements have been made by\nincorporating calculated molecular properties into the representation, either by concatenating with the\nlearnt representations [ 13], or through devising pre-training schemes [ 14]. Finally, a range of model\narchitectures have been explored including autoencoders [5], RNNs [9] and transformers [10, 11].\nAside from the modal limitations of representing molecules as strings, a drawback to learning from\ntext-based molecular representations is introduced by the ambiguity of linearizing the molecular\ngraph [ 15]. In the case of SMILES, many valid sequences may represent the same molecule\ndepending on the traversal path of the molecular graph. This ambiguity has led to the development of\ncanonicalization algorithms [ 16,17] which, while practical, introduce artifacts to linearized SMILES\nsuch that a language model may be distracted by the rules of canonicalization. Previous works have\nshown the bene\ufb01ts of learning using permutations of SMILES [18].\nMachine Learning for Molecules Workshop at NeurIPS 2020. https://ml4molecules.github.ioarXiv:2011.13230v1  [cs.LG]  26 Nov 2020MolBER T \nCLS C ( MA SK N ... CLS C ( C N ... \nEMBEDDING P HYS C HEM P RED SMILES-E Q M ASKED L M \nSMILES (or pair of SMILES) Figure 1: Diagram of M OLBERTillustrating the various auxiliary tasks utilized for pre-training.\nIn this work, we evaluate the application of the widely used Bidirectional Encoder Representations\nfrom Transformers (BERT) [ 19] architecture for the generation of molecular representations. We\nexplore the impact of employing a range of domain-relevant auxiliary tasks during pre-training and\nevaluate the produced learnt representations on downstream Virtual Screening and QSAR benchmarks.\nCode and pre-trained models are available at https://github.com/BenevolentAI/MolBERT.\n2 M OLBERT\nMOLBERT, as depicted in Figure 1, is a bidirectional language model that uses the BERT archi-\ntecture [ 19]. To understand the impact of pre-training with different domain-relevant tasks on\ndownstream applications, we experiment with the following set of self-supervised tasks:\nMasked language modeling (M ASKED LM): The canonical task proposed by BERT, whereby the\nmodel is trained to predict the true identity of masked tokens. The task is optimized using the\ncross-entropy loss between the sequence output and the masked tokens of the input.\nSMILES equivalence (SMILES-E Q):Given an input of two SMILES where the second is, with\nequal probability, either randomly sampled from the training set or a synonymous permutation of\nthe \ufb01rst SMILES, the task is to predict whether the two inputs represent the same molecule. This\nis a", " Introduction\nRecent years have featured a trend towards pre-trained language representations in NLP systems, applied in increasingly\n\ufb02exible and task-agnostic ways for downstream transfer. First, single-layer representations were learned using word\nvectors [ MCCD13 ,PSM14 ] and fed to task-speci\ufb01c architectures, then RNNs with multiple layers of representations\nand contextual state were used to form stronger representations [ DL15 ,MBXS17 ,PNZtY18 ] (though still applied to\ntask-speci\ufb01c architectures), and more recently pre-trained recurrent or transformer language models [ VSP+17] have\nbeen directly \ufb01ne-tuned, entirely removing the need for task-speci\ufb01c architectures [RNSS18, DCLT18, HR18].\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension,\nquestion answering, textual entailment, and many others, and has continued to advance based on new architectures\nand algorithms [ RSR+19,LOG+19,YDY+19,LCG+19]. However, a major limitation to this approach is that while\nthe architecture is task-agnostic, there is still a need for task-speci\ufb01c datasets and task-speci\ufb01c \ufb01ne-tuning: to achieve\nstrong performance on a desired task typically requires \ufb01ne-tuning on a dataset of thousands to hundreds of thousands\nof examples speci\ufb01c to that task. Removing this limitation would be desirable, for several reasons.\nFirst, from a practical perspective, the need for a large dataset of labeled examples for every new task limits the\napplicability of language models. There exists a very wide range of possible useful language tasks, encompassing\nanything from correcting grammar, to generating examples of an Results for SAT task.\n Figure H.3: All Related Work\nSeveral lines of work have focused on increasing parameter count and/or computation in language models as a\nmeans to improve generative or task performance. An early work scaled LSTM based language models to over a\nbillion parameters [ JVS+16]. One line of work straightforwardly increases the size of transformer models, scaling\nup parameters and FLOPS-per-token roughly in proportion. Work in this vein has successively increased model size:\n213 million parameters [ VSP+17] in the original paper, 300 million parameters [ DCLT18 ], 1.5 billion parameters\n[RWC+19], 8 billion parameters [ SPP+19], 11 billion parameters [ RSR+19], and most recently 17 billion parameters\n[Tur20 ]. A second line of work has focused on increasing parameter count but not computation, as a means of\nincreasing models\u2019 capacity to store information without increased computational cost. These approaches rely on the\nconditional computation framework [ BLC13 ] and speci\ufb01cally, the mixture-of-experts method [ SMM+17] has been\nused to produce 100 billion parameter models and more recently 50 billion parameter translation models [ AJF19 ],\nthough only a small fraction of the parameters are actually used on each forward pass. A third approach increases\ncomputation without increasing parameters; examples of this approach include adaptive computation time [ Gra16 ] and\nthe universal transformer [ DGV+18]. Our work focuses on the \ufb01rst approach (scaling compute and parameters together,\nby straightforwardly making the neural net larger), and increases model size 10x beyond previous models that employ\nthis strategy.\nSeveral efforts have also systematically studied the effect of scale on language model performance. [ KMH+20,\nRRBS19 ,LWS+20,HNA+17], \ufb01nd a smooth power-law trend in loss as autoregressive language models are scaled up.\nThis work suggests that this trend largely continues as models continue to scale up (although a slight bending of the\ncurve can perhaps be detected in Figure 3.1),", " Introduction\nTraining a machine learning model to perform natural language processing (NLP) tasks\noften requires that the model can process text in a way that is amenable to downstream\nlearning. This can be loosely viewed as developing general-purpose knowledge that allows\nthe model to \u201cunderstand\u201d text. This knowledge can range from low-level (e.g. the spelling\n\u2217.Equalcontribution. Adescriptionofeachauthor\u2019scontributionisavailableinAppendixA.Correspondence\ntocraffel@gmail.com .\n1.https://github.com/google-research/text-to-text-transfer-transformer\n\u00a92020 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei\nLi, and Peter J. Liu.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ . Attribution requirements are provided at\nhttp://jmlr.org/papers/v21/20-074.html .arXiv:1910.10683v4  [cs.LG]  19 Sep 2023Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nor meaning of words) to high-level (e.g. that a tuba is too large to fit in most backpacks).\nIn modern machine learning practice, providing this knowledge is rarely done explicitly;\ninstead, it is often learned as part of an auxiliary task. For example, a historically common\napproach is to use word vectors (Mikolov et al., 2013b,a; Pennington et al., 2014) to map\nword identities to a continuous representation where, ideally, similar words map to similar\nvectors. These vectors are often learned through an objective that, for example, encourages\nco-occurring words to be positioned nearby in the continuous space (Mikolov et al., 2013b).\nRecently, it has become increasingly common to pre-train the entire model on a data-rich\ntask. Ideally, this pre-training causes the model to develop general-purpose abilities and\nknowledge that can then be transferred to downstream tasks. In applications of transfer\nlearning to computer vision (Oquab et al., 2014; Jia et al., 2014; Huh et al., 2016; Yosinski\net al., 2014), pre-training is typically done via supervised learning on a large labeled data set\nlike ImageNet (Russakovsky et al., 2015; Deng et al., 2009). In contrast, modern techniques\nfor transfer learning in NLP often pre-train using unsupervised learning on unlabeled data.\nThis approach has recently been used to obtain state-of-the-art methods in natural\nlanguage processing , 2013.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. MASS: Masked sequence to\nsequence pre-training for language generation. arXiv preprint arXiv:1905.02450 , 2019.\n65Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of\nMachine Learning Research , 2014.\nSandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J. Pal. Learning\ngeneral purpose distributed sentence representations via large scale multi-task learning.\narXiv preprint arXiv:1804.00079 , 2018.\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning with neural\nnetworks. In Advances in neural information processing systems , 2014.\nRichard S. Sutton. The bitter lesson. http://www.incompleteideas.net/IncIdeas/\nBitterLesson.html , 2019.\nWilson L. Taylor. \u201cCloze procedure\u201d: A new tool for measuring readability. Journalism\nBulletin, 1953.\nTrieu H. Trinh and Quoc V. Le. A simple method for commonsense reasoning. arXiv preprint\narXiv:1806.02847 , 2018.\nAdam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip\nBachman, and Kaheer Suleman. NewsQA: A machine comprehension dataset. arXiv\npreprint arXiv:1611.09830 , 2016.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural\ninformation processing systems , 2017.\nElena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of representations\nin the transformer: A study with machine translation and language modeling", " Introduction\nDeep Learning has recently enabled generative models for molecules [ 21]. SMILES strings [ 26]\noffer a convenient representation of molecules for generative results for the different experiments of this work are available at:\ngithub.com/bioinf-jku/FCD Conclusions. In previous studies, the assessment of generative molecules was based on speci\ufb01c\nproperties such as logP, druglikeness or SA score. However, looking at all these properties individi-\nually makes the comparison of generative models dif\ufb01cult. We introduce the FCD, a novel metric for\ngenerative models for drug design. FCD is based on a multi-task network and therefore incorporates\na wide variety of important chemical and biological features into a single metric. FCD was able to\n6real molecules\nLSTM_Segler.smi\nDRD2_ORGAN2_04_30_Benhenda.smi\nDRD2_canon_Agent_Olivecrona.smi\nDRD2_reduced_Agent_Olivecrona.smi\nDRD2_RL_40_Benhenda.smi\nDRD2_ORGAN2_04_60_Benhenda.smi\nDRD2_RL_60_Benhenda.smi\nbaseline0102030405060Fr\u00e9chet ChemNet Distancegenerated smiles\nFCD 0.22\nFCD 1.62\nFCD 24.14\nFCD 31.15\nFCD 33.63\nFCD 35.28\nFCD 38.04\nFCD 47.85\nFCD 58.76Figure 2: FCD of generated molecules based on different Acknowledgments\nWe thank Marwin Segler, Marcus Olivecrona and Mostapha Benhenda for providing their generated\nmolecules. Further more we thank Marwin Segler for helpful discussion. KP, TU, and GK funded by\nthe Institute of Bioinformatics, Johannes Kepler University Linz Austria.\nThis work was supported by Merck Group (research agreement 05/2016), Zalando (research agree-\nment 01/2016) and by LIT (LIT-2017-3-YOU-003).\n7References\n[1]Benhenda, M. (2017). ChemGAN challenge for drug discovery: can AI reproduce natural\nchemical diversity? arXiv preprint arXiv:1708.08227 .\n[2]Bento, A. P., Gaulton, A., Hersey, A., Bellis, L. J., Chambers, J., Davies, M., Kr\u00fcger, F. A., Light,\nY ., Mak, L., McGlinchey, S., Nowotka, M., Papadatos, G., Santos, R., and Overington, J. P. (2013).\nThe ChEMBL bioactivity database: an update. Nucleic Acids Research , 42(D1):D1083\u2013D1090.\n[3]Bickerton, G. R., Paolini, G. V ., Besnard, J., Muresan, S., and Hopkins, A. L. (2012). Quantifying\nthe chemical beauty of drugs. Nature Chemistry , 4(2):90\u201398.\n[4]Dowson, D. C. and Landau, B. V . (1982). The Fr\u00e9chet distance between multivariate normal\ndistributions. Journal of Multivariate Analysis , 12:450\u2013455.\n[5]Ertl, P. and Schuffenhauer, A. (2009). Estimation of synthetic accessibility score of drug-like\nmolecules based on molecular complexity and fragment contributions. Journal of Cheminformatics ,\n1(1):8.\n[6]Fr\u00e9chet, M. (1957). Sur la distance de deux lois de probabilit\u00e9. C. R. Acad. Sci. Paris , 244:689\u2013\n692.\n[7]G\u00f3mez-Bombarelli, R., Wei, J. N., Duvenaud, D., Hern\u00e1ndez-Lobato, J. M., S\u00e1nchez-Lengeling,\nB., Sheberla, D., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., and Aspuru-Guzik, A.\n(2016). Automatic chemical design using a data-driven continuous representation of molecules.\nACS Central Science .\n[8]Guimaraes, G. L., Sanchez-Lengeling, B., Outeiral, C., Cunha Farias, P. L., and Aspuru-Guzik, A.\n(2017). Objective-reinforced generative adversarial networks (ORGAN) for sequence generation\nmodels. arXiv preprint arXiv:1705.10843 .\n[9]Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S. (2017). GANs trained\nby a two time-scale update rule converge to a local nash equilibrium. In Advances in Neural\nInformation Processing Systems , pages 6629\u20136640.\n[10] Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Computation ,\n9(8):1735\u20131780.\n[11] Irwin, J. J., Sterling, T., Mysinger, M. M., Bolstad, E. S., and Coleman, R. G. (2012). ZINC:\nA free tool to discover chemistry for biology. Journal of Chemical Information and Modeling ,\n52(7):1757\u20131768.\n[12] Jaques, N., Gu, S., Bahdanau, D., Hern\u00e1ndez-Lobato, J. M., Turner, R. E., and Eck, D. (2017).\nSequence tutor: Conservative \ufb01ne-tuning of sequence generation models with kl-control. arXiv\npreprint arXiv:1705.10843 .\n[13] Klambauer, G., Unterthiner, T., Mayr, A., and Hochreiter, S. (2017). Self-normalizing neural\nnetworks. In Guyon, I., Luxburg, U. V ., Bengio, S., Wallach, H., Fergus,", " Introduction\nAn important aspect of dialogue response generation\nsystems, which are trained to produce a reasonable\nutterance given a conversational context, is how to\nevaluate the quality of the generated response. Typi-\ncally, evaluation is done using human-generated su-\npervised signals, such as a task completion test or a\nuser satisfaction score (Walker et al., 1997; M \u00a8oller\net al., 2006; Kamm, 1995), which are relevant when\nthe dialogue is task-focused. We call models opti-\nmized for such supervised objectives supervised di-\nalogue models , while those that do not are unsuper-\nvised dialogue models .\nThis paper focuses on unsupervised dialogue re-\nsponse generation models, such as chatbots. These\n\u0003Denotes equal contribution.models are receiving increased attention, partic-\nularly using end-to-end training with neural net-\nworks (Serban et al., 2016; Sordoni et al., 2015;\nVinyals and Le, 2015). This avoids the need to col-\nlect supervised labels on a large scale, which can\nbe prohibitively expensive. However, automatically\nevaluating the quality of these models remains an\nopen question. Automatic evaluation metrics would\nhelp accelerate the deployment of unsupervised re-\nsponse generation systems.\nFaced with similar challenges, other natural lan-\nguage tasks have successfully developed automatic\nevaluation metrics. For example, BLEU (Papineni\net al., 2002a) and METEOR (Banerjee and Lavie,\n2005) are now standard for evaluating machine\ntranslation models, and ROUGE (Lin, 2004) is often\nused for automatic summarization. These metrics\nhave recently been adopted by dialogue researchers\n(Ritter et al., 2011; Sordoni et al., 2015; Li et al.,\n2015; Galley et al., 2015b; Wen et al., 2015; Li\net al., 2016). However these metrics assume that\nvalid responses have signi\ufb01cant word overlap with\nthe ground truth responses. This is a strong assump-\ntion for dialogue systems, where there is signi\ufb01cant\ndiversity in the space of valid responses to a given\ncontext. This is illustrated in Table 1, where two rea-\nsonable responses are proposed to the context, but\nthese responses do not share any words in common\nand do not have the same semantic meaning.\nIn this paper, we investigate the correlation be-\ntween the scores from several automatic evaluation\nmetrics and human judgements of dialogue response\nquality, for a variety of response generation models.\nWe consider both statistical word-overlap similar-arXiv:1603.08023v2  [cs.CL]  3 Jan 2017Context of Conversation\nSpeaker A: Hey John, what do you want to do tonight?\nSpeaker B: Why don\u2019t we go see a movie?\nGround-Truth Response\nNah, I hate that stuff, let\u2019s do something active.\nModel Response\nOh sure! Heard the \ufb01lm about Turing is out!\nTable 1: Example showing the intrinsic diversity\nof valid responses in a dialogue. The (reasonable)\nmodel response would receive a BLEU score of 0.\nity metrics such as BLEU, METEOR, and ROUGE,\nand word embedding metrics derived from word\nembedding models such as Word2Vec (Mikolov et\nal., 2013). We \ufb01nd that all metrics show either\nweak or no correlation with human judgements, de-\nspite the fact that word overlap metrics have been\nused extensively in the literature for evaluating dia-\nlogue response models (see above, and Lasguido et\nal. (2014)). In particular, we show that these metrics\nhave only a small positive correlation on the chitchat\noriented Twitter dataset, and no correlation at all on\nthe technical Ubuntu Dialogue Corpus. For the word\nembedding metrics, we show that this is true even\nthough all metrics are able to signi\ufb01cantly distin-\nguish between baseline and state-of-the-art models\nacross multiple datasets. We further highlight the\nshortcomings of these metrics using: a) a statisti-\ncal analysis of our", " Introduction\nMany current NLP systems and techniques treat words as atomic units - there is no notion of similar-\nity between words, as these are represented as indices in a vocabulary. This choice has several good\nreasons - simplicity, robustness and the observation that simple models trained on huge amounts of\ndata outperform complex systems trained on less data. An example is the popular N-gram model\nused for statistical language modeling - today, it is possible to train N-grams on virtually all available\ndata (trillions of words [3]).\nHowever, the simple techniques are at their limits in many tasks. For example, the amount of\nrelevant in-domain data for automatic speech recognition is limited - the performance is usually\ndominated by the size of high quality transcribed speech data (often just millions of words). In\nmachine translation, the existing corpora for many languages contain only a few billions of words\nor less. Thus, there are situations where simple scaling up of the basic techniques will not result in\nany signi\ufb01cant progress, and we have to focus on more advanced techniques.\nWith progress of machine learning techniques in recent years, it has become possible to train more\ncomplex models on much larger data set, and they typically outperform the simple models. Probably\nthe most successful concept is to use distributed representations of words [10]. For example, neural\nnetwork based language models signi\ufb01cantly outperform N-gram models [1, 27, 17].\n1.1 Goals of the Paper\nThe main goal of this paper is to introduce techniques that can be used for learning high-quality word\nvectors from huge data sets with billions of words, and with millions of words in the vocabulary. As\nfar as we know, none of the previously proposed architectures has been successfully trained on more\n1arXiv:1301.3781v3  [cs.CL]  7 Sep 2013than a few hundred of millions of words, with a modest dimensionality of the word vectors between\n50 - 100.\nWe use recently proposed techniques for measuring the quality of the resulting vector representa-\ntions, with the expectation that not only will similar words tend to be close to each other, but that\nwords can have multiple degrees of similarity [20]. This has been observed earlier in the context\nof in\ufb02ectional languages - for example, nouns can have multiple word endings, and if we search for\nsimilar words in a subspace of the original vector space, it is possible to \ufb01nd words that have similar\nendings [13, 14].\nSomewhat surprisingly, it was found that similarity of word representations goes beyond simple\nsyntactic regularities. Using a word offset technique where simple algebraic operations are per-\nformed on the word vectors, it was shown for example that vector(\u201dKing\u201d) - vector(\u201dMan\u201d) + vec-\ntor(\u201dWoman\u201d) experiments also look very promising. In the future, it would be also\ninteresting to compare our techniques to Latent Relational Analysis [30] and others. We believe that\nour comprehensive test set will help the research community to improve the existing techniques for\nestimating the word vectors. We also expect that high quality word vectors will become an important\nbuilding block for future NLP applications.\n107 Follow-Up Work\nAfter the initial version of this paper was written, we published single-machine multi-threaded C++\ncode for computing the word vectors, using both the continuous bag-of-words and skip-gram archi-\ntectures4. The training speed is signi\ufb01cantly"], "bleu": 0.16840364617665377, "rouge_l": 0.29829829829829835, "gpt_metric_score": 0.5, "bert_score": 0.20024177432060242}
{"paper_key": "GP-GPT: Large Language Model for Gene-Phenotype Mapping", "current_5q": "### [Question 1] - What is the problem?\nHow can we effectively represent and map the complex relationships between genes, phenotypes, and diseases using an AI-based system that integrates both structured and unstructured genomic knowledge?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem is crucial for advancing our understanding of the intricate interplay between genetic factors and diseases, which can lead to improved disease prediction, prevention, and treatment strategies. By developing a comprehensive model like GP-GPT, we can facilitate knowledge discovery in bioinformatics, enhance hypothesis generation, and uncover previously hidden gene-disease associations. This research could significantly impact future studies in genomics and personalized medicine, ultimately leading to more effective therapeutic interventions and a deeper understanding of human health.\n\n### [Question 3] - Why is it hard?\nThe challenges in addressing this problem stem from the complexity of biological systems, where genes, proteins, and phenotypes interact in multifaceted ways. Naive approaches may fail because they often focus on isolated components rather than the holistic relationships across the entire genome system. Additionally, the integration of diverse data types\u2014structured genomic data and unstructured biological text\u2014poses significant technical and theoretical obstacles. The need for sophisticated models that can accurately capture and represent these intricate relationships adds to the complexity of the task.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has primarily concentrated on single or dual-molecule analyses, leading to a fragmented understanding of gene-disease relationships. Existing solutions often lack the capability to integrate various data sources comprehensively, and many have overlooked the potential of unstructured data. Barriers such as limited computational resources, inadequate modeling techniques, and the absence of a unified framework for integrating diverse genomic knowledge have hindered progress. The GP-GPT approach differs by leveraging large language models to synthesize and analyze both structured and unstructured data, providing a more holistic view of the genomic landscape.\n\n### [Question 5] - What are the key components of my approach and results?\nThe proposed methodology involves developing the GP-GPT model, which integrates structured data from sources like OMIM, DisGeNET, and dbGaP with unstructured biological text. The model will categorize and identify gene entities, gene functions, protein entities, protein functions, phenotype entities, and genotype-phenotype associations. The expected outcomes include a comprehensive knowledge mapping of the entire genome system, enhanced understanding of gene-disease relationships, and the generation of new hypotheses for further research. The effectiveness of the model will be evaluated using metrics", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can a multimodal framework that integrates structural and functional neuroimaging data with cognitive assessment scores be developed to accurately analyze and predict the progression of mild cognitive impairment (MCI) to Alzheimer's disease (AD)?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is crucial for the research community as it addresses the pressing need for early identification and intervention strategies for individuals at risk of progressing from MCI to AD. The ability to predict this progression can dramatically impact clinical practices by enabling timely therapeutic interventions, potentially slowing cognitive decline. Furthermore, this research could pave the way for future studies that explore the intricate relationships between brain structure, function, and cognitive performance, leading to enhanced understanding of neurodegenerative processes. Ultimately, advancements in this area may lead to the development of targeted treatments and improved quality of life for patients and their families.\n\n[Question 3]: Why is it hard?  \nThe complexity of this problem arises from the multifaceted nature of both the neuroimaging data and cognitive assessments involved. Integrating diverse data types\u2014structural MRI, functional MRI, and cognitive scores\u2014requires sophisticated methodologies capable of handling high-dimensional data and capturing nonlinear relationships. Naive approaches may fail due to oversimplification or an inability to model the intricate interactions and temporal dynamics of brain networks. Additionally, the challenge of interpretability in machine learning models poses a significant barrier, as clinicians need understandable insights into how predictions are made to trust and apply these findings in practice. Overcoming these technical, theoretical, and practical obstacles is essential for the development of a robust predictive framework.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on isolated modalities or employed traditional statistical methods that do not account for the complex interdependencies between neuroimaging and cognitive data. There is a lack of comprehensive models that utilize advanced machine learning techniques to integrate these modalities effectively. Additionally, many studies have overlooked the potential of algebraic structures and cohomological methods to reveal hidden relationships within the data. Barriers such as limited access to diverse datasets, inadequate computational resources, and the absence of interdisciplinary collaboration among neuroimaging, cognitive science, and machine learning fields have hindered progress. My approach aims to fill these gaps by leveraging novel methodologies that enhance data integration and interpretation.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves the development of a multimodal neural network architecture that incorporates structural and functional neuroimaging data alongside cognitive assessment scores. I will utilize a dataset consisting of longitudinal neuroimaging and cognitive data from individuals diagnosed with MCI, with a focus on those who transition to AD. Key metrics for evaluation will include predictive accuracy, interpretability of model outputs, and insights into brain region contributions via cohomological analysis. Expected outcomes include a validated model that not only predicts the progression of MCI to AD with high accuracy but also provides meaningful visualizations of brain interactions and dynamics, ultimately contributing to the understanding of cognitive decline mechanisms and informing clinical interventions.", "referenced_intros": [" Introduction\nRecent multimodal foundation models are very widely adopted but still model different modalities separately,\noften using modality specific encoders or decoders. This can limit their ability to integrate information across\nmodalities and generate multimodal documents that can contain arbitrary sequences of images and text. In\nthis paper, we present Chameleon , a family of mixed-modal foundation models capable of generating and\nreasoning with mixed sequences of arbitrarily interleaved textual and image content (Figures 2-4). This\nallows for full multimodal document modeling, which is a direct generalization of standard multimodal tasks\nsuch as image generation, understanding and reasoning over images, and text-only LLMs. Chameleon is\ninstead designed to be mixed-model from inception and uses a uniform architecture trained from scratch in an\nend-to-end fashion on an interleaved mixture of all modalities, i.e., images, text, and code.\nOur unified approach uses fully token-based representations for both image and textual modalities (Figure 1).\nBy quantizing images into discrete tokens, analogous to words in text, we can apply the same transformer\narchitecture to sequences of both image and text tokens, without the need for separate image/text encoders\n(Alayrac et al., 2022; Liu et al., 2023b; Lauren\u00e7on et al., 2023) or domain-specific decoders (Ramesh et al.,\n2022; Jin et al., 2023; Betker et al., 2023). This early-fusion approach, where all modalities are projected into\na shared representational space from the start, allows for seamless reasoning and generation across modalities.\nHowever, it also presents significant technical challenges, particularly in terms of optimization stability and\nscaling.\nWe address these challenges through a combination of architectural innovations and training techniques. We\nintroduce novel modifications to the transformer architecture, such as query-key normalization and revised\nplacement of layer norms, which we find to be crucial for stable training in the mixed-modal setting (Section\n2.3). We further show how to adapt the supervised finetuning approaches used for text-only LLMs to the\nmixed-modal setting, enabling strong alignment at scale (Section 3). Using these techniques, we successfully\ntrain Chameleon-34B on 5x the number of tokens as Llama-2 \u2013 enabling new mixed-modal applications while\nstill matching or even outperforming existing LLMs on unimodal benchmarks.\n1arXiv:2405.09818v1  [cs.CL]  16 May 2024Mixed-Modal Auto-Regressive LM \nTEXT PROMPT \u201cWhat can I bake \nwith this?\u201d TEXT OUTPUT \u201cHere is a recipe for \nbanana bread.\u201d \nImage Tokenizer Image De-Tokenizer \nIMAGE PROMPT \nIMAGE OUTPUT \nStart \nImageStart \nImage End\nImage\nEnd\nImageStart \nImage \nStart \nImageEnd\nImage\nMixed Modal Auto-Regressive LM \n(a) Mixed-Modal Pre-Training (b) Mixed-Modal Generation Figure 1 Chameleon represents all modalities \u2014 images, text, and code, as discrete tokens and uses a uniform\ntransformer-based architecture that is trained from scratch in an end-to-end fashion on \u223c10T tokens of interleaved\nmixed-modal data. As a result, Chameleon can both reason over, as well as generate, arbitrary mixed-modal documents.\nText tokens are represented in green and image tokens are represented in blue.\nExtensive evaluations demonstrate that Chameleon is a broadly capable model on a diverse set of tasks.\nOn visual question answering and image captioning benchmarks, Chameleon-34B achieves state-of-the-art\nperformance, outperforming models like Flamingo, IDEFICS and Llava-1.5 (Section 5.2). At the same time,\nit maintains competitive performance on text-only benchmarks, matching models like Mixtral 8x7B and\nGemini-Pro on commonsense reasoning and reading comprehension tasks (Section 5.1). But perhaps most\nimpressively, Chameleon unlocks entirely new capabilities in terms of mixed-modal reasoning and", " Introduction\nMedicaldatafromdiversesourceslikebiobanks,electronichealthrecords,medicalimaging,wearables,\nbiosensors, and genomic sequencing are enabling the development of multimodal AI solutions that can\nbetter capture the complexity of human health and disease (Acosta et al., 2022). While AI in medicine\nhas primarily focused on narrow tasks with single input and output types (Rajpurkar et al., 2022),\nrecent advances in generative AI show promise in addressing multimodal, multi-task challenges in\nmedical settings (Moor et al., 2023a,b).\nThe emergence of large language models (LLMs) and large multimodal models (LMMs) such\nas Flamingo (Alayrac et al., 2022), PaLI (Chen et al., 2022), GPT-4 (Achiam et al., 2023), GPT-4v\n(OpenAI, 2023), PaLM (Anil et al., 2023; Chowdhery et al., 2023), LLaMA (Touvron et al., 2023),\nLLaVa(Liuetal.,2023,2024a), andMistral7B(Jiangetal.,2023)thatpromisesignificantlyenhanced\ncontext length and improved multimodal capabilities suggests that the realization of highly complex\nmultimodal reasoning across various medical data will soon be achievable. These advancements have\ncatalyzed the expansion of LLMs specifically designed for medical domains, such as Med-PaLM and its\nsuccessor Med-PaLM 2 (Singhal et al., 2023a,b), Clinical Camel (Toma et al., 2023), MedAlpaca (Han\net al., 2023), BioMistral (Labrak et al., 2024), sc-GPT (Cui et al., 2024), and others. Going beyond\ntext alone, recent works have extended the capabilities of these base multimodal models by building\nmodels that cover various medical imaging modalities like Med-PaLM M (Tu et al., 2024), Med-\nFlamingo (Moor et al., 2023b) as well as those that focus on a specific imaging domain, such as\nradiology (Hamamci et al., 2024; Hyland et al., 2023; Tanno et al., 2024; Thawkar et al., 2023; Xu\net al., 2023) and histopathology (Ikezogwo et al., 2024; Lu et al., 2024; Sun et al., 2024).\nThereleaseoftheGeminimodels(GeminiTeam,Google,2023;Google,2024),withtheiradvanced\nmultimodal capabilities and breakthroughs in long-context understanding, marked a significant step\nforward in multimodal reasoning. Given its inherent human focus, medicine is a field in which\nadvanced multimodal systems like Gemini are expected to be transformative (Acosta et al., 2022).\nEvaluations have already started to evaluate the base performance of these newer multimodal models\n(Pal and Sankarasubbu, 2024). However, the true potential of multimodal foundation models in the\nmedical field remains largely underexplored due to the complexity of optimizing for problems in this\nfield (Moor et al., 2023a; Rajpurkar et al., 2022) and a lack of diverse and meaningful evaluations\nthat are grounded in clinical use cases (Fleming et al., 2023; Royer et al., 2024; Zhang et al., 2023a).\nTo better understand the nuances of model capabilities and limitations, it is necessary to optimize\nmultimodal models for a diversity of relevant clinical applications and rigorously evaluate them on\nappropriate clinical datasets.\nThis report details our efforts in exploring Gemini\u2019s capabilities across a range of challenging multi-\nmodal medical tasks. Our evaluation benchmarks include 2D and 3D radiology images, histopathology\npatches, ophthalmology images, dermatology images, and genetic risk scoring. Our benchmark suite\nincludes both open benchmark datasets and our own curated datasets. Open benchmark datasets have\nthe advantage of being established and enabling direct comparison to others\u2019 work, but they are often\nlimited or methodologically flawed, leading to methods in predicting disease risk. These Appendix, Breast, Cervix, Colon and rectum, Fallopian Tube, Gallbladder, Liver, Lymph node, Ovary, Placenta, Prostate,\nSkin, Thyroid, Upper GI, Uterus, Vas deferens.\n\u2021TCGA study types: BLCA, BRCA, COAD, HNSC, KIRC, LIHC, LUAD, LUSC, OV, STAD.\nTable A.9|Examples of a prediction prompt for coronary artery disease using", " INTRODUCTION\nThe impressive capabilities of AI for biomedicine span a wide spec-\ntrum, from the atomic level, where it attempts to solve partial\ndifferential equations for quantum systems, to the molecular level,\nwhere it accurately predicts the structures of chemicals and pro-\nteins, and extends even further, encompassing societal predictions\nlike forecasting infectious disease outbreaks [ 108]. Amidst this\nlandscape of possibilities, recent advancements in large language\n*These authors have made equal contributions to this paper. They are listed in alpha-\nbetical order by last name.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nKDD \u201924, August 25\u201329, 2024, Barcelona, Spain\n\u00a92024 Association for Computing Machinery.\nACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00\nhttps://doi.org/XXXXXXX.XXXXXXXmodels (LLMs), notably exemplified by models like ChatGPT1, have\nrisen to the forefront, demonstrating significant proficiency in tasks\ntied to natural language. These tasks include language translation,\nconstructing chatbots, and answering questions [104].\nInterestingly, when we turn our attention to biomedical data,\nwe observe a striking resemblance to natural language in terms of\nsequences. Biomedical literature and health records are laid out as\ntextual narratives, biological sequences or sequencing data takes\nthe form of molecular or expression sequences, and sensor data\nlike brain signals is inherently sequential time series [ 90,91]. This\nobservation prompts a compelling question: Can we leverage the\nadvanced LLMs to drive biomedical knowledge discoveries?\nIn this survey paper, we embark on a journey to explore pre-\ncisely this intersection\u2014the fusion of cutting-edge large language\nmodels with biomedical inquiry. Our exploration zooms in on three\npivotal categories of biomedical data: 1) textual data, 2) biologi-\ncal sequences, and 3) brain signals. By drawing inspiration from\nthe transformative capabilities of LLMs, we seek to unravel novel\nunderstanding and innovation within each domain.\nAs we move forward, we further discuss the intricate challenges\naccompanying AI infusion into biomedical research. The foundation\nof trustworthiness stands tall\u2014how do we ensure the reliability of\nAI-enhanced biomedical insights? The concept of personalization\nemerges as a critical consideration, urging us to tailor LLMs to\nthe specific contours of biomedical investigation. Furthermore, the\nmulti-modal nature of biomedical data motivates us to handle data\nrepresentations that span across various modalities.\n2 LLMS ON DIVERSE BIOMEDICAL DATA\nWe comprehensively survey the topics of LLMs for biomedicine\nbased on three pivotal categories of biomedical data: 1) textual data,\n2) biological sequences, and 3) brain signals.\n2.1 LLMs on Biomedical Textual Data\nFirst, we introduce LLMs in the realm of biomedical textual data,\nwhich encompasses diverse domains like biomedical literature\n[3,12,33,49,106] and electronic health records [ 4,79]. This form of\nbiomedical textual data closely mirrors the fundamental structure of\nlarge language models. It finds extensive utility across biomedicine\nand healthcare, facilitating tasks such as extracting valuable in-\nformation and responding to queries. The applicability spans a\nmultitude of areas, underpinning biomedical and healthcare infor-\nmation extraction [94, 95, 113] and question-answering [46].\nSciBERT. SciBERT [ 12] is a BERT-based model [ 24] pre-trained\non", " Introduction\nMolecules and proteins are two crucial bio-entities\nin drug discovery, forming the foundation of bi-\nological activities (Dara et al., 2022; AI4Science\nand Quantum, 2023). A molecule can be repre-\nsented by its SMILES (Weininger, 1988; Weininger\net al., 1989) or SELFIES (Krenn et al., 2020)\nsequence, and a protein can be described by\na FASTA (Lipman and Pearson, 1985; Pearson\nand Lipman, 1988) sequence. With the advance-\nment of Language Models (LMs), an increas-\ning body of work focuses on understanding the\nmolecules and proteins by modeling their bio-\nsequences (Chithrananda et al., 2020; Rives et al.,\n2021; Lin et al., 2022).\nNotably, biological literature (Canese and Weis,\n2013; White, 2020) is full of extensive informa-\ntion on molecules and proteins. When a biological\nentity is mentioned in such literature, its context\nis predominantly centered around a description of\nsome characteristics of the entity. Consequently,\nthere has been a growing body of work dedicated\nto the joint modeling of text and biological en-\ntities (Pei et al., 2024), such as Galactica (Tay-\nlor et al., 2022), MolXPT (Liu et al., 2023c),\nBioT5 (Pei et al., 2023) and BioMedGPT (Luo\net al., 2023c), which are all scientific models\ntrained on text, molecule and protein sequences.\nDespite their achievements, substantial opportuni-\nties for enhancement still remain: (1) Prior works\nneglect the importance of modeling the textual\nname of molecules, such as International Union\nof Pure and Applied Chemistry (IUPAC), which\nprovides a standard and systematic naming method\nfor ensuring uniformity and clarity across the sci-\nentific community. Different from SMILES andarXiv:2402.17810v2  [q-bio.QM]  31 May 2024SELFIES, IUPAC bears a closer resemblance to\nnatural language that is evident in its widespread\nadoption within scientific literature (Klinger et al.,\n2008). (2) Previous models were predominantly\nspecialist models, necessitating the training of a\nseparate model for each downstream task, thereby\nlacking in generality and increasing the training\nand developing cost (Liu et al., 2023c; Pei et al.,\n2023). (3) Most of the previous models based on\nT5 (Raffel et al., 2020) and GPT (Brown et al.,\n2020) architectures only focus on the classification\ntasks since they do not implement specialized tok-\nenization for numerical data, which Related Work\n2.1 Biological Cross-modal Models\nRecent advancements in LLMs have led to an in-\ncreased focus on jointly modeling molecules, pro-\nteins, and text, aiming to enhance the understand-\ning of bio-entities through text.\nMolecule-Text. MolT5 (Edwards et al., 2022)\nis jointly trained on general text and molecule\nSMILES using T5 (Raffel et al., 2020) masked\nspan prediction objective. MoMu (Su et al., 2022)\nemploys contrastive learning on molecular graphs\nand related text, and MolFM (Luo et al., 2023b)\nfurther incorporates knowledge graph embedding\nfor molecule representation. MolXPT (Liu et al.,\n2023c) is jointly trained on molecule SMILES and\nwrapped text using GPT (Brown et al., 2020) frame-\nwork. MolCA (Liu et al., 2023d) enhances LMs by\nintegrating 2D molecular graph perception through\na cross-modal projector and uni-modal adapter.\nGIT-Mol (Liu et al., 2023a) is a multi-modal\nLLM that synergizes graphs, images, SMILES, and\nmolecule captions. Text+Chem T5 (Christofidel-\nlis et al., 2023) is a multi-domain, multi-task lan-\nguage model capable of concurrently processing\nmolecules and natural language.\nProtein-Text. Several notable works focus on\njointly modeling proteins and text. ProteinDT (Liu\net al., 2023b) presents a text-guided protein design\nframework. BioTranslator (Xu et al., 2023b) is a\ncross-modal translation system, which can annotateStep 1: Pre-trained Data CollectionStep 2: Dataset CleaningStep 3: Exclusive TokenizationStep 4: Pretraining\nStep 5: Multi-task Instruction-based Finetuning\nMoleculeProteinTextSingle Domain CorpusCross Domain", " Introduction\nSince the release of ChatGPT in November 2022, the advent of AI technologies has marked a significant\ntransformation, reshaping interactions and integrating deeply into various facets of daily life and indus-\ntry [1, 2]. Building on this momentum, OpenAI released, in February 2024, Sora , a text-to-video gener-\native AI model that can generate videos of realistic or imaginative scenes from text prompts. Compared\nto previous video generation models, Sora is distinguished by its ability to produce up to 1-minute long\nvideos with high quality while maintaining adherence to user\u2019s text instructions [3]. This progression of\nSora is the embodiment of the long-standing AI research mission of equipping AI systems (or AI Agents)\nwith the capability of understanding and interacting with the physical world in motion. This involves devel-\noping AI models that are capable of not only interpreting complex user instructions but also applying this\nunderstanding to solve real-world problems through dynamic and contextually rich simulations.\nFigure 2: Examples of Sora in text-to-video generation. Text instructions are given to the OpenAI Sora\nmodel, and it generates three videos according to the instructions.\nSora demonstrates a remarkable ability to accurately interpret and execute complex human instructions,\nas illustrated in Figure 2. The model can generate detailed scenes that include multiple characters that\nperform specific actions against intricate backgrounds. Researchers attribute Sora \u2019s proficiency to not\nonly processing user-generated textual prompts but also discerning the complicated interplay of elements\nwithin a scenario. One of the most striking aspects of Sora is its capacity for up to a minute-long video\nwhile maintaining high visual quality and compelling visual coherency. Unlike earlier models that can\nonly generate short video clips, Sora \u2019s minute-long video creation possesses a sense of progression and a\nvisually consistent journey from its first frame to the last. In addition, Sora \u2019s advancements are evident in its\nability to produce extended video sequences with nuanced depictions of motion and interaction, overcoming\nthe constraints of shorter clips and simpler visual renderings that characterized earlier video generation\nmodels. This capability represents a leap forward in AI-driven creative tools, allowing users to convert text\nnarratives to rich visual stories. Overall, these advances show the potential of Sora as aworld simulator to\nprovide nuanced insights into the physical and contextual dynamics of the depicted scenes. [3].\nTechnology. At the heart of Sora is a pre-trained diffusion transformer [4]. Transformer models have\nproven scalable and effective for many natural language tasks. Similar to powerful large language models\n(LLMs) such as GPT-4, Sora can parse text and comprehend complex user instructions. To make video\ngeneration computationally efficient, Sora employs spacetime latent patches as its building blocks. Specif-\nically, Sora compresses a raw input video into a latent spacetime representation. Then, a sequence of latent\nspacetime patches is extracted from the compressed video to encapsulate both the visual appearance and\nmotion dynamics over brief intervals. These patches, analogous to word tokens in language models, provide\nSora with detailed visual phrases to be used to construct videos. Sora \u2019s text-to-video generation is per-\nformed by a diffusion transformer model. Starting with a frame filled with visual noise, the model iteratively\ndenoises the image and introduces specific details according to the provided text prompt. In essence, the\n3generated video emerges through a multi-step refinement", "Abstract \u2014Large language models (LLMs) have undergone\nsignificant expansion and have been increasingly integrated\nacross various domains. Notably, in the realm of robot task\nplanning, LLMs harness their advanced reasoning and language\ncomprehension capabilities to formulate precise and efficient\naction plans based on natural language instructions. However,\nfor embodied tasks, where robots interact with complex environ-\nments, text-only LLMs often face challenges due to a lack of\ncompatibility with robotic visual perception. This study provides\na comprehensive overview of the emerging integration of LLMs\nand multimodal LLMs into various robotic tasks. Additionally,\nwe propose a framework that utilizes multimodal GPT-4V\nto enhance embodied task planning through the combination\nof natural language instructions and robot visual perceptions.\nOurresults are presented\n(Fig. 5 \u223cFig. 7).\nYou are an excellent robot task planner. Given a natural language instruction and information about the working \nenvironment, you break it down into a sequence of step -by-step instructions and corresponding robot actions.\nPredefined Action Pool:\n* move_hand (): Move the robot hand from one position to another with/without grasping an object.\n* grasp_object (): Grab an object.\n* release_object (): Release an object in the robot hand.\nNecessary robot actions are defined as above. Note some actions can be done by  move_hand () like open a \ndrawer by pull back and close it by push forward. If necessary, add new actions to the pool to complete the task.\nYou generate the task plan and output it as JSON with three keys:\n* JSON{\"task_cohesion \"}: A JSON containing information about the robot's actions that have been split up.\n* JSON{\"environment_before \"}: The state of the environment before the actions.\n* JSON{\"environment_after \"}: The state of the environment after the actions.\nThree keys exist in JSON{\"task_cohesion \"}.\n* JSON{\"task_cohesion \"}{\"task_sequence \"}: Contains a list of robot actions. Only the behaviors \ndefined in the \"Predefined Action Pool\" will be used.\n* JSON{\"task_cohesion \"}{\"step_instructions \"}: Contains a list of step -by-step instructions \ncorresponding to the JSON{\"task_cohesion \"}{\"task_sequence \"}.\n* JSON{\"task_cohesion \"}{\"object_name \"}: The name of the target object.\nYou should only return the JSON, without any explanation or notes.SYSTEM\nUSER Instruction : <natural  language  instruction> .\nWorking  Env: as shown  in the given  image . <image>\nRobot task instruction: <natural language instruction>\nTask plan generated by GPT -4: <task plan>\nFrames sampled from a reference demonstration for the above robot task: <images>\nGenerate a description of the video.\nScore the generated actions on a scale from 0 to 10, based on how well they match the demo video: \na perfect match scores 10.\nYou should only return a JSON, which has three keys:\n*  JSON{\"demo_video_ description \"}: The description of the reference demonstration video.\n*  JSON{\"matching_ score\"}: The matching score.\n*  JSON{\"explanation \"}: The explanation of your score.USERASSISTANT Task  planning  response .\nASSISTANT Evaluation  response .\nFig. 4. Full prompts.JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 16\nStep by Step Instruction\n1.Move robot hand to the location of the green rice chip bag\n2.Grasp the green rice chip bag\n3.Move robot hand with the green rice chip bag towards the location of the \nbrown chip bag\n4.Release the green rice chip bag near the brown chip bag\nAction Plan\nmove_hand (location of the green rice chip bag )\ngrasp_object (green rice chip bag )\nmove_hand (location of", " introduction of ChatGPT has ushered in a transformative era in the realm of Large LLMs, significantly\ninfluencing their utilization for diverse downstream tasks. The emphasis on cost-effective training and deployment\nhas emerged as a crucial aspect in the evolution of LLMs. This paper has provided a comprehensive survey of the\nevolution of large language model training techniques and inference deployment technologies in alignment with\nthe emerging trend of low-cost development. The progression from traditional statistical language models to neural\nlanguage models, and subsequently to PLMs such as ELMo and transformer architecture, has set the stage for the\ndominance of LLMs. The scale and performance of these models, particularly exemplified by the GPT series, have\nreached unprecedented levels, showcasing the phenomenon of emergence and enabling versatile applications across\nvarious domains. Notably, the release of ChatGPT by OpenAI in November 2022 has marked a pivotal moment in\nthe LLM landscape, revolutionizing the strength and effectiveness of AI algorithms. However, the current reliance\nonOpenAI\u2019sinfrastructureunderscoresthenecessityforalternativeLLMs,emphasizingtheneedfordomain-specific\nmodels and advancements in the training and deployment processes.\nTraininganddeployingLLMspresentchallengesthatdemandexpertiseinhandlinglarge-scaledataanddistributed\nparalleltraining.TheengineeringcapabilitiesrequiredforLLMdevelopmenthighlightthecollaborativeeffortsneeded\nbetween researchers and engineers. As we explore the technical aspects of LLM training and inference in this review,\nit becomes evident that a deep understanding of these processes is essential for researchers venturing into the field.\nLookingahead,thefutureofLLMsholdspromisingdirections,includingfurtheradvancementsinmodelarchitectures,\nimproved training efficiency, and broader applications across industries. The insights provided in this review aim to\nequipresearcherswiththeknowledgeandunderstandingnecessarytonavigatethecomplexitiesofLLMdevelopment,\nfosteringinnovationandprogressinthisdynamicfield.AsLLMscontinuetoevolve,theirimpactonnaturallanguage\nprocessing and AI as a whole is poised to shape the future landscape of intelligent systems. Introduction\nLanguage modeling (LM) is a fundamental approach for achieving cognitive intelligence in the field of natural\nlanguage processing (NLP), and its progress has been notable in recent years [1; 2; 3]. It assumes a central role\nin understanding, generating, and manipulating human language, serving as the cornerstone for a diverse range of\nNLP applications [4], including machine translation, chatbots, sentiment analysis, and text summarization. With\nthe evolution of deep learning, the early statistical language models (SLM) have gradually transformed into neural\nlanguage models (NLM) based on neural networks. This shift is characterized by the adoption of word embeddings,\nrepresentingwordsasdistributedvectors.Notably,thesewordembeddingshaveconsistentlyexcelledinpracticalNLP\ntasks, profoundly shaping the field\u2019s progress. Pre-trained language models (PLM) represent a subsequent phase in\nthe evolution of language models following NLM. Early attempts at PLMs included ELMo [5], which was built on a\nBidirectionalLSTMarchitecture.However,withtheadventofthetransformerarchitecture[6],characterizedbyparallel\nself-attention mechanisms, the pre-training and fine-tuning learning paradigm has propelled PLM to prominence as\ntheprevailingapproach.Thesemodelsaretypicallytrainedviaself-supervisiononextensivedatasets,cementingtheir\nstatus as the primary methodology in the field.\nTheTransformerarchitectureisexceptionallywell-suitedforscalingupmodels,andresearchanalysishasrevealed\nthat increasing the model\u2019s scale or training data size can significantly enhance its performance. Many studies have\npushed the boundaries of model performance by continuously expanding the scale of PLM [7; 8; 9; 10]. As models\ngrow larger, a remarkable phenomenon known as \"emergence\" occurs, wherein they exhibit astonishing performance\n[8].Thesemodelsarecapableofgeneratinghigh-qualitytextandpossessrobustlearningandreasoningabilities.They\ncaneventacklefew-shotlearningtasksthroughin-contextlearning(ICL)[8].Thisremarkablecapabilityenablestheir\nseamless application to a wide range of downstream tasks across diverse domains [11; 12; 13; 14].\n\u2217Corresponding author\nORCID(s):\nYiheng Liu et al.: Preprint submitted to Elsevier Page 1 of 30arXiv:2401.02038v2  [cs.CL]  6 Jan 2024A Comprehensive Overview from Training to Inference\nPre-trained language models (PLMs) with significantly larger parameter sizes and extensive training data are\ntypically denoted as Large Language Models (LLMs) [15; 16; 17]. The model size usually exceeds 6-10 billion (6-\n10B)parameters.AprominentmilestoneinthedevelopmentofLLMsisexemplifiedbytheGPTseries[18;7;8;19].\nNotably, OpenAI released ChatGPT in November 2022, marking a pivotal moment in the era of LLMs and a game-\nchanging moment in the field of artificial intelligence. ChatGPT has", " Introduction\nIntegrating Artificial Intelligence (AI) in education has be-\ncome a transformative force as the educational landscape\ncontinually evolves. Inspired by the recent development of\nGPT-4V [ 158] and Gemini[ 76], the idea of multimodality in\nAI for education heralds a synergistic confluence of vari-\nous sensory channels and cognitive strategies to enhance\n1arXiv:2312.06037v2  [cs.AI]  12 Dec 2023Lee and Shi, et al.\nMultimodal\nAGI\nInteractive Learning\nLanguage Learning Asst.\nCustomized \nLearning Pathway\nGamification \nReal -Time Feedback \nand Assessment\nAugmented Reality (AR) \nEducational Experience\nVirtual Tutor\nAccessibility \nEnhancement\nText\nGraphics\nVideoAudio\nFigure 1. Overview of Multimodal AGI for Education.\nteaching-learning and assessment. This exploration com-\nmences with an exposition of the multimodal nature of learn-\ning \u2014 how learners engage with information via auditory,\nvisual, and kinesthetic means [ 141] \u2014 and the consequent\nimperative for educational technologies to cater to this diver-\nsity. With its capacity to process and synthesize vast streams\nof multimodal information, AI is a potent ally in this regard\n[202]. Particularly, it is evidenced that the multifaceted di-\nmensions of multimodal AI applications cast light on the\npotential to pave the way toward Artificial General Intelli-\ngence (AGI) within the educational domain.\nAGI is a hypothetical machine able to understand, learn,\nand apply knowledge across a range of cognitive tasks at\na human-like level [ 142,228]. Recent progress in AI tech-\nnologies showcases a wide spectrum of intelligence in text,\ngraphic, video, and audio analysis and generation. Particu-\nlarly, the progress in generative AI has set forth the mission\nfor AGI as a significant stride for society. For example, Elon\nMusk is on a mission to create the world\u2019s first AGI [ 50].\nOpenAI claimed pioneering research on the path to AGI \u2013\n\"We believe our research will eventually lead to artificial gen-\neral intelligence [AGI], a system that can solve human-level\nproblems. Building safe and beneficial AGI is our mission\n[161].\" Google also deployed Gemini, which reportedly out-\nperforms human experts since it \"is built from the ground up\nfor multimodality - reasoning seamlessly across text, images,\nvideo, audio, and code\" [ 75]. While AGI remains a nascent\naspiration, the strides in multimodal AI in education provide\na microcosm of the broader potentials and challenges inher-\nent in pursuing such a comprehensive form of intelligence.\nConceptualizing the integration of AGI into education paves\nthe way for incoming groundbreaking innovations that are\nredefining traditional teaching and learning paradigms.Through this paper, we aim to provide a conceptual frame-\nwork for understanding the role of multimodal AI in educa-\ntional settings and to speculate on how these advancements\nmight inform and inspire the trajectory of AGI for education\n(see Fig. 1 for an overview if multimode AGI for education).\nBy weaving together the threads of current AI capabilities\nwith the tapestry of educational needs and outcomes, we\npropose a vision where AI supports, transforms, and rede-\nfines the pedagogical processes, embodying collaborative\nintelligence alongside educators and learners. In pursuit of\nthis vision, we examine the current state of AI applications\nin education, identify the gaps and opportunities for more\nsophisticated multimodal interactions, and project the impli-\ncations of these technologies for the development of AGI for\neducation. Realizing that the journey toward AGI is fraught\nwith technical challenges and ethical considerations, we dis-\ncussed the issues and concerns, providing a fertile ground\nfor addressing these issues in a controlled, impactful, and\nbenevolent manner.\n2 Theoretical Foundations of\nMultimodality in Learning\n2.1 Concept of Multimodality\nThe learning and information processing channels in hu-\nmans\u2019", " Introduction\nLarge language models (LLMs) such as ChatGPT [ 1] and GPT-4 [ 2] have demonstrated immense\nprogress in natural language processing [ 3,4,5,6,7,8]. However, their ability to interpret and\nleveragevisualinformationremainsrelativelyunderexplored[ 9,10,11,12,13], especiallyinspecialized\ndomains such as medicine and the general biomedical field [ 9,14,15,16,17,18,19,20,21]. In\nthis paper, we present a large-scale evaluation probing GPT-4V\u2019s capabilities and limitations for\nbiomedical image analysis.\n1.1 Background: The overall Related Work\n3.1 Foundation Models\nThe Transformer architecture, known for its flexibility and cross-modal capabilities, has become a\nwidely adopted backbone for language and vision models. Initially applied in the field of natural\nlanguage processing [ 27], the Transformer addressed the issue of sequential text processing and\nintroduced a global attention mechanism, achieving state-of-the-art performance in diverse tasks\n[19,23,24,55,77,143,144,145,146,147,148,149,150,151]. Building upon the Transformer\narchitecture, models like Transformer-based BERT achieved remarkable performance across multiple\nlanguage processing tasks. With the increase in training data and model parameters, large-scale\nTransformer-based language models emerged. Models such as GPT-1 [ 32], GPT-2 [ 31], GPT-3 [ 33],\nGPT-4 [ 152], Llama [ 153], Llama2 [ 153], PaLM [ 154], and others have progressively improved\nperformance across various natural language processing tasks. Notably, ChatGPT [ 1] and GPT-4\nhave demonstrated impressive zero-shot reasoning abilities, producing satisfactory Experiments and Observation\n4.1 Chest Radiography\nPrompt:  \nYou are a professional chest radiologist that read chest X -ray image and extract observation from it. Below is an \nobservation plan consisting of 13 common chest radiographic observations based on the prevalence in the chest X -ray \nimages and clinical releva nce.  \nAtelectasis:  \nCardiomegaly:  \nConsolidation:  \nEdema:  \nEnlarged Cardiomediastinum:  \nFracture:  \nLung Lesion:  \nLung Opacity:  \nPleural Effusion:  \nPleural Other:  \nPneumonia:  \nPneumothorax:  \nSupport Devices:  \nThe chest X -ray image is given as follow. And based on this chest X -ray image, fill out the given 13 observations with 4 \nlabels: 1, -1, 0, 2. These labels have the following interpretation:1 - The observation was clearly present on the chest x -\nray image. 0  - The observation was clearly absent on the chest x -ray image. -1 - The observation was unclear if it exists. \n2 - None of the above. Strictly follow the format provided in the observation plan. No title, summary, or explanation in \nthe answer. No empty lin e between rows. Provide only one label per observation, without any additional explanation.  \n \n \n   \n \n \n \n GPT-4V:\nAtelectasis: -1, Cardiomegaly: 1 , Consolidation: 0, Edema: 0, Enlarged Cardiomediastinum: 1, Fracture: 0 ,Lung Lesion: \n0, Lung Opacity: 1, No Finding: 0, Pleural Effusion: 0 , Pleural Other: 0, Pneumonia: 0, Pneumothorax: 0, Support  \nDevices: 1.\nReference answer:\nAtelectasis: 2, Cardiomegaly: 1, Consolidation: 2, Edema: 1, Enlarged Cardiomediastinum: 2, Fracture: 2, Lung Lesion: \n2, Lung Opacity: 2, No Finding: 2, Pleural Effusion: 2, Pleural Other: 2, Pneumonia: 2, Pneumothorax: 2, Support \nDevices: 2.\n \n  \nFigure 2: Chest: Case 1. A demonstration case of Classification task on MIMIC-CXR dataset.\nGreen denotes the correct classification. Red in the figure denotes the incorrect classification.\n29Prompt:  \nYou are a professional chest radiologist that reads chest X -ray images.  \nAbove is a chest x -ray image with", " Introduction\nMolecules and proteins are two essential bio-\nentities in drug discovery (Dara et al., 2022). Small\nmolecule drugs have been the cornerstone of the\npharmaceutical industry for nearly a century, owing\nto their unique advantages such as oral availability,\ndiverse modes of action, etc (AstraZeneca, 2023).\nProteins serve as the foundation of life science,\nfunctioning as drug targets or crucial elements in\ndisease pathways. As illustrated in Figure 1, both\n\u2217Corresponding authors: Lijun Wu ( lijuwu@microsoft.\ncom), Yingce Xia ( yinxia@microsoft.com ), and Rui Yan\n(ruiyan@ruc.edu.cn )\nName: Aspirin\nSMILES: CC(=O)OC1=CC=CC=C1C(=O)O\nSELFIES: [C][C][=Branch1][C][=O][O][C][=C][C]\n[=C][C][=C][Ring1][=Branch1][C][=Branch1][C][\n=O][O]\nStructure:Name: Hemoglobin subunit beta\nGene: HBB\nFASTA: MVHLTPEEKSAVTALWGKVN \u2026\nStructure:\nFigure 1: Representations of molecule and protein.\nMolecule can be represented by its name, bio-sequence\n(SMILES and SELFIES), and 2D graph structure. Pro-\ntein can be represented by its name, corresponding gene\nname, bio-sequence (FASTA), and 3D structure.\nmolecules and proteins can be represented using se-\nquences. A molecule can be depicted by a SMILES\nsequence (Weininger, 1988; Weininger et al., 1989),\nwhich is derived by traversing the molecular graph\nthrough depth-first search and applying specific\nbranching rules. A protein can be represented by\na FASTA sequence (Lipman and Pearson, 1985;\nPearson and Lipman, 1988), which outlines the\namino acids in a protein. The sequential formats of\nmolecules and proteins facilitate the application of\nTransformer models (Vaswani et al., 2017) and pre-\ntraining techniques (Liu et al., 2019; Radford et al.,\n2019) from natural language processing (NLP) to\nthe biomedical field. Chemberta (Chithrananda\net al., 2020) and ESM (Rives et al., 2021; Lin et al.,\n2022) apply masked language modeling to molecu-\nlar SMILES and protein FASTA respectively, while\nMolGPT (Bagal et al., 2022) and ProtGPT2 (Ferruz\net al., 2022) leverage GPT-style models for molec-\nular and protein generation.\nScientific literature (Beltagy et al., 2019; Canese\nand Weis, 2013) and biological databases (KimarXiv:2310.07276v3  [cs.CL]  29 Jan 2024et al., 2023; Boutet et al., 2007) serve as knowledge\nrepositories of molecules and proteins. These re-\nsources detail properties, experimental results for a set\nof inhibitors of human beta-secretase 1 (BACE-1).\nIf the given molecule can inhibit BACE-1, indicate\nvia \"Yes\". Otherwise, response via \"No\".\n(6) SIDER\nTask Definition :Definition: Molecule property\nprediction task (a binary classification task) for the\nSIDER dataset. The Side Effect Resource (SIDER)\nis a dataset of marketed drugs and adverse drug re-\nactions (ADR). If the given molecule can cause\nthe side effect of \u27e8side effect \u27e9, indicate via\"Yes\". Otherwise, response via \"No\". where\u27e8side\neffect \u27e9refers to the corresponding side effects for\neach subtask.\nF.1.2 Protein Property Prediction\nDatasets\n(1) Solubility prediction is to predict whether a pro-\ntein is soluble or not. We follow the same splitting\nmethod with DeepSol (Khurana et al., 2018).\n(2) Localization prediction aims predict whether a\nprotein is \u201cmembrane-bound\u201d or \u201csoluble\u201d, which\nis a simple version of subcellular localization pre-\ndiction task. We follow the same splitting method\nwith DeepLoc (Armenteros et al., 2017).\nBaselines\n(1) Feature engineers. The DDE (Dipeptide Devi-\nation from Expected Mean) (Saravanan and Gau-\ntham, 2015) feature descriptor, consisting of 400\ndimensions, is based on the dipeptide frequency\nwithin a protein sequence. The Moran feature\ndescriptor (Moran correlation) (Feng and Zhang,\n2000), with 240 dimensions, characterizes the dis-\ntribution of amino acid properties within a protein\nsequence.\n(2) Protein sequence encoders, including\nLSTM (Hochreiter and Schmidhuber, 1997),\nTransformers (Vaswani et al., 2017), CNN (O\u2019Shea\nand Nash, 2015) and ResNet (He et al., 2016). The\namino acid features in the last layer are aggregated\nfor final prediction.\n(3) Pre-trained protein language models. Prot-\nBert (Elnaggar et al., 2021) and ESM-1b (Rives\net", "ABSTRACT\nThe advancement of Large Language Models (LLMs) has remarkably pushed the\nboundaries towards artificial general intelligence (AGI), with their exceptional\nability on understanding diverse types of information, including but not limited\nto images and audio. Despite this progress, a critical gap remains in empowering\nLLMs to proficiently understand and reason on graph data. Recent studies under-\nscore LLMs\u2019 underwhelming performance on fundamental graph reasoning tasks.\nIn this paper, we endeavor to unearth the obstacles that impede LLMs in graph\nreasoning, pinpointing the common practice of converting graphs into natural lan-\nguage descriptions ( Graph2Text ) as a fundamental bottleneck. To overcome this\nimpediment, we introduce GraphLLM, a pioneering end-to-end approach that syn-\nergistically integrates graph learning models with LLMs. This integration equips\nLLMs with the capability to proficiently interpret and reason on graph data, har-\nnessing the superior expressive power of graph learning models. Our empirical\nevaluations across four fundamental graph reasoning tasks validate the effective-\nness of GraphLLM. Theresults on the\nfour graph reasoning tasks. GIN variant and GAT variant only achieve average accuracies of 24.2%\nand 17.3%, respectively. The significant disparity in accuracy between GIN variant, GAT variant,\n14GraphLLM: Boosting Graph Reasoning Ability of Large Language Model\nTable 6: Inference time on the four graph reasoning tasks.\nInput Format MethodLLaMA2-7B LLaMA2-13B\nMaximum Path\nSumSubstructure\nCountingShortest\nPathBipartite Graph\nMatchingMaximum Path\nSumSubstructure\nCountingShortest\nPathBipartite Graph\nMatching\nAdjacency\nListZero-shot 0.1673 0.1541 0.2649 0.1385 0.2878 0.2670 0.4517 0.2402\nFew-shot 0.4269 0.6506 0.5168 0.6116 0.7479 1.1150 0.8848 1.0604\nCoT 4.9367 2.4122 5.5155 4.2542 8.2850 4.1148 9.2961 7.2886\nLoRA(attn) 0.1710 0.1568 0.2804 0.1420 0.2926 0.2698 0.4601 0.2455\nLoRA(attn+ffn) 0.1818 0.1654 0.2842 0.1503 0.3071 0.2842 0.4813 0.2586\nPrefix Tuning 0.1846 0.1694 0.2947 0.1519 0.3161 0.2910 0.4963 0.2603\nEdge List\n(Random Order)Zero-shot 0.1642 0.1447 0.2521 0.1486 0.2869 0.2508 0.4355 0.2573\nFew-shot 0.4216 0.6259 0.4938 0.6560 0.7350 1.0678 0.8457 1.1473\nCoT 4.8385 2.3190 5.3227 4.5724 8.1369 3.9703 9.0008 7.8130\nLoRA(attn) 0.1678 0.1465 0.2569 0.1511 0.2923 0.2539 0.4431 0.2622\nLoRA(attn+ffn) 0.1783 0.1556 0.2714 0.1597 0.3054 0.2670 0.4636 0.2758\nPrefix Tuning 0.1777 0.1623 0.2757 0.1632 0.3080 0.2821 0.4724 0.2825\nGraphLLM 0.0449 0.0484 0.0734 0.0523 0.0583 0.0616 0.0937 0.0665\nand GraphLLM indicates that the practice of decoupling node information and structural informa-\ntion plays an essential role in improving GraphLLM\u2019s structure understanding ability, subsequently\nenhancing the graph reasoning capability.\nTable 7: Ablation study on graph transformer.\nAblationMaximum Triplet\nSumSubstructure\nCountingShortest\nPathBipartite Graph\nMatching\nGT\u2192GINConv 0.2237 \u00b1.0060 0.3878 \u00b1.0650 0.2122 \u00b1.0053 0.1427 \u00b1.0019\nGT\u2192GATConv 0.1819 \u00b1.0053 0.2598 \u00b1.0102 0.1443 \u00b1.0017 0.1052 \u00b1.0015\nGraphLLM 0.9577 \u00b1.0058 0.9990 \u00b1.0007 0.9726 \u00b1.0011 0.9981 \u00b1.0015\n15GraphLLM: Boosting Graph Reasoning Ability of Large Language Model\nD E XAMPLES OF GRAPH REASONING TASKS\nSubstructure Counting\nInput:\nHere are the descriptions of 15 atoms in a molecule.\nAtom 1: The Carbon atom has an atomic number of 6, denoted as \u201dC\u201d. Carbon has an elec-\ntronegativity value of approximately 3.25. The covalent radius of a Carbon atom is about ...\nAtom 2: The Carbon atom has an atomic number of 6, denoted as \u201dC\u201d. Carbon has an elec-\ntronegativity value of approximately 2.16. The covalent radius of a Carbon atom is about ...\nAtom 3: The Oxygen atom has an atomic number of 8, denoted as \u201dO\u201d. Oxygen has an elec-\ntronegativity value of approximately 3.52. The covalent radius of a Oxygen atom is about ...\n...\nAtom 15: The Nitrogen atom has an atomic number of 7, denoted as \u201dN\u201d. Nitrogen has an\nelectronegativity value of approximately 2.95. The covalent radius of a Nitrogen atom is ...\nThese atoms", " Introduction\nIn recent years, there have been unprecedented advancement s in large language models (LLMs) [30,\n21] such as Transformers [35], BERT [9], GPT [5], and their va riants. LLMs can be treated\nas foundation models that can be readily applied to diverse d ownstream tasks with little adapta-\ntion [5, 18, 21]. These models have achieved state-of-the-a rt results demon-\nstrate that while LLMs exhibit reasonable node classi\ufb01cati on capabilities even without explicit graph\ndata, likely by relying on contextual clues, their zero-sho t performance continues to lag behind state-\nof-the-art GNNs specialized for this domain. However, inco rporating graph topology information\ncan signi\ufb01cantly boost performance on edge-level link pred iction tasks, with GPT-4 even surpassing\ncertain GNNs in select cases. On more complex graph classi\ufb01c ation tasks, limitations emerge in han-\ndling increased output complexity. In summary, this resear ch provides valuable evidence that LLMs\nhave promising capabilities on graph analytics, while also revealing clear areas for improvement\ncompared to specialized graph models.\nOur future work should explore more rigorous benchmarking L LMs on graph learning tasks with\ngraph specialized models, novel prompt designs to focus on t opological structures, evaluating on\nadditional graph tasks, and even \ufb01ne-tuning open-sourced L LMs on graphs. By exploring these\n6avenues, the full potential of large language models for adv ancing graph representation learning and\nanalytics can be more promising. experiments on R EDDIT due to its text richness and se-\nmantic ambiguity. Only GPT-3.5 was tested since the informa tion of one community is large even\nwe have summarized the information from each user. We select edtop-k post summaries of the most\nreplied users as representative information of a community . As shown in Table 4, when GPT needs\nto make predictions from full 70 communities, the accuracy w as 50.7%. The accuracy decreased\nfrom 77.3% to 50.7% when possible communities in the <SubReddits> list increased from 1 to 70.\nGraph-level Task Structure? Prompt to GPT\nZero-shot Yes There are texts from representative users of one Reddit c ommunity:\n(REDDIT ) <Posts> . There are following communities: <SubReddits> . Which\ncommunity does these texts belong to? You should only output one\ncommunity from given communities.\nTable 7: Example prompt used in graph classi\ufb01cation experim ents. Structural information is given\nby a list of top-k important nodes a graph.\n4 discussion, delving\ninto the depth of our discoveries across varied experimenta l setups. We conclude by summarizing\nthe key points and proposing ideas for future explorations.\n2 Related Works\nLarge language models for graph-structured data. In recent literature, a few preliminary stud-\nies [44, 7, 40, 13] have made attempts to uncover the potentia l of LLMs in handling graph-structured\ndata. Unfortunately, a comprehensive examination of LLMs\u2019 capacity to extract and harness cru-\ncial topological structures across diverse prompt setting s, task levels, and datasets remains underex-\nplored. Both Chen et al.[7] and Guo et al.[13] proposed to app ly LLMs directly on graph data. Their\nresearch primarily focus on the node classi\ufb01cation task, co nstrained to a selected few datasets within\nthe citation network domain, and thereby fails to offer a tho rough exploration of LLMs\u2019 ability over\ndiverse task levels and datasets. In addition, Ye et al.[44] \ufb01ne-tuned LLMs on a designated dataset\nto outperform GNN, underscoring a distinct research object ive compared", " Introduction\nLarge Language Models (LLMs) has come through remarkable development [1 \u20134], The development\nin LLMs has spurred achievements in proposing and developing large foundation models in computer\nvision aspect [1,5 \u20139]. While Large Language Models (LLMs) such as ChatGPT and GPT-4 have\ndisplayed remarkable capacities in natural language processing (NLP) of many areas [10 \u201319], their\ndirect application in niche areas like healthcare has posed challenges.\nSpecifically, in radiation oncology, a sector demanding utmost precision, the generic nature of\nmainstream LLMs like ChatGPT or GPT-4 falls short. Distinct from other clinical practices,\nradiation oncology presents two salient features: a high level of complexity and stringent requirements\nfor precision [20,21]. This involves a chain of activities such as initial consultation, multi-modal\nimaging-based simulation, treatment planning, quality assurance, plan execution, and patient follow-\nup [22\u201328]. These steps incorporate a dynamic interplay between imaging data and text-based clinical\n\u2217Co-first authors.\n1arXiv:2309.10160v3  [physics.med-ph]  6 Nov 2023information, continually updated and accurately communicated to inform the subsequent phase\nof radiation treatment. Ultimately, this intricate process aims to ensure optimal implementation\nof radiation therapy. This process is traditionally time-consuming, reliant on manual analysis of\nvast amounts of unstructured clinical data, and susceptible to variations in human interpretation.\nEfficient tools for language-involved processing can significantly enhance each phase of radiation\ntherapy, and potentially improve treatment outcomes. This is especially true for advanced radiation\ntherapy techniques requiring even greater complexity and precision, such as Intensity-Modulated\nProton Therapy (IMPT) [29 \u201333]. The necessity arises for a model that assimilates clinical domain\nknowledge with the conciseness and specificity inherent in radiation oncology. Furthermore, medical\ninstitutes and healthcare practitioners need to have their localized LLMs because of the privacy\nregulations for patient health information (PHI). Besides, the collaboration of NLP and radiation\noncology still remains a underlooked field which even has enormous amount of available text data.\nSome previous works have already expanded in medical domain [34 \u201336]. In detail, fine-tuned LLMs\ncan be used to generate radiotherapy treatment regimens and other medical reports [14,37 \u201339],\ndetermine radiation treatment modality such as proton versus photon therapy, predict diagnosis\ndescription or ICD code based on patient details. These models all indicate the potential capabilities\nof LLMs in radiation oncology. By dealing with clinical notes and other patient\u2019s medical diagnosis\nand images, it is able to construct a conversational model for clinicians and patients about radiation\noncology and oncology in general. However, there still leaves a blank for radiation oncology to\nembrace such a comprehensive and powerful model.\nIn order to maximizing the potential of clinical notes in radiation oncology, we put forward a\npioneering solution called RadOnc-GPT. RadOnc-GPT addresses above-mentioned issues by offering\na specialized LLM tailored to generate radiation oncology impressions from clinical data, boasting\nimproved clarity, specificity, and clinical relevance.\n2 Related work\n2.1 Large Language Models (LLMs)\nThe NLP landscape has seen a significant shift with the rise of LLMs such as GPT-4 [40], PaLM [41].\nThese models, characterized by their few-shot and zero-shot learning capabilities, mark a departure\nfrom the conventional pre-training and fine-tuning methodologies including BERT [42], GPT [43],\nGPT-2 [44], and their variants [45 \u201347]. Moreover, models like Alpaca [48] and Dolly [49] illustrate\nthe growing trend towards instruction-based LLMs. These LLMs have shown great potentials in\nvarious domains and have profoundly affected the development of all walks of", " introduction to convolutional neural\nnetworks,\u201d arXiv preprint arXiv:1511.08458 , 2015.\n[19] L. R. Medsker and L. Jain, \u201cRecurrent neural networks,\u201d Design and\nApplications , vol. 5, pp. 64\u201367, 2001.\n[20] L. Scime and J. Beuth, \u201cAnomaly detection and classification in a laser\npowder bed additive manufacturing process using a trained computer\nvision algorithm,\u201d Additive Manufacturing , vol. 19, pp. 114\u2013126, 2018.\n[21] P. J. Rani, J. Bakthakumar, B. P. Kumaar, U. P. Kumaar, and S. Kumar,\n\u201cV oice controlled home automation system using natural language\nprocessing (nlp) and internet of things (iot),\u201d in 2017 Third Interna-\ntional Conference on Science Technology Engineering & Management\n(ICONSTEM) , pp. 368\u2013373, IEEE, 2017.\n[22] Z. Liu, W. Lin, Y . Shi, and J. Zhao, \u201cA robustly optimized bert pre-\ntraining approach with post-training,\u201d in China National Conference\non Chinese Computational Linguistics , pp. 471\u2013484, Springer, 2021.\n[23] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,\nS. Ozair, A. Courville, and Y . Bengio, \u201cGenerative adversarial net-\nworks,\u201d Communications of the ACM , vol. 63, no. 11, pp. 139\u2013144,\n2020.\n[24] J. Ho, A. Jain, and P. Abbeel, \u201cDenoising diffusion probabilistic\nmodels,\u201d Advances in Neural Information Processing Systems , vol. 33,\npp. 6840\u20136851, 2020.\n[25] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d\nAdvances in neural information processing systems , vol. 30, 2017.\n[26] G. Lu, S. Li, G. Mai, J. Sun, D. Zhu, L. Chai, H. Sun, X. Wang, H. Dai,\nN. Liu, et al. , \u201cAgi for agriculture,\u201d arXiv preprint arXiv:2304.06136 ,\n2023.\n[27] S. Rezayi, Z. Liu, Z. Wu, C. Dhakal, B. Ge, H. Dai, G. Mai,\nN. Liu, C. Zhen, T. Liu, et al. , \u201cExploring new frontiers in agricultural\nnlp: Investigating the potential of large language models for food\napplications,\u201d arXiv preprint arXiv:2306.11892 , 2023.\n[28] J. Ma and B. Wang, \u201cTowards foundation models of biological image\nsegmentation,\u201d Nature results show\nthat this geospatial foundation model leads to a 15 percent\nperformance improvement over the state-of-the-art model by\nusing only half-labeled data.\n3) Challenges in FM Design for Environment Monitoring:\nDespite the recent success in foundation model development\nfor earth observation and environmental monitoring, we also\nidentify several unique challenges:\n1)Integration of data with various spatial/temporal cov-\nerage: As we discussed in Section III-E5, environmental\nmonitoring data collected from different sensors can have\ndifferent spatial coverage and temporal coverage. How to\nintegrate them into a unified format so that they can be\nused for foundation model training? CLimaX [235] lists\nthis as one of their major challenges when developing\na foundation model based on different earth observation\ndata. They partially solve the diverse spatial coverage\nchallenge by leveraging the image patch idea from Vi-\nsion Transformer (ViT) [236]. They splitted the globe\nspace into various spatial patches. For an environmental\nmonitoring variable with a partial spatial coverage, they\ncan only feed the patches with available data to ViT\nwhich does not necessary to form a complete grid. Similar\npractices can be used to solve the diverse temporal\ncoverage challenge.\n2)Integration of data with various spatial/temporal\nresolutions: Similarly, death observation and environ-\nmental monitoring data collected from different sensors\ninherently have different spatial resolutions and temporal\nresolution. Most existing approaches [235], [237], [50]\nsimply downsample the high-resolution data or upsample\nthe low-resolution data to make the shape of input data\nmatch each other. This practice can bring unnecessary\nnegative impacts", " Introduction\nTransformer-based large language models (LLMs) such as ChatGPT and GPT-4 have shown impres-\nsive capabilities in natural language processing [ 1,2,3,4]. The development in transformer-based\nNLP models has also spurred advancements in developing and applying transformer-based models in\ncomputer vision [ 5,6,7,8] and other modalities [ 9,10,11,12,13,14,15,12,16,17,18,5,19]. Since\nNovember 2022, inspired by the versatile capabilities and wide popularity of ChatGPT, LLMs have\nbeen applied in clinical studies [ 20], pharmacy [ 21], radiology [ 22,23,24,25], Alzheimer\u2019s disease\n[26, 27], agriculture [28] and brain science research [29].\n\u2217Co-first authors.\n1arXiv:2309.06419v1  [cs.CL]  29 Aug 2023Figure 1: The overall framework of Radiology-Llama2.\nHowever, their application in specialized domains like healthcare has been limited.\nFirst, localized large language models are a must for real world healthcare, since hospitals cannot\nshare data or upload data to commercial models such as ChatGPT or GPT-4 due to privacy\nregulations [13, 30, 3].\nIn addition, LLMs trained on general domain, such as ChatGPT [ 31], GPT-4 [ 32] and PaLM 2 [ 33],\nlack medical knowledge in specialized domains such as radiology, and it is necessary to design a\nmodel that is properly trained on domain data that is clinically meaningful.\nMoreover, our Radiology-Llama2 perfectly imitates the style or radiologists, yet models like ChatGPT\ngenerate comprehensive but Wikipedia-like responses unlike the concise and simple language style of\nreal radiologists that facilitates quick information exchange. Finally, this work opens the door for\npersonalized radiological assistants that are tailored to the style of individual physicians [34].\nThis work addresses this gap through Radiology-Llama2, an LLM tailored for radiology through\ninstruction tuning to generate radiology impressions from findings. Evaluations show it surpasses\ngeneral LLMs in coherence, conciseness and clinical utility of generated impressions.\n\u2022State-of-the-Art Performance: Outperforms any other language models in deriving clinical\nimpressions [2], setting a new benchmark on MIMIC-CXR and OpenI datasets.\n\u2022Flexibility and Dynamism: Unlike its BERT-based counterparts [ 35,36], Radiology-Llama2\nis not tied to a specific input structure, allowing for a broader range of inputs and adaptability\nto different tasks within radiology, including complex reasoning.\n2\u2022Clinical Usability with Conversational Capabilities: Generative LLMs offers inherent\nconversational functionality [ 7], enabling it to provide contextual insights and responses in a\nhuman-like manner. This makes Radiology-Llama2 particularly useful for medical professionals\nin a clinical setting, enhancing both diagnosis and reporting.\n2 Related work\n2.1 Large Language Models (LLMs)\nRecent developments in NLP are marked by the emergence of LLMs such as GPT-3 [ 37], GPT-4 [ 32],\nPaLM [38], and PaLM-2 [ 33]. Contrasting the earlier pre-training and fine-tuning approach observed\nin BERT [ 35], GPT [39], GPT-2 [ 40], and their variants [ 41,15,36], these new LLMs exhibit few-shot\nand zero-shot learning capabilities using in-context learning. Furthermore, open-source models like\nLLaMA [42] and Bloom [43] have entered the scene, promoting broader accessibility.\nThere\u2019s also an increasing interest in instruction-tuned models such as Alpaca [ 44], StableLM [ 45],\nand Dolly [46].\n2.2 Domain-Specific Language Models (DSLMs)\nDSLMs, such as AgriBERT [ 47], are tailored to specific domains, aimed at optimal performance in\nrelated tasks. Specifically, AgriBERT is trained on agricultural texts, making it suitable for tasks in\nagriculture. SciEdBERT [ 17] is designed for the educational sector and focuses on middle school\nchemistry and physics, offering insights into evaluating students\u2019 responses. ClinicalRadioBERT [ 48],\nin the healthcare sector, is adept at radiation oncology and", " Introduction\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\ncomplex reasoning tasks requiring expert knowledge across a wide range of \ufb01elds, including in specialized\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\nchat interfaces, which has led to rapid and widespread adoption among the general public.\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\n(Ho\ufb00mann et al., 2022), but none of these models are suitable substitutes for closed \u201cproduct\u201d LLMs, such\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavily\ufb01ne-tunedtoalignwithhuman\npreferences, which greatly enhances their usability and safety. This step can require signi\ufb01cant costs in\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\nthe community to advance AI alignment research.\nIn this work, we develop and release Llama 2, a family of pretrained and \ufb01ne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-speci\ufb01cdata\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\nthispapercontributesathoroughdescriptionofour\ufb01ne-tuningmethodologyandapproachtoimproving\nLLM safety. We hope that this openness will enable the community to reproduce \ufb01ne-tuned LLMs and\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\nWealsosharenovelobservationswemadeduringthedevelopmentof L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle andL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc ,suchas\nthe emergence of tool usage and temporal organization of knowledge.\n3Figure 3: Safety human evaluation Results\nSee evaluations for pretraining (Section 2); \ufb01ne-tuning (Section 3); and safety (Section 4).\nEthical Considerations and Limitations (Section 5.2)\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle is a new technology that carries risks with use. Testing conducted to date has been in\nEnglish, and has notcovered, nor could it coverall scenarios. For these reasons, aswith all LLMs,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle\u2019s potential outputs cannot be predicted in advance, and the model may in some instances\nproduceinaccurateorobjectionableresponsestouserprompts. Therefore,beforedeployingany\napplications of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle, developers should perform safety testing and tuning tailored to their\nspeci\ufb01c applications of the model. Please see the Responsible Use Guide available available at\nhttps://ai.meta.com/llama/responsible-user-guide\nTable 52: Model card for L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle .\n77 Discussion\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1). We then discuss the\nlimitations of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc (Section 5.2). Lastly, we present our strategy for responsibly releasing these\nmodels (Section 5.3).\n5.1 Learnings and Observations\nOur tuning process revealed several interesting Related Work\nLarge Language Models. The recent years have witnessed a substantial evolution in the \ufb01eld of LLMs.\nFollowing the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\nmodels, e.g. Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Ho\ufb00mann et al.,\n2022) rede\ufb01ned those scaling laws towards the number of tokens rather than model weights. Notable in\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationale\ufb03ciencyduringinference\n(Touvron et al., 2023). A parallel discourse has unfolded around the", " Introduction\nAlzheimer\u2019s disease (AD), named after German psychiatrist Alois Alzheimer, is the most common\nform of dementia. AD degenerates brain cells, seriously a\ufb00ecting patients\u2019 quality of life [ 1]. Patients\nwith AD have a shorter life expectancy with a median survival time of 3 to 6 years after diagnosis,\nwhich is even shorter for those with other underlying diseases [ 2]. Memory loss is a hallmark symptom\nof AD, with patients getting lost and forgetting family and friends [ 3]. AD also impairs language\nability, making it di\ufb03cult to read, write, and communicate [ 3], and may cause di\ufb03culty swallowing\nand movement disorders in advanced stages [ 4]. AD is also a signi\ufb01cant societal and economic\nburden, with 50 million people worldwide a\ufb04icted by the disease in 2020, projected to rise to 152\nmillion by 2050 [ 1]. The cost of AD diagnosis, treatment, and care worldwide is estimated to be\n1arXiv:2307.02514v1  [eess.AS]  5 Jul 2023around 1 trillion US dollars per year [1].\nWhile AD is incurable, early diagnosis can slow down its development, making it crucial to detect the\ndisease at its early stages [ 5]. However, medical diagnostic Related Work\nThere is prior work that utilizes patients\u2019 speech transcript for AD detection and diagnosis. A\nstudy by Ben Ammar et al. [ 7] proposed an AD detection model that extracts linguistic features\nfrom patient speech transcripts and performs feature selection based on the KNN algorithm. The\nselected features are then used to train a machine learning classi\ufb01er, such as SVM, for the \ufb01nal\ndiagnosis. Yamanki et al. [ 8] proposed a contrastive learning model based on Siamese BERT to\nextract discriminative features from both the text of the patient speech transcripts and other features\nsuch as demographic, lexical, semantic information. The extracted features are then used for AD\ndiagnosis using machine learning classi\ufb01ers. The work by Roshanzamir et al. [ 9] developed text\ndata processing pipeline for analyzing patient speech transcript data. The pipeline consists of an\naugmentation module that enriches the input text data and a splitter that breaks text into sentences.\nThe model then uses BERT to encode the sentences and the output encoded embeddings are used as\ninput for various classi\ufb01cation models, including multi-layer perceptron (MLP), convolutional neural\nnetwork (CNN), and bidirectional LSTM (biLSTM).\nSome other work also incorporates speech data of patients to assist in AD diagnosis. A study\nproposed by Bertini et al. [ 10] uses log mel spectrograms and audio data augmentation techniques.\nThe patients\u2019 audio data are \ufb01rst converted into log mel spectrograms, which is then enhanced\nusing data augmentation techniques. Then, an autoencoder learns a condensed representation of\nthe spectrogram, which then serves as input for a multilayer perceptron. Martinc et al. [ 11] use\naudio feature engineering for diagnosing AD. Speci\ufb01cally, they extract acoustic and textual features\nfrom the speech segments using openSMILE toolkit and GloVe, and further extract Active Data\nRepresentation (ADR) features based on them. A study by Agbavor et al. [ 12] uses pre-trained\naudio model including data2vec and wav2vec2 to extract audio features from patients, and evaluates\nits performance on the ADReSSo (Alzheimer\u2019s Dementia Recognition through Spontaneous Speech\nonly) dataset.\n3 Methods in Natural Language Processing:\nSystem Demonstrations , pages 119\u2013126, 2020.\n16 introduction to the data augmentation results in the audio modality,", " Introduction 1\n2 Preliminaries and results of this experiment, see Fig. A.1.\nTable A.7: Optimization settings for in-context learning.\nSoft prompting Few-shot prompting\nOptimizer AdamW AdamW\nOptimizer momentum ( \u03b21,\u03b22) 0.9, 0.999 0.9, 0.999\nLearning Rate 0.001 0.0001\nBatch Size 16 2\nWeight Decay (model) 0 0\nWeight Decay ( Hyenalayers) 0 0\nResid dropout 0 0\nEmbed dropout 0.1 0.1\nReverse complement aug. true false\nLR-schedule Plateau -\nA.4 Chromatin Profile Details Related Work 4\n2.1 Transformers and Attention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 Long Context Strategies in Genomics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.3 Large Convolutional Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n3HyenaDNA Long-Range Genomic Foundation Models 5\n3.1 The HyenaDNA Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n3.2 Training Long Sequence Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n3.3 Downstream Adaptation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n4 Experiments 6\n4.1 Pretraining on the Human Genome . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n4.2 Single Nucleotide Resolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n4.3 In-context Learning for Genomic Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n4.4 Ultralong-Range Genomics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.4.1 Chromatin Profile Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.4.2 Biotype Embeddings . . . . . .", " Introduction\nAlzheimer\u2019s Disease (AD), a progressive neurodegenerative disorder, remains\none of the most pressing public health concerns globally in the 21st century\n[1,2]. This disease, characterized by cognitive impairments such as memory\nloss, predominantly affects aging populations, exerting an escalating burden\non global healthcare systems as societies continue to age [3]. The significance\nof AD is further magnified by the increasing life expectancy globally, with\nthe disease now recognized as a leading cause of disability and dependency\namong older people [4]. Consequently, AD has substantial social, economic,\nand health system implications, making its understanding and awareness of\nparamount importance [5,6].\nDespite the ubiquity and severity of AD, a gap persists in comprehensive,\ndata-driven public understanding of this complex health narrative. Tradition-\nally,publichealthprofessionalshavetorelyonlabor-intensivemethodssuchas\nweb scraping, API data collection, data postprocessing, and analysis/synthesis\nto gather insights from news media, health reports, and other textual sources\n[7,8,9]. However, these methods in natural language processing , pages 1533\u20131544, 2013.\n44. Gengchen Mai, Krzysztof Janowicz, Rui Zhu, Ling Cai, and Ni Lao. Geographic ques-\ntion answering: challenges, uniqueness, classification, and future directions. AGILE:\nGIScience series , 2:8, 2021.\n45. Milan Gritta, Mohammad Taher Pilehvar, and Nigel Collier. Which melbourne? aug-\nmenting geocoding with maps. Association for Computational Linguistics, 2018.\n46. Morteza Karimzadeh, Scott Pezanowski, Alan M MacEachren, and Jan O Wallgr\u00fcn.\nGeotxt: A scalable geoparsing system for unstructured text geolocation. Transactions\nin GIS, 23(1):118\u2013136, 2019.\n47. Jimin Wang, Yingjie Hu, and Kenneth Joseph. Neurotpr: A neuro-net toponym recog-\nnition model for extracting locations from social media messages. Transactions in GIS ,\n24(3):719\u2013735, 2020.\n48. Dirk Ahlers. Assessment of the accuracy of geonames gazetteer data. In Proceedings of\nthe 7th workshop on geographic information retrieval , pages 74\u201381, 2013.\n49. Gengchen Mai, Yingjie Hu, Song Gao, Ling Cai, Bruno Martins, Johannes Scholz, Jing\nGao, and Krzysztof Janowicz. Symbolic and subsymbolic geoai: Geospatial knowledge\ngraphs and spatially explicit machine learning. Trans GIS , 26(8):3118\u20133124, 2022.\n50. Yiting Ju, Benjamin Adams, Krzysztof Janowicz, Yingjie Hu, Bo Yan, and Grant\nMcKenzie. Things and strings: improving place name disambiguation from short texts\nby combining entity co-occurrence with topic modeling. In Knowledge Engineering and\nKnowledge Management: 20th International Conference, EKAW 2016, Bologna, Italy,\nNovember 19-23, 2016, Proceedings 20 , pages 353\u2013367. Springer, 2016.\n51. Liam Magee, Lida Ghahremanlou, Karen Soldatic, and Shanthi Robertson. Intersec-\ntional bias in causal language models. arXiv preprint arXiv:2107.07691 , 2021.\n52. Emilio Ferrara. Should chatgpt be biased? challenges and risks of bias in large language\nmodels.arXiv preprint arXiv:2304.03738 , 2023.\n53. Wenxiong Liao, Zhengliang Liu, Haixing Dai, Shaochen Xu, Zihao Wu, Yiyang Zhang,\nXiaoke Huang, Dajiang Zhu, Hongmin Cai, Tianming Liu, et al. Differentiate chatgpt-\ngenerated and human-written medical texts. arXiv preprint arXiv:2304.11567 , 2023.\n54. Julian Hazell. Large language models can be used to effectively scale spear phishing\ncampaigns. arXiv preprint arXiv:2305.06972 , 2023. Related Work\n2.1 Large Language Models\nLarge language models (LLMs), with their origins in Transformer-based pre-\ntrained language models (PLMs) such as BERT [13] and GPT [14], have sub-\nstantially transformed the field of natural language processing (NLP). LLMs\nhave superseded previous results and deriving actionable insights. This ac-\ncelerates the research process and enhances the accuracy and reliability of the\nfindings in diverse areas, such as social sciences, economics, technology, and\nmore.\n5.3 Transforming Public Health\nFurthermore, the insights obtained from this research have broader implica-\ntions beyond public health. The automation capabilities of AD-AutoGPT can\nrevolutionize the field", "Abstract \u2014In this review, we explore the potential applications\nof Arti\ufb01cial General Intelligence (AGI) models in healthcare,\nfocusing on foundational Large Language Models (LLMs), Large\nVision Models, and Large Multimodal Models. We emphasize the\nimportance of integrating clinical expertise, domain knowledge,\nand multimodal capabilities into AGI models. In addition, we lay\nout key roadmaps that guide the development and deployment\nof healthcare AGI models. Throughout the review, we provide\ncritical perspectives on the potential challenges and pitfalls\nassociated with deploying large-scale AGI models in the medical\n\ufb01eld. This comprehensive review aims to offer insights into the\nfuture implications of AGI in medical imaging, healthcare and\nbeyond.\nIndex Terms \u2014ChatGPT, GPT-4, LLM, AGI, Medical Imaging\nI. I NTRODUCTION\nAGI models such as LLMs have demonstrated success\n[1] in general domains. However, applying them directly to\nhealthcare can pose signi\ufb01cant challenges, potentially leading\nto decreased performance or even making it impossible [2].\nThese challenges primarily stem from the medical domain\u2019s\nunique characteristics, such as the specialized nature of clin-\nical text and medical imaging, and the expertise needed for\naccurate interpretation. For example, medical imaging data,\nwhich encompasses images obtained from various modali-\nties [3], [4] such as X-rays, computed tomography (CT),\nmagnetic resonance imaging (MRI), ultrasound, microscope,\n(Corresponding authors: Xiang Li, Tianming Liu, Dinggang Shen)\nXiang Li and Quanzheng Li are with the Department of Radiology,\nMassachusetts General Hospital and Harvard Medical School, Boston 02115,\nUSA. (e-mail: fxli60,li.quanzheng g@mgh.harvard.edu).\nLu Zhang and Dajiang Zhu are with the Department of Computer Science\nand Engineering, The University of Texas at Arlington, Arlington 76019,\nUSA. (e-mail: lu.zhang2@mavs.uta.edu and dajiang.zhu@uta.edu).\nZihao Wu, Zhengliang Liu, Lin Zhao and Tianming Liu are with the School\nof Computing, The University of Georgia, Athens 30602, USA. (e-mail:\nfzihao.wu1,zl18864,lin.zhao,tliu g@uga.edu).\nYixuan Yuan is with the Department of Electronic Engineering, Chinese\nUniversity of Hong Kong, Hong Kong. (e-mail: yxyuan@ee.cuhk.edu.hk).\nJun Liu is with the Department of Radiology, Second Xiangya Hospital,\nChangsha 410011, China. (e-mail: junliu123@csu.edu.cn).\nGang Li is with the Department of Radiology at the University\nof North Carolina at Chapel Hill, Chapel Hill 27599, USA. (e-mail:\ngang li@med.unc.edu).\nPingkun Yan is with the Department of Biomedical Engineering at\nRensselaer Polytechnic Institute, Troy, New York 12180, USA. (e-mail:\nyanp2@rpi.edu).\nWei Liu is with the Department of Radiation Oncology, Mayo Clinic,\nScottsdale 85259, USA. (e-mail: liu.wei@mayo.edu).\nDinggang Shen is with the School of Biomedical Engineering, Shang-\nhaiTech University, Shanghai 201210, China; Shanghai United Imaging Intel-\nligence Co., Ltd., Shanghai 200230, China; Shanghai Clinical Research and\nTrial Center, Shanghai, 201210, China. (e-mail: Dinggang.Shen@gmail.com).and more, is primarily acquired for diagnostic or therapeutic\npurposes, aiming to provide vital insights into a patient\u2019s\nhealth condition [5], [6]. Interpreting these images demands\nspecialized knowledge and expertise in anatomy, pathology,\nand radiology. In contrast, natural images typically consist\nof everyday objects that can be accurately recognized by\nmost individuals based on common sense. This distinction\npresents a notable challenge when it comes to annotating a\nsubstantial volume of high-quality medical imaging data, as\nit necessitates the involvement of numerous experts, which\nis often impractical or unfeasible. Consequently, the medical\ndomain faces a scarcity of extensive training data required\nfor directly training large models from scratch, in contrast to\nthe abundant availability of such data in the general domain.\nMoreover, due to the heterogeneity between medical data and\ngeneral data, it is not optimal to directly apply LLMs (e.g.,\nGPT-4 [7]) and large multimodal models (e.g., Kosmos-1 [8])\ntrained on general data to the medical domain. In addition,\nclinical data", " Introduction\nFinetuning large language models (LLMs) is a highly effective way to improve their performance,\n[40,62,43,61,59,37] and to add desirable or remove undesirable behaviors [ 43,2,4]. However,\nfinetuning very large models is prohibitively expensive; regular 16-bit finetuning of a LLaMA 65B\nparameter model [ 57] requires more than 780 GB of GPU memory. While recent quantization methods for effective instruction tuning. arXiv\npreprint arXiv:2301.13688 , 2023.\n[40] S. Min, M. Lewis, L. Zettlemoyer, and H. Hajishirzi. Metaicl: Learning to learn in context.\narXiv preprint arXiv:2110.15943 , 2021.\n[41] A. Nematzadeh, K. Burns, E. Grant, A. Gopnik, and T. Griffiths. Evaluating theory of mind in\nquestion answering. In Proceedings of the 2018 Conference on Empirical Background\nBlock-wise k-bit Quantization Quantization is the process of discretizing an input from a rep-\nresentation that holds more information to a representation with less information. It often means\ntaking a data type with more bits and converting it to fewer bits, for example from 32-bit floats to\n8-bit Integers. To ensure that the entire range of the low-bit data type is used, the input data type is\ncommonly rescaled into the target data type range through normalization by the absolute maximum\nof the input elements, which are usually structured as a tensor. For example, quantizing a 32-bit\nFloating Point (FP32) tensor into a Int8 tensor with range [\u2212127,127]:\nXInt8=round\u0012127\nabsmax (XFP32)XFP32\u0013\n=round (cFP32\u00b7XFP32), (1)\nwhere cis the quantization constant orquantization scale . Dequantization is the inverse:\ndequant (cFP32,XInt8) =XInt8\ncFP32=XFP32(2)\nThe problem with this approach is that if a large magnitude value (i.e., an outlier) occurs in the input\ntensor, then the quantization bins\u2014certain bit combinations\u2014are not utilized well with few or no\nnumbers quantized in some bins. To prevent the outlier issue, a common approach is to chunk the\ninput tensor into blocks that are independently quantized, each with their own quantization constant c.\nThis can be formalized as follows: We chunk the input tensor X\u2208Rb\u00d7hintoncontiguous blocks of\nsizeBby flattening the input tensor and slicing the linear segment into n= (b\u00d7h)/Bblocks. We\nquantize these blocks independently with Equation 1 to create a quantized tensor and nquantization\nconstants ci.\nLow-rank Adapters Low-rank Adapter (LoRA) finetuning [ 28] is a method that reduces memory\nrequirements by using a small set of trainable parameters, often termed adapters, while not updating\nthe full model parameters which remain fixed. Gradients during stochastic gradient descent are\npassed through the fixed pretrained model weights to the adapter, which is updated to optimize the\nloss function. LoRA augments a linear projection through an additional factorized projection. Given\na projection XW =YwithX\u2208Rb\u00d7h,W\u2208Rh\u00d7oLoRA computes:\nY=XW +sXL 1L2, (3)\nwhereL1\u2208Rh\u00d7randL2\u2208Rr\u00d7o, and sis a scalar.\nMemory Requirement of Parameter-Efficient Finetuning One important point of discussion is\nthe memory requirement of LoRA during training both in terms of the number and size of adapters\nused. Since the memory footprint of LoRA is so minimal, we can use more adapters to improve\nperformance without significantly increasing the total memory used. While LoRA was designed as a\n3Parameter Efficient Finetuning (PEFT) method, most of the memory footprint for LLM finetuning\ncomes from activation gradients and not from the learned LoRA parameters. For a 7B LLaMA\nmodel trained on FLAN v2 with a batch size of 1, with LoRA weights equivalent to commonly used\n0.2% of the original model weights[ 28,37], the LoRA input gradients have a", " Introduction\nPresent-day large language models (LLMs) display remarkable behaviors: they appear to solve\ncoding tasks, translate between languages, engage in open-ended dialogue, and much more. As a\nresult, their societal impact is rapidly growing, as they make their way into products, services, and\npeople\u2019s own daily tasks. In this context, it is vital that we move beyond behavioral evaluation to\ndeeply explain, in human-interpretable terms, the internal processes of these models, as an initial step\nin auditing them for safety, trustworthiness, and pernicious social biases.\nThe theory of causal abstraction [ 5,22] provides a generic framework for representing interpretability experiments.\nThere is a large number of high-level models to solve the task, and we only test a portion of them.\nWe think that this is sufficient to demonstrate the advantages of our pipeline. It would be interesting\nif humans can be in the loop of testing different hypotheses of the high-level causal model in future\nwork. On the other hand, not all the high-level models are interesting to analyze. For instance, if\ntwo high-level models are equivalent (e.g., swapping variable names), it is not in our interest to find\nalignments.\n18Can Boundless DAS be applied to find circuits in a model?\nYes, it can. We believe that \u201ccircuit analysis\u201d can be theoretically grounded in causal abstraction and\nis deeply compatible with our work. Previous work in this mode usually relies on the assumption\nof localist representation (i.e., there exists a one-to-one mapping between a group of neurons and\na high-level concept). This is often too idealized, as multiple concepts can easily be aligned with\nthe same group of neurons, or a group of neurons may map to multiple concepts. Boundless DAS\nactually drops this assumption by specifically focusing on distributed alignments. More importantly,\nBoundless DAS can be easily used in a head-wise alignment search where we add a shared rotation\nmatrix on top of head representations of all the tokens.\n19Figure 8: Interchange Intervention Accuracy (IIA) evaluated with correct input examples only as well\nas incorrect input examples only for our \u201cLeft and Right Boundary\u201d causal model. The higher the\nnumber is, the more faithful the alignment is. We color each cell by scaling IIA using the model\u2019s\ntask performance as the upper bound and a dummy classifier (predicting the most frequent label) as\nthe lower bound.\nFigure 9: Interchange Intervention Accuracy (IIA) evaluated with different settings of brackets in the\ninstruction. The seen setting is for training, and the unseen setting is for evaluation. The higher the\nnumber is, the more faithful the alignment is. We color each cell by scaling IIA using the model\u2019s\ntask performance as the upper bound and a dummy classifier (predicting the most frequent label) as\nthe lower bound.\n20Figure 10: Interchange Intervention Accuracy (IIA) evaluated with two different irrelevant contexts\ninserted as prefixes. The higher the number is, the more faithful the alignment is. We color each\ncell by scaling IIA using the model\u2019s task performance as the upper bound and a dummy classifier\n(predicting the most frequent label) as the lower bound.\nFigure 11: Interchange Intervention Accuracy (IIA) evaluated with twenty different irrelevant\ncontexts generated by GPT4-Aug05-2023 . Correlation is 0.99 with the \u201cLeft and Right Boundary\u201d\ncausal model.\n21Figure 12: Interchange Intervention Accuracy (IIA) with random initialized rotation matrix and\nlearned optimal boundary", " Introduction\nIt has been a long standing goal of humanity to develop Ar-\nti\ufb01cial General Intelligence (AGI) that exhibits human-level\nor even surpassing intelligence. An essential characteristic\nof human intelligence is its ability to process information\nfrom multiple modalities, which enables individuals to com-\nprehend their surroundings through multiple sources of in-\n*Equal contribution1School of Life Science and Technol-\nogy, University of Electronic Science and Technology of China,\nChengdu 611731, China2Department of Computer Science and En-\ngineering, The University of Texas at Arlington, Arlington 76019,\nUSA3School of Computing, The University of Georgia, Athens\n30602, USA4Glasgow College, University of Electronic Science\nand Technology of China, Chengdu 611731, China5School of Au-\ntomation, Northwestern Polytechnical University, Xi\u2019an 710072,\nChina6Department of Electronic Engineering, Chinese University\nof Hong Kong, Hong7Department of Radiotion Oncology, Mayo\nClinic, Arizona, USA8Department of Radiology, Massachusetts\nGeneral Hospital and Harvard Medical School, Boston 02115,\nUSA9School of Biomedical Engineering, ShanghaiTech Univer-\nsity, Shanghai 201210, China10Shanghai United Imaging Intel-\nligence Co., Ltd., Shanghai 200230, China11Shanghai Clinical\nResearch and Trial Center, Shanghai, 201210, China. Correspon-\ndence to: Xi Jiang <xijiang@uestc.edu.cn >.formation and communicate effectively with others (Zhao\net al., 2023). Similarly, arti\ufb01cial intelligence systems are\nalso expected to ef\ufb01ciently handle, integrate, and utilize mul-\ntimodal data to solve real-world problems. The recent break-\nthroughs of large language models (LLMs) have provided\nnew insights into realizing this goal. LLMs were initially\nproposed in the \ufb01eld of Natural Language Processing (NLP)\nto solve various complex NLP tasks, and have demonstrated\nremarkable abilities in learning and reasoning. Compared\nto traditional language models, these LLMs adopt a novel\nprompt technique which allows the pre-trained LLMs to be\nadapted to downstream tasks without \ufb01ne-tuning the models\nthemselves. Through the \ufb02exible prompt design, the lan-\nguage model could be pre-trained on massive amounts of\nraw text and perform few-shot or even zero-shot learning,\nthus adapting to new scenarios with few or no labeled data\n(Liu et al., 2023c). For example, the in-context prompt in the\nGPT series, which is based on auto-regressive pre-training\nand prompt-based \ufb01ne-tuning, allowed the model to produce\nan ideal result for previously unseen tasks without the need\nto update any parameter (Zhang et al., 2023).\nWhile large-scale AGI uni-modal (images or texts) models\nhave demonstrated impressive performance in a variety of\ntasks (Brown et al., 2020; Kirillov et al., 2023), the complex-\nity and diversity of many real-world problems in arti\ufb01cial\nintelligence often require the integration of information from\nmultiple modalities, such as text, image, and audio. Multi-\nmodal models utilize various methods in natural language processing. ACM\nComputing Surveys , 55(9):1\u201335, 2023c.\nLiu, X., Ji, K., Fu, Y ., Weng, T., Du, Z., Yang, Z., and Tang,\nJ. P-tuning: Prompt tuning can be comparable to \ufb01ne-\ntuning across scales and tasks. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics , pp. 61\u201368, 2022.\nNilsback, M.-E. and Zisserman, A. Automated \ufb02ower\nclassi\ufb01cation over a large number of classes. In 2008\nSixth Indian Conference on Computer Vision, Graph-\nics & Image Processing , pp. 722\u2013729, 2008. doi:\n10.1109/ICVGIP.2008.47.\nOpenAI. Gpt-4 technical report, 2023.\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.,\nMishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A.,\net al. Training language models to follow instructions\nwith human feedback. Advances in Neural Information\nProcessing Systems , 35:27730\u201327744, 2022.\nParkhi, O. M., Vedaldi, A., Zisserman, A., and Jawahar, C.\nCats and dogs. In 2012 IEEE conference on computer\nvision and pattern recognition , pp. 3498\u20133505. IEEE,\n2012.Instruction-ViT: Multi-Modal Prompts for", " introduction to deep reinforcement learning,\u201d Foundations\nand Trends\u00ae in Machine Learning , vol. 11, no. 3-4, pp. 219\u2013354, 2018.\n[113] E. Crothers, N. Japkowicz, and H. Viktor, \u201cMachine generated text: A\ncomprehensive survey of threat models and detection results, limitations,\nand potential,\u201d arXiv preprint arXiv:2303.09038 , 2023.\n[19] B. Lamichhane, \u201cEvaluation of chatgpt for nlp-based mental health\napplications,\u201d arXiv preprint arXiv:2303.15727 , 2023.\n[20] E. Wallace, S. Feng, N. Kandpal, M. Gardner, and S. Singh, \u201cUniversal\nadversarial triggers for attacking and analyzing nlp,\u201d in Proceedings\nof the 2019 Conference on Empirical methods\nfor multimodal medical data mining,\u201d Expert Systems with Applica-\ntions , p. 117006, 2022.\n[129] B. Jacob, A. Kaushik, P. Velavan, and M. Sharma, \u201cAutonomous\ndrones for medical assistance using reinforcement learning,\u201d Advances\nin Augmented Reality and Virtual Reality , pp. 133\u2013156, 2022.\n[130] Y . Liu, T. Han, S. Ma, J. Zhang, Y . Yang, J. Tian, H. He, A. Li,\nM. He, Z. Liu et al. , \u201cSummary of chatgpt/gpt-4 research and per-\nspective towards the future of large language models,\u201d arXiv preprint\narXiv:2304.01852 , 2023.\n[131] J. S. Chen and S. L. Baxter, \u201cApplications of natural language pro-\ncessing in ophthalmology: present and future,\u201d Frontiers in Medicine ,\nvol. 9, 2022.\n[132] M. Thakur, S. Dhanalakshmi, H. Kuresan, R. Senthil,\nR. Narayanamoorthi, and K. W. Lai, \u201cAutomated restricted boltzmann\nmachine classifier for early diagnosis of parkinson\u2019s disease using\ndigitized spiral drawings,\u201d Journal of Ambient Intelligence and\nHumanized Computing , vol. 14, no. 1, pp. 175\u2013189, 2023.\n[133] E. A. Martin, A. G. D\u2019Souza, S. Lee, C. Doktorchik, C. A. Eastwood,\nand H. Quan, \u201cHypertension identification using inpatient clinical notes\nfrom electronic medical records: an explainable, data-driven algorithm\nstudy,\u201d Canadian Medical Association Open Access Journal , vol. 11,\nno. 1, pp. E131\u2013E139, 2023.\n[134] M. A. Azam, K. B. Khan, S. Salahuddin, E. Rehman, S. A. Khan, M. A.\nKhan, S. Kadry, and A. H. Gandomi, \u201cA review on multimodal medical\nimage fusion: Compendious analysis of medical modalities, multimodal\ndatabases, fusion techniques and quality metrics,\u201d Computers in biology\nand medicine , vol. 144, p. 105253, 2022.\n[135] R. Chengoden, N. Victor, T. Huynh-The, G. Yenduri, R. H. Jhaveri,\nM. Alazab, S. Bhattacharya, P. Hegde, P. K. R. Maddikunta, and\nT. R. Gadekallu, \u201cMetaverse for healthcare: A survey on potential\napplications, challenges and future directions,\u201d IEEE Access , 2023.\n[136] Q. D. Buchlak, N. Esmaili, C. Bennett, and F. Farrokhi, \u201cNatural\nlanguage processing applications in the clinical neurosciences: A\nmachine learning augmented systematic review,\u201d Machine Learning in\nClinical Neuroscience: Foundations and Applications , pp. 277\u2013289,\n2022.\n[137] B. Kutela, K. Msechu, S. Das, and E. Kidando, \u201cChatgpt\u2019s scientific\nwritings: A case study on traffic safety,\u201d Available at SSRN 4329120 ,\n2023. background and\nsignificance of Prompt Engineering and outlines the scope and\nfocus of the review. It describes the literature search process\nfollowed and provides an outline of the article.\nSection II presents the basics of Prompt Engineering, in-\ncluding common LLMs, and the elements and components of\nprompts.\nSection III discusses the different types of prompts available\nin the literature, with a focus on manual prompts such as\n1https://braininspiredai.github.io/prompt trend inmedicalJOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 3\nFig. 2. The graphical representation is utilized to depict the number of research papers on prompt engineering for NLP in the medical domain, published from\n2019 to April 6, 2023, revealing the trend", " Introduction\n1.1 results show that medical texts generated by ChatGPT are more \ufb02uent and logical\nbut more general in content and language style, while medical texts written by humans are more\ndiverse and speci\ufb01c. Although ChatGPT can generate human-like text, due to the di\ufb00erences in\ntheir language style and content, the text written by ChatGPT can still be accurately detected by\ndesigning machine learning algorithms, and the F1 exceeds 95% .\n5.2 Limitations\nWe only use ChatGPT as an example to analyze the di\ufb00erence between medical texts generated by\nLLM and medical texts written by humans. However, more advanced LLMs have emerged. It will\nbe part of our future work to analyze more language styles generated by LLM and summarize the\nlanguage construction rules of LLM.\n5.3 abstract data set,\n\"outcomes\", \"study\", \"potential\", \"suggest\", etc. are used as nodes in the CART and XGBoost\nmodels.\nIn addition to visualizing the global features of CART and XGBoost, we also use the toolkit of\ntransformers-interpret5to visualize the local features of the samples, and the Discussion\n5.1 Principal introduction and open debate about risks and bene\ufb01ts. The medical \ufb01eld is\na \ufb01eld related to human health and life. We provide a simple demonstration to identify ChatGPT-\ngenerated medical content, which can help reduce the harm caused to humans by ChatGPT-generated\nerroneous and incomplete information. Assessing and mitigating the risks associated with LLM and\nits potential harm is a complex and interdisciplinary challenge that requires combining knowledge\nfrom various \ufb01elds to avoid its risks and drives the healthy development of LLM.\n11Figure 9: Visualization of BERT. References\n[1]Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language\nunderstanding by generative pre-training. 2018.\n[2]Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of NAACL-HLT , pages\n4171\u20134186, 2019.\n[3]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information\nprocessing systems , 30, 2017.\n[4]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\nfew-shot learners. Advances in neural information processing systems , 33:1877\u20131901, 2020.\n[5]Long Ouyang, Je\ufb00 Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin,\nChong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models\nto follow instructions with human feedback. arXiv preprint arXiv:2203.02155 , 2022.\n[6]Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep\nreinforcement learning from human preferences. Advances in neural information processing\nsystems, 30, 2017.\n[7]John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal\npolicy optimization algorithms. arXiv preprint arXiv:1707.06347 , 2017.\n12[8]Teo Susnjak. Applying bert and chatgpt for sentiment analysis of lyme disease in scienti\ufb01c\nliterature. arXiv preprint arXiv:2302.06474 , 2023.\n[9]Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Huang, Zihao Wu, Lin Zhao, Wei Liu,\nNinghao Liu, Sheng Li, Dajiang Zhu, et al. Chataug: Leveraging chatgpt for text data\naugmentation. arXiv preprint arXiv:2302.13007 , 2023.\n[10]Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie,\nJinan Xu, Yufeng Chen, Meishan Zhang, et al. Zero-shot information extraction via chatting\nwith chatgpt. arXiv preprint arXiv:2302.10205 , 2023.\n[11]Zhengliang Liu, Xiaowei Yu, Lu Zhang, Zihao Wu, Chao Cao, Haixing Dai, Lin", " Introduction\nLarge language models (LLMs) such as PaLM\n(Chowdhery et al., 2022) and GPT-4 (OpenAI,\n2023) have shown great success on a wide range\nof general-domain Natural Language Processing\n(NLP) tasks. They also achieve state-of-the-art\n(SOTA) performance on domain-speci\ufb01c tasks like\nbiomedical question answering (Singhal et al.,\n2022; Li\u00e9vin et al., 2022; Nori et al., 2023). How-\never, since there is no intrinsic mechanism for auto-\nregressive LLMs to \u201cconsult\u201d with any source oftruth, they can generate plausible-sounding but in-\ncorrect content (Ji et al., 2023). To tackle the hallu-\ncination issue, various studies have been proposed\nto augment LLMs (Mialon et al., 2023) by either\nconditioning them on retrieved relevant content\n(Guu et al., 2020; Lewis et al., 2020; Borgeaud\net al., 2022) or allowing them to use other external\ntools such as program APIs (Gao et al., 2022; Parisi\net al., 2022; Schick et al., 2023; Qin et al., 2023).\nIn this work, we propose to teach LLMs to use\nthe Web APIs of the National Center for Biotech-\nnology Information (NCBI). NCBI provides API\naccess to its entire biomedical databases and tools,\nincluding Entrez Programming Utilities (E-utils)\nand Basic Local Alignment Search Tool (BLAST)\nURL API (Altschul et al., 1990; Schuler et al.,\n1996; Sayers et al., 2019). Enabling LLMs to use\nNCBI Web APIs can provide easier and more pre-\ncise access to biomedical information, especially\nfor users who are inexperienced with the database\nsystems. More importantly, Web APIs can relieve\nusers from locally implementing functionalities,\nmaintaining large databases, and heavy computa-\ntion burdens because the only requirement for using\nWeb APIs is an internet connection.\nWe introduce GeneGPT, a novel method that\nprompts Codex (Chen et al., 2021) to use NCBI\nWeb APIs by in-context learning (Brown et al.,\n2020). GeneGPT consists of two main modules:\n(a) a speci\ufb01cally designed prompt that consists of\ndocumentations and demonstrations of API usage,\nand (b) an inference algorithm that integrates API\ncalls in the Codex decoding process. We evaluate\nGeneGPT on GeneTuring (Hou and Ji, 2023), a\nquestion answering (QA) benchmark for genomics,\nand compare GeneGPT to a variety of other LLMs\nsuch as the new Bing1, ChatGPT2, and BioGPT\n(Luo et al., 2022). GeneGPT achieves the best\nperformance on eight GeneTuring tasks with an\n1https://www.bing.com/new\n2https://chat.openai.com/arXiv:2304.09667v3  [cs.CL]  16 May 2023GeneGPTpromptGeneGPTOutputHello.YourtaskistouseNCBIAPIstoanswergenomicquestions.TherearetwotypesofWebAPIsyoucanuse:EutilsandBLAST.#Documentation1YoucancallEutilsby:\"[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/{esearch|efetch|esummary}.fcgi?db={gene|snp|omim}&retmax={}&{term|id}={}]\".{API_DOC}#Documentation2ForDNAsequences,youcanuseBLASTby:\"[https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD={Put|Get}&PROGRAM=blastn&MEGABLAST=on&DATABASE=nt&FORMAT_TYPE={XML|Text}&QUERY={sequence}&HITLIST_SIZE={max_hit_size}]\".{API_DOC}#Demonstration1Question:WhatistheofficialgenesymbolofLMP10?[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=gene&retmax=3&retmode=json&term=LMP10]->[{API_CALL}][https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&retmax=3&retmode=json&id={ids}]->[{API_CALL}]Answer:PSMB10#Demonstration2Question:WhichgeneisSNPrs1217074595associatedwith?[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=snp&retmax=3&retmode=json&id=1217074595]->[{API_CALL}]Answer:LINC01270#Demonstration3Question:WhataregenesrelatedtoMeesmanncornealdystrophy?[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=omim&retmax=15&term=Meesmann+corneal+dystrophy]->[{API_CALL}][https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=omim&retmax=15&retmode=json&id={ids}]->[{API_CALL}]Answer:KRT12,KRT3#Demonstration4Question:AligntheDNAsequencetothehumangenome:ATTCT[...]TCTCT[https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Put&PROGRAM=blastn&MEGABLAST=on&DATABASE=nt&FORMAT_TYPE=XML&QUERY=ATTCT[...]TCTCT&HITLIST_SIZE=5]->[{API_CALL}][https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Get&FORMAT_TYPE=Text&RID={RID}]->[{API_CALL}]Answer:chr15:91950805-91950932GeneGPTOutputGeneHopQuestionGeneTuring QuestionWhichchromosomedoesSNPrs1430464868locateonhumangenome?[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=snp&retmax=3&retmode=json&id=1430464868]->[{\"header\u201d:{\"type\":\"esummary\",\"version\":\"0.3\"},\"result\":{\"uids\":[\"1430464868\"],\"1430464868\":{\"uid\":\"1430464868\",\"snp_id\":1430464868,\"allele_origin\":\"\",\"global_mafs\":[{\"study\":\"GnomAD\",\"freq\":\"C=0.000007/1\"},{\"study\":\"ALFA\",\"freq\":\"C=0./0\"}],\"global_population\":\"\",\"global_samplesize\":\"\",\"suspected\":\"\",\"clinical_significance\":\"\",\"genes\":[],\"acc\":\"NC_000013.11\",\"chr\":\"13\",\"handle\":[*TRUNCATED*]merged_sort\":\"0\"}}}]Answer:chr13\n\u2705WhatisthefunctionofthegeneassociatedwithSNPrs1241371358?Let'sdecomposethequestiontosub-questionsandsolvethemstepbystep.Sub-question1:WhichgeneisSNPrs1241371358associatedwith?[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=snp&retmax=10&retmode=json&id=1241371358]->[{\"header\":{\"type\":\"esummary\",\"version\":\"0.3\"}},\"result\":{\"uids\":[\"1241371358\"][*TRUNCATED*]\"merged_sort\":\"0\"}}]Answer:LRRC23Sub-question2:WhatisthefunctionofLRRC23?[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=gene&retmax=10&retmode=json&id=10233]->[{\"header\":{\"type\":\"esummary\u201d[*TRUNCATED*]\"merged_sort\":\"0\"}}]Answer:Predictedtobeactiveincytosol.\n\u2705Figure 1: Left: GeneGPT uses NCBI Web API documentations and demonstrations in the prompt for in-context\nlearning. Right: Examples of GeneGPT answering GeneTuring and GeneHop questions with NCBI Web APIs.\naverage score of 0.83, which is remarkably higher\nthan the previous SOTA (0.44 by New Bing). In\naddition, we systematically characterize GeneGPT\nand \ufb01nd that: (1) API demonstrations are more\nuseful than documentations for in-context learn-\ning; (2) GeneGPT generalizes to longer chains of\nsubquestion decomposition and API calls with sim-\nple demonstrations; (3) GeneGPT makes speci\ufb01c\nerrors that are enriched for each task.\nIn summary, our contributions are three-fold:\n1.We introduce GeneGPT, a novel method that\nuses NCBI Web APIs to answer biomedical\nquestions. To the best of our knowledge, this\nis the \ufb01rst study on augmenting LLMs with\ndomain-speci\ufb01c Web API tools.\n2.GeneGPT achieves SOTA performance on 8\ntasks in the GeneTuring benchmark, largely\noutperforming previous best results\n[https://eutils.ncbi.nlm.nih.gov/\nentrez/eutils/esearch.fcgi?db=gene&\nretmax=5&retmode=json&sort=relevance&\nterm=AC093802.1 ]\nFigure 14: An example of Error type 4 (E4). The model\nmakes the right API call but there is no entry returned\nfrom the API. The gene AC093802.1 is not indexed by\nthe NCBI gene database.\nOther errors (O): Errors that cannot be classi-\n\ufb01ed into E1-4 are included in", " introduction of our iterative optimization algorithm based\non the fixed prompt, where we present the experiments. \u201cFixed\u201d\nrepresents the output discussion on the setting\nof the number of good and bad responses in Section I of\nsupplementary materials. In the process of each iteration, good\nresponse or bad response will be updated, which enables our\nprompt to optimize ChatGPT\u2019s responses in time.\nTo summarize, our approach involves utilizing a dynamic\nprompt to establish a contextual understanding that is highly\nrelevant to the semantics of the given test case. This context\nis then fed into ChatGPT to obtain an initial response, which\nis further evaluated and incorporated into an iterative prompt.\nThe iterative prompt is used to elicit subsequent responses that\nare specific to the task domain, thereby enabling self-iterative\nupdates of ChatGPT\u2019s generated result with limited examples.\nOur experimental Methods for semantic text similarity analysis,\u201d in 2020 International\nConference on INnovations in Intelligent SysTems and Applications\n(INISTA) . IEEE, 2020, pp. 1\u20136.\n[43] J. Irvin, P. Rajpurkar, M. Ko, Y . Yu, S. Ciurea-Ilcus, C. Chute, H. Mark-\nlund, B. Haghgoo, R. Ball, K. Shpanskaya et al. , \u201cChexpert: A large\nchest radiograph dataset with uncertainty labels and expert comparison,\u201d\ninProceedings of the AAAI conference on artificial intelligence , vol. 33,\n2019, pp. 590\u2013597.\n[44] T. Zhang, V . Kishore, F. Wu, K. Q. Weinberger, and Y . Artzi, \u201cBertscore:\nEvaluating text generation with bert,\u201d in International Conference on\nLearning Representations , 2019.\n[45] Z. Liu, Y . Li, P. Shu, A. Zhong, L. Yang, C. Ju, Z. Wu, C. Ma, J. Luo,\nC. Chen et al. , \u201cRadiology-llama2: Best-in-class large language model\nfor radiology,\u201d arXiv preprint arXiv:2309.06419 , 2023.\nChong Ma received his master degree of computer science from Northwestern\nPolytechnical University (Xi\u2019an) in 2019. He is currently pursuing his Ph.D\nat school of automation of Northwestern Polytechnical University. His main\nresearch interests are deep learning, medical image analysis and natural\nlanguage processing.\nZihao Wu received his B.E. degree from the School of Microelectronics,\nTianjin University, Tianjin, China, in 2017 and Master degree in Electri-\ncal Engineering and Computer Science Department, Vanderbilt University,\nNashville, USA, in 2020. Currently he is pursuing a PhD in computer science\nat University of Georgia under the supervision of Dr. Tianming Liu. His\ncurrent research interests include brain inspired AI and deep learning-based\nmedical image analysis.\nJiaqi Wang received her master degree of Statistics from Henu University\n(Kai\u2019feng) in 2020. She is currently pursuing her Ph.D. at School of Computer\nScience of Northwestern Polytechnical University. Her main research interests\nare deep learning, EEG signal analysis and human-computer interaction.\nShaochen Xu received his B.S. degree in Computer Science from the\nUniversity of Georgia in 2019. He is currently pursuing his PhD degree at\nthe University of Georgia under the supervision of Dr. Tianming Liu with\na research interest in deep learning, natural language processing, and vision\ntransformers.\nYaonai Wei received his master degree of Control science and engineering\nfrom Northwestern Polytechnical University (Xi\u2019an) in 2021. He is currently\npursuing his Ph.D at school of automation of Northwestern Polytechnical\nUniversity. His main research interests are deep learning, brain science and\nartificial general intelligence.\nZhengliang Liu received his B.A. and M.S. degrees in computer science\nfrom the University of Wisconsin-Madison and Washington University in St.\nLouis, in 2018 and 2021, respectively. He is a PhD student in the School of\nComputing, University of Georgia, Athens, GA.", " INTRODUCTION\nUnderstanding how cells work is an essential problem in biology,\nand it is also very important in biomedical areas because of disease\nphenotype and precision medicine. From a genome-scale view, the\nwhole cell system is modeled by level, starting from DNA, mRNA,\nand protein to metabolomics, and finally, inferring the phenotype.\nWe define these molecules and molecule sets as biological factors.\nAt each level, the same type of biological factors interact or regulate\neach other, which determines cell fate, driving the cells to develop,\ndifferentiate, and do other activities [1].\nThanks to single-cell sequencing technologies, we can obtain\ngene expression data from the mRNA level, which is fundamental\nto analyzing the whole cell system. Currently, gene expression\ndata is widely used to identify cell states during cell development,\ncharacterize specific tissues or organs, and analyze patient-specific\ndrug responses [31].\nMany deep learning RELATED WORK\nGene expression and its applications: By RNA sequencing, it\nis easy to obtain gene expression which is a value to represent the\namount of gene transcripts from a DNA fragment [ 10]. It has been\nused in a variety of biological applications, including single-cell\nanalysis [ 46,49], disease diagnosis [ 41] and drug discovery [ 32].\nBut most of these models lack transparency and ignore the existing\nbiological knowledge.\nKnowledge graph enhanced downstream tasks: The emergence\nof knowledge bases/graphs has led to enhancing the performance in\nmany fields of computer science, such as computer vision and nat-\nural language processing [ 22,26,34]. Similarly, knowledge graphs\nalso have been widely used for specific biological tasks such as\ncancer diagnosis in recent years [ 11,35]. Some BACKGROUND\nThe biological system is modeled by a complex network that con-\nnects many biologically relevant entities to work together to per-\nform one or more particular functions. It could be at the organ/tissue\nscale, such as the nervous system, or the integumentary system. On\nthe micro/nanoscopic scale, examples include cells, organelles, and\nso on. In this work, we focus on the simulation of the biological\nsystem in a cell at a genome-scale.Biological Factor Regulatory Neural Network Conference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nFigure 1: The pipeline of BFReg-NN. We build the hierarchical biological network inspired by the cell system, modeling several\nlevels to separate mRNA, protein, pathway and phenotype, and simulating biological factor interactions both at the intra-level\nand inter-level. We obtain the gene expression value from RNA sequencing as input, to predict the property of the phenotype\nas output. Taking the cancer dataset NCI-60 as an example. We know that the regulatory activations start from gene HIF1A and\nTP53 to gene AURKA and CDKN1A at the gene level [16]. And at the protein level, the translated proteins Q16665 and P04637\nstimulate P17858 and O14965 respectively [38]. We mark those relations as existing biological knowledge by the black solid\nlines. Multiple genes with their products consist of pathways to drive cells to different types. For example, PFKL and HIF1A\nare activated in the HEPG2 cell line pathway, which leads to a type of liver cancer [36]. Besides, new regulatory relations\nwould be identified at each level shown as dotted lines. After training, we learn the good representations of biological factors,\nand employ them for different downstream tasks with various output formats.\nThanks to the development of sequencing technologies, it is\neasy and cheap to obtain an amount", " Introduction\nThe advent of large language models (LLM) has completely transformed natural language processing\n(NLP) [ 1]. The traditional paradigm of NLP follows the typical pipeline of creating customized\nsolutions for downstream applications through supervised training. For example, a pre-trained BERT\n[2] model must be modi\ufb01ed with additional network layers and then \ufb01ne-tuned on labeled training\ndata to perform tasks such as sequence classi\ufb01cation or question answering. In some situations, it\nmight also be bene\ufb01cial or necessary to further pre-train such models on domain speci\ufb01c data to\n\u2217*co-corresponding author: shen.jiajian@mayo.edu\n\u2020*co-corresponding author: liu.wei@mayo.edu\n1arXiv:2304.01938v1  [physics.med-ph]  1 Apr 2023LLMs - radiation oncology physics\nattain acceptable performance [ 3,4]. For example, AgriBERT [ 5] was pre-trained on agriculture-\nrelated text data, to properly address NLP tasks in the food and agriculture domain. However, the\nexpansive size and exceptional few-shot learning capabilities enable LLMs to solve NLP problems\nthrough in-context learning , which reduces or even eliminates the need for annotated training samples\n[6,7]. During in-context learning, LLMs generalize from a few examples (or no examples at all)\nbased on prompts, which typically are descriptive user inputs that characterize desired responses\nfrom LLMs [ 6,8]. For example, \"summarize the following text\" is a straightforward prompt that\nasks the language model to produce a summary for the input text. In general, LLMs provides a\nnovel and simpli\ufb01ed work\ufb02ow for NLP that could potentially do away with supervised \ufb01ne-tuning\nand its associated intricacies such as hyper-parameter tuning and model architecture modi\ufb01cation.\nFurthermore, in-context learning signi\ufb01cantly reduces the need for expensive and time-consuming\nhuman annotation [6, 9]. It is especially desirable in medicine and science due to the limited data\navailable in these domains [10, 11, 4, 12].\nIn recent months, the world has witnessed the rise of of ChatGPT1, which has enjoyed signi\ufb01cant\nglobal popularity given its unprecedented language capabilities and accessibility to the general public\nthrough a chatbot interface. ChatGPT is based on the powerful GPT-3 model [ 6], one of the \ufb01rst\nlarge language models in history. The 175-billion-parameters GPT-3 was trained on a large data\ncollection that encapsulated diverse Internet data (including the Common Crawl2and Wikipedia3).\nIt demonstrates exceptional performance in a variety of NLP tasks spanning from text summarization\nto named entity recognition (NER) through its text generation objective (indeed, many NLP tasks\ncan be translated to some forms of text generation). ChatGPT inherits these capabilities from\nGPT-3, along with the massive knowledge on diverse topics stored in the parameter space. More\nimportantly, ChatGPT was trained through Reinforcement Learning from Human Feedback (RLHF),\na reinforcement learning process that incorporates human preferences and human ranked values\nthrough user feedback. This process tunes the model to generate outputs that are most appealing\nand relevant to human users. The capabilities of ChatGPT empowers diverse practical applications\nranging from essay writing to code generation [13].\nOne of the most powerful LLM to date is GPT-44, a successor to GPT-3. While OpenAI has not\nrevealed much about its technical details yet, GPT-4 has demonstrated superior performance over\nthe GPT-3.5-based ChatGPT in various scenarios [ 14,9,12,15]. In fact, as of March 2023, GPT-4\nis powering Microsoft\u2019s search engine, Bing [ 16], which demonstrates the potential of LLM-based\nsearch. In addition, unlike its predecessors, GPT-4 is a multi-modal model that accepts image inputs,\nwhich undoubtedly leads to more interesting", " introduction to computing with neural nets. IEEE Assp\nmagazine. 1987;4(2):4-22.\n[85] Rumelhart DE, Hinton GE, Williams RJ. Learning representations by\nback-propagating errors. nature. 1986;323(6088):533-6.\n[86] Cortes C, Vapnik V. Support-vector networks. Machine learning.\n1995;20:273-97.\n[87] Quinlan JR. Induction of decision trees. Machine learning. 1986;1:81-106.\n[88] Opitz D, Maclin R. Popular ensemble Discussion\n5.1 Limitations\nWhile signi\fcant progress has been made in the development of AGI and brain-\ninspired AI, there are still several limitations that need to be overcome before we\ncan achieve true human-level intelligence in machines. Some of these limitations\ninclude:\nLimited understanding of the human brain : Despite signi\fcant ad-\nvancements in neuroscience and brain-inspired AI, we still have a limited un-\nderstanding of how the human brain works. This makes it challenging to create\n15machines that can fully replicate human intelligence.\nData e\u000eciency: Current AGI and brain-inspired AI systems require vast\namounts of training data to achieve comparable performance to humans. This is\nin contrast to humans, who can learn from relatively few examples and generalize\nto new situations with ease. How to e\u000eciently learn from few samples is still\nan opening question.\nEthics : There are also ethical considerations to consider with AGI. As\nthese systems become more intelligent, they may be able to make decisions that\nhave far-reaching consequences. Ensuring that these decisions are aligned with\nhuman values and ethical principles is critical for preventing unintended harm.\nSafety : Safety is also a signi\fcant concern with AGI. Ensuring that these\nsystems do not cause unintended harm, either through malicious intent or unin-\ntentional mistakes, is critical for their widespread adoption. Developing robust\nsafety mechanisms and ensuring that AGI systems are aligned with human val-\nues is essential.\nComputational Cost : Current LLM models requires massive computa-\ntional resources to train and operate, making it challenging to develop and\ndeploy in a wide range of scenarios. Meanwhile, the computational cost can\nlimit the number of researchers and organizations working in the \feld, which\nmay slow the progress towards AGI. Additionally, the energy consumption of\nAGI systems can be prohibitively high, making them unsustainable from an\nenvironmental perspective.\n5.2 Future of AGI\nThe future of AGI is an exciting and rapidly evolving \feld. While the devel-\nopment of AGI remains a challenge, it has the potential to revolutionize many\naspects of our lives, from healthcare to transportation to education. One po-\ntential avenue for advancing AGI is through the creation of more powerful and\nsophisticated AGI foundation models. Recent breakthroughs in natural lan-\nguage processing, computer vision, knowledge graph, and reinforcement learn-\ning have led to the development of increasingly advanced AGI models such as\nChatGPT and GPT-4. These models have shown impressive capabilities in var-\nious applications. Further advances in AGI foundation model research, as well\nas improvements in hardware and computational algorithms, are very likely to\naccelerate the development of AGI.\nAnother approach to developing AGI is through the integration of di\u000berent\nAI systems and technologies across multiple domains, including adding human\nin the loop through reinforcement learning from expert feedback. For example,\ncombining natural language processing with computer vision and robotics under\nthe guidance of human experts could lead to the creation of more versatile and\nadaptable intelligent systems. This integration could also help overcome the\nlimitations of current AI systems, which are often specialized in speci\fc domains\nand lack the \rexibility to transfer knowledge across domains.\nThe development of AGI also", " Introduction\nLarge language models, also known as LLMs, have become an increasingly prevalent part of our\nday-to-day lives, with their use extending to a wide range of domains including web browsing, voice\nassistants, and coding assistance tools.[ 1,2,3,4] These models have the potential to signi\ufb01cantly\nimpact society in numerous ways.[ 5,6,7] This system card analyzes GPT-4, the latest large language\nmodel in the GPT family of models.[ 8,9,10] Since it \ufb01nished training in August of 2022, we have\nbeen evaluating, adversarially testing, and iteratively improving the model and the system-level\nmitigations around it. Our mitigations and processes alter GPT-4\u2019s behavior and prevent certain\nkinds of misuses, though they have limitations, pointing to the need for anticipatory planning and\ngovernance[ 11] and further safety research. Our approach to deployment balances minimizing risk\nfrom deployment, enabling positive use cases, and learning from deployment.\nGPT models are often trained in two stages. First, they are trained, using a large dataset of text\nfrom the Internet, to predict the next word. The models are then \ufb01ne-tuned with additional data,\nusing an algorithm called reinforcement learning from human feedback (RLHF), to produce outputs\nthat are preferred by human labelers.[ 10,12,13] Training language models on large text datasets\nhas given rise to capabilities such as few-shot learning[ 10] and the ability to carry out a wide range\nof natural language tasks spanning di\ufb00erent domains, including question answering, arithmetic, and\nclassi\ufb01cation. Fine-tuning has made these models more controllable and useful.\n1.1 Overview of \ufb01ndings and mitigations\nIn this system card,1we outline the safety challenges that arise from GPT-4, and explain the\ninterventions we implemented to mitigate potential harms from its deployment. We focus on safety\nchallenges not because they necessarily outweigh the potential bene\ufb01ts,2but because we wish to\nmotivate further work in safety measurement, mitigation, and assurance. The scope of this system\ncard is narrower than the potential scope of abilities GPT-4 can be used to unlock; notably, both\ncustom \ufb01ne-tuning and image capabilities are explicitly out of scope.\nWe focus on analyzing two versions of the model: an early version \ufb01ne-tuned for instruction\nfollowing (\u201cGPT-4-early\u201d); and a version \ufb01ne-tuned for increased helpfulness and harmlessness[ 18]\nthat re\ufb02ects the further mitigations outlined in this system card (\u201cGPT-4-launch\u201d).3When we\ndiscuss the risks of GPT-4 we will often refer to the behavior of GPT-4-early, because it re\ufb02ects the\nrisks of GPT-4 when minimal safety mitigations are applied. In most cases, GPT-4-launch exhibits\nmuch safer behavior due to the safety mitigations we applied.\nKnown risks associated with smaller language models are also present with GPT-4. GPT-4\ncan generate potentially harmful content, such as advice on planning attacks or hate speech. It\ncan represent various societal biases and worldviews that may not be representative of the users\nintent,4or of widely shared values. It can also generate code that is compromised or vulnerable.\nThe additional capabilities of GPT-4 also lead to new risk surfaces.\nTo understand the extent of these risks, we engaged more than 50 experts to help us gain a more\nrobust understanding of the GPT-4 model and potential deployment risks. We selected these areas\n1This document takes inspiration from the concepts of model cards and system cards.[ 14,15,16] This document\noften takes the system level of analysis, with that system including non-model mitigations such as use policies, access\ncontrols, and", " Introduction\nProteins serve as the mainstay governing diverse biological\nprocesses and life itself, inducing important applications in\ndrug discovery (Teague, 2003) and healthcare (Organization\n& University, 2007). Recent studies have proven the great\npromise of machine learning methods. We leave this as our future work.\nD. More Zero-shot Text-to-Protein Retrieval experiments, the non-\nparametric classi\ufb01er based on ESM-1b and the one based\non ProtST-ESM-1b serve as two baselines for zero-shot\nclassi\ufb01ers.\nC. Experimental results\ndemonstrate the general effectiveness of ProtST-ESM-1b on\nretrieving the binders of diverse ligands. In the future work,\nwe will study how ProtST enables zero-shot text-to-protein\nretrieval of other types of functional proteins, e.g., antigen\nbinders, toxic substance binders, transcription factors, etc.\nE. More Ablation Study\nE.1. Ablation Study of Pre-training Losses\nIn Tabs. 14 and 15, we report the performance of ProtST-\nESM-1b on all benchmark tasks by using full or partial\npre-training losses. It can be observed that: (1) removing\nthe lossLMPM leads to performance decay on 16 out of\n24 benchmark metrics; (2) removing the loss LGCleads to\ndecay on 20 out of 24 benchmark metrics; (3) removing the\nlossLMMP diminishes model performance on 19 out of 24\nbenchmark metrics. Therefore, all pre-training losses are\nnecessary to maximize the effectiveness of a ProtST-induced\nPLM, whereLGCandLMMP inject different granularities\nof protein property information into a PLM, and LMPM\npreserves the PLM\u2019s original representation power.\nAR\nNDC\nEQ\nGH\nIL\nKMF\nPSTW\nY\nV\nHydrophobic (aromatic)\nHydrophobic (aliphatic)\nPositive\nNegative\nPolar neutralSpecial cases\nSmall (<130 Dalton)\nMedium\nBig (>150 Dalton)Figure 6: Amino acid representations learned by the linear layer\nfor unimodal mask prediction (ProtST-ESM-1b is used).\nA\nRN\nD\nCE\nQG\nHI\nLK\nM\nFP\nS\nT\nW\nYV\nHydrophobic (aromatic)\nHydrophobic (aliphatic)\nPositive\nNegative\nPolar neutralSpecial cases\nSmall (<130 Dalton)\nMedium\nBig (>150 Dalton)\nFigure 7: Amino acid representations learned by the linear layer\nfor multimodal mask prediction (ProtST-ESM-1b is used).\nE.2. Ablation Study of Biomedical Language Model\nPubMedBERT owns two versions: (1) the PubMedBERT-\nabs trained by using only PubMed abstracts, and (2) the\nPubMedBERT-full trained by using additional PubMed Cen-\ntral full-text articles. In this experiment, we compare the\neffectiveness of these two models by respectively using\nthem as the BLM of ProtST-ESM-1b.\nTabs. 16 and 17 report the performance comparison of these\ntwo models on all benchmark tasks. We can observe that:\n(1) PubMedBERT-full outperforms PubMedBERT-abs on\nall four benchmark metrics of localization prediction; (2)\nPubMedBERT-abs performs better than PubMedBERT-full\non 10 out of 12 benchmark metrics of \ufb01tness prediction;\n(3) PubMedBERT-abs outperforms PubMedBERT-full on 5\nout of 8 benchmark metrics of function annotation. There-\nfore, PubMedBERT-full does not show superiority over\nPubMedBERT-abs in ProtST pre-training, which owes to\nthe fact that the protein property descriptions in the ProtDe-\n17ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts\nMembrane-bound Soluble\nFigure 8: Visualization of protein representations on the binary\nlocalization prediction dataset (ProtST-ESM-1b is used).\nCell membrane\nCytoplasm\nEndoplasmic reticulum (ER)\nGolgi apparatus\nLysosome/VacuoleMitochondrion\nNucleus\nPeroxisome\nPlastid\nExtracellular\nFigure 9: Visualization of protein representations on the subcellu-\nlar localization prediction dataset (ProtST-ESM-1b is used).\nscribe dataset are more like abstracts than full-text articles.\nF. More Visualization\nWell-trained PLMs should have the capacity to extract struc-\ntural, functional, and even evolutionary features of proteins.\nAs a result, the learned representations in PLMs are ex-\npected to have certain intrinsic organization patterns in the\nembedding space to capture these protein characteristics. To\ndemonstrate the effectiveness of ProtST-ESM-1b, we use\nt-SNE (Van der Maaten & Hinton, 2008) to visualize such\ninformation at different scales from amino acid decomposi-\ntions to protein functional properties.\nBiophysical Properties of Amino Acids: It is known that\nthe biophysical properties of amino acids, such as hydropho-\nbicity, aromaticity and charge, highly in\ufb02uence the bio-\nlogical structures of proteins and", " Introduction\nWriting is critical in science learning because it is the medium for students to\nexpress their thought processes. In classroom settings, educators have engaged\nstudents in writing explanations of phenomena, design solutions, arguments, etc.\n[10][15], with which students develop scienti\fc knowledge and competence. How-\never, it is time-consuming for teachers to review and evaluate natural languagearXiv:2301.12031v1  [cs.AI]  27 Jan 20232 Zhengliang Liu, Xinyu He , Lei Liu, Tianming Liu, and Xiaoming Zhai\nwriting, thus preventing the timely understanding of students' thought processes\nand academic progress. Recent development in machine learning (ML), especially\nnatural language processing (NLP), has proved to be a promising approach to\npromoting the use of writing in science teaching and learning [17]. For example,\nvarious NLP methods in scoring student responses to science assessment\ntasks [1].\nFig. 1. The SciEdBERT framework. A student response instance is classi\fed based on\nthe latent representation of word vectors.\nStudies have shown that the performance on NLP tasks can be improved by\nusing domain-speci\fc data to contextualize language models [5]. Several BERT-\nbased language models, such as SciBERT [3], AgriBERT [12], BioBERT [8],\nand ClinicalRadioBERT [11], have demonstrated signi\fcant success on domain-Title Suppressed Due to Excessive Length 3\nspeci\fc tasks. Therefore, it is reasonable to speculate that ML-based scoring of\nstudents' scienti\fc writing can be improved if we have a domain-speci\fc lan-\nguage model for scienti\fc education. In this case, we need to \fnd the proper\ndomain-speci\fc data that are directly relevant to student writing. It is impor-\ntant to note that student responses are preliminary expressions of general science\nknowledge and lack the rigor of academic journal publications. In addition, their\nwriting is also in\ruenced by the developmental progress of writing skills and the\nlength of the required tasks. These characteristics of student writing are chal-\nlenges for using NLP tools to score students' writing [9] [6]. Therefore, to further\nimprove the application of large pre-trained language models to automatically\nscore students' scienti\fc writing, we use di\u000berent datasets to train BERT and\ncompare their performance on various downstream tasks. In this work, we make\nthe following contributions:\n1. We provide a method to improve model performance on the downstream\ntasks by contextualizing BERT with the downstream context in advance.\n2. We prove the e\u000bectiveness of domain-speci\fc data in improving BERT-\nbased model performance.\n3. We will release our language models, which can be further tested and used\nin other science education tasks.\n2 Methodology\n2.1 Architecture/ Background\nThe BERT (Bidirectional Encoder Representations from Transformers) language\nmodel [4] is based on the transformer architecture [13]. It is trained using the\nmasked language modeling (MLM) objective, which requires the model to predict\nmissing words in a sentence given the context. This training process is called pre-\ntraining. The pre-training of BERT is unsupervised and only requires unlabeled\ntext data. During pre-training, word embedding vectors are multiplied with three\nsets of weights (query, key and value) to obtain three matrices Q,K, and V,\nrespectively. These matrices are then used to calculate attention scores, which\nare weights that measure the importance among input words. For example, in the\nexample \"I love my cats.\", the word \"I\" should (ideally) be strongly associated\nwith the word \"my\", since they refer to the same subject.\nFig. 2. An example of BERT's attention mechanism4 Zhengliang Liu, Xinyu He , Lei Liu, Tianming Liu, and Xiaoming Zhai\nFor", " Introduction\nPretrained language models have become a cornerstone of modern natural language pro-\ncessing (NLP) pipelines because they often produce better performance from smaller quan-\ntities of labeled data. The development of ELMo (Peters et al., 2018), ULMFiT (Howard\nand Ruder, 2018), GPT (Radford et al., 2018), and BERT (Devlin et al., 2019) led to the\nwidespread use of pretrained models as an initialization for finetuning on downstream tasks.\nThe subsequent finding that pretrained language models can perform useful tasks without\nany additional training (Radford et al., 2019; Brown et al., 2020) further demonstrated their\nutility. In addition, the empirical observation that a language model's performance tends to\nincrease as the model is made larger\u0016sometimes predictably (Hestness et al., 2017; Kaplan\n1.hf.co/bigscience/bloom\n3BigScience Workshop\net al., 2020; Hoffmann et al., 2022) and sometimes suddenly (Wei et al., 2022)\u0016has led to a\ntrend of increasing scale (Zeng et al., 2021; Rae et al., 2021; Smith et al., 2022; Chowdhery\net al., 2022). Apart from environmental concerns (Strubell et al., 2019; Lacoste et al., 2019;\nSchwartz et al., 2020), the costs of training large language models (LLMs) are only afford-\nable for well-resourced organizations. Furthermore, until recently, most LLMs were not\npublicly released. As a result, the majority of the research community has been excluded\nfrom the development of LLMs. This exclusion has had concrete consequences; for exam-\nple, most LLMs are primarily trained on English-language text (with notable exceptions in\nChinese and Korean, e.g. Wang et al., 2021; Zeng et al., 2021; Kim et al., 2021).\nTo address these issues, we present the BigScience Large Open-science Open-access Mul-\ntilingual Language Model (BLOOM, BigScience Workshop, 2022). BLOOM is a 176 billion\nparameter language model trained on 46 natural languages and 13 programming languages\nthat was developed and released by a collaboration of hundreds of researchers. The com-\npute for training BLOOM was provided through a French public grant from GENCI and\nIDRIS, leveraging IDRIS' Jean Zay supercomputer. To build BLOOM, we undertook a\nthorough design process for each of its components, including the training dataset (Sec-\ntion 3.1), model architecture and training objective (Section 3.2), and engineering strategy\nfor distributed learning (Section 3.4). We also performed an analysis of the model's capa-\nbilities (Section 4). Our overall aim is not only to publicly release a large-scale multilingual\nlanguage model with performance comparable to recently developed systems, but also to\ndocument the coordinated process that went into its development (Section 2.2). The pur-\npose of this paper is to provide a high-level overview of these design steps while referencing\nthe individual reports we produced over the course of developing BLOOM.\n2. Background\nBefore describing the BLOOM model itself, in this section we provide necessary background not only in machine learning and\ncomputer science, but also linguistics, statistics, socio-cultural anthropology, philosophy,\nlaw, and other fields. Of those, hundreds of individuals have directly contributed to one\nof the project's released artifacts. While the largest number of participants ultimately\noriginated from the US, 38 countries were represented.\nOrganization The set of related research questions tackled by the BigScience effort was\nreflected in the project's organization into working groups. Each working group comprised\nseveral participants with various levels of involvement, including chairs whose role was\nto self-organize around a specific aspect of the overall project. Importantly, participants\nwere encouraged to join more than", " Introduction\nText mining and knowledge discovery from biomedical\nliterature play important roles in drug discovery, clinical\ntherapy, pathology research, etc. Typical tasks include\nrecognizing named entities in the articles, mining the\ninteraction between drugs and proteins/diseases/other drugs,\nanswering questions given reference text, generating abstracts\nfor given phrases/words, etc. People have accumulated large\namounts of literature in the previous studies. For example,\nPubMed1, one of the most popular biomedical search engines,\ncovers more than 30 Marticles and the number still rapidly\nincreases every day as new discoveries are continuously coming\nout. Therefore, automatically mining the knowledge from\nliterature becomes an urgent demand.\nPre-training models have demonstrated their powerful\ncapability in natural language processing (NLP). On the GLUE\nbenchmark, a widely used benchmark for natural language\nunderstanding, pre-training based methods in natural language processing. arXiv preprintarXiv:2107.13586 , 2021.\n49. Xiang Lisa Li and Percy Liang. Pre\fx-tuning: Optimizing\ncontinuous prompts for generation. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers) , pages 4582{4597, Online,\nAugust 2021. Association for Computational Linguistics.\n50. Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan,\nSam Gross, Nathan Ng, David Grangier, and Michael Auli.\nfairseq: A fast, extensible toolkit for sequence modeling. In\nProceedings of NAACL-HLT 2019: Demonstrations , 2019.\n51. Diederik P Kingma and Jimmy Ba. Adam: A method for\nstochastic optimization. In ICLR (Poster) , 2015.\n52. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pierric\nCistac, Tim Rault, R\u0013 emi Louf, Morgan Funtowicz, Joe\nDavison, Sam Shleifer, Patrick von Platen, Clara Ma,\nYacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao,\nSylvain Gugger, Mariama Drame, Quentin Lhoest, and\nAlexander M. Rush. Transformers: State-of-the-art\nnatural language processing. In Proceedings of the 2020\nConference on Empirical abstract, containing\na question, a reference context, a long answer, and a\nyes/no/maybe label which is the answer to the question. We\nuse the original train/validation/test split with 450, 50 and 500\nrespectively, noted as PQA-L in [16] for evaluation. We also use\nthe additional dataset noted as PQA-A and PQA-U in [16] for\n\fne-tuning. We use the continuous embedding with length=9\nas the soft prompt. We format the data into source sequence\nand target sequence as described before. We apply techniques\nsuch as two-stage \fne-tuning [16] and noisy labels to improve\nthe performance. We measure and compare the classi\fcation\naccuracy of the reasoning required setting described in [16].\nFrom the Experiments\nIn this section, we pre-train our BioGPT and evaluate\nit on the following four biomedical NLP tasks across six\ndatasets: end-to-end relation extraction on BC5CDR [13], KD-\nDTI [14] and DDI [15], question answering on PubMedQA [16],\ndocument classi\fcation on HOC [17], and text generation\non self-created dataset. We use fairseq [50] as our code\nbase for implementation. We adopt the GPT-2 medium model\ncon\fguration as our backbone model con\fguration. We perform\nBPE to learn to tokenize the corpus and construct the\nvocabulary instead of using the learned vocabulary from GPT-\n2 due to the domain gap between the biomedical domain and\nthe general domain.\nFor pre-training, we pre-train BioGPT on 8 NVIDIA V100\nGPUs for 200 ksteps, with 1024 tokens per GPU and 64\naccumulated steps (i.e., the \fnal batch size is 1024 \u00028\u000264 =\n524288 tokens). We use Adam [51] as the optimizer with a peak\nlearning rate of 2\u000210\u00004and 20000 warm-up steps. The learning\nrate follows an inverse square root decay schedule after reaching\nthe", " Introduction to the bio -entity recognit ion task at JNLPBA . in Proceedings of the \ninternational joint workshop on natural language processing in biomedicine and its applications . 2004. Citeseer.  \n27. Bada M, Eckert M, Evans D, et al., Concept annotation in the CRAFT corpus.  BMC bioinformatics, 20 12. 13(1): p. 1 -20. \n28. Wei C -H, Kao H -Y, and Lu Z, GNormPlus: an integrative approach for tagging genes, gene families, and protein \ndomains.  BioMed research international, 2015. 2015 . \n29. Wei C -H, Allot A, Leaman R, et al., PubTator central: automated con cept annotation for biomedical full text articles.  \nNucleic acids research, 2019. 47(W1): p. W587 -W593.  BioRED: A Rich  Biomedical Re lation Extraction Dataset  \n30. Wei C -H, Lee K, Leaman R, et al. Biomedical mention disambiguation using a deep learning approach . in Proceedings \nof the 10th ACM International Confe rence on Bioinformatics, Computational Biology and Health Informatics . 2019.  \n31. Leaman R and Lu Z, TaggerOne: joint named entity recognition and normalization with semi -Markov Models.  \nBioinformatics, 2016. 32(18): p. 2839 -2846.  \n32. Hendrickx I, Kim S N, Kozareva Z, et al. Semeval -2010 task 8: Multi -way classification of semantic relations between \npairs of nominals . in ACL (Workshop on Semantic Evaluation) . 2019.  \n33. Zhang Y, Zhong V, Chen D, et al. Position -aware attention and superv ised data improve slot filling . in Proceedings of \nthe 2017 Conference on Empirical abstract in a set con-\ntaining both terms in the query corresponding to that set.  \nLLL [9] 167 sen-\ntences  - 377 rela-\ntions  Sentence  The LLL05 challenge task aims to learn rules to extract pro-\ntein/gene interactions in the form of relations from biology ab-\nstracts from the Medline bibliography database.  The challenge \naims to test the ability of ML systems to learn rules for identify-\ning the gene/proteins that interact and their roles, agent or tar-\nget. \nBioCreative II \nPPI IPS [10] 1,098 full -\ntexts  - - Document  The BioCreative II PPI protei n interaction pairs subtask (IPS) \nprovides 750 and 356 full texts for training and test sets, re-\nspectively. The full -text includes corresponding gene mention \nsymbols and PPI pairs.  \nBioCreative \nII.5 IPT [11] 122 full -\ntexts  - - Document  The BioCreative II.5 interaction pair task (IPT) provide  595 \nfull-texts for both training (FEBS Letters articles from 2008) \nand test (FEBS Letters articles from 2007) sets. The full -texts \ninclude both with and without curatable protein interaction s, \nand only 122 full -texts contain PPI annotations.  \nBioCreative \nVI PM [12] 5,509 ab-\nstracts  - 1,232 re-\nlations  Document  BC6PM contains PubMed abstracts (from IntAct/Mint  [13]) an-\nnotated with those interacting PPI pairs affected by mutations. \nThe relation annotation is represented in Entrez Gene ID pair.  \nChemical -protein interaction  \nChemProt  \n[14] 2,482 ab-\nstracts  32,514 \nchemicals,  \n30,912 \ngenes  10,270 \nrelations  Sentence  The ChemProt dataset consists of manually annotated chemi-\ncal compound/drug and gene/protein mentions and 22 different", " Introduction\nRNA plays an important role in performing various types of biological functions, such as cell signaling, gene\nexpression, and post-transcriptional regulations [1\u20133]. Determination of RNA structure or type is also an essential\npart of RNA-based therapeutics, including mRNA vaccines, RNA interference and CRISPR-based therapeutics\n[4\u20136]. Among all RNA transcripts, about 5% served as mRNAs responsible for protein coding, while the sub-\nstantial remaining portion is non-coding RNAs (ncRNAs) [7, 8]. Particularly, these ncRNAs must sustain speci\ufb01c\nstructures to conduct corresponding biological functions. Different ncRNAs, such as small nuclear ribonucleo-\nproteins (snRNPs), ribosomes, microRNAs, small nucleolar ribonucleoproteins (snoRNPs), long ncRNAs, and\ntelomerase, also interact with proteins to form stable RNA-protein complexes to perform speci\ufb01c functions [1, 9].\nAccurately modelling ncRNAs structures could help understand their performed functions and various biolog-\nical processes. Despite a large number of ncRNA sequences, few of their structures and functions are known\n[10, 11]. Traditionally, RNA three-dimensional (3D) structures assessed by experimental approaches, including\nnuclear magnetic resonance, X-ray crystallography and cryogenic electron microscopy, are expensive and time-\nconsuming. Therefore, computational approaches are developed and applied to bridge the gap.\n*Corresponding Author. Email: liyu@cse.cuhk.edu.hk and siqisun@fudan.edu.cn.\n\u2020Equal \ufb01rst authorship.\n1arXiv:2204.00300v5  [q-bio.QM]  8 Aug 2022Regarding the RNA structure prediction, most existing approaches focus on the RNA secondary structure pre-\ndiction, which could further be divided into three categories: thermodynamic Results\nLearning from large-scale unlabeled non-coding RNA sequences. As shown in Figure 1, in order to take\nadvantage of a massive amount of unlabeled ncRNA data and avoid relying on label information, we propose\nour RNA foundation model (RNA-FM) based on the BERT [38] language model architecture. It is built upon\n12 transformer-based bidirectional encoder blocks and trained on 23 million sequences from the RNAcentral\ndatabase in a self-supervised manner. After training, RNA-FM produces a L\u0002640embedding matrix for each\nRNA sequence with length L. These embeddings are expected to contain rich information within the ncRNA\nuniverse. We veri\ufb01ed the effectiveness of RNA-FM on various applications. Firstly, to investigate what has been\nlearned by the model and the physical meaning of the model outputs, we analyze the derived embeddings directly\nand examine how ncRNAs of similar function and structure gather in a 2-dimensional plane, resulting in the RNA\nAtlas in Figure 2. Also, the embedding from RNA-FM can be used to infer the long non-coding RNA (lncRNA)\nevolutionary trend, which suggests that the evolutionary information has been learned by our model implicitly.\nFurthermore, models using RNA-FM embeddings could improve over state-of-the-art approaches consistently on\nvarious structural-related and functional-related downstream prediction problems, including both SARS-CoV-2\nstudy and gene expression regulation modeling.\nRNA-FM learns multi-dimension biological information of RNA universe. To demystify what has been\nlearned by the large-scale RNA-FM model from the million-scale data and the physical meaning of the model\noutputs, we take a closer look into RNA biological information contained in the RNA-FM embedding, including\nits structural/functional properties and evolutionary information. Such analysis shows the interpretability of the\nRNA-FM model.\nRNA functions and structures vary across different RNA types, and RNA-FM is expected to encode these\nrich properties within our generated embeddings from pure RNA sequences. We build RNA Atlas by employing\n3Figure 1: Overview of RNA foundation model (RNA-FM) design and applications . RNA-FM consists of 12\ntransformer layers. In the pre-training stage, the RNA-FM is", " Introduction, his life and Appendix C.2. We \ufb01nd that the inter- and intra-group validation accuracies for predicting the human-\npreferred output are 72.4 \u00060.4%, and 69.6\u00060.9% respectively, suggesting our RMs can generalize\nwell to held-out labelers drawn from the same set as the training labelers.\nE.3 Metadata related work in Section 2, before diving\ninto our method and experiment details in Section 3, including our high-level methodology (3.1), task\nand dataset details (3.3 and 3.2), human data collection (3.4), how we trained our models (3.5), and\nour evaluation procedure (3.6). We then present our discussion of the limitations of our work in Section 5.3.\nThe literature often frames alignment using such terms as \u201chuman preferences\u201d or \u201chuman values.\u201d\nIn this work, we have aligned to a set of labelers\u2019 preferences that were in\ufb02uenced, among others\nthings, by the instructions they were given, the context in which they received them (as a paid job),\nand who they received them from. Some crucial caveats apply:\nFirst, we are aligning to demonstrations and preferences provided by our training labelers, who\ndirectly produce the data that we use to \ufb01ne-tune our models. We describe our labeler hiring process\nand demographics in Related work\nResearch on alignment and learning from human feedback. We build on previous techniques\nto align models with human intentions, particularly reinforcement learning from human feed-\nback (RLHF). Originally developed for training simple robots in simulated environments and Atari\ngames (Christiano et al., 2017; Ibarz et al., 2018), it has recently been applied to \ufb01ne-tuning language\nmodels to summarize text (Ziegler et al., 2019; Stiennon et al., 2020; B\u00f6hm et al., 2019; Wu et al.,\n2021). This work is in turn in\ufb02uenced by similar work using human feedback as a reward in domains\nsuch as dialogue (Jaques et al., 2019; Yi et al., 2019; Hancock et al., 2019), translation (Kreutzer et al.,\n2018; Bahdanau et al., 2016), semantic parsing (Lawrence and Riezler, 2018), story generation (Zhou\nand Xu, 2020), review generation (Cho et al., 2018), and evidence extraction (Perez et al., 2019).\nMadaan et al. (2022) use written human feedback to augment prompts and improve the performance\nof GPT-3. There has also been work on aligning agents in text-based environments using RL with\n4a normative prior (Nahian et al., 2021). Our work can be seen as a direct application of RLHF to\naligning language models on a broad distribution of language tasks.\nThe question of what it means for language models to be aligned has also received attention re-\ncently (Gabriel, 2020). Kenton et al. (2021) catalog behavioral issues in LMs that result from\nmisalignment, including producing harmful content and gaming misspeci\ufb01ed objectives. In concur-\nrent work, Askell et al. (2021) propose language assistants as a testbed for alignment research, study\nsome simple baselines, and their scaling properties.\nTraining language models to follow instructions. Our work is also related to research on cross-\ntask generalization in language models, where LMs are \ufb01ne-tuned on a broad range of public NLP\ndatasets (usually pre\ufb01xed with an appropriate instruction) and evaluated on a different set of NLP\ntasks. There has been a range of work in this domain (Yi et al., 2019; Mishra et al., 2021; Wei\net al., 2021; Khashabi et al., 2020; Sanh et al., 2021; Aribandi et al., 2021),", " Introduction\nThe evolution of deep learning methodologies and continual expansion of computing capacity has\nenabled many advancements in language modeling \ufb01eld. In speci\ufb01c, transformer-based architectures\nhave foreshadowed the creation of BERT and its many variants, surpassing previously held records\nin GLUE, SQuAD, and MultiNLI benchmarks [ 1\u20134]. BERT-based architectures have become\nlightweight and more ef\ufb01cient (DistilBERT) and trained more effectively to become increasingly\nperformant (RoBERTa) [5, 6].\nAs we build more capable machine learning models with increasingly minute differences in perfor-\nmance benchmarks, it is important that our model behavior is interpretable. Evaluation of language\nmodel performance is moving towards \ufb01ne-grained diagnostics that go beyond simply answering if a\nmodel outperforms another and instead delve into the scale and type of errors the model makes. There\nare two main approaches in this area: curating a set of dif\ufb01cult examples, and developing in-depth\nmetrics for targeted model evaluation [ 7]. Our work is positioned within the latter approach, as a\ndiagnostic benchmark to allow for nuanced studies into a model\u2019s strengths and weaknesses. These\ndiagnostic studies, often using counterfactual or annotated training examples, can be followed by\ntailored \ufb01ne-tuning approaches to improve de\ufb01cient areas [8\u201311].\nIn this paper, we contribute a pipeline for deeper analysis of language model performance by\ngenerating knowledge graph (KG) extracts as inspired from Petroni et al. [12]. We aim to address\ntwo main research directions:\n1st Workshop on eXplainable AI approaches for debugging and diagnosis (XAI4Debugging@NeurIPS2021).arXiv:2111.08546v1  [cs.LG]  16 Nov 2021\u2022How can we quantitatively compare language model knowledge acquisition? Can we extend\nthis analysis to the same model at different stages of early training?\n\u2022 As a language model trains, what linguistic traits does it learn over time?\nWe run this pipeline on a RoBERTa architecture at various stages of early training and on pretrained\nmodels from the Transformers library (BERT-Base, DistilBERT, RoBERTa) [ 13]. Our objective is\nto capture a snapshot of learned knowledge from the current state of the model. We achieve this\nby training with a masked language model objective and querying our models using cloze \"\ufb01ll-in-\nthe-blank\" statements. After replacing the predicted word in the masked statement, we generate a\nknowledge graph comprised of subject-verb-object triples which acts as a representation of knowledge\ngenerated from the language model. We analyze this work in two ways: by extending previous\nliterature in graph representations to quantitatively compare differences between language model\nknowledge extracts using graph-edit distance and graph2vec metrics and by proposing a part-of-\nspeech (POS) tagging analysis to better understand a model\u2019s linguistic strengths. The novelty in this\nwork arises from using these proposed metrics to compare language models with each other over time,\nin an analysis that goes beyond accuracy and loss. The results demonstrate that in each\ntraining phase, language models tend to create better connections and more meaningful triples across\ntheir extracted knowledge graph, which justi\ufb01es our intuition towards the performance increase\nacross our metrics in each training epoch (RoBERTa 1 through 7 epochs) and pretrained model\nadvancement (DistilBERT, BERT, RoBERTa). These generated knowledge graphs are a large step\ntowards addressing the research questions: How well does my language model perform in comparison\nto another (using metrics other than accuracy)? What are the linguistic strengths of my language\nmodel? What kind of data should I train my model on to", "ABSTRACT\nAn important paradigm of natural language processing consists of large-scale pre-\ntraining on general domain data and adaptation to particular tasks or domains. As\nwe pre-train larger models, full \ufb01ne-tuning, which retrains all model parameters,\nbecomes less feasible. Using GPT-3 175B as an example \u2013 deploying indepen-\ndent instances of \ufb01ne-tuned models, each with 175B parameters, is prohibitively\nexpensive. We propose Low-RankAdaptation, or LoRA, which freezes the pre-\ntrained model weights and injects trainable rank decomposition matrices into each\nlayer of the Transformer architecture, greatly reducing the number of trainable pa-\nrameters for downstream tasks. Compared to GPT-3 175B \ufb01ne-tuned with Adam,\nLoRA can reduce the number of trainable parameters by 10,000 times and the\nGPU memory requirement by 3 times. LoRA performs on-par or better than \ufb01ne-\ntuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite hav-\ning fewer trainable parameters, a higher training throughput, and, unlike adapters,\nno additional inference latency . We also provide an empirical investigation into\nrank-de\ufb01ciency in language model adaptation, which sheds light on the ef\ufb01cacy of\nLoRA. We release a package that facilitates the integration of LoRA with PyTorch\nmodels and provide our implementations and model checkpoints for RoBERTa,\nDeBERTa, and GPT-2 at https://github.com/microsoft/LoRA .\n1 I NTRODUCTION\nPretrained \nWeights\n\ud835\udc4a\u2208\u211d\ud835\udc51\u00d7\ud835\udc51\nxh\n\ud835\udc35=0\n\ud835\udc34=\ud835\udca9(0,\ud835\udf0e2)\n\ud835\udc51\ud835\udc5fPretrained \nWeights\n\ud835\udc4a\u2208\u211d\ud835\udc51\u00d7\ud835\udc51\nxf(x)\n\ud835\udc51\nFigure 1: Our reparametriza-\ntion. We only train AandB.Many applications in natural language processing rely on adapt-\ningonelarge-scale, pre-trained language model to multiple down-\nstream applications. Such adaptation is usually done via \ufb01ne-tuning ,\nwhich updates all the parameters of the pre-trained model. The ma-\njor downside of \ufb01ne-tuning is that the new model contains as many\nparameters as in the original model. As larger models are trained\nevery few months, this changes from a mere \u201cinconvenience\u201d for\nGPT-2 (Radford et al., b) or RoBERTa large (Liu et al., 2019) to a\ncritical deployment challenge for GPT-3 (Brown et al., 2020) with\n175 billion trainable parameters.1\nMany sought to mitigate this by adapting only some parameters or\nlearning external modules for new tasks. This way, we only need\nto store and load a small number of task-speci\ufb01c parameters in ad-\ndition to the pre-trained model for each task, greatly boosting the\noperational ef\ufb01ciency when deployed. However, existing techniques\n\u0003Equal contribution.\n0Compared to V1, this draft includes better baselines,experiments we ran. \u201cU\u201d indicates unseen categories, \u201cS\u201d indicates seen\ncategories, and \u201cA\u201d indicates all categories in the test set of WebNLG.\nF.2 A DDITIONALAppendix C for\nmore details on the datasets we use. We use NVIDIA Tesla V100 for allmethods on MNLI(m)- n.\nwhere our similarity is de\ufb01ned as:\n\u001e(A;B;i;j ) = (Ui\nA;Uj\nB) =Pp\ni=1\u001b2\ni\np=1\np\u0010\n1\u0000d(Ui\nA;Uj\nB)2\u0011\nThis similarity satis\ufb01es that if Ui\nAandUj\nBshare the same column span, then \u001e(A;B;i;j ) = 1 . If\nthey are completely orthogonal, then \u001e(A;B;i;j ) = 0 . Otherwise, \u001e(A;B;i;j )2(0;1).\nH A DDITIONALreferences. Each\nsample input (x;y)consists of a sequence of slot-value pairs, along with a corresponding natural\nlanguage reference text. The dataset is released under Creative Commons BY-NC-SA 4.0.\nDART is an open-domain data-to-text dataset described in Nan et al. (2020). DART inputs are\nstructured as sequences of ENTITY \u2014 RELATION \u2014 ENTITY triples. With 82Kexamples in\ntotal, DART is a signi\ufb01cantly larger and more complex data-to-text task compared to E2E. The\ndataset is released under the MIT license.\nWebNLG is another commonly used dataset for data-to-text evaluation (Gardent et al., 2017). With\n22Kexamples in total WebNLG comprises 14 distinct categories, nine", " Introduction to the bio-entity recognition task at\nJNLPBA. In Proceedings of the International Joint Workshop on Natural Language\nProcessing in Biomedicine and its Applications (NLPBA/BioNLP) , pages 73\u201378,\nGeneva, Switzerland. COLING.\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. (2018). BERT: pre-training of deep\nbidirectional transformers for language understanding. CoRR ,abs/1810.04805 .\nDodge, J., Sap, M., Marasovic, A., Agnew, W., Ilharco, G., Groeneveld, D., and\nGardner, M. (2021). Documenting the english colossal clean crawled corpus.\nCoRR ,abs/2104.08758 .\nDo\u02d8 gan, R. I., Leaman, R., and Lu, Z. (2014). Ncbi disease corpus: A resource\nfor disease name recognition and concept normalization. Journal of Biomedical\nInformatics ,47, 1 \u2013 10.\nHabibi, M., Weber, L., Neves, M., Wiegandt, D., and Leser, U. (2017). Deep\nlearning with word embeddings improves biomedical named entity recognition.\nBioinformatics (Oxford, England) ,33, i37\u2013i48.\nHerrero-Zazo, M., Segura-Bedmar, I., Mart\u00ednez, P., and Declerck, T. (2013). The\nddi corpus: An annotated corpus with pharmacological substances and drug\u2013drug\ninteractions. Journal of Biomedical Informatics ,46(5), 914\u2013920.\nIslamaj Do\u02d8 gan, R., Kim, S., Chatr-aryamontri, A., Wei, C.-H., Comeau, D. C.,\nAntunes, R., Matos, S., Chen, Q., Elangovan, A., Panyam, N. C., Verspoor, K.,\nLiu, H., Wang, Y ., Liu, Z., Alt\u0131nel, B., H\u00fcs\u00fcnbeyi, Z. M., \u00d6zg\u00fcr, A., Fergadis, A.,\nWang, C.-K., Dai, H.-J., Tran, T., Kavuluru, R., Luo, L., Steppi, A., Zhang, J., Qu,\nJ., and Lu, Z. (2019). Overview of the BioCreative VI Precision Medicine Track:\nmining protein interactions and mutations for precision medicine. Database ,2019 .\nbay147.\nKrallinger, M., Rabal, O., Leitner, F., Vazquez, M., Salgado, D., lu, Z., Leaman,\nR., Lu, Y ., Ji, D., Lowe, D., Sayle, R., Batista-Navarro, R., Rak, R., Huber, T.,\nRockt\u00e4schel, T., Matos, S., Campos, D., Tang, B., Xu, H., and Valencia, A. (2015).\nThe chemdner corpus of chemicals and drugs and its annotation principles. Journal\nof Cheminformatics ,7, S2.\nKudo, T. and Richardson, J. (2018). Sentencepiece: A simple and language\nindependent subword tokenizer and detokenizer for neural text processing. CoRR ,\nabs/1808.06226 .Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C. H., and Kang, J. (2019).\nBiobert: a pre-trained biomedical language representation model for biomedical\ntext mining. CoRR ,abs/1901.08746 .\nLi, J., Sun, Y ., Johnson, R., Sciaky, D., Wei, C.-H., Leaman, R., Davis, A. P.,\nMattingly, C., Wiegers, T., and lu, Z. (2016). Biocreative v cdr task corpus: a\nresource for chemical disease relation extraction. Database ,2016 , baw068.\nPa\ufb01lis, E., Frankild, S., Fanini, L., Faulwetter, S., Pavloudi, C., Vasileiadou, A.,\nArvanitidis, C., and Jensen, L. (2013). The species and organisms resources for\nfast and accurate identi\ufb01cation of taxonomic names in text. PLoS ONE ,8.\nPeng, Y ., Yan, S., and Lu, Z. (2019). Transfer learning in biomedical natural language\nprocessing: An evaluation of BERT and elmo on ten benchmarking datasets. CoRR ,\nabs/1906.05474 .\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li,\nW., and Liu, P. J. (2019). Exploring the limits of transfer learning with a uni\ufb01ed\ntext-to-text transformer. CoRR ,abs/1910.10683 .\nRomanov, A. and Shivade, C. (2018). Lessons from natural language inference in the\nclinical domain. In Proceedings of the 2018 Conference on Empirical Related Work\nThe introduction of the transformer (Vaswani et al. , 2017) marked\na signi\ufb01cant achievement for natural language processing. This is\ndemonstrated by the success of transformer-based architectures such as\nBERT (Devlin et al. , 2018), which, at", " Introduction and Motivating Work\nPre-training methods in natural language processing , pp.\n1527\u20131536, 2017.\nStallkamp, J., Schlipsing, M., Salmen, J., and Igel, C. The\nGerman Traf\ufb01c Sign Recognition Benchmark: A multi-\nclass classi\ufb01cation competition. In IEEE International\nJoint Conference on Neural Networks , pp. 1453\u20131460,\n2011.\nStroud, J. C., Ross, D. A., Sun, C., Deng, J., Sukthankar, R.,\nand Schmid, C. Learning video representations from tex-\ntual web supervision. arXiv preprint arXiv:2007.14937 ,\n2020.\nSzegedy, C., Ioffe, S., Vanhoucke, V ., and Alemi,\nA. Inception-v4, inception-resnet and the impact\nof residual connections on learning. arXiv preprint\narXiv:1602.07261 , 2016.\nTan, H. and Bansal, M. Lxmert: Learning cross-modality\nencoder representations from transformers. arXiv preprint\narXiv:1908.07490 , 2019.\nTan, M. and Le, Q. V . Ef\ufb01cientnet: Rethinking model\nscaling for convolutional neural networks. arXiv preprint\narXiv:1905.11946 , 2019.\nTaori, R., Dave, A., Shankar, V ., Carlini, N., Recht, B.,\nand Schmidt, L. Measuring robustness to natural dis-\ntribution shifts in image classi\ufb01cation. arXiv preprint\narXiv:2007.00644 , 2020.\nThomee, B., Shamma, D. A., Friedland, G., Elizalde, B., Ni,\nK., Poland, D., Borth, D., and Li, L.-J. Yfcc100m: The\nnew data in multimedia research. Communications of the\nACM , 59(2):64\u201373, 2016.Learning Transferable Visual Models From Natural Language Supervision 35\nTian, Y ., Krishnan, D., and Isola, P. Contrastive multiview\ncoding. arXiv preprint arXiv:1906.05849 , 2019.\nTian, Y ., Wang, Y ., Krishnan, D., Tenenbaum, J. B., and\nIsola, P. Rethinking few-shot image classi\ufb01cation: a\ngood embedding is all you need? arXiv preprint\narXiv:2003.11539 , 2020.\nTorralba, A., Fergus, R., and Freeman, W. T. 80 million tiny\nimages: A large data set for nonparametric object and\nscene recognition. IEEE transactions on pattern analysis\nand machine intelligence , 30(11):1958\u20131970, 2008.\nTouvron, H., Vedaldi, A., Douze, M., and J \u00b4egou, H. Fix-\ning the train-test resolution discrepancy. In Advances in\nneural information processing systems , pp. 8252\u20138262,\n2019.\nVaradarajan, J. and Odobez, J.-M. Topic models for scene\nanalysis and abnormality detection. In 2009 IEEE 12th\nInternational Conference on Computer Vision Workshops,\nICCV Workshops , pp. 1338\u20131345. IEEE, 2009.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\nL., Gomez, A. N., Kaiser, \u0141., and Polosukhin, I. Atten-\ntion is all you need. In Advances in neural information\nprocessing systems , pp. 5998\u20136008, 2017.\nVeeling, B. S., Linmans, J., Winkens, J., Cohen, T., and\nWelling, M. Rotation equivariant CNNs for digital pathol-\nogy. June 2018.\nVirtanen, P., Gommers, R., Oliphant, T. E., Haberland, M.,\nReddy, T., Cournapeau, D., Burovski, E., Peterson, P.,\nWeckesser, W., Bright, J., van der Walt, S. J., Brett, M.,\nWilson, J., Millman, K. J., Mayorov, N., Nelson, A. R. J.,\nJones, E., Kern, R., Larson, E., Carey, C. J., Polat, \u02d9I.,\nFeng, Y ., Moore, E. W., VanderPlas, J., Laxalde, D.,\nPerktold, J., Cimrman, R., Henriksen, I., Quintero, E. A.,\nHarris, C. R., Archibald, A. M., Ribeiro, A. H., Pedregosa,\nF., van Mulbregt, P., and SciPy 1.0 Contributors. SciPy\n1.0: Fundamental Algorithms for Scienti\ufb01c Computing\nin Python. Nature results reported\nin Taori et al. (2020)\u2019s evaluation suite. Zero-shot CLIP im-\nproves the state of the art on 5 of the 7 datasets, ImageNet-R,\nObjectNet, ImageNet-Sketch, ImageNet-Vid, and Youtube-\nBB. CLIP\u2019s improvements are largest on ImageNet-Vid and\nYoutube-BB due to its \ufb02exible zero-shot capability and on\nImageNet-R, which likely re\ufb02ects CLIP\u2019s pre-training dis-\ntribution including signi\ufb01cant amounts of creative content.\nA similar behavior has been documented for the Instagram\npre-trained ResNeXt models as discussed in Taori et al.\n(2020).Learning Transferable Visual Models From Natural Language Supervision 48\nF. Model Hyperparameters\nHyperparameter Value\nBatch size", " Introduction\nThe GPT-3 model (Brown et al., 2020) has made\nwaves in the NLP community by demonstrating as-\ntounding few-shot capabilities on myriad language\nunderstanding tasks. Given only a natural lan-\nguage prompt and a few demonstrations of the task,\nGPT-3 is able to make accurate predictions without\nupdating any of the weights of its underlying lan-\n*The \ufb01rst two authors contributed equally.\n1Alternatively, language models\u2019 b est friends f orever.\n2Our implementation is publicly available at https://\ngithub.com/princeton-nlp/LM-BFF .guage model. However, while remarkable, GPT-3\nconsists of 175B parameters, which makes it chal-\nlenging to use in most real-wold applications.\nIn this work, we study a more practical scenario\nin which we only assume access to a moderately-\nsized language model such as BERT (Devlin et al.,\n2019) or RoBERTa (Liu et al., 2019), and a small\nnumber of examples (i.e., a few-shot setting), which\nwe can use to \ufb01ne-tune the weights of the language\nmodel. This setting is appealing as (1) such mod-\nels can be trained on typical research hardware;\n(2) few-shot settings are realistic, as it is generally\nboth easy to acquire a few annotations (e.g., 32\nexamples) and ef\ufb01cient to train on them; and (3)\nupdating parameters typically leads to better perfor-\nmance. Inspired by GPT-3\u2019s \ufb01ndings, we propose\nseveral novel strategies for expanding its few-shot\nlearning abilities to our setting, considering both\nclassi\ufb01cation and\u2014for the \ufb01rst time\u2014regression.\nFirst, we follow the route of prompt-based pre-\ndiction, \ufb01rst developed by the GPT series (Radford\net al., 2018, 2019; Brown et al., 2020) for zero-shot\nprediction and recently studied by PET (Schick and\nSch\u00a8utze, 2021a,b) for \ufb01ne-tuning. Prompt-based\nprediction treats the downstream task as a (masked)\nlanguage modeling problem, where the model di-\nrectly generates a textual response (referred to as\nalabel word ) to a given prompt de\ufb01ned by a task-\nspeci\ufb01c template (see Figure 1(c)). Finding the\nright prompts, however, is an art\u2014requiring both\ndomain expertise and an understanding of the lan-\nguage model\u2019s inner workings. Even if signi\ufb01cant\neffort is invested, manual prompts are likely to be\nsuboptimal. We address this issue by introducing\nautomatic prompt generation, including a pruned\nbrute-force search to identify the best working label\nwords, and a novel decoding objective to automat-\nically generate templates using the generative T5\nmodel (Raffel et al., 2020)\u2014all of which only re-\nquire the few-shot training data. This allows usarXiv:2012.15723v2  [cs.CL]  2 Jun 2021MLMhead\u00b7\u00b7\u00b7noutterly \u2714\u00b7\u00b7\u00b7MLMheadgreat (label:positive)terrible (label:negative) \u2714label:positivelabel:negative \u2714CLShead\n[CLS] No reason to watch . It was  [MASK] . [SEP] A fun ride . It was great . [SEP] The drama discloses nothing . It was terrible . [SEP][CLS]  No reason to watch . [SEP] [CLS] it's a [MASK] movie in every regard , and [MASK] painful to watch . [SEP]MLMhead\u00b7\u00b7\u00b7greatterrible \u2714\u00b7\u00b7\u00b7(a) MLM pre-training(b) Fine-tuning\n(c) Prompt-based fine-tuning with demonstrations (our approach)Demonstration for label:positiveDemonstration for label:negativeTemplateInputVocab   V<latexit sha1_base64=\"/8v18XM/5jjHz8Bu3KqobBykbcg=\">AAAB9HicbVDLSgMxFL3js9ZX1aWbYCuIizJTFF0W3LisYB/QDiWTZtrQJDMmmUIZ+h1uXCji1o9x59+YaWehrQcCh3Pu5Z6cIOZMG9f9dtbWNza3tgs7xd29/YPD0tFxS0eJIrRJIh6pToA15UzSpmGG006sKBYBp+1gfJf57QlVmkXy0Uxj6gs8lCxkBBsr+ZWewGZEME9bs0q/VHar7hxolXg5KUOORr/01RtEJBFUGsKx1l3PjY2fYmUY4XRW7CWaxpiM8ZB2LZVYUO2n89AzdG6VAQojZZ80aK7+3kix0HoqAjuZZdTLXib+53UTE976KZNxYqgki0NhwpGJUNYAGjBFieFTSzBRzGZFZIQVJsb2VLQleMtfXiWtWtW7ql4/1Mr1y7yOApzCGVyABzdQh3toQBMIPMEzvMKbM3FenHfnYzG65uQ7J/AHzucPSEyRtg==</latexit>\nLabel space    Y<latexit sha1_base64=\"KiH56zM6qOeuxejTCrDO4mnCAPI=\">AAAB9HicbVDLSsNAFL2pr1pfVZduBltBXJSkKLosuHFZwT6kDWUynbRDJ5M4MymU0O9w40IRt36MO//GSZqFth4YOJxzL/fM8SLOlLbtb6uwtr6xuVXcLu3s7u0flA+P2iqMJaEtEvJQdj2sKGeCtjTTnHYjSXHgcdrxJrep35lSqVgoHvQsom6AR4L5jGBtJLfaD7AeE8yTx3l1UK7YNTsDWiVOTiqQozkof/WHIYkDKjThWKmeY0faTbDUjHA6L/VjRSNMJnhEe4YKHFDlJlnoOTozyhD5oTRPaJSpvzcSHCg1CzwzmWZUy14q/uf1Yu3fuAkTUaypIItDfsyRDlHaABoySYnmM0MwkcxkRWSMJSba9FQyJTjLX14l7XrNuaxd3dcrjYu8jiKcwCmcgwPX0IA7aEILCDzBM7zCmzW1Xqx362MxWrDynWP4A+vzB0zekbk=</latexit>\nLabel mapping            M(Y)\n<latexit sha1_base64=\"EwIV6ulOE3r2P2XPhMU3VSsyDnU=\">AAACA3icbZDLSsNAFIZP6q3WW9SdbgZbobooSVF0WXDjRqhgL9KGMplO2qGTCzMToYSCG1/FjQtF3PoS7nwbJ20Qrf4w8PGfc5hzfjfiTCrL+jRyC4tLyyv51cLa+sbmlrm905RhLAhtkJCHou1iSTkLaEMxxWk7EhT7Lqctd3SR1lt3VEgWBjdqHFHHx4OAeYxgpa2euVfq+lgNCebJ1aT8zbeTo1LPLFoVayr0F+wMipCp3jM/uv2QxD4NFOFYyo5tRcpJsFCMcDopdGNJI0xGeEA7GgPsU+kk0xsm6FA7feSFQr9Aoan7cyLBvpRj39Wd6ZJyvpaa/9U6sfLOnYQFUaxoQGYfeTFHKkRpIKjPBCWKjzVgIpjeFZEhFpgoHVtBh2DPn/wXmtWKfVI5va4Wa8dZHHnYhwMogw1nUINLqEMDCNzDIzzDi/FgPBmvxtusNWdkM7vwS8b7F0pnlzg=</latexit>\nVocab   V<latexit sha1_base64=\"/8v18XM/5jjHz8Bu3KqobBykbcg=\">AAAB9HicbVDLSgMxFL3js9ZX1aWbYCuIizJTFF0W3LisYB/QDiWTZtrQJDMmmUIZ+h1uXCji1o9x59+YaWehrQcCh3Pu5Z6cIOZMG9f9dtbWNza3tgs7xd29/YPD0tFxS0eJIrRJIh6pToA15UzSpmGG006sKBYBp+1gfJf57QlVmkXy0Uxj6gs8lCxkBBsr+ZWewGZEME9bs0q/VHar7hxolXg5KUOORr/01RtEJBFUGsKx1l3PjY2fYmUY4XRW7CWaxpiM8ZB2LZVYUO2n89AzdG6VAQojZZ80aK7+3kix0HoqAjuZZdTLXib+53UTE976KZNxYqgki0NhwpGJUNYAGjBFieFTSzBRzGZFZIQVJsb2VLQleMtfXiWtWtW7ql4/1Mr1y7yOApzCGVyABzdQh3toQBMIPMEzvMKbM3FenHfnYzG65uQ7J/AHzucPSEyRtg==</latexit>Figure 1: An illustration of (a) masked language model (MLM) pre-training, (b) standard \ufb01ne-tuning, and (c) our\nproposed LM-BFF using prompt-based \ufb01ne-tuning with demonstrations. The underlined text is the task-speci\ufb01c\ntemplate , and colored words are label words .\nto cheaply obtain effective prompts that match or\noutperform our manually chosen ones.\nSecond, we adopt the idea of incorporating\ndemonstrations as additional context. GPT-3\u2019s\nnaive \u201cin-context learning\u201d", " Introduction\nGenetic diseases are mostly caused by gene mutations, although recent\nstudies reveal that epigenetic factors can also play a role [1]. Among the\nexisting experiments. It is thus reasonable to achieve a relatively low\nperformance for MVE.\nFUTURE PERSPECTIVES\nIn this section, we present possible future directions that may address\ncurrent challenging issues for more accurately predicting disease genes.\nLearning with Limited Labeled Data\nLearning with limited labelled data has been a challenging task in disease\ngene prediction. Existing efforts to overcome this dif\ufb01culty include PU\nlearning and oversampling techniques. For example, PU learning introduction for these Conclusion\nDiscovering disease causing genes and analyzing their roles in the disease\nare not only critical for understanding disease formation mechanism,\nbut also extremely important for designing appropriate drugs for\ncorresponding clinical therapies. Linkage analysis and genome-wide\nassociation studies (GWAS) form the basis of disease gene prediction.\nHowever, they generate a large number of false positives in their statistical\nanalysis of biomarkers. Computational approaches are ef\ufb01cient and\ncomplementary tools to help biologists \ufb01lter out noisy false positives\nand provide a list of genes which are worth for further clinical study.\nIn this survey, we focus on network-based research, leveraging various\nnetworks in their problem formulation for disease gene prediction. We\nprovide an organized, up-to-date overview of state-of-the-art network-\nbased approaches. We also perform an empirical comparison study on\ndifferent computational Results and Discussion\nWe demonstrate the performance comparison of 14 state-of-the-art References\n[1] Fides Zenk, Eva Loeser, Rosaria Schiavo, Fabian Kilpert, Ozren\nBogdanovi\u00b4 c, and Nicola Iovino. Germ line\u2013inherited h3k27me3\nrestricts enhancer function during maternal-to-zygotic transition.\nScience , 357(6347):212\u2013216, 2017.\n[2] Sora Yoon et al. Ef\ufb01cient pathway enrichment and network\nanalysis of GWAS summary data using GSA-SNP2. Nucleic Acids\nResearch , 46(10):e60\u2013e60, 03 2018.\n[3] Xiujuan Wang, Natali Gulbahce, and Haiyuan Yu. Network-based", " Introduction\nRecent years have featured a trend towards pre-trained language representations in NLP systems, applied in increasingly\n\ufb02exible and task-agnostic ways for downstream transfer. First, single-layer representations were learned using word\nvectors [ MCCD13 ,PSM14 ] and fed to task-speci\ufb01c architectures, then RNNs with multiple layers of representations\nand contextual state were used to form stronger representations [ DL15 ,MBXS17 ,PNZtY18 ] (though still applied to\ntask-speci\ufb01c architectures), and more recently pre-trained recurrent or transformer language models [ VSP+17] have\nbeen directly \ufb01ne-tuned, entirely removing the need for task-speci\ufb01c architectures [RNSS18, DCLT18, HR18].\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension,\nquestion answering, textual entailment, and many others, and has continued to advance based on new architectures\nand algorithms [ RSR+19,LOG+19,YDY+19,LCG+19]. However, a major limitation to this approach is that while\nthe architecture is task-agnostic, there is still a need for task-speci\ufb01c datasets and task-speci\ufb01c \ufb01ne-tuning: to achieve\nstrong performance on a desired task typically requires \ufb01ne-tuning on a dataset of thousands to hundreds of thousands\nof examples speci\ufb01c to that task. Removing this limitation would be desirable, for several reasons.\nFirst, from a practical perspective, the need for a large dataset of labeled examples for every new task limits the\napplicability of language models. There exists a very wide range of possible useful language tasks, encompassing\nanything from correcting grammar, to generating examples of an Results for SAT task.\n Figure H.3: All Related Work\nSeveral lines of work have focused on increasing parameter count and/or computation in language models as a\nmeans to improve generative or task performance. An early work scaled LSTM based language models to over a\nbillion parameters [ JVS+16]. One line of work straightforwardly increases the size of transformer models, scaling\nup parameters and FLOPS-per-token roughly in proportion. Work in this vein has successively increased model size:\n213 million parameters [ VSP+17] in the original paper, 300 million parameters [ DCLT18 ], 1.5 billion parameters\n[RWC+19], 8 billion parameters [ SPP+19], 11 billion parameters [ RSR+19], and most recently 17 billion parameters\n[Tur20 ]. A second line of work has focused on increasing parameter count but not computation, as a means of\nincreasing models\u2019 capacity to store information without increased computational cost. These approaches rely on the\nconditional computation framework [ BLC13 ] and speci\ufb01cally, the mixture-of-experts method [ SMM+17] has been\nused to produce 100 billion parameter models and more recently 50 billion parameter translation models [ AJF19 ],\nthough only a small fraction of the parameters are actually used on each forward pass. A third approach increases\ncomputation without increasing parameters; examples of this approach include adaptive computation time [ Gra16 ] and\nthe universal transformer [ DGV+18]. Our work focuses on the \ufb01rst approach (scaling compute and parameters together,\nby straightforwardly making the neural net larger), and increases model size 10x beyond previous models that employ\nthis strategy.\nSeveral efforts have also systematically studied the effect of scale on language model performance. [ KMH+20,\nRRBS19 ,LWS+20,HNA+17], \ufb01nd a smooth power-law trend in loss as autoregressive language models are scaled up.\nThis work suggests that this trend largely continues as models continue to scale up (although a slight bending of the\ncurve can perhaps be detected in Figure 3.1),", " Introduction\nTraining a machine learning model to perform natural language processing (NLP) tasks\noften requires that the model can process text in a way that is amenable to downstream\nlearning. This can be loosely viewed as developing general-purpose knowledge that allows\nthe model to \u201cunderstand\u201d text. This knowledge can range from low-level (e.g. the spelling\n\u2217.Equalcontribution. Adescriptionofeachauthor\u2019scontributionisavailableinAppendixA.Correspondence\ntocraffel@gmail.com .\n1.https://github.com/google-research/text-to-text-transfer-transformer\n\u00a92020 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei\nLi, and Peter J. Liu.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ . Attribution requirements are provided at\nhttp://jmlr.org/papers/v21/20-074.html .arXiv:1910.10683v4  [cs.LG]  19 Sep 2023Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nor meaning of words) to high-level (e.g. that a tuba is too large to fit in most backpacks).\nIn modern machine learning practice, providing this knowledge is rarely done explicitly;\ninstead, it is often learned as part of an auxiliary task. For example, a historically common\napproach is to use word vectors (Mikolov et al., 2013b,a; Pennington et al., 2014) to map\nword identities to a continuous representation where, ideally, similar words map to similar\nvectors. These vectors are often learned through an objective that, for example, encourages\nco-occurring words to be positioned nearby in the continuous space (Mikolov et al., 2013b).\nRecently, it has become increasingly common to pre-train the entire model on a data-rich\ntask. Ideally, this pre-training causes the model to develop general-purpose abilities and\nknowledge that can then be transferred to downstream tasks. In applications of transfer\nlearning to computer vision (Oquab et al., 2014; Jia et al., 2014; Huh et al., 2016; Yosinski\net al., 2014), pre-training is typically done via supervised learning on a large labeled data set\nlike ImageNet (Russakovsky et al., 2015; Deng et al., 2009). In contrast, modern techniques\nfor transfer learning in NLP often pre-train using unsupervised learning on unlabeled data.\nThis approach has recently been used to obtain state-of-the-art methods in natural\nlanguage processing , 2013.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. MASS: Masked sequence to\nsequence pre-training for language generation. arXiv preprint arXiv:1905.02450 , 2019.\n65Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of\nMachine Learning Research , 2014.\nSandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J. Pal. Learning\ngeneral purpose distributed sentence representations via large scale multi-task learning.\narXiv preprint arXiv:1804.00079 , 2018.\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning with neural\nnetworks. In Advances in neural information processing systems , 2014.\nRichard S. Sutton. The bitter lesson. http://www.incompleteideas.net/IncIdeas/\nBitterLesson.html , 2019.\nWilson L. Taylor. \u201cCloze procedure\u201d: A new tool for measuring readability. Journalism\nBulletin, 1953.\nTrieu H. Trinh and Quoc V. Le. A simple method for commonsense reasoning. arXiv preprint\narXiv:1806.02847 , 2018.\nAdam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip\nBachman, and Kaheer Suleman. NewsQA: A machine comprehension dataset. arXiv\npreprint arXiv:1611.09830 , 2016.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural\ninformation processing systems , 2017.\nElena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of representations\nin the transformer: A study with machine translation and language modeling", " Introduction\nNatural language processing (NLP) has been\nshaken in recent months with the dramatic suc-\ncesses enabled by transfer learning and contextual\nword embedding models, such as ELMo (Peters\net al., 2018), ULMFiT (Howard and Ruder, 2018),\nand BERT (Devlin et al., 2018).\nThese models have been primarily explored for\ngeneral domain text, and, recently, biomedical text\nwith BioBERT (Lee et al., 2019). However, clin-\nical narratives (e.g., physician notes) have known\ndifferences in linguistic characteristics from both\ngeneral text and non-clinical biomedical text, mo-\ntivating the need for specialized clinical BERT\nmodels.In this work, we build and publicly release ex-\nactly such an embedding model.1Furthermore,\nwe demonstrate on several clinical NLP tasks the\nimprovements this system offers over traditional\nBERT and BioBERT alike.\nIn particular, we make the following contribu-\ntions:\n1. We train and publicly release BERT-Base and\nBioBERT-\ufb01netuned models trained on both\nall clinical notes and only discharge sum-\nmaries.2\n2. We demonstrate that using clinical speci\ufb01c\ncontextual embeddings improves both upon\ngeneral domain results demonstrates the\nutility of using domain-speci\ufb01c contextual embed-\ndings for non de-ID clinical NLP tasks. Addition-\nally, on one task Discharge Summary BERT offers\nperformance improvements over Clinical BERT,\nso it may be that adding greater speci\ufb01city to the\nunderlying corpus is helpful in some cases. We\nrelease both models with this work for public use.Qualitative Embedding Comparisons Table 3\nshows the nearest neighbors for 3 words each\nfrom 3 categories under BioBERT and Clinical\nBERT. These lists suggest that Clinical BERT re-\ntains greater cohesion around medical or clinic-\noperations relevant terms than does BioBERT. For\nexample, the word \u201cDischarge\u201d is most closely\nassociated with \u201cadmission,\u201d \u201cwave,\u201d and \u201csight\u201d\nunder BioBERT, yet only the former seems rele-\nvant to clinical operations. In contrast, under Clin-\nical BERT, the associated words all are meaningful\nin a clinical operations context.\nLimitations & Future Work This work has\nseveral notable limitations. First, we do not ex-\nperiment with any more advanced model architec-\ntures atop our embeddings. This likely hurts our\nperformance. Second, MIMIC only contains notes\nfrom the intensive care unit of a single healthcare\ninstitution (BIDMC). Differences in care practices\nacross institutions are signi\ufb01cant, and using notes\nfrom multiple institutions could offer signi\ufb01cant\ngains. Lastly, our model shows no improvements\nfor either de-ID task we explored. If our hypoth-\nesis is correct as to its cause, a possible solution\ncould entail introducing synthetic de-ID into the\nsource clinical text and using that as the source for\nde-ID tasks going forward.5 Related Work\nContextual Embeddings in General Tradi-\ntional word-level vector representations, such as\nword2vec (Mikolov et al., 2013), GloVe (Penning-\nton et al., 2014), and fastText (Bojanowski et al.,\n1github.com/EmilyAlsentzer/clinicalBERT\n2Discharge summaries are commonly used in downstream\ntasks.arXiv:1904.03323v3  [cs.CL]  20 Jun 20192017), express all possible meanings of a word as\na single vector representation and cannot disam-\nbiguate the word senses based on the surround-\ning context. Over the last two years, ELMo (Pe-\nters et al., 2018) and BERT (Devlin et al., 2018)\npresent strong solutions that can provide contex-\ntualized word representations. By pre-training on\na large text corpus as a language model, ELMo\ncan create a context-sensitive embedding for each\nword in a given sentence, which will be fed into\ndownstream tasks. Compared to ELMo, BERT is\ndeeper and contains much more parameters, thus\npossessing greater representation power. More im-\nportantly, rather than simply providing word em-\nbeddings as features, BERT can be incorporated\ninto a downstream task and gets \ufb01ne-tuned as an\nintegrated task-speci\ufb01c architecture.\nBERT has, in general, been found", " Introduction\nto the bio-entity recognition task at jnlpba. In NLP-\nBA/BioNLP .\nTim Dettmers. 2019. TPUs vs\nGPUs for Transformers (BERT).\nhttp://timdettmers.com/2018/10/17/tpus-vs-gpus- \nAccessed: 2019-02-22.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL-HLT .\nRezarta Islamaj Dogan, Robert Leaman, and Zhiyong\nLu. 2014. NCBI disease corpus: A resource for dis-\nease name recognition and concept normalization.\nJournal of biomedical informatics , 47:1\u201310.\nTimothy Dozat and Christopher D. Manning. 2017.\nDeep biaf\ufb01ne attention for neural dependency pars-\ning. ICLR .\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind\nTafjord, Pradeep Dasigi, Nelson F. Liu, Matthew\nPeters, Michael Schmitz, and Luke S. Zettlemoyer.\n2017. Allennlp: A deep semantic natural language\nprocessing platform. In arXiv:1803.07640 .\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model \ufb01ne-tuning for text classi\ufb01cation. In\nACL.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath.\n2019. Clinicalbert: Modeling clinical notes and pre-\ndicting hospital readmission. arXiv:1904.05342 .\nAlistair E. W. Johnson, Tom J. Pollard aand Lu Shen,\nLiwei H. Lehman, Mengling Feng, Moham-\nmad Ghassemi, Benjamin Moody, Peter Szolovits,\nLeo Anthony Celi, , and Roger G. Mark. 2016.Mimic-iii, a freely accessible critical care database.\nInScienti\ufb01c Data, 3:160035 .\nDavid Jurgens, Srijan Kumar, Raine Hoover, Daniel A.\nMcFarland, and Daniel Jurafsky. 2018. Measuring\nthe evolution of a scienti\ufb01c \ufb01eld through citation\nframes. TACL , 06:391\u2013406.\nJin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and\nJun\u2019ichi Tsujii. 2003. GENIA corpus - a semanti-\ncally annotated corpus for bio-textmining. Bioinfor-\nmatics , 19:i180i182.\nSu Kim, David Mart\u00b4 \u0131nez, Lawrence Cavedon, and Lars\nYencken. 2011. Automatic classi\ufb01cation of sen-\ntences to support evidence based medicine. In BMC\nBioinformatics .\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. ICLR .\nJens Kringelum, Sonny Kim Kj\u00e6rulff, S\u00f8ren Brunak,\nOle Lund, Tudor I. Oprea, and Olivier Taboureau.\n2016. ChemProt-3.0: a global chemical biology dis-\neases mapping. In Database .\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So,\nand Jaewoo Kang. 2019. BioBERT: a pre-trained\nbiomedical language representation model for\nbiomedical text mining. In arXiv:1901.08746 .\nJiao Li, Yueping Sun, Robin J. Johnson, Daniela Sci-\naky, Chih-Hsuan Wei, Robert Leaman, Allan Peter\nDavis, Carolyn J. Mattingly, Thomas C. Wiegers,\nand Zhiyong Lu. 2016. BioCreative V CDR task\ncorpus: a resource for chemical disease relation\nextraction. Database : the journal of biological\ndatabases and curation .\nYi Luan, Luheng He, Mari Ostendorf, and Hannaneh\nHajishirzi. 2018. Multi-task identi\ufb01cation of enti-\nties, relations, and coreference for scienti\ufb01c knowl-\nedge graph construction. In EMNLP .\nMark Neumann, Daniel King, Iz Beltagy, and Waleed\nAmmar. 2019. ScispaCy: Fast and robust mod-\nels for biomedical natural language processing. In\narXiv:1902.07669 .\nDat Quoc Nguyen and Karin M. Verspoor. 2019. From\npos tagging to dependency parsing for biomedical\nevent extraction. BMC Bioinformatics , 20:1\u201313.\nBenjamin Nye, Junyi Jessy Li, Roma Patel, Yinfei\nYang, Iain James Marshall, Ani Nenkova, and By-\nron C. Wallace. 2018. A corpus with multi-level an-\nnotations of patients, interventions and outcomes to\nsupport language processing for medical literature.\nInACL.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer,\nMatt Gardner, Christopher Clark, Kenton Lee, and\nLuke S. Zettlemoyer. 2018. Deep contextualized\nword representations. In NAACL-HLT .Alec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nNils Reimers and Iryna Gurevych. 2017. Optimal hy-\nperparameters for deep lstm-networks for sequence\nlabeling tasks. In EMNLP .\nArnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Dar-\nrin Eide, Bo-June Paul Hsu, and Kuansan Wang.\n2015. An overview of microsoft academic service\n(MAS) and applications. In WWW .\nAshish Vaswani, Noam Shazeer, Niki", " Introduction\nTransfer from pre-trained models yields strong performance\non many NLP tasks (Dai & Le, 2015; Howard & Ruder,\n2018; Radford et al., 2018). BERT, a Transformer network\ntrained on large text corpora with an unsupervised loss,\nattained state-of-the-art performance on text classi\ufb01cation\nand extractive question answering (Devlin et al., 2018).\nIn this paper we address the online setting, where tasks\narrive in a stream. The goal is to build a system that per-\nforms well on all of them, but without training an entire new\nmodel for every new task. A high degree of sharing between\n*Equal contribution1Google Research2Jagiellonian University.\nCorrespondence to: Neil Houlsby <neilhoulsby@google.com>.\nProceedings of the 36thInternational Conference on Machine\nLearning , Long Beach, California, PMLR 97, 2019. Copyright\n2019 by the author(s).\n1Code at https://github.com/google-research/\nadapter-bert\n105106107108109\nNum trainable parameters / task\u221225\u221220\u221215\u221210\u2212505Accuracy delta (%)\nAdapters (ours)\nFine-tune top layersFigure 1. Trade-off between accuracy and number of trained task-\nspeci\ufb01c parameters, for adapter tuning and \ufb01ne-tuning. The y-axis\nis normalized by the performance of full \ufb01ne-tuning, details in\nSection 3. The curves show the 20th,50th, and 80th performance\npercentiles across nine tasks from the GLUE benchmark. Adapter-\nbased tuning attains a similar performance to full \ufb01ne-tuning with\ntwo orders of magnitude fewer trained parameters.\ntasks is particularly useful for applications such as cloud\nservices, where models need to be trained to solve many\ntasks that arrive from customers in sequence. For this, we\npropose a transfer learning strategy that yields compact and\nextensible downstream models. Compact models are those\nthat solve many tasks using a small number of additional\nparameters per task. Extensible models can be trained in-\ncrementally to solve new tasks, without forgetting previous\nones. Our method yields a such models without sacri\ufb01cing\nperformance.\nThe two most common transfer learning techniques in NLP\nare feature-based transfer and \ufb01ne-tuning. Instead, we\npresent an alternative transfer method based on adapter\nmodules (Rebuf\ufb01 et al., 2017). Features-based transfer in-\nvolves pre-training real-valued embeddings vectors. These\nembeddings may be at the word (Mikolov et al., 2013), sen-\ntence (Cer et al., 2019), or paragraph level (Le & Mikolov,\n2014). The embeddings are then fed to custom downstream\nmodels. Fine-tuning involves copying the weights from a\npre-trained network and tuning them on the downstream\ntask. Recent work shows that \ufb01ne-tuning often enjoys betterarXiv:1902.00751v2  [cs.LG]  13 Jun 2019Parameter-Ef\ufb01cient Transfer Learning for NLP\nperformance than feature-based transfer (Howard & Ruder,\n2018).\nBoth feature-based transfer and \ufb01ne-tuning require a new\nset of weights for each task. Fine-tuning is more parameter\nef\ufb01cient if the lower layers of a network are shared between\ntasks. However, our proposed adapter tuning method is even\nmore parameter ef\ufb01cient. Figure 1 demonstrates this trade-\noff. The x-axis shows the number of parameters trained per\ntask; this corresponds to the marginal increase in the model\nsize required to solve each additional task. Adapter-based\ntuning requires training two orders of magnitude fewer pa-\nrameters to \ufb01ne-tuning, while attaining similar performance.\nAdapters are new modules added between layers of a\npre-trained network. Adapter-based tuning differs from\nfeature-based transfer and \ufb01ne-tuning in the following way.\nConsider a function (neural network) with parameters w:\n\u001ew(x). Feature-based transfer composes \u001ewwith a new\nfunction,\u001fv, to yield\u001fv(\u001ew(x)). Only the new, task-\nspeci\ufb01c, parameters, v, are then trained. Fine-tuning in-\nvolves adjusting the original parameters, w, for each new\ntask, limiting compactness. For adapter tuning, a new\nfunction, w;v(x), is de\ufb01ned, where parameters ware\ncopied over from pre-training. The initial parameters v0\nare set such that the new function", " Introduction\nRecurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht\u22121and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [ 21] and conditional\ncomputation [ 32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3 Model Architecture\nMost competitive neural sequence transduction"], "bleu": 0.1817481424558092, "rouge_l": 0.31001076426264806, "gpt_metric_score": 0.5, "bert_score": 0.24811887741088867}
{"paper_key": "Assessing the Utility of Large Language Models for Phenotype-Driven Gene Prioritization in Rare Genetic Disorder Diagnosis.", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we improve phenotype-driven gene prioritization for rare disease diagnosis using machine learning techniques?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for the research community as it can significantly enhance the accuracy and efficiency of identifying disease-causing genes, particularly in rare Mendelian diseases. Improved gene prioritization can lead to better diagnostic tools, which can ultimately facilitate personalized medicine approaches and targeted therapies. This research could pave the way for future studies that integrate machine learning with genomic data, potentially transforming how genetic disorders are diagnosed and treated.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in improving phenotype-driven gene prioritization stem from the complexity of biological data and the inherent variability in phenotypic expression among individuals. Naive approaches may fail due to the high dimensionality of genomic data, the noise present in phenotype data, and the intricate relationships between genes and phenotypes. Additionally, existing models may not adequately capture the nuances of genetic interactions or the context-specific nature of gene expression, making it difficult to achieve reliable predictions.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often been limited by the lack of comprehensive datasets that integrate both phenotypic and genotypic information, as well as the computational power required to analyze such data effectively. Many existing solutions have focused on either phenotype or genotype without adequately bridging the two. Our approach aims to leverage advanced machine learning techniques and larger, more diverse datasets to create a more holistic model that can better account for the complexities of gene-phenotype relationships.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves using a machine learning framework that integrates phenotype data with genomic information to prioritize candidate genes. We will utilize a dataset comprising genomic sequences and corresponding phenotypic data from individuals diagnosed with rare diseases. The performance of our model will be evaluated using metrics such as precision, recall, and F1-score to assess its accuracy in predicting disease-causing genes. We expect our approach to yield a more accurate list of prioritized genes, thereby improving the diagnostic process for rare diseases.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can a hybrid framework that leverages large language models (LLMs) and multimodal inputs enhance the extraction of clinical phenotypes from unstructured healthcare data, particularly for the identification of rare genetic disorders?\n\n[Question 2]: Why is it interesting and important?  \nThe implications of solving this problem are significant for both the research community and clinical practice. Accurate extraction of clinical phenotypes from unstructured data can lead to more precise diagnoses, particularly in the context of rare genetic disorders, which often go undetected due to their atypical presentation in clinical notes. By developing a framework that integrates textual and visual data, we can enhance the breadth of information available for analysis, leading to improved patient outcomes. This research could advance knowledge in the fields of medical informatics and machine learning, potentially influencing future studies on automated clinical assessments and decision-making. Additionally, the ethical considerations of utilizing such a framework will contribute to discussions on responsible AI in healthcare.\n\n[Question 3]: Why is it hard?  \nThe challenges in solving this problem stem from the complexities of unstructured healthcare data, which includes variability in clinical notes, diverse terminology, and the need for contextual understanding. Naive approaches may fail due to their inability to capture the nuances of clinical language and the interplay between textual and visual data. Furthermore, integrating multimodal inputs requires sophisticated data processing techniques to ensure that the information is harmonized effectively. Technical obstacles include developing algorithms capable of reinforcement learning that can adaptively refine prompt engineering based on real-world clinical feedback, as well as ensuring the interpretability of the model's outputs in a clinical context.\n\n[Question 4]: Why hasn't it been solved before?  \nPrior research has often focused on either textual data extraction or visual data analysis in isolation, leading to a gap in comprehensive approaches that combine both modalities. Existing solutions may lack the adaptability necessary to refine their processes based on clinical outcomes, limiting their effectiveness in real-world settings. Barriers have included insufficient integration of reinforcement learning techniques in the context of healthcare data and the challenge of maintaining interpretability and ethical standards in AI applications. My approach differs by proposing a hybrid framework that not only integrates multimodal data but also employs adaptive learning strategies to continuously enhance performance, addressing the limitations of previous methodologies.\n\n[Question 5]: What are the key components of my approach and results?  \nThe proposed methodology involves developing a hybrid framework that utilizes large language models for dynamic prompt engineering, integrating both textual clinical notes and visual data from facial imaging. The dataset will comprise a diverse collection of unstructured healthcare data, including clinical notes and corresponding images of patients with rare genetic disorders. Key metrics for evaluating the framework's effectiveness will include accuracy in phenotype extraction, adaptability in prompt refinement, and interpretability of results. Expected outcomes include a significant improvement in the precision and relevance of extracted clinical terms, enhanced identification of rare genetic disorders, and a framework that can be utilized in clinical decision-making contexts while adhering to ethical standards.", "referenced_intros": [" introduction\nofprompt patterns to document successful approaches forsystematically engineering different output and interact ion\ngoals when working with conversational LLMs. We focus\nlargely on engineering domain-independent prompt pattern s\nand introduce a catalog of essential prompt patterns to solv e\nproblems ranging from production of visualizations and cod e\nartifacts to automation of output steps that help fact check\noutputs.\nThe remainder of this paper is organized as follows: Sec-\ntion II introduces prompt patterns and compares these patte rns\nto well-known software patterns [10]; Section III describe s\n16 prompt patterns that have been applied to solve common\nproblems in the domain of conversational LLM interaction an d\noutput generation for automating software development tas ks;\nSection IV discusses related work; and Section V presents\nconcluding remarks and lessons learned.\nII. C OMPARING SOFTWARE PATTERNS\nWITH PROMPT PATTERNS\nThe quality of the output(s) generated by a conversational\nLLM is directly related to the quality of the prompts provide d\nby the user. As discussed in Section I, the prompts given to\na conversational LLM can be used to program interactions\nbetween a user and an LLM to better solve a variety of\nproblems. One contribution of this paper is the framework it\nprovides to document patterns that structure prompts to sol ve\na range of software tasks that can be adapted to different\ndomains.\nThis framework is useful since it focuses on codifying\npatterns that can be applied to help users better interact\nwith conversational LLMs in a variety of contexts, rather\nthan simply discussing interesting examples or domain-spe ci\ufb01c\nprompts. Codifying this knowledge in pattern form enhances\nreuse and transferability to other contexts and domains whe re\nusers face similar\u2014but not identical\u2014problems.\nThe topic of knowledge transfer has been studied exten-\nsively in the software patterns literature [10], [11] at mul tiple\nlevels, e.g., design, architectural, and analysis. This paper\napplies a variant of a familiar pattern form as the basis of\nour prompt engineering approach. Since prompts are a form\nof programming, it is natural to document them in pattern\nform.\nA. Overview of Software Patterns\nA software pattern provides a reusable solution to a recur-\nring problem within a particular context [10]. Documenting\nsoftware patterns concisely conveys (and generalizes) fro m\nspeci\ufb01c problems being addressed to identify important for ces\nand/or requirements that should be resolved and/or address ed\nin successful solutions.\nA pattern form also includes guidance on how to implement\nthe pattern, as well as information on the trade-offs and\nconsiderations to take into account when implementing a\npattern. Moreover, example applications of the pattern are\noften provided to further showcase the pattern\u2019s utility in\npractice. Software patterns are typically documented in astylized form to facilitate their use and understanding, su ch\nas:\n\u2022A name and classi\ufb01cation . Each pattern has a name that\nidenti\ufb01es the pattern and should be used consistently. A\nclassi\ufb01cation groups patterns into broad categories, such\nas creational, structural, or behavioral.\n\u2022The intent concisely conveys the purpose the pattern is\nintended to achieve.\n\u2022The motivation documents the underlying problem the\npattern is meant to solve and the importance of the\nproblem.\n\u2022The structure and participants . The structure describes\nthe different pattern participants (such as classes and\nobjects) and how they collaborate to form a generalized\nsolution.\n\u2022Example code concretely maps the pattern to some\nunderlying programming language(s) and aids developers\nin gaining greater insight into how that pattern can be\napplied effectively.\n\u2022Consequences summarize the pros and cons of applying\nthe pattern in", " Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the Seventh Conference on Natural\nLanguage Learning at HLT-NAACL 2003 , pages 142\u2013\n147.\nChenguang Wang, Xiao Liu, Zui Chen, Haoyun Hong,\nJie Tang, and Dawn Song. 2022. Deepstruct: Pre-\ntraining of language models for structure prediction.\nInFindings of the Association for Computational\nLinguistics: ACL 2022 , pages 803\u2013823.\nYucheng Wang, Bowen Yu, Yueyang Zhang, Tingwen\nLiu, Hongsong Zhu, and Limin Sun. 2020. TPLinker:\nSingle-stage joint extraction of entities and relations\nthrough token pair linking. In Proceedings of the\n28th International Conference on Computational Lin-\nguistics , pages 1572\u20131582, Barcelona, Spain (On-\nline). International Committee on Computational Lin-\nguistics.\nZihan Wang, Jingbo Shang, Liyuan Liu, Lihao Lu, Ji-\nacheng Liu, and Jiawei Han. 2019. Crossweigh:\nTraining named entity tagger from imperfect anno-\ntations. In Proceedings of the 2019 Conference on\nEmpirical experiments on\nsix datasets across two languages to validate its ef-\nfectiveness. Surprisingly, ChatIE achieves impres-\nsive performance and even surpasses some full-shot\nmodels on several datasets. This work paves the\nway for a new paradigm for zero-shot IE, where the\nexperts decompose IE task into multiple simpler\nand easier sub-tasks, define chat-like prompts, and\ndirectly runs those specifications without trainingand finetuning. Appendix C.\nthe manually marked argument appendix B). We use Rel\non NYT11-HRL because there is no annotation of\nentity types and use Rel+ on DuIE2.0.\nNER. We consider the complete matching and\nuse the micro F1. Only when both the boundary\nand the type of the predicted entity are correct, will\nwe regard it as correct.\nEE. We adopt different evaluation metrics on\nthe DuEE1.0 and ACE05 dataset. For the DuEE1.0\ndataset, F-measure (F16) is scored according to\nthe word-level matching. For the ACE05 dataset,\nthe predicted argument Results\nNER. The baseline approach on NER is\nAdaSeq Bert-CRF on both datasets. We train\nAdaSeq Bert-CRF in different settings to get the\nfew/full-shot performances in Tab. 1 (Row fs-\n1/5/10/20/50/100 and full-shot). We also provide\nsome supervised approaches for reference: Noise-\nrobust Co-regularization + LUKE(Zhou and Chen,\n2021), BERT-MRC+DSC (Li et al., 2020b), Base-\nline + BS (Zhu and Li, 2022) and W2NER (Li\net al., 2021), shown in Tab. 12. The Sup-SOTA\napproaches shown in Tab. 1 are Noise-robust Co-\nregularization + LUKE and BERT-MRC+DSC for\nconllpp and MSRA, respectively.\nRE. The two baseline approaches ( i.e., Pad-\ndleNLP LIC2021 IE and CasRel) are trained on\nDuIE2.0 and NYT11-HRL, respectively, for fs-\n1/5/10/20/50/100 and full-shot. For the Related Work\nWorking with an enormous amount of labeling\ndata is always hectic, labor-intensive, and time-\nconsuming. Hence, researchers focus on zero/few-\nshot technologies even though IE is challenging\n13The Conclusion\nTo the best of our knowledge, we quantitatively\ninvestigate for the first time whether strong IE mod-\nels can be constructed by directly prompting LLMs.\nWe presented ChatIE, a multi-turn QA framework\nfor zero-shot information extraction based on Chat-\nGPT. Through this interactive mode, ChatIE can\ndecompose complex IE tasks into several parts and\ncompose the References\nMonica Agrawal, Stefan Hegselmann, Hunter Lang,\nYoon Kim, and David Sontag. 2022. Large language\nmodels are zero-shot clinical information extractors.\narXiv preprint arXiv:2205.12689 .\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems , 33:1877\u20131901.\nLingjiao Chen, Matei Zaharia, and James Zou. 2023.\nHow is chatgpt\u2019s behavior changing over time? arXiv\npreprint arXiv:2307.09009 .\nXinya Du and Claire Cardie. 2020. Event extraction by\nanswering (almost) natural questions. In Proceedings\nof the"], "bleu": 0.1509690106791407, "rouge_l": 0.30596175478065235, "gpt_metric_score": 0.5, "bert_score": 0.27501288056373596}
{"paper_key": "Thought Graph: Generating Thought Process for Biological Reasoning", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively identify and categorize biological processes from gene sets that exhibit weak signals and divergent conclusions across different research groups?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for advancing precision medicine, particularly in cancer treatment, as it enables a deeper understanding of the relationships between genes, diseases, and biological processes. By accurately identifying biological processes, researchers can develop targeted therapies and improve patient outcomes. This work could also foster collaboration within the research community by providing a standardized framework for interpreting gene behavior, ultimately leading to more consistent findings and innovative applications in drug development and disease management.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in solving this problem stem from the inherent complexity of biological systems, where individual genes often provide weak signals and do not converge on a singular biological theme. Naive approaches may fail due to the lack of context and the inability to integrate diverse data sources effectively. Additionally, the discrepancies in human annotations and the need for precise yet inclusive coverage of biological processes complicate the task. Overcoming these technical and theoretical obstacles requires sophisticated methodologies that can handle the nuances of biological data and facilitate meaningful connections.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often been limited by a lack of comprehensive frameworks that integrate domain-specific knowledge and advanced analytical techniques. Many existing solutions have not adequately addressed the variability in gene expression data or the complexities of biological processes. Barriers such as insufficient computational models and the absence of collaborative tools for researchers have hindered progress. Our approach differs by introducing the Thought Graph framework, which leverages a Tree-of-Thought architecture and integrates external knowledge bases to enhance the understanding of gene relationships and biological processes.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves the use of the Thought Graph framework, which incorporates a Tree-of-Thought architecture to facilitate thought expansion with a Large Language Model (LLM). We will utilize a dataset comprising gene expression data and relevant biological annotations, applying metrics that assess the accuracy and relevance of identified biological processes. The expected outcomes include a set of high-level biological processes generated from the input gene set, demonstrating improved consistency and relevance compared to traditional methods, thereby advancing our understanding of gene behavior in health and disease contexts.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question we aim to address is: How can we develop an adaptive Thought Graph framework that integrates real-time updates from dynamic knowledge graphs and emerging biological discoveries, utilizing reinforcement learning to enhance the accuracy of gene set interpretations for precision medicine applications?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is crucial for advancing precision medicine, as it directly impacts the accuracy and contextual relevance of insights derived from biological data. By refining gene set interpretations through an adaptive framework, we can provide clinicians and researchers with timely and actionable insights that reflect the latest discoveries in biology. This is particularly significant given the rapid pace of biological research and the need for tools that can keep up with new information. Enhancing the reliability of outputs from large language models (LLMs) will also address the pervasive issue of hallucinations in AI-generated insights, leading to more trustworthy applications in clinical settings. The broader implications of this research include improving patient outcomes through more personalized therapies, ultimately shaping the future of healthcare and informing subsequent research endeavors in genomics and bioinformatics.\n\n[Question 3]: Why is it hard?  \nThe complexity of this problem arises from several interrelated challenges. First, the dynamic nature of biological knowledge means that information is constantly evolving, making it difficult to maintain an up-to-date framework that accurately reflects current understanding. Naive approaches may fail because they do not account for the intricacies of biological interactions and the contextual nuances that influence gene function. Additionally, integrating reinforcement learning techniques with real-time updates presents theoretical and technical obstacles, such as developing effective feedback loops and ensuring the stability of the adaptive framework. There are also practical challenges in sourcing and validating the influx of data from diverse knowledge graphs and experimental results, which require sophisticated data integration and processing capabilities.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research in this domain has often been siloed, focusing on either static knowledge graphs or isolated machine learning techniques without the integration of real-time feedback mechanisms. Existing solutions have failed to address the inherent complexity of biological data and the need for continuous updates, resulting in outdated or inaccurate interpretations. Additionally, a lack of interdisciplinary collaboration among computational biologists, data scientists, and clinicians has limited the development of comprehensive frameworks that can adaptively incorporate new discoveries. Our approach differs by leveraging reinforcement learning to create a dynamic system that not only updates with new data but also learns from feedback, thus providing a more robust and reliable tool for precision medicine.\n\n[Question 5]: What are the key components of my approach and results?  \nOur proposed methodology involves the development of an adaptive Thought Graph framework that will utilize reinforcement learning algorithms to refine gene set interpretations based on real-time data from dynamic knowledge graphs. We will collect a diverse dataset comprising emerging biological discoveries, clinical trial results, and existing genomic data. The success of our framework will be measured using metrics such as accuracy of gene set interpretations, reduction in hallucinations in LLM outputs, and the framework's responsiveness to new data. Expected outcomes include a significant enhancement in the reliability of insights provided to clinicians and researchers, leading to improved decision-making in precision medicine and a framework that evolves in tandem with ongoing biological research.", "referenced_intros": [" Introduction\nLarge language models (LLMs) seek to emulate hu-\nman intelligence through statistical training on ex-\ntensive datasets (Huang and Chang, 2022). LLMs\noperate on input text to predict the subsequent to-\nken or word in the sequence while identifying pat-\nterns and connections between words and phrases,\naiming to comprehend and generate human-like\ntext. Due to their stochastic decoding processes,\ni.e., sampling the next token in the sequence, these\nmodels exhibit probabilistic behavior, potentially\nyielding varied outputs or predictions for the same\ninput across different instances. Additionally, if\nthe training data includes misinformation, biases,\nor inaccuracies, these flaws may be mirrored or\namplified in the content produced by these models.\nLLMs also face challenges in accurately interpret-\ning phrases or terms when the context is vague and\nresides in a knowledge gap region of the model,\nleading to outputs that may sound plausible but\nFigure 1: Knowledge Graphs (KG) employed to reduce\nhallucinations in LLMs at different stages.\nare often irrelevant or incorrect (Ji et al., 2023;\nLenat and Marcus, 2023). This phenomenon, often\ntermed \"hallucinations,\" undermines the reliability\nof these models (Mallen et al., 2023).\nAddressing the issue of hallucinations in these\nmodels is challenging due to their inherent prob-\nabilistic nature. To effectively tackle this issue,\nthere have been continuous research efforts in mak-\ning knowledge updates and model tuning (Zhang\net al., 2023c; Mialon et al., 2023; Petroni et al.,\n2019). However, adding random information does\nnot improve the model\u2019s interpretation and reason-\ning capabilities. Instead, providing more granular\nand contextually relevant, precise external knowl-\nedge can significantly aid the model in recalling\nessential information (Jiang et al., 2020).\nOne emerging research trend is enhancing LLMs\nthrough integrating knowledge representation tools\nsuch as knowledge graphs (KGs) (Mruthyunjaya\net al., 2023). Zheng et al. (Zheng et al., 2023)\ndemonstrate that augmenting these models with\ncomprehensive external knowledge from KGs can\nboost their performance and facilitate a more robust\nreasoning process. The strategies for enhancing\nLLMs with KGs can be grouped into three main\ncategories, each uniquely contributing to the refine-\nment of the model as shown in Figure 1: enhanc-arXiv:2311.07914v2  [cs.CL]  16 Mar 2024KG-augmented\nLLM\nKnowledge-aware\nValidation (\u00a7 3.3)Fact-aware LM (Logan IV et al., 2019), SURGE (Kang et al., 2022b), FOLK (Wang and Shu, 2023),\nCritic-Driven (Lango and Du\u0161ek, 2023)Knowledge-aware\nTraining (\u00a7 3.2)\nFine-tuning\n(\u00a7 3.2.2)SKILL (Moiseev et al., 2022), KGLM (Youn and Tagkopoulos, 2022),\nLMSI (Huang et al., 2022), CoT Fine-Tuning (Kim et al., 2023)Pre-training\n(\u00a7 3.2.1)\nKnowledge-ProbingRewire-then-Probe (Meng et al., 2021),\nKnowledge graph extraction (Kassner\net al., 2021; Swamy et al., 2021)Knowledge-FusionJointLK (Sun et al., 2021b),\nLKPNR (Runfeng et al., 2023)Knowledge-\nGuided MaskingSKEP (Tian et al., 2020), GLM (Shen\net al., 2020; Zhang et al.)Knowledge-\nEnhanced ModelsERNIE 3.0 (Sun et al., 2021a),\nKALM (Rosset et al., 2020)Knowledge-aware\nInference (\u00a7 3.1)\nKG-controlled Gen-\neration (\u00a7 3.1.3)Know-Prompt (Chen et al., 2022), KB-Binder (Li et al., 2023),\nBeamQA (Atif et al., 2023), NeMo guardrails (Rebedea et al., 2023), AL-\nCUNA (Yin et al., 2023a), PRCA (Yang et al., 2023)KG-augmented\nReasoning (\u00a7 3.1.2)IRCoT (Trivedi et al., 2022), Reasoning on graphs (Luo et al., 2023),\nMindMap (Wen et al., 2023), MOT (Li and Qiu, 2023), ReCEval (Prasad\net al., 2023), RAP (Hao et al., 2023), EoT (Yin et al., 2023b)KG-augmented\nRetrieval (\u00a7 3.1.1)KAPING (Baek et al., 2023),StructGPT (Jiang et al., 2023), IAG (Zhang\net al., 2023b), SAFARI (Wang et al., 2023b), KICGPT (Wei et al., 2023),\nRigel Facts (Sen et al., 2023), Retrieve-Rewrite-Answer (Wu et al., 2023)\nFigure 2: Taxonomy of Knowledge Graph-Augmented Large Language Models\ning", "experiments.\nBMC\nBioinformatics\n5\n,\n34\n(2004).\n3.\nBeissbarth,\nT.\n&\nSpeed,\nT.\nP.\nGOstat:\nfind\nstatistically\noverrepresented\nGene\nOntologies\nwithin\na \ngroup\nof\ngenes.\nBioinformatics\n20\n,\n1464\u20131465\n(2004).\n4.\nSubramanian,\nA.\net\nal.\nGene\nset\nenrichment\nanalysis:\na\nknowledge-based\napproach\nfor\ninterpreting \ngenome-wide\nexpression\nprofiles.\nProc.\nNatl.\nAcad.\nSci.\nU.\nS.\nA.\n102\n,\n15545\u201315550\n(2005).\n5.\nAl-Shahrour,\nF.\net\nal.\nFrom\ngenes\nto\nfunctional\nclasses\nin\nthe\nstudy\nof\nbiological\nsystems.\nBMC \nBioinformatics\n8\n,\n114\n(2007).\n6.\nBackes,\nC.\net\nal.\nGeneTrail\u2014advanced\ngene\nset\nenrichment\nanalysis.\nNucleic\nAcids\nRes.\n35\n, \nW186\u2013W192\n(2007).\n7.\nHuang,\nD.\nW.,\nSherman,\nB.\nT.\n&\nLempicki,\nR.\nA.\nSystematic\nand\nintegrative\nanalysis\nof\nlarge\ngene \nlists\nusing\nDAVID\nbioinformatics\nresources.\nNat.\nProtoc.\n4\n,\n44\u201357\n(2009).\n8.\nChen,\nE.\nY.\net\nal.\nEnrichr:\ninteractive\nand\ncollaborative\nHTML5\ngene\nlist\nenrichment\nanalysis\ntool. \nBMC\nBioinformatics\n14\n,\n128\n(2013).\n9.\nPomaznoy,\nM.,\nHa,\nB.\n&\nPeters,\nB.\nGOnet:\na\ntool\nfor\ninteractive\nGene\nOntology\nanalysis.\nBMC \nBioinformatics\n19\n,\n470\n(2018).\n10.\nCerami,\nE.\nG.\net\nal.\nPathway\nCommons,\na\nweb\nresource\nfor\nbiological\npathway\ndata.\nNucleic\nAcids \nRes.\n39\n,\nD685\u201390\n(2011).\n11.\nFabregat,\nA.\net\nal.\nThe\nReactome\npathway\nKnowledgebase.\nNucleic\nAcids\nRes.\n44\n,\nD481\u20137\n(2015).\n12.\nPico,\nA.\nR.\net\nal.\nWikiPathways:\npathway\nediting\nfor\nthe\npeople.\nPLoS\nBiol.\n6\n,\ne184\n(2008).\n13.\nKanehisa,\nM.,\nGoto,\nS.,\nSato,\nY.,\nFurumichi,\nM.\n&\nTanabe,\nM.\nKEGG\nfor\nintegration\nand\ninterpretation \nof\nlarge-scale\nmolecular\ndata\nsets.\nNucleic\nAcids\nRes.\n40\n,\nD109\u201314\n(2012).\n14.\nPillich,\nR.\nT.\net\nal.\nNDEx\nIQuery:\na\nmulti-method\nnetwork\ngene\nset\nanalysis\nleveraging\nthe\nNetwork \nData\nExchange.\nBioinformatics\n39\n,\n(2023).\n15.\nWang,\nS.\net\nal.\nTyping\ntumors\nusing\npathways\nselected\nby\nsomatic\nevolution.\nNat.\nCommun.\n9\n,\n4159 \n(2018).\n16.\nAshburner,\nM.\net\nal.\nGene\nOntology:\ntool\nfor\nthe\nunification\nof\nbiology.\nNat.\nGenet.\n25\n,\n25\u201329\n(2000).\n17.\nGene\nOntology\nConsortium\net\nal.\nThe\nGene\nOntology\nknowledgebase\nin\n2023.\nGenetics\n224\n,\n(2023).\n18.\nKanehisa,\nM.\n&\nGoto,\nS.\nKEGG:\nkyoto\nencyclopedia\nof\ngenes\nand\ngenomes.\nNucleic\nAcids\nRes.\n28\n, \n27\u201330\n(2000).\n19.\nKanehisa,\nM.\nToward\nunderstanding\nthe\norigin\nand\nevolution\nof\ncellular\norganisms.\nProtein\nSci.\n28\n, \n1947\u20131951\n(2019).\n20.\nKanehisa,\nM.,\nFurumichi,\nM.,\nSato,\nY.,\nKawashima,\nM.\n&\nIshiguro-Watanabe,\nM.\nKEGG\nfor \ntaxonomy-based\nanalysis\nof\npathways\nand\ngenomes.\nNucleic\nAcids\nRes.\n51\n,\nD587\u2013D592\n(2023).\n2721.\nCroft,\nD.\nReactome:\nA\ndatabase\nof\nbiological\npathways.\nNature\nPrecedings\n(2010) \ndoi:\n10.1038/npre.2010.5025.1\n.\n22.\nJassal,\nB.\net\nal.\nThe\nreactome\npathway\nknowledgebase.\nNucleic\nAcids\nRes.\n48\n,\nD498\u2013D503\n(2020).\n23.\nSollis,\nE.\net\nal.\nThe\nNHGRI-EBI\nGWAS\nCatalog:\nknowledgebase\nand\ndeposition\nresource.\nNucleic \nAcids\nRes.\n51\n,\nD977\u2013D985\n(2023).\n24.\nBlake,\nJ.\nA.\net\nal.\nThe\nMouse\nGenome\nDatabase\ngenotypes::phenotypes.\nNucleic\nAcids\nRes.\n37\n, \nD712\u20139\n(2009).\n25.\nWeng,\nM.-P.\n&\nLiao,\nB.-Y.\nMamPhEA:\na\nweb\ntool\nfor\nmammalian\nphenotype\nenrichment\nanalysis. \nBioinformatics\n26\n,\n2212\u20132213\n(2010).\n26.\nKeenan,\nA.\nB.\net\nal.\nChEA3:\ntranscription\nfactor\nenrichment\nanalysis\nby\northogonal\nomics\nintegration. \nNucleic\nAcids\nRes.\n47\n,\nW212\u2013W224\n(2019).\n27.\nRubin,\nJ.\nD.\net\nal.\nTranscription\nfactor\nenrichment\nanalysis\n(TFEA)\nquantifies\nthe\nactivity\nof\nmultiple \ntranscription\nfactors\nfrom\na\nsingle\nexperiment.\nCommun\nBiol\n4\n,\n661\n(2021).\n28.\nFranz\u00e9n,\nO.,\nGan,\nL.-M.\n&\nBj\u00f6rkegren,\nJ.\nL.\nM.\nPanglaoDB:\na\nweb\nserver\nfor\nexploration\nof\nmouse \nand\nhuman\nsingle-cell\nRNA\nsequencing\ndata.\nDatabase\n2019\n,\n(2019).\n29.\nZhang,\nX.\net\nal.\nCellMarker:\na\nmanually\ncurated\nresource\nof\ncell\nmarkers\nin\nhuman\nand\nmouse. \nNucleic\nAcids\nRes.\n47\n,\nD721\u2013D728\n(2019).\n30.\nHu,\nC.\net\nal.\nCellMarker\n2.0:\nan\nupdated\ndatabase\nof\nmanually\ncurated\ncell\nmarkers\nin\nhuman/mouse \nand\nweb\ntools\nbased\non\nscRNA-seq\ndata.\nNucleic\nAcids\nRes.\n51\n,\nD870\u2013D876\n(2023).\n31.\nVaswani,\nA.\net\nal.\nAttention\nis\nall\nyou\nneed.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.1706.03762 \n(2017).\n32.\nDevlin,\nJ.,\nChang,\nM.-W.,\nLee,\nK.\n&\nToutanova,\nK.\nBERT:\nPre-training\nof\nDeep\nBidirectional \nTransformers\nfor\nLanguage\nUnderstanding.\nin\nProceedings\nof\nthe\n2019\nConference\nof\nthe\nNorth \nAmerican\nChapter\nof\nthe\nAssociation\nfor\nComputational\nLinguistics:\nHuman\nLanguage\nTechnologies, \nVolume\n1\n(Long\nand\nShort\nPapers)\n4171\u20134186\n(Association\nfor\nComputational\nLinguistics,\n2019).\n33.\nBrown,\nT.\nB.\net\nal.\nLanguage\nModels\nare\nFew-Shot\nLearners.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2005.14165\n(2020).\n34.\nOpenAI.\nGPT-4\nTechnical\nReport.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.2303.08774\n(2023).\n35.\nTouvron,\nH.\net\nal.\nLlama\n2:\nOpen\nFoundation\nand\nFine-Tuned\nChat\nModels.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2307.09288\n(2023).\n36.\nJiang,\nA.\nQ.\net\nal.\nMixtral\nof\nExperts.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.2401.04088\n(2024).\n37.\nGemini\nTeam\net\nal.\nGemini:\nA\nFamily\nof\nHighly\nCapable\nMultimodal\nModels.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2312.11805\n(2023).\n38.\nMoghaddam,\nS.\nR.\n&\nHoney,\nC.\nJ.\nBoosting\nTheory-of-Mind\nPerformance\nin\nLarge\nLanguage\nModels \nvia\nPrompting.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.2304.11490\n(2023).\n39.\nHebenstreit,\nK.,\nPraas,\nR.,\nKiesewetter,\nL.\nP.\n&\nSamwald,\nM.\nAn\nautomatically\ndiscovered \nchain-of-thought\nprompt\ngeneralizes\nto\nnovel\nmodels\nand\ndatasets.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2305.02897\n(2023).\n40.\nCaufield,\nJ.\nH.\net\nal.\nStructured\nprompt\ninterrogation\nand\nrecursive\nextraction\nof\nsemantics\n(SPIRES):\n28A\nmethod\nfor\npopulating\nknowledge\nbases\nusing\nzero-shot\nlearning.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2304.02711\n(2023).\n41.\nWei,\nJ.\net\nal.\nChain-of-Thought\nPrompting\nElicits\nReasoning\nin\nLarge\nLanguage\nModels.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2201.11903\n(2022).\n42.\nMiller,\nG.\nA.\n&\nCharles,\nW.\nG.\nContextual\ncorrelates\nof\nsemantic\nsimilarity.\nLang.\nCogn.\nProcess.\n6\n, \n1\u201328\n(1991).\n43.\nXiong,\nM.\net\nal.\nCan\nLLMs\nExpress\nTheir\nUncertainty?\nAn\nEmpirical\nEvaluation\nof\nConfidence \nElicitation\nin\nLLMs.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.2306.13063\n(2023).\n44.\nFu,\nJ.,\nNg,\nS.-K.,\nJiang,\nZ.\n&\nLiu,\nP.\nGPTScore:\nEvaluate\nas\nYou\nDesire.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2302.04166\n(2023).\n45.\nDuan,\nQ.\net\nal.\nLINCS\nCanvas\nBrowser:\ninteractive\nweb\napp\nto\nquery,\nbrowse\nand\ninterrogate\nLINCS \nL1000\ngene\nexpression\nsignatures.\nNucleic\nAcids\nRes.\n42\n,\nW449\u201360\n(2014).\n46.\nBarrett,\nT.\net\nal.\nNCBI\nGEO:\narchive\nfor\nfunctional\ngenomics\ndata\nsets--update.\nNucleic\nAcids\nRes. \n41\n,\nD991\u20135\n(2013).\n47.\nZheng,\nF.\net\nal.\nInterpretation\nof\ncancer\nmutations\nusing\na\nmultiscale\nmap\nof\nprotein\nsystems.\nScience \n374\n,\neabf3067\n(2021).\n48.\nGroh,\nB.\nS.\net\nal.\nThe\nantiobesity\nfactor\nWDTC1\nsuppresses\nadipogenesis\nvia\nthe\nCRL4WDTC1\nE3 \nligase.\nEMBO\nRep.\n17\n,\n638\u2013647\n(2016).\n49.\nHu,\nY.-H.\net\nal.\nWDFY1\nmediates\nTLR3/4\nsignaling\nby\nrecruiting\nTRIF.\nEMBO\nRep.\n16\n,\n447\u2013455 \n(2015).\n50.\nNing,\nF.\net\nal.\nHes1\nattenuates\ntype\nI\nIFN\nresponses\nvia\nVEGF-C\nand\nWDFY1.\nJ.\nExp.\nMed.\n216\n, \n1396\u20131410\n(2019).\n51.\nYeo,\nI.\nJ.\net\nal.\nPRDX6\nInhibits\nNeurogenesis\nthrough\nDownregulation\nof\nWDFY1-Mediated\nTLR4 \nSignal.\nMol.\nNeurobiol.\n56\n,\n3132\u20133144\n(2019).\n52.\nSchick,\nT.\net\nal.\nToolformer:\nLanguage\nModels\nCan\nTeach\nThemselves\nto\nUse\nTools.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2302.04761\n(2023).\n53.\nYao,\nS.\net\nal.\nReAct:\nSynergizing\nreasoning\nand\nacting\nin\nlanguage\nmodels.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2210.03629\n(2022).\n54.\nFezari,\nM.\n&\nAli-Al-Dahoud,\nA.\nA.\nD.\nFrom\nGPT\nto\nAutoGPT:\na\nBrief\nAttention\nin\nNLP\nProcessing \nusing\nDL.\nresearchgate.net\n.\n55.\nShen,\nY.\net\nal.\nHuggingGPT:\nSolving\nAI\nTasks\nwith\nChatGPT\nand\nits\nFriends\nin\nHugging\nFace. \nhttps://doi.org/10.48550/arXiv.2303.17580\nPreprint\nat\n(2023).\n56.\nNair,\nV.,\nSchumacher,\nE.,\nTso,\nG.\n&\nKannan,\nA.\nDERA:\nEnhancing\nLarge\nLanguage\nModel \nCompletions\nwith\nDialog-Enabled\nResolving\nAgents.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2303.17071\n(2023).\n57.\nShinn,\nN.\net\nal.\nReflexion:\nLanguage\nAgents\nwith\nVerbal\nReinforcement\nLearning.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2303.11366\n(2023).\n58.\nLi,\nG.,\nAl\nKader\nHammoud,\nH.\nA.,\nItani,\nH.,\nKhizbullin,\nD.\n&\nGhanem,\nB.\nCAMEL:\nCommunicative \nAgents\nfor\n\u2018Mind\u2019\nExploration\nof\nLarge\nScale\nLanguage\nModel\nSociety.\nPreprint\nat \nhttps://doi.org/10.48550/arXiv.2303.17760\n(2023).\n2959.\nKeskar,\nN.\nS.,\nMcCann,\nB.,\nVarshney,\nL.\nR.,\nXiong,\nC.\n&\nSocher,\nR.\nCTRL:\nA\nConditional\nTransformer \nLanguage\nModel\nfor\nControllable\nGeneration.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.1909.05858 \n(2019).\n60.\nHoltzman,\nA.,\nBuys,\nJ.,\nDu,\nL.,\nForbes,\nM.\n&\nChoi,\nY.\nThe\nCurious\nCase\nof\nNeural\nText\nDegeneration. \nPreprint\nat\nhttps://doi.org/10.48550/arXiv.1904.09751\n(2019).\n61.\nSmith,\nB.\net\nal.\nThe\nOBO\nFoundry:\ncoordinated\nevolution\nof\nontologies\nto\nsupport\nbiomedical\ndata \nintegration.\nNat.\nBiotechnol.\n25\n,\n1251\u20131255\n(2007).\n62.\nTirmizi,\nS.\nH.\net\nal.\nMapping\nbetween\nthe\nOBO\nand\nOWL\nontology\nlanguages.\nJ.\nBiomed.\nSemantics \n2\nSuppl\n1\n,\nS3\n(2011).\n63.\nLiu,\nF.,\nShareghi,\nE.,\nMeng,\nZ.,\nBasaldella,\nM.\n&\nCollier,\nN.\nSelf-Alignment\nPretraining\nfor\nBiomedical \nEntity\nRepresentations.\nPreprint\nat\nhttps://doi.org/10.48550/arXiv.2010.11784\n(2020).\n64.\nFang,\nZ.,\nLiu,\nX.\n&\nPeltz,\nG.\nGSEApy:\na\ncomprehensive\npackage\nfor\nperforming\ngene\nset\nenrichment \nanalysis\nin\nPython.\nBioinformatics\n39\n,\n(2023).\n30Acknowledgments\nWe\nwould\nlike\nto\nthank\nall\nmembers\nof\nthe\nIdeker\nlab,\nespecially\nXiaoyu\nZhao\nand\nAkshat\nSinghal\nfor\nproofreading\nthe\nmanuscript\nand\nproviding\ninsightful\ncomments,\nChristopher\nChuras\nfor\nhelping\nwith\nthe\norganization\nof\nthe\nGitHub\nrepository.\nThis\nwork\nwas\nsupported\nby\nNational\nInstitutes\nof\nHealth\ngrants\nU24\nCA269436,\nOT2\nOD032742,\n5U24HG012107,\nU01\nMH115747,\nand\nU54\nCA274502.\nAdditional\nsupport\nwas\nreceived\nfrom\nSchmidt\nFutures.\nAuthors\nand\nAffiliations\nDepartment\nof\nMedicine,\nUniversity\nof\nCalifornia\nSan\nDiego,\nLa\nJolla,\nCalifornia,\nUSA\nMengzhou\nHu,\nIngoo\nLee,\nRudolf\nT.\nPillich,\nRobin\nBachelder,\nTrey\nIdeker\n&\nDexter\nPratt\nDepartment\nof\nComputer\nScience\nand\nEngineering,\nUniversity\nof\nCalifornia\nSan\nDiego,\nLa\nJolla,\nCalifornia,\nUSA\nSahar\nAlkhairy\n&\nTrey\nIdeker\nDepartment\nof\nPhysics,\nUniversity\nof\nCalifornia\nSan\nDiego,\nLa\nJolla,\nCalifornia,\nUSA\nKevin\nSmith\nCorresponding\nAuthors\nCorrespondence\nto\nTrey\nIdeker\n(tideker@ucsd.edu)\nand\nDexter\nPratt\n(depratt@ucsd.edu).\nAuthor\nContributions\nM.H.,\nS.A.,\nT.I.,\nand\nD.P.\ndesigned\nthe\nstudy.\nM.H.\nand\nS.A.\ndeveloped\nand\nimplemented\nthe\nautomated\nLLM-based\ngene\nset\ninterpretation\npipeline,\nperformed\nthe\ndata\nanalysis,\nand\norganized\nthe\nGitHub\nrepository.\nS.A.\ndeveloped\nand\nassessed\nthe\nsemantic\nsimilarity\ncalculation.\nI.L.\nand\nM.H.\ncontributed\nto\nthe\ndevelopment\nof\nthe\ncitation\nsearch\nand\nvalidation\npipeline.\nD.P.\ncontributed\nto\nthe\ncoding\nand\nthe\nevaluation\nof\nthe\nanalysis.\nR.P.\nassisted\nin\nthe\nstudy\ndesign,\nprompt\nengineering\nand\nthe\nevaluation\nof\nthe\nanalysis.\nM.H.,\nR.P.,\nR.B.\nand\nD.P.\nconducted\nthe\nscientific\nreview\nof\nthe\nLLM\noutput.\nD.F.\nbuilt\nthe\nweb\n31interface\nfor\nthe\nGSAI\ntool,\nand\nK.S.\nset\nup\nthe\nserver\nfor\nopen-source\nLLMs.\nM.H.,\nS.A.,\nT.I.,\nand\nD.P.\nwrote\nthe\nmanuscript\nwith\ninput\nfrom\nall\nauthors.\nAll\nauthors\napproved\nthe\nfinal\nversion\nof\nthis\nmanuscript.\nAuthor\nDeclarations\nTI\nis\na\nco-founder,\nmember\nof\nthe\nadvisory\nboard,\nand\nhas\nan\nequity\ninterest\nin\nData4Cure\nand\nSerinus\nBiosciences.\nTI\nis\na\nconsultant\nfor\nand\nhas\nan\nequity\ninterest\nin\nIdeaya\nBiosciences.\nThe\nterms\nof\nthese\narrangements\nhave\nbeen\nreviewed\nand\napproved\nby\nthe\nUniversity\nof\nCalifornia\nSan\nDiego\nin\naccordance\nwith\nits\nconflict-of-interest\npolicies.\nData\navailability\nPublicly\navailable\ngene\nsets\nwere\nused\nin\nthis\nstudy.\nGene\nOntology\n(2023-11-15\nrelease)\nis\navailable\nat\nhttp://release.geneontology.org/2023-11-15/ontology/index.html.\nThe\nselected\nNeST\ngene\nset\nis\navailable\nto\ndownload\nfrom\nhttps://github.com/idekerlab/llm_evaluation_for_gene_set_interpretation/blob/main/data/Omics_data/NeS\nT__IAS_clixo_hidef_Nov17.edges.\nThe\nL1000\ndata\nwas\ndownloaded\nfrom\nhttps://maayanlab.cloud/Harmonizome/dataset/LINCS+L1000+CMAP+Signatures+of+Differentially+Expre\nssed+Genes+for+Small+Molecules.\nThe\nviral\ninfection\ndata\nwas\ndownloaded\nfrom\nhttps://maayanlab.cloud/Harmonizome/dataset/GEO+Signatures+of+Differentially+Expressed+Genes+for\n+Viral+Infections.\nCode\navailability\nThe\ncode\nfor\nrunning\nthe\nLLM\ngene\nset\nanalysis\npipeline\nand\nthe\nevaluation\ntasks\nis\navailable\nat\nhttps://github.com/idekerlab/llm_evaluation_for_gene_set_interpretation\nwith\nthe\nMIT\nLicense.\n32Extended\nData\nFigures\nand\nTables\nExtended\nData\nFig.\n1:\nSchematic\nof\nthe\ncitation\nmodule.\na\n,\nGPT-4\nis\nasked\nto\nprovide\ngene\nsymbol \nkeywords\nand\nfunctional\nkeywords\nseparately.\nMultiple\ngene\nkeywords\nand\nfunctions\nare\ncombined\nand \nused\nto\nsearch\nPubMed\nfor\nrelevant\npaper\ntitles\nand\nabstracts\nin\nthe\nscientific\nliterature.\nGPT-4\nis\nqueried \nto\nevaluate\neachresults\nof\nthe\nGPT-4\nname\n/\nGO\nname\nsimilarity\ncomparison.\ne\n,\nHierarchical\nview\nof\nthe\nGO\nterm\n\u201cNegative\nRegulation\nof\nTriglyceride\nCatabolic\nProcess\u201d\nand\nits\nancestors.\nBlue\nbox:\ngene\nset\nquery,\nyellow\nbox:\ngene\nset\nof\nbest\nmatch\nGO\nname\n(most\nsimilar\nGO\nname\nto\nGPT-4\nname),\ndashed\nlines\nwith\narrows:\nsemantic\nsimilarities\nbetween\nnames,\nred\ntext:\nGPT-4\nproposed\nname.\n20Fig.\n3:\nEvaluation\nof\nLLM\nself-confidence.\na,\nInvestigation\nof\nmodel-assigned\nconfidence\nscores\n(chat \nbubbles)\nfor\nthe\nability\nto\ndistinguish\nactual\nGO\nterms\nfrom\n50/50\nmix\nand\nrandom\ngene\nsets\n(light\nDNA \nstrands\nfrom\nthe\nsame\nGO\nterm,\ndark\nDNA\nstrands\nrandomly\nselected\nfrom\noutside\nthe\nGO\nterm).\nb,\nBar \ngraphs\nshowing\nthe\nconfidence\nrating\nassigned\nby\neach\nmodel\nfor\nreal,\ncontaminated,\nor\nrandom\ngene \nsets.\nIncreasingV\nshades\nof\npurple\nindicate\nlow\nto\nhigh\nscore\nbins.\n\u201cHigh\nconfidence\u201d\n(dark\npurple): \n0.87\u20131.00;\n\u201cMedium\nconfidence\u201d\n(medium\npurple):\n0.80\u20130.86;\n\u201cLow\nconfidence\u201d\n(light\npurple):\n0.01\u20130.79; \nand\n\u201cName\nnot\nassigned\u201d\n(gray):\n0.\nFor\ncomparison\nto\nfunctional\nenrichment\n(rightmost\ngroup\nof\nbars), \n\u201cHigh\nconfidence\u201d\nfor\na\ngene\nset\nis\ndefined\nas\np\n\u2264\n0.05\n(dark\npurple,\nBenjamini-Hochberg\ncorrection), \notherwise\n\u201cName\nnot\nassigned\u201d\n(gray)\nis\nused.\nSignificant\ndifference\nin\nconfidence\ndistributions\nbetween \nreal,\n50/50\nmix\nand\nrandom\nis\ndenoted\nby\nasterisks\n(*p<0.05;\n**p<0.01;\n***p<0.001,\n****p<0.0001)\nusing \nchi-squared\ntest.\n21\nTable\n1:\nBest\nand\nworst\nLLM\nnames\nfor\nGO\nterms\nby\nsemantic\nsimilarity.\nGO\nName\n(GO\nterm\nID)\nLLM\nName\nSemantic\nSimilarity\nLLM\nLLM\nNames\nwith\nHighest\nSimilarity\nto\nGO\nNames\nSynaptic\nvesicle\nexocytosis\n(GO:0016079)\nSynaptic\nvesicle\nexocytosis\n1.00\nGemini\nPro\nSynaptic\nvesicle\nexocytosis\n(GO:0016079)\nSynaptic\nvesicle\nexocytosis\nand\nneurotransmitter\nrelease\n0.94\nGPT-3.5\nPentose-phosphate\nshunt\n(GO:0006098)\nPentose\nphosphate\npathway\n0.89\nGPT-3.5\nGlucose-6-phosphate\ntransport\n(GO:0015760)\nGlucose-6-phosphate\nmetabolism\nand\ntransport\n0.89\nMixtral\nInstruct\nProtein\nquality\ncontrol\nfor\nmisfolded\nor\nincompletely\nsynthesized\nproteins\n(GO:0006515)\nProtein\nquality\ncontrol\nand\ndegradation\n0.88\nGPT-4\nLLM\nNames\nwith\nLowest\nSimilarity\nto\nGO\nNames\nnegative\nregulation\nof\nfat\ncell\ndifferentiation\n(GO:0045599)\nRegulation\nof\nWnt\nsignaling\nand\ncellular\nstress\nresponse\n0.13\nGPT-4\nNegative\nregulation\nof\nCD8-positive,\nalpha-beta\nT\ncell\ndifferentiation\n(GO:0043377)\nRegulation\nof\niron\nhomeostasis\n0.11\nLlama2\n70b\nNegative\nregulation\nof\npeptide\nsecretion\n(GO:0002792)\nGlucose\nhomeostasis\nand\nenergy\nmetabolism\n0.09\nGPT-3.5\nNegative\nregulation\nof\npeptide\nsecretion\n(GO:0002792)\nGlucose\nhomeostasis\nand\nenergy\nmetabolism\n0.09\nMixtral\nInstruct\nNegative\nregulation\nof\nCD8-positive,\nalpha-beta\nT\ncell\ndifferentiation\n(GO:0043377)\nRegulation\nof\nion\ntransport\nand\ncellular\nhomeostasis\n0.09\nGPT-3.5\n22Table\n2:\nNumbers\nof\n\u2018omics\ngene\nsets\nannotated\nby\nGPT-4\nversus\nfunctional\nenrichment.\n\u2020\nA\ngene\nset\nis\nannotated\nvia\nGPT-4\nif\nthe\nconfidence\nscore\n\u2265\n0.80 \n\u2021\nA\ngene\nset\nis\nannotated\nvia\nenrichment\nanalysis\nif\nBH-adjusted\np\n\u2264\n0.05\nand\nJaccard\nIndex\n\u2265\n0.10.\n23\nGPT-4\nAnnotated\n\u2020\nNot\nAnnotated\nTotal\nFunctional \nEnrichment\nAnnotated\n\u2021\n36\n4\n40\nNot\nAnnotated\n97\n163\n260\nTotal\n133\n167\n300Table\n3:\nRepresentative\nanalysis\nfor\nprotein\ninteraction\nclusters\n(NeST:\n\u201cCluster2-123\u201d).\nGenes\n(n\n=\n13)\nLYST\nNRDE2\nREN\nSNRP A1\nSNX6\nSNX7\nSNX12\nSOR T1\nTMEM9\nTMEM123\nTMEM189 \nWASHC3\nWDFY1\nAnalysis\nMethod\nAssigned\nName\nConfidence\n/ \nEnrichment\nFDR\n(JI)\nGPT -4\nEndosomal\nSorting\nand\nTrafficking\n0.85\n(Medium)\nGene\nset \nenrichment\nNegative\nRegulation\nof\nLipoprotein\nLipase\nActivity \n(GO:0051005)\n0.036\n(0.059)\nGPT -4\nAnalysis\nParagraph\n1.\nLYST,\nor\nlysosomal\ntrafficking\nregulator ,\nis\ninvolved\nin\nthe\nregulation\nof\nlysosomal\nsize\nand\nmorphology .\nIt\nplays \na\nrole\nin\nthe\nsorting\nand\ntrafficking\nof\nendosomal\ncargo\ndestined\nfor\nlysosomes,\nwhich\nis\ncrucial\nfor\nmaintaining \ncellular\nhomeostasis\nand\nproper\norganelle\nfunction.\nWestphal\net\nal.\n\"Lysosomal\ntrafficking\nregulator\nLyst\nlinks\nmembrane\ntrafficking\nto\ntoll-like \nreceptor-mediated\ninflammatory\nresponses.\"\nThe\nJournal\nof\nexperimental\nmedicine,\n2017,\npp.\n227-244.\nSetaluri.\n\"Sorting\nand\ntargeting\nof\nmelanosomal\nmembrane\nproteins:\nsignals,\npathways,\nand \nmechanisms.\"\nPigment\ncell\nresearch,\n2000,\npp.\n128-34.\nSteffens\net\nal.\n\"Physical,\nFunctional\nand\nGenetic\nInteractions\nbetween\nthe\nBEACH\nDomain\nProtein \nSPIRRIG\nand\nLIP5\nand\nSKD1\nand\nIts\nRole\nin\nEndosomal\nTrafficking\nto\nthe\nVacuole\nin\nArabidopsis.\" \nFrontiers\nin\nplant\nscience,\n2017,\npp.\n1969.\n2.\nNRDE2\nis\nless\ncharacterized\nbut\nis\nthought\nto\nbe\ninvolved\nin\nnuclear\nRNAi\nand\nmay\nplay\na\nrole\nin\nthe\nregulation \nof\ngene\nexpression\nat\nthe\npost-transcriptional\nlevel\n,\npotentially\ninfluencing\nthe\nstability\nor\nlocalization\nof\nspecific \nmRNA\ntranscripts.\nWang\net\nal.\n\"NRDE2\nnegatively\nregulates\nexosome\nfunctions\nby\ninhibiting\nMTR4\nrecruitment\nand \nexosome\ninteraction.\"\nGenes\n&\ndevelopment,\n2019,\npp.\n536-549.\nWan\net\nal.\n\"A\nConserved\nNRDE-2/MTR-4\nComplex\nMediates\nNuclear\nRNAi\nin\nCaenorhabditis\nelegans.\" \nGenetics,\n2020,\npp.\n1071-1085.\nFlemr\net\nal.\n\"Mouse\nnuclear\nRNAi-defective\n2\npromotes\nsplicing\nof\nweak\n5'\nsplice\nsites.\"\nRNA\n(New\nYork, \nN.Y.),\n2023,\npp.\n1140-1 165.\n3.\nREN,\nalso\nknown\nas\nrenin,\nis\nprimarily\ninvolved\nin\nblood\npressure\ncontrol\nand\nelectrolyte\nbalance.\nIt\ncatalyzes \nthe\nconversion\nof\nangiotensinogen\nto\nangiotensin\nI\nand\nis\na\nkey\ncomponent\nof\nthe\nrenin-angiotensin\nsystem \n(RAS),\nwhich\nis\nnot\ndirectly\nrelated\nto\nendosomal\nsorting\nbut\nmay\nbe\naffected\nby\nvesicular\ntrafficking\nprocesses\n.\nGubler\net\nal.\n\"Renin-angiotensin\nsystem\nin\nkidney\ndevelopment:\nrenal\ntubular\ndysgenesis.\"\nKidney \ninternational,\n2010,\npp.\n400-6.\nRossi\net\nal.\n\"Interactions\nbetween\nendothelin-1\nand\nthe\nrenin-angiotensin-aldosterone\nsystem.\" \nCardiovascular\nresearch,\n1999,\npp.\n300-7.\nLiu\net\nal.\n\"AMPK:\na\nbalancer\nof\nthe\nrenin-angiotensin\nsystem.\"\nBioscience\nreports,\n2019.\n4.\nSNRP A1\nis\na\nsmall\nnuclear\nribonucleoprotein\nthat\nis\npart\nof\nthe\nspliceosome\ncomplex.\nIt\nis\ninvolved\nin \npre-mRNA\nsplicing,\na\nprocess\nthat\noccurs\nin\nthe\nnucleus\nand\nis\nnot\ndirectly\nrelated\nto\nendosomal\nsorting.\n24Wu\net\nal.\n\"Major\nspliceosome\ndefects\ncause\nmale\ninfertility\nand\nare\nassociated\nwith\nnonobstructive \nazoospermia\nin\nhumans.\"\nProceedings\nof\nthe\nNational\nAcademy\nof\nSciences\nof\nthe\nUnited\nStates\nof \nAmerica,\n2016,\npp.\n4134-9.\nTanikawa\net\nal.\n\"The\nspliceosome\nU2\nsnRNP\nfactors\npromote\ngenome\nstability\nthrough\ndistinct \nmechanisms;\ntranscription\nof\nrepair\nfactors\nand\nR-loop\nprocessing.\"\nOncogenesis,\n2016,\npp.\ne280.\nKim\net\nal.\n\"The\nunique\nspliceosome\nsignature\nof\nhuman\npluripotent\nstem\ncells\nis\nmediated\nby\nSNRP A1, \nSNRPD1,\nand\nPNN.\"\nStem\ncell\nresearch,\n2017,\npp.\n43-53.\n5.\nSNX6,\nSNX7,\nand\nSNX12\nare\nmembers\nof\nthe\nsorting\nnexin\nfamily .\nThese\nproteins\nare\ninvolved\nin\nendosomal \nsorting\nand\ntrafficking,\nplaying\nroles\nin\nthe\nretromer\ncomplex,\nwhich\nis\nresponsible\nfor\nthe\nretrograde\ntransport\nof \ncargo\nfrom\nendosomes\nto\nthe\ntrans-Golgi\nnetwork.\nBonifacino\nand\nHurley .\n\"Retromer .\"\nCurrent\nopinion\nin\ncell\nbiology ,\n2008,\npp.\n427-36.\nHarterink\net\nal.\n\"A\nSNX3-dependent\nretromer\npathway\nmediates\nretrograde\ntransport\nof\nthe\nWnt\nsorting \nreceptor\nWntless\nand\nis\nrequired\nfor\nWnt\nsecretion.\"\nNature\ncell\nbiology ,\n2011,\npp.\n914-923.\nWassmer\net\nal.\n\"The\nretromer\ncoat\ncomplex\ncoordinates\nendosomal\nsorting\nand\ndynein-mediated \ntransport,\nwith\ncarrier\nrecognition\nby\nthe\ntrans-Golgi\nnetwork.\"\nDevelopmental\ncell,\n2009,\npp.\n110-22.\n6.\nSOR T1,\nor\nsortilin,\nfunctions\nin\nthe\nsorting\nof\nproteins\nto\nthe\nlysosomes.\nIt\nis\ninvolved\nin\nthe\ntransport\nof \nlysosomal\nenzymes\nand\nmay\nalso\nplay\na\nrole\nin\nneurotrophic\nsignaling\nand\napoptosis.\nJansen\net\nal.\n\"Roles\nfor\nthe\npro-neurotrophin\nreceptor\nsortilin\nin\nneuronal\ndevelopment,\naging\nand\nbrain \ninjury .\"\nNature\nneuroscience,\n2007,\npp.\n1449-57.\nStrong\net\nal.\n\"Hepatic\nsortilin\nregulates\nboth\napolipoprotein\nB\nsecretion\nand\nLDL\ncatabolism.\"\nThe\nJournal \nof\nclinical\ninvestigation,\n2012,\npp.\n2807-16.\nS\u00e1nchez\net\nal.\n\"SOR T1\nMutation\nResulting\nin\nSortilin\nDeficiency\nand\np75(NTR)\nUpregulation\nin\na\nFamily \nWith\nEssential\nTremor .\"\nASN\nneuro,\n2015.\n7.\nTMEM9,\nTMEM123,\nand\nTMEM189\nare\ntransmembrane\nproteins\nwith\nless\nwell-characterized\nfunctions. \nHowever ,\ntransmembrane\nproteins\noften\nplay\nroles\nin\ncellular\ntransport\nand\nsignaling,\npotentially\ncontributing\nto \nthe\ntrafficking\nsystem.\nJung\net\nal.\n\"TMEM9\npromotes\nintestinal\ntumorigenesis\nthrough\nvacuolar-A TPase-activated\nWnt/\n\u03b2-\ncatenin \nsignalling.\"\nNature\ncell\nbiology ,\n2018,\npp.\n1421-1433.\nDodeller\net\nal.\n\"The\nlysosomal\ntransmembrane\nprotein\n9B\nregulates\nthe\nactivity\nof\ninflammatory\nsignaling \npathways.\"\nThe\nJournal\nof\nbiological\nchemistry ,\n2008,\npp.\n21487-94.\nJung\net\nal.\n\"TMEM9-v-A TPase\nActivates\nWnt/\n\u03b2-\nCatenin\nSignaling\nVia\nAPC\nLysosomal\nDegradation\nfor \nLiver\nRegeneration\nand\nTumorigenesis.\"\nHepatology\n(Baltimore,\nMd.),\n2021,\npp.\n776-794.\n8.\nWASHC3\nis\npart\nof\nthe\nWASH\ncomplex,\nwhich\nis\ninvolved\nin\nendosomal\nsorting\nand\nthe\nregulation\nof\nactin \npolymerization.\nIt\nplays\na\nrole\nin\nthe\nfission\nof\ntransport\nintermediates\nfrom\nthe\nendosomes.\n9.\nWDFY1\nis\na\nWD\nrepeat\nand\nFYVE\ndomain-containing\nprotein\nthat\nis\nimplicated\nin\nendosomal\nsorting\nand \nsignaling\npathways,\npotentially\nacting\nas\nan\nadaptor\nin\nthe\nendosomal\nsystem\n.\nHu\net\nal.\n\"WDFY1\nmediates\nTLR3/4\nsignaling\nby\nrecruiting\nTRIF .\"\nEMBO\nreports,\n2015,\npp.\n447-55.\nYeo\net\nal.\n\"PRDX6\nInhibits\nNeurogenesis\nthrough\nDownregulation\nof\nWDFY1-Mediated\nTLR4\nSignal.\" \nMolecular\nneurobiology ,\n2019,\npp.\n3132-3144.\nNing\net\nal.\n\"Hes1\nattenuates\ntype\nI\nIFN\nresponses\nvia\nVEGF-C\nand\nWDFY1.\"\nThe\nJournal\nof \nexperimental\nmedicine,\n2019,\npp.\n1396-1410.\n25To\nsummarize,\nthe\nmajority\nof\nthe\nproteins\nin\nthis\nset\nare\ninvolved\nin\nthe\nprocesses\nof\nendosomal\nsorting\nand \ntrafficking,\nwhich\nare\nessential\nfor\nthe\nproper\ndistribution\nand\ndegradation\nof\ncellular\ncomponents.\nWhile\nnot\nall \nproteins\nare\ndirectly\nlinked\nto\nthis\nprocess,\nthe\npreponderance\nof\nsorting\nnexins\nand\nrelated\nproteins\nsuggests\na \nstrong\nfunctional\ntheme.\nThe\npresence\nof\nproteins\nlike\nREN\nand\nSNRP A1,\nwhich\nare\nnot\ndirectly\nrelated\nto \nendosomal\nsorting,\nslightly\nlowers\nthe\nconfidence\nscore.\nHowever ,\nthe\noverall\nfunction\nof\nthe\nsystem\nappears\nto \nbe\ncentered\non\nthe\nendosomal-lysosomal\npathway\nand\nthe\nregulation\nof\ncargo\nsorting\nand\ntrafficking\nwithin\nthe \ncell.\nXu\net\nal.\n\"Lysosomal\nphysiology .\"\nAnnual\nreview\nof\nphysiology ,\n2015,\npp.\n57-80.\n\u2020\nOrange\ntext\n:\nunverified\nstatement\nwith\nunassertive\ntone\n26References\n1.\nZeeberg,\nB.\nR.\net\nal.\nGoMiner:\na\nresource\nfor\nbiological\ninterpretation\nof\ngenomic\nand\nproteomic\ndata. \nGenome\nBiol.\n4\n,\nR28\n(2003).\n2.\nBreitling,\nR.,\nAmtmann,\nA.\n&\nHerzyk,\nP.\nIterative\nGroup\nAnalysis\n(iGA):\na\nsimple\ntool\nto\nenhance \nsensitivity\nand\nfacilitate\ninterpretation\nof\nmicroarrayMethods\n).\nIn\nformulating\nthe\nengineered\nprompt\nfor\nthis\ntask,\nwe\ndid\nnot\nstipulate\nthat\nthe\ntitle\norbackground\nsimilarities\nwere\nthen\nconcatenated\ninto\na\nsingle\nlist,\nsorted\nin\ndescending\norder\n(largest\nto\nsmallest),\nand\nthe\nrank\nof\nthe\nactual\nsimilarity\nwas\nrecorded\nand\nexpressed\nas\na\npercentile.\nThis\npercentile\nscore\nis\nthus\nthe\npercentage\nof\nGO-BP\nterm\nnames\nthat\nare\nless\nsimilar\nto\nthe\nGPT-4\nname\nthan\nto\nthe\nassigned\nname\nof\nthe\nGO\nterm\nquery.\n\u2018Omics\ndata\nprocessing.\nFor\neach\n\u2018omics\nsource\nwe\nselected\ngene\nsets\nwith\na\nsize\nbetween\n3\nand\n100\ngenes.\nFurthermore,\nin\nthe\nL1000\ndataset,\nwe\nselected\nthe\ncontext\nwith\nthe\ngreatest\nnumber\nof\nobservations\n{Cell\nline:\n\"MCF7\",\nduration:\n6.0h,\ndosage:\n10.0\u00b5m}.\nFor\nthe\nViral\ndisease\nperturbations\ndataset,\nwe\nused\na\nz-score\ncutoff\nof\n2.\nEvaluation\nof\nGO\nenrichment.\nWe\nused\nthe\nEnrichr\nweb\nservice\nto\nperform\ngene\nset\nenrichment\nin\nboth\nTask\n1\nand\nTask\n2.\nGO-BP\nterms\nfor\nthe\nqueried\ngene\nset\nwere\nobtained\nusing\nthe\n\u201cgp.enrichr\u201d\nfunction\nfrom\nGSEAPY\npackage\n64\n.\nTask\n1\nutilized\na\ncustom\ninput,\nthe\nGO-BP\n(2023-11-15\nversion\nand\nTask\n2\napplied\npredefined\nparameters\n{gene_sets\n=\n'GO_Biological_Process_2023',\norganism='human'}.\nIn\nTask\n2,\nwe\ncomputed\nthe\nJaccard\nIndex\noverlap\nbetween\nthe\ngene\nset\nof\ninterest\nand\nthe\nGO\nterm.\nFor\ncases\nwith\nmultiple\nsignificant\nGO\nterms\n(adjusted\np-value\n\u2264\n0.05)\nwe\nselected\nthe\nterm\nwith\nthe\nlargest\nJI.\nA\ngene\nset\nwas\nconsidered\nannotated\nby\nenrichment\nanalysis\nif\nthe\nadjusted\np-value\nwas\n\u2264\n0.05\nand\nthe\nlargest\nJI\nwas\n\u2265\n0.1.\nEvaluation\nof\nGPT-4\nfor\n\u2018omics\ngene\nsets.\nFor\neach\n\u2018omics\ngene\nset,\nwe\nqueried\nthe\nGPT-4\npipeline\n(described\nabove)\nfor\na\nname,\nanalysis\ntext,\nand\nconfidence\nscore.\nA\ngene\nset\nwas\nconsidered\nannotated\nby\nGPT-4\nif\nthe\nconfidence\nscore\nwas\n\u2265\n0.8.\n15Identification\nand\nvalidation\nof\nrelevantmethods\nare\nnot\nthe\nfocus\nof\nour\ncurrent\nevaluation.\nOur\nexplorations\ndo,\nhowever,\nrepresent\na\nfuture\ndirection\nfor\nresearch\nin\ngenomic\nanalysis\nand\nthe\ndevelopment\nof\nAI\nmodels.\nOur\nstudy\nhas\nalso\nnot\nattempted\nto\naugment\nLLM\nprompts\nwith\ndescriptions\nof\nthe\nbiological\nand\nexperimental\ncontext\nin\nwhich\na\ngene\nset\nwas\ndiscovered,\ninformation\nthat\nmight\nimprove\nthe\nspecificity,\ndepth,\nand\nquality\nof\nthe\nanalysis.\nFuture\nwork\ncould\nexplore\nthe\ninclusion\nof\ndisease\nand\nexperimental\nconditions\nin\nthe\nprompt\nto\nenable\nthe\nproposal\nof\ncontext-specific\ngene\nfunctions.\nSuch\nprior\ncontext\nhas\nbeen\ndifficult\nto\ncapture\nusing\ngene\nset\nfunctional\nenrichment\ntools,\nsince\ntheir\npre-existing\nmapping\nof\ngene\nsets\nto\nfunctional\nterms\nis\nstatic\nand\ndoes\nnot\nattempt\nto\nencode\nthe\npractically\ninfinite\nspace\nof\nbiological\nconditions.\nIn\nsummary,\none\nmight\nhave\nsuspected\nthat\nusing\nLLMs\nto\nstudy\ngene\nfunction\nwould\nproduce\nstatements,\nhypotheses,\nandabstract,\nsaving\nsupportingDiscussion\nThe\nevaluations\nperformed\nhere\nsuggest\nthat\nLLMs\nhave\nnotable\npotential\nas\nautomated\nassistants\nfor\nunderstanding\nthe\ncollective\nfunctions\nof\ngene\nsets.\nIn\nthe\nanalysis\nof\ngene\nsets\nfrom\nthe\nGene\nOntology\n(GO),\nfour\nout\nof\nfive\nLLMs\nperformed\ncomparably\nin\nproposing\nnames\nsimilar\nto\nthe\nnames\nassigned\nby\nthe\nGO\ncurators,\nwith\nGPT-4\nproducing\nhighly\nsimilar\nnames\nfor\nmost\ngene\nsets.\nLLMs\nshowed\nvarying\nability\nto\nscore\nconfidence\nin\na\nproposed\nname,\nor\nto\nrefuse\nto\ngenerate\na\nname\nin\ncases\nof\nlowest\nconfidence.\nThe\naccompanying\nanalysis\ntext\nwas\nfound\nto\nbe\nlargely\nfactual,\nalthough\nGPT-4\u2019s\noccasional\ngeneration\nof\nunverifiable\nstatements\nshows\nthat\neven\ncurrent\nstate-of-the-art\nLLMs\nshould\nbe\ncoupled\nto\nfact-checking\nand/or\nreference\nvalidation,\nwhether\nautomated\nor\nmanual.\nWhen\nthe\nGPT-4\nname\nfor\na\nGO\ngene\nset\nwas\nnot\nsimilar\nto\nthe\ncurated\nname,\nin\nroughly\na\nthird\nof\nthose\ncases\nit\nwas\nconceptually\nbroader\n(\nFig.\n2d\n).\nFor\nthe\nremaining\ngene\nsets\nwith\ndiscrepant\nnaming,\nit\nis\npossible\nthe\nmismatch\nis\ndue\nto\na\nfailure\nof\nGPT-4\nto\nrecover\na\nwell-documented\ncommon\nfunction\nor\nthat\nthe\nGO\nterm\nno\nlonger\nreflects\nthe\nup-to-date\nliterature.\nAlternatively,\nit\nis\npossible\nthat\nboth\nGPT-4\nand\nGO\noffer\nvalid,\nbut\nalternate,\ninterpretations.\nWe\nindeed\nfind\nanecdotal\nevidence\nfor\nthis\nlast\npossibility:\nfor\nexample,\nDendritic\nCell\nDendrite\nAssembly\n(GO:0097026)\nis\nannotated\nwith\ntwo\nchemokines,\nCCL19\nand\nCCL21,\nand\ntheir\nreceptor\nCCR7,\nbut\nthese\nproteins\nare\nalso\ncritical\nto\nthe\nrelated\nprocess\nof\nlymphocyte\nhoming,\nconsistent\nwith\nthe\nGPT-4\nproposed\nname\n\"Lymphocyte\nHoming\nand\nImmune\nResponse\nRegulation.\u201d\nIn\nother\ncases,\nthe\nnames\nare\nof\ndifferent\ntypes,\nsuch\nas\nthe\nhigh-level\nphenotypic\nGO\nterm\nReproductive\nBehavior\n(GO:0019098),\nwhich\nGPT-4\nnamed\nNeurotransmission\nand\nNeuroendocrine\nSignaling,\nfocusing\ninstead\non\nmolecular\nand\ncellular\nprocesses\n(\nSupplementary\nTable\n2\n).\nThe\ncurrent\nstate\nof\nthe\nart,\nfunctional\nenrichment\nanalysis,\nis\na\nstatistical\nmethod\nto\nquantify\nthe\nagreement\nof\na\ngene\nset\nwith\nsets\nstored\nin\nfixed\ncurated\nreference\ndatabases.\nIn\ncontrast,\nGPT-4\n10synthesizes\ncommon\nfunctions\nfor\ngenes\nbased\non\nactive\nreasoning\nover\na\nlarge\ncorpus\nof\nbiomedical\nknowledge,\nproducingreferences.\nb,\nPrompts\nused\nto\nquery\nthe\nGPT-4\nmodel.\n33\nExtended\nData\nFig.\n2:\nDistribution\nof\nGO\nterm\ngene\nsizes\n.\na,\nDistribution\nof\nterm\nsize\n(number\nof\ngenes)\nfor\nterms\nin\nthe\nBiological\nProcess\nbranch\n(GO-BP).\nTerms\nwith\n3-100\ngenes\nshown\n(n\n=\n8,910).\nb,\nDistribution\nof\nterm\nsize\nfor\nthe\n1000\nGO\nterms\nused\nin\nTask\n1.\nExtended\nData\nFig.\n3:\nEvaluation\nof\nGPT-4\nin\nrecovery\nof\nGO-CC\nand\nGO-MF\nnames.\na\n,\nCumulative\nnumber\nof\nGO-CC\nterm\nnames\nrecovered\nby\nGPT-4\n(y-axis)\nat\na\ngiven\nsimilarity\npercentile\n(x-axis).\n0\n=\nleast\nsimilar,\n100\n=\nmost\nsimilar.\nBlue\ncurve:\nsemantic\nsimilarities\nbetween\nGPT-4\nnames\nand\nassigned\nGO-CC\nterm\nnames.\nGrey\ndashed\ncurve:\nsemantic\nsimilarities\nbetween\nGPT-4\nnames\nand\nrandom\nGO-CC\nterm\nnames.\nThe\nred\ndotted\nline\nmarks\nthat\n642\nof\nthe\n1000\nsampled\nGO-CC\nnames\nare\nrecovered\nby\nGPT-4\nat\na\nsimilarity\npercentile\nof\n95%.\nb\n,\nAs\nfor\npanel\na,\nbut\nfor\nGO-MF\nterms\nrather\nthan\nGO-CC.\nThe\nred\ndotted\nline\nmarks\nthat\n757\nof\nthe\n1000\nsampled\nGO-MF\nnames\nare\nrecovered\nby\nGPT-4\nat\na\nsimilarity\npercentile\nof\n95%.\n34\nExtended\nData\nFig.\n4:\nDistribution\nof\n\u2018omics\ngene\nset\nsizes.\nDistribution\nshown\nfor\nall\n\u2018omics\ngene \nsets\nconsidered\nin\nthis\nstudy\n(n\n=\n300).\nExtended\nData\nFig.\n5:\nEvaluation\nof\nrequired\noverlap.\nThe\npercentage\nof\nomics\ngene\nsets\n(y-axis)\nmatched\nto\nGO\nterms\nwith\nthe\nrequired\noverlap\n(Jaccard\nIndex,\nx-axis).\nThe\nvertical\nred\ndashed\nline\nmarks\na\nthreshold\nJaccard\nIndex\n=\n0.1.\n35\nExtended\nData\nTable\n1:\nEngineered\nprompt\nfor\ngene\nset\nanalysis.\nYou\nare\nan\nefficient\nand\ninsightful\nassistant\nto\na\nmolecular\nbiologist\nWrite\na\ncritical\nanalysis\nof\nthe\nbiological\nprocesses\nperformed\nby\nthis\nsystem\nof\ninteracting\nproteins.\nBase\nyour\nanalysis\non\nprior\nknowledge\navailable\nin\nyour\ntraining\ndata.\nAfter\ncompleting\nyour\nanalysis,\npropose\na\nbrief\nand\ndetailed\nname\nfor\nthe\nmost\nprominent\nbiological\nprocess\nperformed\nby\nthe\nsystem.\nAfter\ncompleting\nyour\nanalysis,\nplease\nalso\nassign\na\nconfidence\nscore\nto\nthe\nprocess\nname\nyou\nselected.\nThis\nscore\nshould\nfollow\nthe\nname\nin\nparentheses\nand\nrange\nfrom\n0.00\nto\n1.00.\nA\nscore\nof\n0.00\nindicates\nthe\nlowest\nconfidence,\nwhile\n1.00\nreflects\nthe\nhighest\nconfidence.\nThis\nscore\nhelps\ngauge\nhow\naccurately\nthe\nchosen\nname\nrepresents\nthe\nfunctions\nand\nactivities\nwithin\nthe\nsystem\nof\ninteracting\nproteins.\nWhen\ndetermining\nyour\nscore,\nconsider\nthe\nproportion\nof\ngenes\nin\nthe\nprotein\nsystem\nthat\nparticipate\nin\nthe\nidentified\nbiological\nprocess.\nFor\ninstance,\nif\nyou\nselect\n\"Ribosome\nbiogenesis\"\nas\nthe\nprocess\nname\nbut\nonly\na\nfew\ngenes\nin\nthe\nsystem\ncontribute\nto\nthis\nprocess,\nthe\nscore\nshould\nbe\nlower\ncompared\nto\na\nscenario\nwhere\na\nmajority\nof\nthe\ngenes\nare\ninvolved\nin\n\"Ribosome\nbiogenesis\".\nPut\nyour\nchosen\nname\nat\nthe\ntop\nof\nthe\nanalysis\nas\n'Process:\n<name>\u2019.\nBe\nconcise,\ndo\nnot\nuse\nunnecessary\nwords.\nBe\nfactual,\ndo\nnot\neditorialize.\nBe\nspecific,\navoid\noverly\ngeneral\nstatements\nsuch\nas\n'the\nproteins\nare\ninvolved\nin\nvarious\ncellular\nprocesses'.\nAvoid\nlisting\nfacts\nabout\nindividual\nproteins.\nInstead,\ntry\nto\ngroup\nproteins\nwith\nsimilar\nfunctions\nand\ndiscuss\ntheir\ninterplay ,\nsynergistic\nor\nantagonistic\neffects\nand\nfunctional\nintegration\nwithin\nthe\nsystem.\nAlso\navoid\nchoosing\ngeneric\nprocess\nnames\nsuch\nas\n'Cellular\nSignaling\nand\nRegulation'.\nIf\nyou\ncannot\nidentify\na\nprominent\nbiological\nprocess\nfor\nthe\nproteins\nin\nthe\nsystem,\nI\nwant\nyou\nto\ncommunicate\nthis\nin\nyou\nanalysis\nand\nname\nthe\nprocess:\n\u201cSystem\nof\nunrelated\nproteins\u201d.\nProvide\na\nscore\nof\n0.00\nfor\na\n\"System\nof\nunrelated\nproteins\".\nTo\nhelp\nyou\nin\nyour\nwork,\nI\nam\nproviding\nan\nexample\nsystem\nof\ninteracting\nproteins\nand\nthe\ncorresponding\nexample\nanalysis\noutput.\nThe\nexample\nsystem\nof\ninteracting\nproteins\nis:\nPDX1,\nSLC2A2,\nNKX6-1,\nGLP1,\nGCG.\nThe\nexample\nanalysis\noutput\nis:\nProcess:\nPancreatic\ndevelopment\nand\nglucose\nhomeostasis\n(0.96)\n1.\nPDX1\nis\na\nhomeodomain\ntranscription\nfactor\ninvolved\nin\nthe\nspecification\nof\nthe\nearly\npancreatic\nepithelium\nand\nits\nsubsequent\ndifferentiation.\nIt\nactivates\nthe\ntranscription\nof\nseveral\ngenes\nincluding\ninsulin,\nsomatostatin,\nglucokinase\nand\nglucose\ntransporter\ntype\n2.\nIt\nis\nessential\nfor\nmaintenance\nof\nthe\nnormal\nhormone-producing\nphenotype\nin\nthe\npancreatic\nbeta-cell.\nIn\npancreatic\nacinar\ncells,\nit\nforms\na\ncomplex\nwith\nPBX1b\nand\nMEIS2b\nand\nmediates\nthe\nactivation\nof\nthe\nELA1\nenhancer .\n2.\nNKX6-1\nis\nalso\na\ntranscription\nfactor\ninvolved\nin\nthe\ndevelopment\nof\npancreatic\nbeta-cells\nduring\nthe\nsecondary\ntransition.\nTogether\nwith\nNKX2-2\nand\nIRX3,\ncontrols\nthe\ngeneration\nof\nmotor\nneurons\nin\nthe\nneural\ntube\nand\nbelongs\nto\nthe\nneural\nprogenitor\n36factors\ninduced\nby\nSonic\nHedgehog\n(SHH)\nsignals.\n3.GCG\nand\nGLP1,\nrespectively\nglucagon\nand\nglucagon-like\npeptide\n1,\nare\ninvolved\nin\nglucose\nmetabolism\nand\nhomeostasis.\nGCG\nraises\nblood\nglucose\nlevels\nby\npromoting\ngluconeogenesis\nand\nis\nthe\ncounter\nregulatory\nhormone\nof\nInsulin.\nGLP1\nis\na\npotent\nstimulator\nof\nGlucose-Induced\nInsulin\nSecretion\n(GSIS).\nPlays\nroles\nin\ngastric\nmotility\nand\nsuppresses\nblood\nglucagon\nlevels.\nPromotes\ngrowth\nof\nthe\nintestinal\nepithelium\nand\npancreatic\nislet\nmass\nboth\nby\nislet\nneogenesis\nand\nislet\ncell\nproliferation.\n4.\nSLC2A2,\nalso\nknown\nas\nGLUT2,\nis\na\nfacilitative\nhexose\ntransporter .\nIn\nhepatocytes,\nit\nmediates\nbi-directional\ntransport\nof\nglucose\nacross\nthe\nplasma\nmembranes,\nwhile\nin\nthe\npancreatic\nbeta-cell,\nit\nis\nthe\nmain\ntransporter\nresponsible\nfor\nglucose\nuptake\nand\npart\nof\nthe\ncell's\nglucose-sensing\nmechanism.\nIt\nis\ninvolved\nin\nglucose\ntransport\nin\nthe\nsmall\nintestine\nand\nkidney\ntoo.\nTo\nsummarize,\nthe\ngenes\nin\nthis\nset\nare\ninvolved\nin\nthe\nspecification,\ndifferentiation,\ngrowth\nand\nfunctionality\nof\nthe\npancreas,\nwith\na\nparticular\nemphasis\non\nthe\npancreatic\nbeta-cell.\nParticularly ,\nthe\narchitecture\nof\nthe\npancreatic\nislet\nensures\nproper\nglucose\nsensing\nand\nhomeostasis\nvia\na\nnumber\nof\ndifferent\nhormones\nand\nreceptors\nthat\ncan\nelicit\nboth\nsynergistic\nand\nantagonistic\neffects\nin\nthe\npancreas\nitself\nand\nother\nperipheral\ntissues.\nHere\nare\nthe\ninteracting\nproteins:\nProteins:\n{protein\nlist}\n\u2020\ntext\ncolor\nmatches\nwith\nFig.\n1a\nprompt\ncolor\n37Extended\nData\nTable\n2:\nOverview\nof\nfive\nlanguage\nmodels.\nModels\nVersion\nrelease\nParams\nContext\nlength\n(tokens)\nCompany\nEstimated\ntime \nusage \n(second/gene \nset)\nEstimated\ncost \n($/gene\nset)\nGPT-4\nTurbo\nNov\n2023\n~1.7T\n128k\nOpenAI\n36.5\n\u2021\n4.8\n10\n-2\u00d7\nGemini\nPro\nDec\n2023\nUnspecified\n32k\nGoogle\n7.9\n0.0\nGPT-3.5\nTurbo\nNov\n2023\n~175B\n16k\nOpenAI\n9.6\n2.8\n10\n-3\u00d7\nMixtral\nInstruct\nDec\n2023\n13B\n(active),\n47B\n(total)\n32k\nMistralAI\n46.4\n0.0\n\u2020\nLlama2\nJuly\n2023\n70B\n4k\nMeta\n61.8\n0.0\n\u2020\n\u2020\nDoes\nnot\nconsider\nthe\ncost\nto\nhost\nan\nopen-source\nmodel.\n\u2021\nGPT-4\ncompute\ntime\nwas\nsignificantly\nshorter\n(1.1s)\nwhen\nasking\nfor\na\ngene\nset\nname\nbut\nnot\nfurther\nanalysis.\n38Supplementary\nInformation\nSupplementary\nTable\n1\nComplete\nanalysis\nof\nGO\nterms,\n50/50\nmix\nand\nrandom\nfor\nall\nmodels\n(related\nto\nTask1:\nFig.\n2\nand\n3)\nSupplementary\nTable\n2\nComplete\nGPT-4\nanalysis\nof\nGO\nterms\n(related\nto\nTask\n1:\nFig.\n3\nand\nTable1).\nSupplementary\nTable\n3\nComplete\nGPT-4\nanalysis\nof\nomics\ngene\nsets\n(related\nto\nTask\n2:\nTable\n2).\nSupplementary\nTable\n4\nReviewer\nfact-checking\nof\nGPT-4\nanalysis\ntext\nand\ncitation\nrelevance\n(related\nto\nTaske\n2:\nTable\n3).\n39Results\nfor\n100\nGO\nterms\nare\nshown\n(dots;\nblack\nhorizontal\nlines\nshow\nmedian\nsemantic\nsimilarities).\nSignificant\ndifference\nin\ndistributions\nis\ndenoted\nby\nasterisks\n(*p<0.05;\n**p<0.01;\n***p<0.001)\nusing\nMann\u2013Whitney\nU\ntest.\nb\n,\nPercentile\ncalibration\nof\nsemantic\nsimilarity\nbetween\nthe\nGO\nand\nGPT-4\nnames\nfor\na\ngene\nset,\nshown\nfor\nthe\nGO\nterm\n\u201cResponse\nto\nX-ray\u201d\nand\nthe\ncorresponding\nGPT-4\nname\n\u201cDNA\nDamage\nResponse\nand\nRepair\u201d.\nThe\nplot\nshows\nthe\nsemantic\nsimilarity\nbetween\nthese\ntwo\nnames\n19\n(vertical\ndark\ngreen\nline,\n0.54)\nversus\nthe\ncomplete\ndistribution\nof\nsemantic\nsimilarity\nscores\nbetween\nthe\nGPT-4\nname\nand\neach\nname\nin\nthe\nGO\nBiological\nProcess\ndatabase\n(GO-BP,\ngray).\nThe\nscore\nof\nthe\nGPT-4\nname\nis\nconverted\nto\na\npercentile,\ni.e.\nthe\npercentage\nof\nall\nnames\nin\nGO\nwith\nlower\nsimilarity\n(here,\n99%).\nRed\ndashed\nline\ndenotes\nthe\n95th\npercentile\nthreshold.\nc\n,\nCumulative\nnumber\nof\nGO\nterm\nnames\nrecovered\nby\nGPT-4\n(y-axis)\nat\na\ngiven\nsimilarity\npercentile\n(x-axis).\n0\n=\nleast\nsimilar,\n100\n=\nmost\nsimilar.\nDark\ngreen\ncurve:\nsemantic\nsimilarities\nbetween\nGPT-4\nnames\nand\nassigned\nGO\nterm\nnames.\nGrey\ndashed\ncurve:\nsemantic\nsimilarities\nbetween\nGPT-4\nnames\nand\nrandom\nGO\nterm\nnames.\nThe\nred\ndotted\nline\nmarks\nthat\n603\nof\n1000\nsampled\nGO\nnames\nare\nrecovered\nby\nGPT-4\nat\nthe\n95th\nsimilarity\npercentile.\nd\n,\nPie\nchart\nsummarizing\nthe", " Introduction\nLarge language models (LLMs) are taking over the world\nof AI. Recent years saw a rapid development of models pri-\nmarily based on the decoder-only Transformer variant [65],\nsuch as GPT [13, 14, 53, 54], PaLM [19], or LLaMA [63].\nPrompt engineering is a resource-efficient approach for\nsolving different LLM tasks. In brief, one includes the task\ndescription within the input sent to an LLM. If this descrip-\ntion is appropriately formulated, the LLM solves the task\nusing its autoregressive token-based mechanism for gener-\nating text. Such prompts may contain example tasks with\nsolutions (few-shot prompting, also referred to as in-context\nlearning (ICL)), or even no example tasks at all (zero-shot\nprompting). In recent years it was shown that this mecha-\nnism can be used to solve a broad set of tasks that involve\nmathematical, commonsense, or symbolic reasoning.\nChain-of-Thought (CoT) [71] is an approach for prompt-\ning, in which one includes the intermediate steps of rea-\nsoning within the prompt (intermediate \u201cthoughts\u201d), besides\nthe task input/output. CoT was shown to significantly im-\nprove the capability of LLMs to solve problems without re-\nsorting to any model updates. One major improvement over\n*Equal contributionCoT, Self-Consistency with CoT (CoT-SC) [67], is a scheme\nwhere multiple CoTs are generated, and then the best one is\nselected as the outcome. More recently, CoT and CoT-SC\nwere extended with Tree of Thoughts (ToT) [43, 75, 77],\nwhich models the LLM reasoning process with a tree. This\nfacilitates using different paths of thoughts, and offers novel\ncapabilities such as backtracking from non-promising out-\ncomes. Unfortunately, the ToT approaches still fundamen-\ntally limit the reasoning abilities within a prompt by impos-\ning the rigid tree structure on the thought process.\nIn this work, we argue that fundamentally more power-\nful prompting can be achieved by enabling LLM thoughts to\nform an arbitrary graph structure. This is motivated by nu-\nmerous phenomena such as human reasoning, brain struc-\nture, or algorithmic execution. When working on a novel\nidea, a human would not only follow a chain of thoughts\n(as in CoT) or try different separate ones (as in ToT), but\nwould actually form a more complex network of thoughts.\nFor example, one could explore a certain chain of reason-\ning, backtrack and start a new one, then realize that a cer-\ntain idea from the previous chain could be combined with\nthe currently explored one, and merge them both into a new\nsolution, taking advantage of their strengths and eliminat-\ning their weaknesses. Similarly, brains form complex net-\nworks, with graph-like patterns such as recurrence [28]. Ex-\necuting algorithms also expose networked patterns, often\nrepresented by Directed Acyclic Graphs. The correspond-\ninggraph-enabled transformations bring a promise of more\npowerful prompting when applied to LLM thoughts, but they\nare not naturally expressible with CoT or ToT.\nWe observe that these (and many other) thought trans-\nformations can be naturally enabled when modeling the\nreasoning process of an LLM as a graph . For this, we\npropose Graph of Thoughts (GoT), an approach that en-\nhances LLMs\u2019 capabilities through networked reasoning\n(contribution #1 ). In GoT, an LLM thought is modeled\nas a vertex, while an edge is a dependency between such\nthoughts. Using GoT, one can aggregate arbitrary thoughts\nby constructing vertices that have more than one incom-\ning edge. Overall, the graph abstraction harnessed by GoT\nseamlessly generalizes CoT and ToT to more complex\nthought patterns, without resorting to any", " Introduction\nBiomedical entity2representation is the founda-\ntion for a plethora of text mining systems in the\nmedical domain, facilitating applications such as\nliterature search (Lee et al., 2016), clinical decision\nmaking (Roberts et al., 2015) and relational knowl-\nedge discovery (e.g. chemical-disease, drug-drug\nand protein-protein relations, Wang et al. 2018).\nThe heterogeneous naming of biomedical concepts\n\u0003Work conducted prior to joining Amazon.\n1For code and pretrained models, please visit: https:\n//github.com/cambridgeltl/sapbert .\n2In this work, biomedical entity refers to the surface forms\nof biomedical concepts, which can be a single word (e.g.\nfever ), a compound (e.g. sars-cov-2 ) or a short phrase (e.g.\nabnormal retinal vascular development ).\nPUBMEDBERT+ SAPBERTPUBMEDBERT\nFigure 1: The t-SNE (Maaten and Hinton, 2008) vi-\nsualisation of UMLS entities under P UBMEDBERT\n(BERT pretrained on PubMed papers) & P UBMED-\nBERT+SAPBERT (PUBMEDBERT further pretrained\non UMLS synonyms). The biomedical names of differ-\nent concepts are hard to separate in the heterogeneous\nembedding space (left). After the self-alignment pre-\ntraining, the same concept\u2019s entity names are drawn\ncloser to form compact clusters (right).\nposes a major challenge to representation learning.\nFor instance, the medication Hydroxychloroquine\nis often referred to as Oxichlorochine (alternative\nname), HCQ (in social media) and Plaquenil (brand\nname).\nMEL addresses this problem by framing it as\na task of mapping entity mentions to uni\ufb01ed con-\ncepts in a medical knowledge graph.3The main\nbottleneck of MEL is the quality of the entity rep-\nresentations (Basaldella et al., 2020). Prior works\nin this domain have adopted very sophisticated\ntext pre-processing heuristics (D\u2019Souza and Ng,\n2015; Kim et al., 2019; Ji et al., 2020; Sung et al.,\n2020) which can hardly cover all the variations\nof biomedical names. In parallel, self-supervised\nlearning has shown tremendous success in NLP via\nleveraging the masked language modelling (MLM)\n3Note that we consider only the biomedical entities them-\nselves and not their contexts, also known as medical concept\nnormalisation/disambiguation in the BioNLP community.arXiv:2010.11784v2  [cs.CL]  7 Apr 2021objective to learn semantics from distributional rep-\nresentations (Devlin et al., 2019; Liu et al., 2019).\nDomain-speci\ufb01c pretraining on biomedical corpora\n(e.g. BIOBERT, Lee et al. 2020 and BIOMEGA-\nTRON , Shin et al. 2020) have made much progress\nin biomedical text mining tasks. Nonetheless, rep-\nresenting medical entities with the existing SOTA\npretrained MLMs (e.g. PUBMEDBERT, Gu et al.\n2020) as suggested in Fig. 1 (left) does not lead to\na well-separated representation space.\nTo address the aforementioned issue, we propose\nto pretrain a Transformer-based language model on\nthe biomedical knowledge graph of UMLS (Boden-\nreider, 2004), the largest interlingua of biomedical\nontologies. UMLS contains a comprehensive col-\nlection of biomedical synonyms in various forms\n(UMLS 2020AA has 4M+ concepts and 10M+ syn-\nonyms which stem from over 150 controlled vocab-\nularies including MeSH, SNOMED CT, RxNorm,\nGene Ontology and OMIM).4We design a self-\nalignment objective that clusters synonyms of the\nsame concept. To cope with the immense size of\nUMLS, we sample hard training pairs from the\nknowledge base and use a scalable metric learning\nloss. We name our model as Self-aligning pre-\ntrained BERT (SAPBERT).\nBeing both simple and powerful, SAPBERTob-\ntains new SOTA performances across all six MEL\nbenchmark datasets. In contrast with the current\nsystems which adopt complex pipelines and hybrid\ncomponents (Xu et al., 2020; Ji et al., 2020; Sung\net al., 2020), SAPBERT applies a much simpler\ntraining procedure without requiring any pre- or\npost-processing steps. At test time, a simple nearest\nneighbour\u2019s search is suf\ufb01cient for making a predic-\ntion. When compared with other domain-speci\ufb01c\npretrained"], "bleu": 0.17572460383031274, "rouge_l": 0.322381930184805, "gpt_metric_score": 1.0, "bert_score": 0.2986902594566345}
{"paper_key": "Large language models in bioinformatics: applications and perspectives", "current_5q": "**[Question 1] - What is the problem?**  \nHow can large language models (LLMs) be effectively applied to various bioinformatics tasks, such as genomics, transcriptomics, proteomics, drug discovery, and single-cell analysis?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for the research community as it can significantly enhance the capabilities of bioinformatics by leveraging the advanced understanding and generative abilities of LLMs. This integration could lead to breakthroughs in biological research, personalized medicine, and drug development, ultimately advancing our knowledge of complex biological systems. Furthermore, successful applications of LLMs in bioinformatics could inspire future research to explore novel methodologies and interdisciplinary approaches, fostering innovation across both fields.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in applying LLMs to bioinformatics stem from the complexity of biological data, which often requires domain-specific knowledge and understanding of intricate biological processes. Naive approaches may fail due to the high dimensionality and variability of biological data, as well as the need for models to generalize across different biological contexts. Additionally, the lack of labeled datasets for certain bioinformatics tasks and the potential for overfitting when fine-tuning on small datasets present significant technical and practical obstacles that must be addressed.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on traditional machine learning methods or domain-specific algorithms that may not fully exploit the capabilities of LLMs. Limitations in computational resources, the complexity of biological data, and a lack of interdisciplinary collaboration have hindered progress. Additionally, existing solutions may not have adequately addressed the unique challenges posed by bioinformatics tasks. Our approach aims to bridge these gaps by integrating LLMs with tailored methodologies that account for the specific characteristics of biological data, thereby improving upon prior work.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves utilizing pre-trained large language models, such as BERT and GPT, and fine-tuning them on specific bioinformatics datasets relevant to genomics, transcriptomics, proteomics, drug discovery, and single-cell analysis. We will employ metrics such as accuracy, F1 score, and area under the curve (AUC) to evaluate model performance. The expected outcomes include improved predictive capabilities for biological tasks, enhanced understanding of biological sequences, and the generation of novel insights that could lead to practical applications in healthcare and research.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question this proposal aims to address is: How can a machine learning-based framework that integrates a specialized large language model for bioinformatics and real-time security assessment techniques improve the interpretation of complex biological data while ensuring the security of Trigger-Action Programming (TAP) systems?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem has significant implications for both the fields of bioinformatics and cybersecurity. By integrating a tailored large language model with real-time security assessments, this research could advance our understanding of complex biological data, particularly in genomics and drug discovery. This innovative approach may lead to the development of more accurate and context-aware hypotheses, ultimately enhancing experimental validation processes. Furthermore, addressing the dual challenge of data interpretation and system security could lead to safer automated systems in bioinformatics, fostering trust and adoption of emerging technologies. The outcomes of this research are expected to stimulate future studies in interdisciplinary domains, bridging gaps between machine learning, biology, and cybersecurity.\n\n[Question 3]: Why is it hard?  \nThis problem presents several challenges and complexities. First, the integration of a large language model tailored for bioinformatics with real-time security assessment techniques requires a sophisticated understanding of both biological ontologies and the security vulnerabilities inherent in TAP systems. Naive approaches may fail due to the intricacies of biological data, which often involves high-dimensional and noisy datasets that complicate accurate hypothesis generation. Additionally, existing security models may not adequately account for the dynamic nature of user behavior and environmental contexts, leading to ineffective anomaly detection. The technical hurdles include the need for robust machine learning algorithms that can process and analyze large-scale biological data while simultaneously adapting security measures in real time. This dual focus necessitates a multidisciplinary approach, blending knowledge from bioinformatics, machine learning, and cybersecurity.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has largely focused on either enhancing bioinformatics tools for data analysis or improving security measures in automated systems, but seldom have these areas intersected. Gaps in existing literature include a lack of specialized models that combine biological knowledge with security assessments. Barriers to solving this problem include the absence of frameworks that can dynamically adapt to user behavior while accurately interpreting biological data. Additionally, the complexity of biological ontologies and the evolving nature of security threats present significant limitations. This proposal seeks to improve upon prior work by introducing an integrated framework that utilizes knowledge graphs and biological ontologies to inform both data interpretation and security assessments, thereby addressing the shortcomings of past research.\n\n[Question 5]: What are the key components of my approach and results?  \nThe proposed methodology involves developing a machine learning framework that combines a specialized large language model with anomaly detection techniques tailored for TAP systems. The framework will utilize biological ontologies and knowledge graphs to generate context-aware hypotheses, which will be validated through experimental setups in genomics and drug discovery. The dataset will consist of genomic sequences, biological annotations, and user behavior logs from TAP systems. Metrics for evaluation will include hypothesis accuracy, system response time, and the effectiveness of security measures in detecting anomalies. Expected outcomes include a validated framework that enhances the interpretation of complex biological data while providing robust security assessments, leading to safer and more effective automated systems in bioinformatics.", "referenced_intros": [], "bleu": 0.16034599365680424, "rouge_l": 0.30136986301369867, "gpt_metric_score": 0.5, "bert_score": 0.2927285432815552}
{"paper_key": "Northeast Materials Database (NEMAD): Enabling Discovery of High Transition Temperature Magnetic Compounds", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we discover novel magnetic materials with greater operating temperature ranges using more abundant elements, while effectively navigating the vast combinatorial space of possible compositions?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for advancing the field of material science, particularly in the development of high-performance permanent magnets that can enhance the efficiency of renewable energy technologies and data storage solutions. By identifying new magnetic materials, we can reduce reliance on rare earth elements, which are limited in availability and often environmentally damaging to extract. This research could lead to significant advancements in energy technologies, medical equipment, and consumer electronics, ultimately contributing to global energy sustainability and technological innovation.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in discovering novel magnetic materials stem from the vast combinatorial space of potential compositions, which makes it difficult to systematically explore and evaluate all possibilities. Conventional methods often fail due to their limitations in handling complex relationships between material composition, structure, and properties. Additionally, the intricate interplay of chemical and physical properties requires sophisticated feature engineering that balances domain expertise with data-driven insights. Naive approaches may overlook critical interactions and lead to suboptimal material selections.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has been limited by the reliance on traditional experimental methods and a lack of comprehensive data-driven approaches to material discovery. Many studies have focused on known magnetic materials without adequately exploring the potential of new compositions. Barriers such as the complexity of feature engineering and the need for advanced computational techniques have hindered progress. Our approach differs by employing a systematic feature engineering strategy that captures the elemental composition and structural properties of materials, enabling a more thorough exploration of the material space.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves creating an 84-dimensional elemental proportion vector for each compound based on its chemical composition, which captures the distribution of elements. We will also incorporate additional features related to atomic properties, such as the average atomic number of each compound. The dataset will consist of various magnetic materials, and we will evaluate our models using metrics such as predictive accuracy and material performance. The expected outcomes include the identification of novel magnetic materials with enhanced properties and broader operating temperature ranges, paving the way for practical applications in energy and technology sectors.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question this proposal aims to address is: How can a hybrid machine learning framework that integrates graph neural networks with the Northeast Materials Database (NEMAD) be developed to optimize the design of novel magnetocaloric materials for refrigeration applications?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem has significant implications for both the research community and practical applications in refrigeration technologies. The magnetocaloric effect (MCE) presents a promising alternative to conventional gas-compression refrigeration, potentially leading to more efficient and environmentally friendly cooling solutions. By leveraging advanced machine learning techniques to explore the vast materials space, this research could expedite the discovery of high-performance magnetocaloric materials, significantly enhancing cooling efficiencies in the critical temperature range of 10 K to 100 K. The findings could inspire future research in materials science, energy efficiency, and sustainable technologies, ultimately impacting industries reliant on refrigeration.\n\n[Question 3]: Why is it hard?  \nThe complexities of this problem stem from a combination of factors. First, the design of magnetocaloric materials involves intricate relationships between their geometric properties, chemical composition, and structural parameters, which are not easily captured by traditional modeling approaches. Naive methods may fail to account for the non-linear interactions and topological features inherent in the materials' behavior. Additionally, the iterative nature of refining predictions based on experimental results introduces challenges in data integration and model training. The need for high-quality experimental data, coupled with the necessity of accurately simulating the MCE across diverse materials, presents substantial technical and theoretical obstacles that must be overcome.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on either computational modeling or experimental approaches in isolation, leading to a gap in integrated methodologies that combine both. Existing machine learning models may lack the capability to effectively process the complex relationships present in magnetocaloric materials, resulting in suboptimal predictions. Additionally, barriers such as limited datasets and insufficient computational resources have hindered the exploration of the full materials space. This proposal differentiates itself by employing a hybrid framework that utilizes graph neural networks to capture the intricate geometric and topological features of materials, thereby enhancing predictive accuracy and enabling a more systematic approach to material discovery.\n\n[Question 5]: What are the key components of my approach and results?  \nThe proposed methodology involves the development of a hybrid machine learning framework that combines graph neural networks with the NEMAD database to analyze magnetocaloric materials. The approach will include the following key components: (1) Data Collection: Curating a comprehensive dataset from NEMAD that includes chemical compositions, structural parameters, and experimentally determined MCE values. (2) Model Development: Designing and training graph neural networks to identify relationships between material properties and performance metrics. (3) Iterative Feedback: Implementing an iterative feedback loop where the model refines its predictions based on new experimental results. (4) Evaluation Metrics: Utilizing metrics such as predictive accuracy, Curie temperature optimization, and cooling efficiency to assess model performance. The expected outcomes include the identification of novel high-performance magnetocaloric materials, providing a roadmap for future research and practical applications in solid-state refrigeration technologies.", "referenced_intros": [" INTRODUCTION\nSolid-state refrigeration presents a groundbreaking avenue driven by the pressing need for\nmore sustainable and efficient cooling technologies [1\u20134]. Specifically, magnetic refrigeration\nshows promise in solid-state cooling applications across a wide temperature range. Magnetic\nrefrigeration is based on the magnetocaloric effect (MCE), where the entropy of a magnetic\nmaterial (the \u201cmagnetic refrigerant\u201d) is controlled by an external magnetic field [1]. When\nan external magnetic field is applied, the microscopic magnetic moments are aligned with\nthe field. As a result, the entropy associated with the magnetic moments in the material is\nreduced. In the process, either heat is released under an isothermal condition or the tem-\nperature of the magnetic refrigerant is increased under an adiabatic condition. When the\nmagnetic field is removed, the effect is reversed. These processes can be combined to form a\nthermodynamic cooling cycle, whose cooling capacity is determined by the isothermal mag-\nnetocaloric entropy change (\u2206 SM) and the adiabatic temperature change (\u2206 Tad) during the\nmagnetization and demagnetization processes. This cycle resembles a Carnot cycle on the\nS-Tdiagram, promising close-to-ideal efficiency [5]. Compared with other cooling technolo-\ngies, magnetic refrigeration has received renewed interest thanks to its solid-state nature,\ncryogen-free operation, reliability, compactness, and capability to reach close-to-Carnot ef-\nficiency at cryogenic temperatures [6]. For these reasons, magnetic refrigeration has been\nwidely applied for applications in space missions [7], scientific instrumentation [8], and as\nan environmentally friendly alternative to vapor compression-based cooling [9]. However,\nmost previous investigations of magnetic refrigeration have focused on either cryogenic tem-\nperatures below a few K or near room temperature, while many technologically important\napplications require efficient cooling in the temperature range between 10 K and 100 K, such\nas hydrogen and methane liquefaction [10] and cryogenic carbon capture [11].\nTo achieve efficient magnetic refrigeration in this temperature range, one key requirement\nis to identify new high-performance magnetic refrigerants with their Curie temperature ( TC)\nin this range, since both \u2206 SMand \u2206 Tadare typically maximized near TC. Therefore, TCsig-\nnifies the ideal working temperature for an MCE material and stands as a crucial parameter\nfor identifying new magnetic refrigerants. In addition, large magnetic moments and favorable\nexchange interactions [12] are fundamental prerequisites for a material to exhibit favorable\nMCE characteristics. In this context, rare-earth-based alloys are state-of-the-art candidates\n2for magnetocaloric refrigeration in the intermediate temperature range. For example, heavy\nrare-earth-based MCE materials, such as HoB 2, [13, 14] ErCo 2, [15] DyAl 2, [16, 17] and\nErAl 2, [16] exhibit significant \u2206 SMand \u2206 Tadvalues in this temperature range due to their\nlarge magnetic moments. Consequently, they are actively researched for applications like\nhydrogen liquefaction because they have TCwithin the required range [18\u201320]. Their typi-\ncal isothermal entropy change \u2206 SMis around 20-30 J kg\u22121K\u22121and adiabatic temperature\nchange \u2206 Tadis around 10 K for an applied magnetic field of 5 T. Historically, these MCE\nmaterials were discovered mainly through an experimental synthesis and characterization\nprocess, which can be expensive, time-consuming, and often relies on trial and error.\nTo make further progress, more efficient methods, J. Appl. Phys. 123(2018).\n[23] Y. Zhang and X. Xu, Machine learning the magnetocaloric effect in manganites from compo-\nsitions and structural parameters, AIP Adv. 10(2020).\n[24] A. G. Kusne, T. Gao, A. Mehta, L. Ke, M. C. Nguyen, K.-M. Ho, V. Antropov, C.-Z. Wang,\nM. J. Kramer, C.", " Introduction\nMagnetic materials play an indispensable role in modern sci-\nence and engineering domains. Their applications span a wide\nrange, from data storage devices like hard disks and tapes to\nelectrical power conversion and transmission systems, and ex-\ntend to medical and consumer electronics. The unique mag-\nnetic properties of these materials enable various technological\napplications to function e fficiently and precisely [1, 2].\nWhile discovering antiferromagnets is relatively easy due to\nthe superexchange nature therein[3], predicting new ferromag-\nnets poses significant challenges. The interplay of the corre-\nlation and itinerancy is believed to be the origin of most fer-\nromagnetism, but a complete understanding is yet to be avail-\nable [4]. The first-principles calculations, such as density func-\ntional theory (DFT), are generally accurate in determining the\nenergy of non-magnetic materials. Unfortunately, they often re-\nsult in incorrect predictions of magnetic properties, especially\nfor magnetic materials where the electronic correlation is rel-\nevant, particularly ferromagnetism. Many magnetic materials\nare strongly correlated, and one often has to go beyond DFT\nor DFT +U approaches [5]. Moreover, the limitations of the\nDFT+U method in predicting magnetic structures are demon-\nstrated by the disagreement between the observed experimental\nand the calculated magnetic configurations [6]. Another draw-\nback of the DFT calculations is that to get a successful descrip-\ntion of exchange interactions in some materials (like antiferro-\nmagnetic Mn 3O4), one has to use hybrid exchange-correlation\nfunctionals, which have a considerable computational cost [7].\nAnother study [8] also suggests that none of the functionals\nEmail addresses: yibo.zhang@unh.edu (Yibo Zhang),\njiadong.zang@unh.edu (Jiadong Zang)work in all conditions, indicating the need for further devel-\nopment of exchange-correlation functionals. The paramount\nimpact is clearly doomed if a reliable way of predicting new\nferromagnets cannot be achieved.\nData-driven materials discovery is an e ffective solution to\nthis challenge. For example, the high-throughput (HT) methods\nThis section presents a comprehensive overview of the work-\nflow employed in GPTArticleExtractor. Our principal aim is toTable 1: Prompts\nTask Prompt\n\u2460Study Type\nFilterBased on the provided abstract from an article and use\nGPT-3.5, guided by question \u2460, for an initial screening to iden-\ntify articles focused on new material research. If the model\ndeems it relevant (judged as True), we proceed to the next step:vectorizing the article using a vector database. This vectoriza-\ntion allows us to find the most relevant snippets based on spe-\ncific sub-questions ( \u2461,\u2462,\u2463,\u2464). These snippets and the ques-\ntions are fed back into GPT-3.5, which generates corresponding\nanswers. This step can also be regarded as a form of text sum-\nmary. Finally, these answers, along with question \u2465, are fed\ninto GPT-4 for answer aggregation and structuring, which are\nthen inserted into the database.\n3. references.\nTitle: {title }, Results\nUsing GPTExtractor, 4,639 articles were identified to report\nmagnetic materials. To evaluate the algorithm\u2019s e ffectiveness,\nwe manually checked the GPT-generated entry with the origi-\nnal article. As shown in Figure 2, 44.5% entries have complete\nstructural and transition temperature information. These entries\nare ready to be included in the database. 15.5% and 20.4%\nare attributed to structure and temperature only, respectively.\nThese articles may be used as backup options and could be in-\ncorporated into the final database once the missing information\nis supplied. Noticeably, 2.8% entries are extracted from the-\nory papers only. Most transition temperatures therein are com-\nputed by Monte Carlo simulations or combined with the first-\nprinciples calculations. Since only experimentally verified data\nare included in this", "methods,\u201d\nComputational Materials Science 151, 41\u201348 (2018).\n31T. Long, N. M. Fortunato, Y . Zhang, O. Gut\ufb02eisch, and H. Zhang, \u201cAn\naccelerating approach of designing ferromagnetic materials via machine\nlearning modeling of magnetic ground state and curie temperature,\u201d Ma-\nterials Research Letters 9, 169\u2013174 (2021).\n32H. C. Dam, V . C. Nguyen, T. L. Pham, A. T. Nguyen, K. Terakura,\nT. Miyake, and H. Kino, \u201cImportant descriptors and descriptor groups of\ncurie temperatures of rare-earth transition-metal binary alloys,\u201d Journal of\nthe Physical Society of Japan 87, 113801 (2018).\n33X. Hu, Y . Zhang, S. Fan, X. Li, Z. Zhao, C. He, Y . Zhao, Y . Liu, and\nW. Xie, \u201cSearching high spin polarization ferromagnet in heusler alloy via\nmachine learning,\u201d J. Phys.: Condens. Matter 32, 205901 (2020).\n34S. Lu, Q. Zhou, Y . Guo, and J. Wang, \u201cOn-the-\ufb02y interpretable machine\nlearning for rapid discovery of two-dimensional ferromagnets with high\nCurie temperature,\u201d Chem 8, 769\u2013783 (2022).\n35F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel,\nM. Blondel, P. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, \u201cScikit-learn:\nMachine learning in Python,\u201d Journal of Machine Learning Research 12,\n2825\u20132830 (2011).\n36P. V . Balachandran, \u201cMachine learning guided design of functional materi-\nals with targeted properties,\u201d Computational Materials Science 164, 82\u201390\n(2019).\n37P. V . Balachandran, D. Xue, and T. Lookman, \u201cStructure\u2013curie temperature\nrelationships in batio 3-based ferroelectric perovskites: anomalous behavior\nof (ba, cd) tio 3 from dft, statistical inference, andresults suggest that DS1 is large\nenough to make an accurate model using our original frac-\ntional features. While the size of ML model using the MAST-\nML descriptors is signi\ufb01cantly smaller than the size of the\nmodel using the composition-only descriptors, both models\nhave the same accuracy and both are ef\ufb01cient enough to be\nused in the large searches below. Our \ufb01nal models used the6\ncomposition-only descriptors.\nGetting more balanced training data may be another way to\nimprove the model. An analysis of DS1 shows a signi\ufb01cant\nimbalance, 38% of the magnetic materials have a TC0\u0000100\nK, while only 15% have a TC600\u00001400 K. This could lead\nthe model to reduce the prediction error at low temperatures\nat the expense of making larger errors at high temperatures.\nThis is counter to the purpose of the model, which is that to\ndiscover candidate high- TCmagnets. Thus, we downsampled\nthe low- TCcompounds to more evenly distribute DS1. The re-\nsulting model is shown in Fig. 6. Even though there is a high\ndensity of low- TCcompounds, apparently they are necessary\nfor accurate predictions of higher- TCcompounds. The bal-\nanced data predictions for high TCmaterials are not as good\nas with the origin model, with an accuracy of 10% less within\n50 K, 14% less within 100 K, and the mean absolute error 14 K\nhigher.\nLet us make one \ufb01nal comment before using the ML model\nto search for new high- TC. With this unprecedented large\ndatabase of magnetic compounds, a large range of training\nset sizes are possible so that the learning rate of the model can\nbe estimated. Figure 7 shows the MAE on a test set of 850\ncompounds (approximately 1/3 the size of DS1, similar to the\npredictions in Fig. 3) while the training set is increased, us-\ning the remaining data. The process was repeated 100 times\nand averaged. A linear \ufb01t reveals", " INTRODUCTION\nAutomated data extraction is increasingly used to de-\nvelop databases in materials science and other fields [1].\nMany databases have been created using natural lan-\nguage processing (NLP) and language models (LMs) [2\u2013\n24]. Recently, the emergence of large language models\n(LLMs) [25\u201329] has enabled significantly greater ability\nto extract complex data accurately [30, 31]. Previous au-\ntomated references identification, and in-\nformation retention capabilities for text within a conver-\nsation. These capabilities, combined with prompt en-\ngineering , which is the process of designing questions\n\u2217mppolak@wisc.edu\n\u2020ddmorgan@wisc.eduand instructions (prompts) to improve the quality of re-\nsults, can result in accurate data extraction without the\nneed for fine-tuning of the model or significant knowledge\nabout the property for which the data is to be extracted.\nPrompt engineering has now become a standard prac-\ntice in the field of image generation [32\u201334] to ensure\nhigh quality RESULTS AND DISCUSSION\nA. Description of the Data Extraction Workflow\nFigure 1 shows a simplified illustration of the\nChatExtract workflow. The full workflow with all of\nthe steps is shown in Fig. 2 so here we only summarize\nthe key ideas behind this workflow. The initial step is\npreparing the data and involves gathering papers, remov-\ning html/xml syntax and dividing into sentences. This\ntask is straightforward, standard for any data extraction\neffort, and described in detail in other works[31].\nThe data extraction is done in two main stages:\n(A) Initial classification with a simple relevancy prompt,\nwhich is applied to all sentences to weed out those that\ndo not contain data.\n(B) A series of prompts that control the data extrac-\ntion from the sentences categorized in stage (A) as posi-\ntive (i.e., as relevant to the materials data at hand). To\nachieve high performance in Stage (B) we have developed\na series of engineered prompts and the key Features of\nthe major Stage (B) are summarized here:\n(1) Split data into single- and multi-valued, since textscontaining a single entry are much more likely to be ex-\ntracted properly and do not require follow up prompts,\nwhile extraction from texts containing multiple values is\nmore prone to errors and requires further scrutinizing and\nverification.\n(2) Include explicitly the possibility that a piece of the\ndata may be missing from the text. This is done to dis-\ncourage the model from hallucinating non-existent data\nto fulfill the task.\n(3) Use uncertainty-inducing redundant prompts that\nencourage negative answers when appropriate. This lets\nthe model reanalyze the text instead of reinforcing pre-\nvious answers.\n(4) Embed all the questions in a single conversation as\nwell as representing the full data in each prompt. This\nsimultaneously takes advantage of the conversational in-\nformation retention of the chat tool while each time re-\ninforcing the text to be analyzed.\n(5) Enforce a strict Yes/No format of answers to reduce\nuncertainty and allow for easier automation.\nStage (A) is the first prompt given to the model. This\nfirst prompt is meant to provide information whether\nthe sentence is relevant at all for further analysis, i.e.\nwhether it contains the data for the property in question\n(value and units). This classification is crucial because,\neven in papers that have been extracted to be relevant by\nan initial keyword search, the ratio of relevant to irrele-\nvant sentences is typically about 1:100. Therefore elim-\nination of irrelevant sentences is a priority in the first\nstep. Then, before starting Stage (B), we expand the\ntext on which we are operating to a", " INTRODUCTION\nSince the dawn of modern science, there has been a con-\ntinuous, exponential growth in the volume of published sci-\nentific literature [1]. When related to materials science, such\nan abundance of data clearly offers a wide range of possibil-\nities and opportunities. Materials data, in fact, can provide\nthe foundation for models and theories to navigate the phys-\nical/chemical space and ultimately drive discovery. Unfortu-\nnately, access to information from unstructured literature at\nsuch a massive scale presents significant technical and prac-\ntical challenges. As a result, in general, curated databases\nare scarce and often limited to theoretical data only. This is\nbecause for theory data one does not need to exploit the lit-\nerature, but simply to run highly standardised first-principles\ncalculations, which are amenable to automated collection [2\u2013\n5]. Importantly, large-scale theoretical datasets have been\nproven to be a revolutionary tool in the search for new mate-\nrials with unique properties and for the discovery of intricate\nmaterials trends. For instance, they have been used to pre-\ndict the existence of novel magnets [6], to identify materials\nregions favourable to superconductivity [7], to design novel\nhigh-entropy alloys [8], to identify low-thermal-conductivity\ncompounds [9], or to predict the zTthermoelectric figure of\nmerit in inorganic materials [10], just to name a few exam-\nples. Furthermore, theory datasets have been a platform for\nconstructing machine-learning (ML) models with enhanced\nthroughput [11\u201313].\nAlthough no calculation can replace an experiment,\ndatabases containing experimental RESULTS & DISCUSSION\nWe have proposed a workflow to automatically extract\nstructured data from unstructured scientific literature. This\nhas minimal need for an extensive implementation effort\nand little or no requirement for familiarity with complex\ngrammar-rule definitions and natural language processing.\nWe have then shown some possible use cases, demonstrat-\ning the ability to generate a database of ferromagnetic Curie\ntemperatures and electronic band gaps comparable to the\none generated using ChemDataExtractor, the state-of-the-art\nrule-based method for data mining from the scientific litera-\nture. This work opens the door for rapid and easy access toexperimental-property databases for materials informatics ap-\nplications.\nCrucially, we have carefully benchmarked the constructed\ndatabases against manually curated reference ones, through\nextensive query tests. These have allowed us to critically as-\nsess the benefit of certain design choices in our workflow, such\nas the relation-extraction step. Most importantly, we have\nbeen able to understand where improvements can be made and\nwhether these are general or specific to the physical property\nextracted.\nFinally, we have tested whether our automatically extracted\ndatabases of compounds and their properties can be used as a\nplatform for constructing machine-learning models, namely\nwhether the database quality is sufficiently high for inte-\ngration in a material-discovery workflow. We have found\nthat the mean absolute error of chemical-informed random-\nforest models, constructed over the automatically extracted\ndatabase, is always larger than that achieved with manually\ncurated ones, roughly by a factor of two. Our best Results are presented for the test sets. Here\nwe report: precision, P, recall, R, and F1score. The size of the\ntest (TeS) and training (TrS) sets are also given (number of sentences\nused). For the case of NER, we report Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP) , 3615\u20133620 (Associ-\nation for Computational Linguistics, Hong Kong, China, 2019).\nURLhttps://aclanthology.org/D19-1371 .\n[33] Araci, D. FinBERT: Financial sentiment analysis with pre-\ntrained language models. Preprint at: https://arxiv.\norg/abs/1908.10063 (2019).\n[34] Lee, J. et al. BioBERT: a pre-trained biomedical", " Introduction\nThe \ufb01rst synthesis of graphene opened a new\nera for two-dimensional (2D) materials.1These\nmaterials, with strong in-plane and weak in-\nterlayer interactions, enclose nearly all elec-\ntronic and optical phenomena found in solids.\nThe subsequent experimental realization and\ntheoretical insights of other 2D materials2\nhavein\ufb02uencedandtransformedourfundamen-tal understanding of materials properties. It\nalso envisaged and put forward several tech-\nnological applications in many areas of con-\ndensed matter physics, chemistry, and mate-\nrials science. In this 2D materials revolution,\nsome breakthroughs were achieved including\nthe discovery of superconductivity in rotated\nbilayer graphene,3the theoretical description of\nsymmetry protected topological phases in bis-\nmutene4and the extremely high electron mo-\n1arXiv:2201.12630v1  [cond-mat.mtrl-sci]  29 Jan 2022bilities in phosphorene.5Although 2D materi-\nalsphysicsoverlapsmanyotherwell-established\nareas, historically, it has been anticipated the\nexistence of mutual exclusion with magnetism,\ni.e., long-range ordering of spin and orbital\nmagnetic moments.6This brings limitations for\nthe integration of 2D materials in magnetic de-\nvices.\nThe study of magnetism and magnetic mate-\nrials goes back to the beginning of the theoreti-\ncal foundations of physics and chemistry. How-\never, even though there have been theoretical\npredictions of magnetic stable monolayers,7a\nde\ufb01nitive experimental observation of magnetic\norder at \ufb01nite temperature in 2D layered ma-\nterials was only reported recently.8\u201311Speci\ufb01-\ncally, scanning magneto-optic Kerr microscopy\nmeasurements revealed intrinsic long-range fer-\nromagnetic order in CrGeTe 3Van der Waals\n(VdW) atomic layers.12Similarly, Bevin Huang\net al., demonstrated for the \ufb01rst time the exis-\ntence of ferromagnetism in CrI 3VdW crystals\ndowntothemonolayerlimit.13Thediscoveryof\n2D magnetism has not only opened a new path\nforpotentialrevolutionaryspintronic14andval-\nleytronic15applications but also raised funda-\nmental questions about the understanding and\nprediction of ferromagnetic (FM) and antiferro-\nmagnetic (AFM) ordering in 2D compounds.\nIn three-dimensional bulk materials, the na-\nture of magnetic ordering ground state is de-\ntermined by collective mechanisms involving\nmagneto-crystalline anisotropy arising from the\nspin-orbit coupling and how magnetic moments\n(S and L) are e\ufb00ectively coupled by exchange\ninteractions. Furthermore, the interplay and\ncoexistence of exchange interactions can give\nrise to not only FM and AFM orderings, but\nalso to a very rich variety of di\ufb00erent magnetic\nstates even in compounds with similar crystal\nstructures.16In the simplest scenario, two iden-\ntical transition metal ions with unpaired elec-\ntrons interact through the isotropic Heisenberg\nHamiltonian ^H=\u0000JS 1S2, where the electron\nspinsS1andS2are coupled by the exchange\ninteraction parameter J. In this isotropic mag-\nnet,dependingontheextentofdelocalizationof\nthe magnetic moments, the magnetic order can\nbe described by four exchange interactions \u2013 in-direct, itinerant, direct, and super exchanges.7\nThese exchange interactions can coexist in a\ngiven compound, suggesting that even without\nmagneto-crystalline anisotropy, the magnetic\nordering is determined by competing e\ufb00ects.\nIndeed, the complexity in predicting magnetic\nordering has been recently recalled: \" the pre-\ndiction of the magnetic state based solely on\nchemical and structural information is a deli-\ncate exercise \".17The description of magnetic\nordering in 2D materials is even more complex.\nSpeci\ufb01cally, in 1966, based on the isotropic\nHeisenbergmodel, MerminandWagnerdemon-\nstrated that, unlike bulk compounds, in 2D ma-\nterials long-range magnetic order is suppressed\nby thermal \ufb02uctuations. This suggests that\n2D materials can only exhibit magnetic or-\nder in the presence of large magneto-crystalline\nanisotropy and hence, the magnetism in 2D and\nbulk materials are supposed to have di\ufb00erent\nphysical mechanisms.6Indeed, in general, there\nis no rule, as a knowledge base, that a priori\ndetermines the magnetic behavior in 2D mate-\nrials or a trend of AFM or FM magnetic or-\nderings in the feature space of atomic proper-\nties. For instance, 2D magnetic semiconductors\ncan violate the Goodenough-Kanamori rules for\nsuperexchange interactions18that discriminate\nFM from AFM orders according to the angles\nbetweend-orbitalsfromTMand p-orbitalsfrom\noxygen anions.19,20Clear and well-de\ufb01ned pat-\nterns would facilitate the search", " Introduction  \nThe continued growth of the global population has raised issues about sustainability and energy \nfuture, demanding improved efficiency of electricity production and consumption. Magnetic \nmaterials have a wide spectrum of applications, particularly in effici ent energy harvesting, \nconversion, and utilization.1,2 Specifically, permanent magnets (PMs) are the key components for \nthe energy related technologies, such as conventional generators, e -mobility, automatization and \nrefrigeration.3,4 Currently, two classes of PMs, namely, the ferrites and AlNiCo, and the high \nperformance PMs based on Nd -Fe-B and Sm -Co are widely used, with a gap in bet ween to be \nfilled by novel PMs, ideally those without critical elements such as heavy rare earths. Moreover, \nFM materials have been widely applied in spintronics, such as sensing, memory and logic, \nwhereas the emerging antiferromagnetic (AFM) spintronics h ave recently drawn intense \nattention.4,5 Two fundamental properties desired for promising candidate magnetic materials are a ferromagnetic (FM) ground state with strong magnetization and a high Curie temperature (T C) \nwhich governs the temperature range of functioning. These properties are also important for \nmagnetic refrigeration which promises enhanced energy efficiency over the conventional cooling \ntechnologies.6 \n \nAlthough T C is readily experimentally measurable, synthesis and optimization of real materials are \ntime-consuming and mostly done based on trial and error. Thus, the development of a \nmethodology to accelerate the developm ent of magnetic materials with a theoretical pre -screening \nis of natural interest. Typical theoretical approaches to evaluate T C rely on the parameterization of \ndensity functional theory (DFT) electronic structure to construct a Heisenberg Hamiltonian, whi ch \ncan be solved via atomistic Monte Carlo simulation. This approach fails even for elemental metal \nlike Co and Ni, due to the strong itinerant nature of magnetism therein.7,8 Moreover, DFT is not \nsufficient in describing the strongly correlated 4f electrons in rare -earths,9 while the orbital \ndependent functional (e.g., DFT+U) treatment is often chosen to fit to experiments due to \ndifferences in composition, synthesis and measurement techniques, which contributes to the error. \nIt is noted that, compared with those obtained based on DFT calculations, the machine learned \nvalues are more accurate. 7\u20139 \n \nThe valence electron features are still assigned with the highest importance of 41%, while that for \nthe magnetic moment of the constituting elements increases to 25% corresponding to the linear \nrelationship between magnetic moment  per atom with the total magnetization. Interestingly, the \nimportance of SOAP drops to only 9%, indicating that the local crystalline environment has less \nimportance when FM ordering is determined. When compared with the CHEM descriptors, the \neffect of inc luding the crystal structure is again marginal but noticeable. For instance, using only \nthe CHEM descriptors Results  \nData  \nUsing the AtomWork database,19 1749 FM and 1056 AFM inter -metallic compounds are collected, \nwhere oxides, sulfites, chlorides, and fluorides having been excluded, along with compounds \nwithout either of Cr, Mn, Fe, Co, and Ni atoms, which are the typical magnetic atoms in tran sition \nmetal based intermetallic magnetic materials. The corresponding crystal structures are collected \nfrom AtomWork and Inorganic Crystal Structure Database (ICSD).20", " INTRODUCTION\nIn this perspective article, we review the current state\nof data-driven materials science with a focus on materials\ndata infrastructures. Data-driven invokes associations\nwith big data, data management, open data and arti\ufb01cial\nintelligence (e.g. machine learning). The public debate of\nthese terms is currently dominated by internet giants like\nGoogle, Amazon, and Facebook who also lead the techno-\nlogical development of data infrastructures, algorithms,\nand analysis tools. Compared to these e-commerce and\nsocial media developments, the \ufb01eld of data-driven mate-\nrials science is still under construction. By way of analogy,\nit is nonetheless still instructive to imagine a Materials\n\u201cGoogle\u201d \u2013 the Materials Ultimate Search Engine (MUSE).\nIn this article, we address what it takes to develop such a\nsearch tool for materials.\nMaterials science, the study of the characteristics and\napplications of materials, is a well established discipline\nthat combines chemistry, physics, and engineering re-\nsearch. Materials scientists frequently dream of designing\nnew materials from scratch for use in society1. However,\ninstead of \ufb01nding new materials using the MUSE, they\ndiscover new materials through conventional experimen-\ntal, theoretical, or computational research (see left panel\nof Fig. 1). This pipeline through which new materials\n\u0003Corresponding author: patrick.rinke@aalto.\ufb01are discovered, designed, developed, manufactured, and\ndeployed remains slow, costly, and highly ine\ufb03cient: By\nthe time a new material comes to market, the patent pro-\ntection of the original invention is at the end of its tenure,\nand proprietary advantage is lost2(see also Ref. 3). By\napplying data science to materials research, we now have a\nway to accelerate the materials value chain from discovery\nto deployment.\nTraditional approach (1st, 2nd, 3rd paradigms)\nnew materials\nnew materialsDatabase driven approach (4th paradigm)\ncollect and share\nFIG. 1. Materials discovery schematic. In the traditional\napproach, new materials are discovered by experimentation,\ntheory, or computation (also referred to as 1st, 2nd, and 3rd\nparadigms and symbolized by the three icons at the top of\nthe left panel). In the 4th paradigm of data-driven materials\nscience, available data is gathered in data infrastructures, and\nmachine learning approaches discover new materials.arXiv:1907.05644v2  [physics.comp-ph]  19 Aug 20192\nData science has developed out of the growing demand\nfor open science combined with the meteoric rise of AI\nand machine learning. As these innovative technologies\nallow ever-larger datasets to be processed and hidden cor-\nrelations to be unveiled, data-driven science is emerging\nas thefourth scienti\ufb01c paradigm4,5(cf. Fig. 1) following\nthe \ufb01rst three eras of experimentally, theoretically, and\ncomputationally propelled scienti\ufb01c discoveries. Often\nconnected to the fourth industrial revolution6or thesec-\nond machine age ,7such data-driven approaches permeate\nscience, business, politics, and even social life. Since ma-\nterials innovation is a critical, well-recognized driver of\neconomic development and societal progress, it is impor-\ntant that new trends, such as data science, are embraced\nif they have the potential to advance the \ufb01eld.\nData-driven materials science andmaterials informat-\nicsare umbrella terms for the scienti\ufb01c practice of sys-\ntematically extracting knowledge from materials datasets.\nThis practice di\ufb00ers from traditional scienti\ufb01c approaches\nin materials research by the volume of processed data\nand the more automated way information is extracted (cf.\nFig. 1), for example, through the use of machine learning\n(see Ref. 5,8\u201323for recent review articles on machine\nlearning in materials science). In our MUSE analogy, this\nwould be the searchand\ufb01ndpart. In addition to data\nprocessing and data analysis tools, data-driven materials\nscience also requires physical infrastructures that host\nand preserve that data. These would be the data storage\npart of our MUSE example, which, as physical infrastruc-\ntures,", " INTRODUCTION\nMagnets [1, 2], compounds in which the atomic spins\narrange themselves yielding a macroscopic order, are\nknown since antiquity, but still represent a fascinating\nclass of materials. In these, the interplay between the\nlocal Hund's coupling, the exchange interaction and the\nmagneto-crystalline anisotropy, is able to generate a mul-\ntitude of ground states, which may di\u000ber both at the\nmicroscopic and macroscopic level. Often the particular\nmagnetic con\fguration of a material is the result of a sub-\ntle balance between the interactions at play, so that the\nprediction of the magnetic state based solely on chemical\nand structural information is a delicate exercise. Prob-\nably the largest subset of magnetic compounds is popu-\nlated by ferromagnets, where the atomic spins align along\nthe same direction. Regardless of the speci\fc magnetic\nphase, a magnet loses its collective order at the critical\ntemperature that, in the case of a ferromagnet, is known\nas the Curie temperature, TC. This means that at and\naboveTCa ferromagnet ceases to be magnetic.\nWhen a magnet is then employed in a given technology,\nfor instance in energy production and transformation or\nin data storage, its TCmust signi\fcantly exceed room\ntemperature. This means that typically a magnet will be\nconsidered as `useful', if its Curie temperature is around\n600 K. Unfortunately, not many magnetic compounds\nreach such value. In Fig. 1 we present the distribution\nof the measured TC's of about 2,500 known ferromagnets\n(see later for details). The median of the distribution is\n227 K, meaning that the vast majority of ferromagnets\nknown to date are actually paramagnetic at room tem-\nperature. Furthermore, it is clear that the number of\ncompounds satisfying the TC>600 K criterion is only\n\u0003janelson@tcd.ie\nysanvitos@tcd.iea small fraction of the total, suggesting that \fnding new\n`useful' ferromagnets is indeed a rare event and welcome\nnews.\n0 200 400 600 800 1000 1200\nCurie Temperature (K)050100150200250300350Number\nH\nLiBe B C N O F\nNaMg Al Si P S Cl\nKCaScTi V CrMnFe Co Ni CuZnGaGeAs Se Br\nRbSr Y Zr NbMo RuRh Pd AgCd In Sn Sb Te I\nCsBa Hf Ta W ReOs Ir Pt Au Hg Tl Pb Bi\nLa Ce Pr Nd SmEuGdTbDyHo ErTm YbLu\nTh U NpPu Cm\n0123456\nlog(abundance)\nFIG. 1. Histogram of the TC's of about 2,000 known ferro-\nmagnets. The median value of the distribution is 227 K. The\ninsert shows the relative elemental abundance, in logarithmic\nscale, for the ferromagnets included in the dataset (the log-\narithm of the number of compounds containing a particular\nelement). The most frequent magnetic element is Co followed\nby Fe and Gd.\nFigure 1 also presents the relative elemental abundance\nfor the ferromagnets included in the dataset, namely for\nevery element the number of compounds that contain\nthat given element. As expected the vast majority of the\nferromagnets contains at least one of the 3 dmagnetic\ntransition metals, Fe, Co, Ni and Mn, with Al being the\nmost frequent of the non-magnetic ions. However, it is\ninteresting to note that, with the only exception of noble\ngases and highly radioactive elements, magnets can be\nmade by incorporating essentially any ion in the periodicarXiv:1906.08534v1  [cond-mat.mtrl-sci]  20 Jun 20192\ntable. This gives us a potentially very large chemical\nspace to explore when designing new magnets.\nIn the last few years there have been a few attempts\nat systematically predicting the existence of new magnets\nahead of experiments performed by di\u000ber-\nent groups may report di\u000berent TC. This is particularly\nrelevant, since the", " INTRODUCTION\nImages and videos constitute a new massive source of data\nfor indexing and search. Extensive metadata for this con-\ntent is often not available. Search and interpretation of this\nand other human-generated content, like text, is di\u000ecult and\nimportant. A variety of machine learning and deep learn-\ning algorithms are being used to interpret and classify these\ncomplex, real-world entities. Popular examples include the\ntext representation known as word2vec [32], representations\nof images by convolutional neural networks [39, 19], and im-\nage descriptors for instance search [20]. Such representations\norembeddings are usually real-valued, high-dimensional vec-\ntors of 50 to 1000+ dimensions. Many of these vector repre-\nsentations can only e\u000bectively be produced on GPU systems,\n1https://github.com/facebookresearch/faissas the underlying processes either have high arithmetic com-\nplexity and/or high data bandwidth demands [28], or cannot\nbe e\u000bectively partitioned without failing due to communi-\ncation overhead or representation quality [38]. Once pro-\nduced, their manipulation is itself arithmetically intensive.\nHowever, how to utilize GPU assets is not straightforward.\nMore generally, how to exploit new heterogeneous architec-\ntures is a key subject for the database community [9].\nIn this context, searching by numerical similarity rather\nthan via structured relations is more suitable. This could be\nto \fnd the most similar content to a picture, or to \fnd the\nvectors that have the highest response to a linear classi\fer\non all vectors of a collection.\nOne of the most expensive operations to be performed on\nlarge collections is to compute a k-NN graph. It is a directed\ngraph where each vector of the database is a node and each\nedge connects a node to its knearest neighbors. This is\nour \ragship application. Note, state of the art methods in high-dimensional spaces. In Proc. International\nConference on Very Large DataBases , pages 194{205, 1998.\n[47] P. Wieschollek, O. Wang, A. Sorkine-Hornung, and\nH. P. A. Lensch. E\u000ecient large-scale approximate nearest\nneighbor search on the GPU. In Proc. IEEE Conference on\nComputer Vision and Pattern Recognition , pages\n2027{2035, June 2016.\n[48] S. Williams, A. Waterman, and D. Patterson. Roo\rine: An\ninsightful visual performance model for multicore\narchitectures. Communications of the ACM , 52(4):65{76,\nApril 2009. results\n(1 thread): R@1 = 0.45 in 20 ms search time per vector. We\nuse a PQ encoding of m= 20, with d= 80 via OPQ [17],\nandjC1j= 218, which uses a comparable dataset storage as\nthe original paper (20 GB). This requires multiple GPUs as\nit is too large for a single GPU's global memory, so we con-\nsider 4 GPUs with S= 2,R= 2. We obtain a R@1 = 0.4517\nin 0.0133 ms per vector. While the hardware platforms are\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdFigure 5: Speed/accuracy trade-o\u000b of brute-force\n10-NN graph construction for the YFCC100M and\nDEEP1B datasets.\ndi\u000berent, it shows that making searches on GPUs is a game-\nchanger in terms of speed achievable on a single machine.\n6.5 The k-NN graph\nAn example usage of our similarity search method is to\nconstruct a k-nearest neighbor graph of a dataset via brute\nforce (all vectors queried against the entire index).\nExperimental setup. We evaluate the trade-o\u000b between\nspeed, precision and memory on two datasets: 95 million\nimages from the Yfcc100M dataset [42] and Deep1B . For\nYfcc100M , we compute CNN descriptors as the one-before-\nlast layer of a ResNet [23], reduced to d= 128 with PCA.\nThe evaluation measures the trade-o\u000b between:\n\u000fSpeed: How much time it takes to build the IVFADC\nindex from scratch", " Introduction . (Wiley, 2007).  \n42. Seko, A., Takahashi, A. & Tanaka, I. Sparse representation for a potential energy surface. \nPhys. Rev. B  90, 024101 (201 4). \n43. Rupp, M., Tkatchenko, A., M \u00fcller, K. -R., Lilienfeld, V. & Anatole, O. Fast and Accurate \nModeling of Molecular Atomization Energies with Machine Learning. Phys. Rev. Lett.  108,  \n58301 (2012).  \n44. Pyzer -Knapp, E. O., Simm, G. N. & Aspuru -Guzik, A. A Bayesian Approach to Calibrating \nHigh -Throughput Virtual Screening Results and Application to Organic Photovoltaic \nMaterials. J. Mater. Chem.  2, 303 (2015).  \n45. Hall, M. et al.  The WEKA data mining software. ACM SIGKDD Explor. Ne wsl. 11, 10 (2009).  \n46. King, D. Dlib -ml: A machine learning toolkit. J. Mach. Learn. Res.  10, 1755 \u20131758 (2009).  \n47. Rodr \u00edguez, J. J., Kuncheva, L. I. & Alonso, C. J. Rotation forest: A new classifier ensemble \nmethod. IEEE Trans. Pattern Anal. Mach. Intell . 28, 1619 \u201330 (2006).  \n48. Meredig, B. & Wolverton, C. Dissolving the Periodic Table in Cubic Zirconia: Data Mining \nto Discover Chemical Trends. Chem. Mater.  26, 1985 \u20131991 (2014).  \n49. Jain, A. et al.  A high -throughput infrastructure for density functional t heory calculations. \nComput. Mater. Sci.  50, 2295 \u20132310 (2011).  \n50. Curtarolo, S. et al.  The high -throughput highway to computational materials design. Nat. \nMater.  12, 191\u2013201 (2013).  \n51. Kirklin, S., Meredig, B. & Wolverton, C. High -Throughput Computational  Screening of New \nLi-Ion Battery Anode Materials. Adv. Energy Mater.  3, 252\u2013262 (2013).  \n52. Gautier, R. et al.  Prediction and accelerated laboratory discovery of previously unknown \n18-electron ABX compounds. Nat. Chem.  7, 308\u2013316 (2015).  \n53. Chen, H. et al.  Carbonophosphates: A New Family of Cathode Materials for Li -Ion Batteries \nIdentified Computationally. Chem. Mater.  24, 2009 \u20132016 (2012).  \n54. Liu, M. et al.  Spinel compounds as multivalent battery cathodes: a systematic evaluation \nbased on ab initio calculations. Energy Environ. Sci.  8, 964\u2013974 (2014).  \n55. Yang, K., Setyawan, W., Wang, S., Buongiorno Nardelli, M. & Curtarolo, S. A search model \nfor topological insulators with high -throughput robustness descriptors. Nat. Mater.  11, \n614\u2013619 (2012).  \n56. Ho, T. K. The random subspace method for constructing decision forests. IEEE Trans. \nPattern Anal. Mach. Intell.  20, 832\u2013844 (1998).  \n57. Shockley, W. & Queisser, H. J. Detailed Balance Limit of Efficiency of p -n Junction Solar 18 \n Cells. J. Appl. Phys.  32, 510 (19 61). \n58. Sparks, T. D., Gaultois, M. W., Oliynyk, A., Brgoch, J. & Meredig, B. Data mining our way to \nthe next generation of thermoelectrics. Scr. Mater.  111,  10\u201315 (2015).  \n59. Wang, W. H., Dong, C. & Shek, C. H. Bulk metallic glasses. Mater. Sci. Eng. R R eports  44, \n45\u201389 (2004).  \n60. Inoue, A. Stabilization of metallic supercooled liquid and bulk amorphous alloys. Acta \nMater.  48, 279\u2013306 (2000).  \n61. L\u00f6ffler, J. F. Formation of Bulk", " INTRODUCTION\nA new class of software tools to assess material prop-\nerties has emerged from two parallel theoretical ad-\nvancements: quantum-mechanical computations based\non density functional theory (DFT), and informatics data\nmining and evolutionary structure screening strategies.\nJoined together, these results. The exten-\nsion is not trivial: the calculations of electronic struc-\nture using hybrid functionals di\u000ber from the standard\nLDA/GGA ones, with or without \\+U\". One cannot\ncompute the bands in the familiar non-selfconsistent way\nof the LDA/GGA because non-local exchange is not de-\ntermined by the pre-computed charge density. There-\nfore to obtain the eigenvalues for strings of k-points the\nfollowing recipe is being implemented. First, Aflow\nperforms a standard LDA/GGA calculation. Second,\na hybrid functional run is performed starting from the\nLDA/GGA wavefunctions on the same k-point mesh and\nenergy cuto\u000b chosen by Aflow . The number of bands is\ndynamically adjusted to achieve full convergence. Then,\nto facilitate e\u000ecient use of computational resources, it\nis further adjusted to include only a few bands over the\nhighest occupied state. Third, the electronic structure\nis computed by performing a hybrid functional run ex-\nplicitly de\fning the same k-point mesh in addition to\nthe desired k-path as speci\fed in the high symmetry ex-\namples of Ref. [48]. The crucial step here is to set the\nmixing weights of the extra k-path to zero, while keep-\ning the original mesh intact. Since the orbitals at the\nextra k-path do not contribute to the total energy, and\nthe wavefunctions on the original mesh are converged as\ninput, it is only necessary to converge the orbitals at\nthe extra k-points mesh with the appropriate vasp in-\nstructions. The band structure calculation following this\nrecipe will take approximately the same amount of time\nas a regular total energy hybrid calculation since the or-\nbitals at the standard mesh are pre-converged.\nAs an example Figure 8 shows the HSE06 band struc-\nture computed along the standard high symmetry lines.\nComparisons can be drawn with the PBE+U electronic\nstructure of Ref. [96]. The HSE06 calculation used\nthe standard value of \u000b= 0:25. (Note that by using\n\u000b= 0:375 the band-gap can be brought to agreement\nwith experiment.) The value of the band-gap is con-\nsiderably improved Eg= 2:48 eV in comparison with\nGGA and PBE+U values of Eg= 0:7 eV andEg= 1:82\neV, respectively (the phenomenologically corrected value\nis 3.36 eV [94]). In other materials this improvementis often better, since ZnO produces one of the largest\nLDA/GGA band-gap errors. The HSE06 band-gaps for\nnarrow and medium gap semiconductors, with the stan-\ndard ratio of the Fock exchange, are in good agreement\nwith experiment. For wide band-gap semiconductors and\ninsulators the gaps, although underestimated, present a\nsigni\fcant improvement over LDA/GGA values [88]. In\naddition, hybrid functionals improve e\u000bective mass esti-\nmation for almost all systems, typically yielding values\nwithin a few percent of experiment [97].\nA fully functional, consistent and robust Aflow\nframework with hybrid functionals is planned for 2012.\nO1Zn1_ICSD_26170 (HEX)\n 0  5  10  15  20Density of States (States/eV)\nAFLOW - www.aflowlib.org consortiums\np\nd\n-8-6-4-2 0 2 4 6 8Energy (eV)\nAFLOW - www.aflowlib.org consortiumK M K KA L H A|L M|K H\nFIG. 8: HSE06 hybrid functional band structure of ZnO. The\nHSE06 gap is 2.48 eV. LDA/GGA gap is 0.7 eV while the\nPBE+U value is 1.82 eV [96]. Standard HSE06 parameters\nwere used, the ratio of exact exchange is 0.25 and the screen-\ning parameter is 0.2", " Introduction\nThe Python programming language is establishing itself as o ne of the most popular lan-\nguages for scienti\ufb01c computing. Thanks to its high-level in teractive nature and its maturing\necosystem of scienti\ufb01c libraries, it is an appealing choice for algorithmic development and\nexploratory data analysis (Dubois, 2007; Milmann and Avaiz is, 2011). Yet, as a general-\npurpose language, it is increasingly used not only in academ ic settings but also in industry.\nScikit-learn harnesses this rich environment to provide state-of-the-a rt implementations\nof many well known machine learning algorithms, while maint aining an easy-to-use interface\ntightly integrated with the Python language. This answers t he growing need for statistical\ndata analysis by non-specialists in the software and web ind ustries, as well as in \ufb01elds\noutside of computer-science, such as biology or physics. Scikit-learn di\ufb00ers from other\nmachine learning toolboxes in Python for various reasons: i)it is distributed under the\nBSD license ii)it incorporates compiled code for e\ufb03ciency, unlike MDP (Zit o et al., 2008)\nand pybrain (Schaul et al., 2010), iii)it depends only on numpy and scipy to facilitate easy\ndistribution, unlike pymvpa (Hanke et al., 2009) that has op tional dependencies such as\nR and shogun, and iv)it focuses on imperative programming, unlike pybrain which uses\na data-\ufb02ow framework. While the package is mostly written in Python, it incorporates\n2826Scikit-learn: Machine Learning in Python\nthe C++ libraries LibSVM (Chang and Lin, 2001) and LibLinear (Fan et al., 2008) that\nprovide reference implementations of SVMs and generalized linear models with compatible\nlicenses. Binary packages areavailable on arich set of plat forms includingWindows and any\nPOSIX platforms. Furthermore, thanks to its liberal licens e, it has been widely distributed\nas part of major freesoftware distributionssuch as Ubuntu, Debian, Mandriva, NetBSD and\nMacports and in commercial distributions such as the \u201cEntho ught Python Distribution\u201d.\n2. Project Vision\nCode quality. Rather than providing as many features as possible, the proj ect\u2019s goal has\nbeentoprovidesolid implementations. Codequality isensu redwithunittests\u2014as of release\n0.8, test coverage is 81%\u2014and the use of static analysis tool s such as pyflakes andpep8.\nFinally, westrivetouseconsistent namingforthefunction sandparametersusedthroughout\na strict adherence to the Python coding guidelines and numpy style documentation.\nBSD licensing. Most of the Python ecosystem is licensed with non-copyleft l icenses. While\nsuch policy is bene\ufb01cial for adoption of these tools by comme rcial projects, it does impose\nsome restrictions: we are unable to use some existing scient i\ufb01c code, such as the GSL.\nBare-bone design and API. To lower the barrier of entry, we avoid framework code and kee p\nthe number of di\ufb00erent objects to a minimum, relying on numpy a rrays for data containers.\nCommunity-driven development. We base our development on collaborative tools such as\ngit, github and public mailing lists. External contributio ns are welcome and encouraged.\nDocumentation. Scikit-learn provides a \u223c300 page user guide including narrative docu-\nmentation, class references, a tutorial, installation ins tructions, as well as more than 60\nexamples, some featuring real-world applications. We try t o minimize the use of machine-\nlearning jargon, while maintaining precision with regards to the algorithms employed.\n3. Underlying Technologies\nNumpy: the base data structure used for data and model parameters. I nput data is pre-\nsented as numpy arrays, thus integrating seamlessly with ot her scienti\ufb01c Python libraries.\nNumpy\u2019s view-based memory model limits copies, even when bi", " introduction by Ho-\nhenberg, Kohn, and Sham1,2, Density Functional\nTheory (DFT) has become the most widely used\nand successful method for simulating systems of\ninteracting electrons, making their original work\none of the most cited in physics. In this letter,\nwe show that the \ufb01eld of computational complex-\nity imposes fundamental limitations on DFT, as\nan e\ufb03cient description of the associated univer-\nsal functional would allow to solve any problem in\nthe class QMA(the quantum version of NP) and\nthus particularly any problem in NPin polyno-\nmial time. This follows from the fact that \ufb01nding\nthe ground state energy of the Hubbard model in\nan external magnetic \ufb01eld is a hard problem even\nfor a quantum computer, while given the univer-\nsal functional it can be computed e\ufb03ciently us-\ning DFT. This provides a clear illustration how\nthe \ufb01eld of quantum computing is useful even if\nquantum computers would never be built.\nThe di\ufb03culty of \ufb01nding the ground state properties\nof a large system of interacting electrons originates both\nfrom the exponential dimension ofthe underlying Hilbert\nspaceandfromthe fermionicnatureofthewavefunction.\nIt isaproblemencounteredvirtuallyeverywherein quan-\ntum chemistry as well as in condensed matter physics:\nfor instance, the spatial con\ufb01guration of a molecule is\nthe one for which the energy of the interacting electrons\nmoving in the nuclear potential, together with the elec-\ntrostatic energy of the nuclei, becomes minimal. Simi-\nlarly, a rich variety of phenomena in solid state physics,\nin particular conductance and magnetic phenomena, can\nbe understood by considering electrons moving in the\nperiodic lattice potential, including such exciting phe-\nnomena as high-temperature superconductivity and the\nfractional quantum Hall e\ufb00ect.\nA system of Nelectrons is described by the Hamilto-\nnian\nH=\u22121\n2N/summationdisplay\ni=1\u2206i\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n=:T+/summationdisplay\n1\u2264i<j\u2264N\u03b3\n|ri\u2212rj|\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n=:I+/summationdisplay\niV(xi) (1)\n(\u03b3 >0, andxi= (ri,si) withriposition and sispin),\nwhere the potential Vcontains both an electrostatic\n\ufb01eld\u03c6(r) and a magnetic \ufb01eld /vectorB(r) which couples to\nthe spin (the coupling to the orbit can be neglected\nfor our purposes, see Supplementary Material), and the\nproblem is to \ufb01nd the ground state within the set of\nfermionic (i.e. antisymmetric) quantum states. Followingthe earlyworkofSlater3, Hohenberg, Kohn, and Sham1,2\nshowed that this problem could be rephrased as a single-\nparticle minimization problem, for the reason that the\nonly problem-dependent part is the external potential V\nwhose expectation value only depends on the local den-\nsity, while the kinetic and interaction terms TandIare\n\ufb01xed and universal for all systems. Thus, the ground\nstate energy is given by\nE0= min\n\u03c1{tr(V\u03c1)+F[\u03c1]}, (2)\nwhere\u03c1is a single-electron density, and the functional F\ncontains the problem-independent minimization over T\nandI,\nF[\u03c1] = min\n\u2126\u2192\u03c1tr[(T+I)\u2126]. (3)\nHere, the minimization runs over all N-electron density\noperators\u2126 which give riseto the reduceddensity \u03c1. The\ncentral requirement for a good DFT algorithm is to \ufb01nd\na suitable approximation to the universal functional, and\nindeed betterand bettertechniques havebeen developed,\nmaking DFT the most widely used and most successful\nalgorithm for treating interacting electrons.\nHowever, as we show in this letter, there exist funda-\nmental limits which constrain the ability to \ufb01nd a gener-\nally applicable and e\ufb03ciently computable approximation\nto the universal functional, and thus put bounds on the\napplicability of DFT. To this end, we consider the 2D\nHubbard model with local magnetic \ufb01elds, which arises\nfrom the problem of interacting electrons for a speci\ufb01-\ncally chosen lattice potential, and can thus be simulated\nusing DFT. We \ufb01rst determine the computational com-\nplexity of solving the Hubbard model and show that it\nis among the hardest problems in the complexity class\nQMA, Quantum Merlin Arthur. QMAcontains problems\nwhich are believed to be hard to solve"], "bleu": 0.16399492914513206, "rouge_l": 0.3157894736842105, "gpt_metric_score": 0.5, "bert_score": 0.3168269097805023}
{"paper_key": "ChemDFM: A Large Language Foundation Model for Chemistry", "current_5q": "### [Question 1] - What is the problem?\nHow can the modification of catalyst acidity and chiral environment enhance the catalytic activity and enantioselectivity in chemical reactions?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem is crucial for advancing the field of catalysis, as it can lead to the development of more efficient and selective catalysts. Improved catalytic performance can have significant implications for various industries, including pharmaceuticals, where enantioselectivity is vital for producing desired compounds. This research could pave the way for future studies focused on optimizing catalyst design, leading to practical applications in green chemistry and sustainable processes.\n\n### [Question 3] - Why is it hard?\nThe challenges in this research stem from the complex interplay between acidity, chiral environment, and catalytic activity. Naive approaches may fail because simply increasing acidity or introducing chiral groups does not guarantee improved performance; it may also affect stability and selectivity negatively. Technical obstacles include the need for precise control over the molecular structure and the reaction conditions, as well as the difficulty in predicting how modifications will influence the catalyst's overall behavior.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has often focused on either acidity or chirality in isolation, neglecting the synergistic effects of modifying both aspects simultaneously. Limitations in understanding the molecular interactions and the lack of comprehensive methodologies for optimizing catalyst properties have hindered progress. My approach differs by integrating the modification of acidic functional groups and chiral environments in a systematic manner, allowing for a more holistic understanding of their combined effects on catalytic performance.\n\n### [Question 5] - What are the key components of my approach and results?\nMy proposed methodology involves synthesizing catalysts with varying degrees of acidic functional groups and chiral substituents. I will utilize a combination of experimental techniques and computational modeling to analyze the effects of these modifications on catalytic activity and enantioselectivity. The dataset will include reaction yields and selectivity metrics, while the expected outcomes are enhanced catalytic performance and a clearer understanding of the relationship between acidity, chirality, and catalytic efficiency.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can we develop a multilingual multimodal dialogue state tracking system that effectively enhances contextual understanding of emotional expressions in real-time conversational interactions, particularly in complex multi-turn dialogues and code-switching scenarios?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is crucial as it holds significant implications for the research community in the fields of natural language processing, human-computer interaction, and affective computing. By improving emotional recognition in multilingual contexts, this research could lead to more nuanced and empathetic conversational AI systems, enhancing user experience across diverse cultural and linguistic backgrounds. This paper will pave the way for future research by establishing a robust framework for integrating multimodal data (text and speech) with emotional context, potentially leading to practical applications in therapy, customer support, and education. Ultimately, addressing this question could advance our understanding of human-computer interactions and foster inclusivity in AI applications, bridging gaps in communication for users with varying language proficiencies.\n\n[Question 3]: Why is it hard?  \nThe challenges involved in solving this problem are multifaceted. Firstly, the emotional expressions conveyed in speech and text can be highly nuanced and context-dependent, making it difficult for traditional dialogue systems to accurately interpret emotions, especially in a multilingual framework. Naive approaches may fail due to their inability to process the interplay between language and emotion effectively, particularly in scenarios where users switch languages mid-conversation (code-switching). Moreover, the integration of real-time feedback loops to refine emotional recognition requires sophisticated algorithms capable of adapting to dynamic user interactions, which poses substantial technical challenges. Additionally, there are practical obstacles related to the availability of high-quality, annotated datasets in low-resource languages, which complicates the training and evaluation of the models.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research in dialogue state tracking often focuses on either linguistic inputs or emotional cues in isolation, leading to a lack of comprehensive models that integrate both aspects effectively. Existing solutions have been limited by their inability to handle multilingual inputs or complex emotional contexts, particularly in real-time scenarios. Furthermore, many studies do not account for the variability introduced by code-switching, which can lead to misinterpretations of user intent and emotion. My approach differs by leveraging instruction-tuning techniques, which have not been widely applied in this context, to enhance the system's ability to learn from both speech and text data. This will address the gaps in previous research by focusing on a holistic, multimodal approach that incorporates real-time feedback mechanisms.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing a multilingual multimodal dialogue state tracking system that employs instruction-tuning to refine emotional recognition. The system will utilize a dataset comprising diverse conversational interactions across multiple languages, including both text and speech components, to train context-aware models. The key metrics for evaluation will include accuracy in emotional recognition, adaptability to user interactions, and the system's performance in code-switching scenarios. The expected outcomes include a robust dialogue system that not only improves emotional recognition accuracy but also demonstrates adaptability across various languages and contexts, setting a new standard for inclusive conversational AI applications. The integration of real-time feedback loops is anticipated to enhance the system's responsiveness, ultimately leading to a more engaging and effective user experience.", "referenced_intros": [" Introduction\nThe incredible capabilities of Large Language Models (LLMs) [ 5,44] have led to their widespread\nuse as versatile tools for completing diverse real-world tasks. This success has sparked interest in\nMulti-modal LLMs [ 59,52], which aim to enhance LLMs by enabling them to process multi-modal\ninputs and outputs. Prior research efforts [ 26,41,12,6,33,35,25] have focused on adapting LLMs\nto molecular tasks, resulting in the development of molecular LLMs. These molecular LLMs can\nanalyze molecule structures [ 35,33,6], address drug-related inquiries [ 26,41], assist in synthesis\nand retrosynthesis planning [12], support drug design [12], and more.\nPrevalent molecular LLMs commonly employ adapter-based architectures, adopting either a linear\nprojection [ 26,41,6] or a Q-Former [ 33,25] as an adapter to translate molecule features into the\nsemantic space of LLM, as illustrated in Figure 1a and Figure 1b. Despite demonstrating initial\ncapabilities in molecular comprehension and yielding promising results underscore the effectiveness of the\nmolecule tokenizer in providing molecule tokens with high-level molecular and textual information,\nthus enhancing molecule comprehension.\nMolecule-Text Retrieval Task. The molecule-text retrieval task involves using a molecule to\nretrieve text (M2T) and using text to retrieve a molecule (T2M). We compare UniMoT with several\n18Table 11: Performance (%) of molecule captioning task on the CheBI-20 [ 11] dataset. Bold indicates\nthe best performance and underline indicates the second best performance.\nModel BLEU-2 \u2191BLEU-4 \u2191ROUGE-1 \u2191ROUGE-2 \u2191ROUGE-L \u2191METEOR \u2191\nT5-Small [38] 50.1 41.5 60.2 44.6 54.5 53.2\nT5-Base [38] 51.1 42.3 60.7 45.1 55.0 53.9\nT5-Large [38] 55.8 46.7 63.0 47.8 56.9 58.6\nMolT5-Small (T5-Small) [11] 51.9 43.6 62.0 46.9 56.3 55.1\nMolT5-Base (T5-Base) [11] 54.0 45.7 63.4 48.5 57.8 56.9\nMolT5-Large (T5-Large) [11] 59.4 50.8 65.4 51.0 59.4 61.4\nMoMu-Small (T5-Small) [39] 53.2 44.5 - - 56.4 55.7\nMoMu-Base (T5-Base) [39] 54.9 46.2 - - 57.5 57.6\nMoMu-Large (T5-Large) [39] 59.9 51.5 - - 59.3 59.7\nInstructMol (Vicuna-7B) [6] 47.5 37.1 56.6 39.4 50.2 50.9\nMolCA (OPT-125M) [33] 61.6 52.9 67.4 53.3 61.5 63.9\nMolCA (OPT-1.3B) [33] 63.9 55.5 69.7 55.8 63.6 66.9\nUniMoT (Llama-2-7B) 66.4 58.3 72.2 58.4 66.4 70.3\nbaselines: Sci-BERT [ 2], KV-PLM [ 58], MoMu [ 39], MoleculeSTM [ 31], MolCA [ 33], and 3D-\nMoLM [ 25]. We report the performance of retrieval using a batch of 64 random samples and the\nentire test set, evaluated with the metrics of Accuracy and Recall@20. We use the checkpoint from\nStage-1 of pretraining. Performance on the PCdes [ 58] and MoMu [ 39] datasets is shown in Table 13.\nUniMoT demonstrates superior performance over the baselines on molecule-text retrieval, particularly\nin molecule-to-text retrieval. This demonstrates that UniMoT has learned fine-grained alignment\nbetween molecules and text, and it can understand molecule-text interactions through the methods, which capture different\naspects of molecular structure and properties.\n\u2022The Validity [ 19] metric assesses the proportion of chemically valid molecules generated,\nensuring that the output consists of plausible chemical structures.\nTogether, these metrics offer a comprehensive evaluation framework, balancing exact matches with\nstructural and chemical validity.\n19Table 12: Examples of molecule captioning task on the ChEBI-20 dataset. We highlight in blue the\ntext that accurately describes the molecule structures in the generated caption, ensuring alignment\nwith the ground truth.\nMolecule Generated Molecule Caption Ground Truth\nThe molecule is an optically active\nform of phenylalaninate having D-\nconfiguration. It is a conjugate base\nof a D-phenylalanine. It is an enan-\ntiomer of a L-phenylalaninate.The", " Introduction\nDeep learning approaches have emerged as a powerful tool\nfor a wide range of tasks (He et al., 2016; Devlin et al., 2019;\nBrown et al., 2020). Recently, researchers have started in-\nvestigating whether the power of neural networks could help\nsolve problems in physics and chemistry, such as predicting\nthe property of molecules with 3D coordinates and simu-\nlating how each atom moves in Euclidean space (Sch\u00fctt\net al., 2018; Gasteiger et al., 2020b; Satorras et al., 2021).\nThese molecular modeling tasks require the learned model\nto satisfy general physical laws, such as the invariance and\nequivariance conditions: The model\u2019s prediction should\nreact physically when the input coordinates change accord-\ning to the transformation of the coordinate system, such as\nrotation and translation.\nA variety of methods, e.g., RDKit (Landrum, 2016). Given the inaccurate 3D structure as the input, the model is\nrequired to predict the equilibrium structure in an iterative manner. The predicted equilibrium structure is used to predict the\nquantum property. Uni-Mol+ simultaneously maintain both atom representations and pair representations, which induce the\ntriplet complexity when updating the pair representations. With the carefully designed training strategy, Uni-Mol+ achieves\n22GeoMFormer: A General Architecture for Geometric Molecular Representation Learning\nstate-of-the-art performance on PCQM4Mv2 while yielding high computational costs.\nSettings. As previously stated, DFT-calculated equilibrium geometric structures are provided for molecules in the training\nset. The molecules in the validation set do not have such information. We follow Uni-Mol+ (Lu et al., 2023) to train our\nGeoMFormer. In particular, our model takes the RDKit-generated geometric structures as the input and is required to predict\nboth the HOMO-LUMO energy gap and the equilibrium structure by leveraging invariant and equivariant representations\nrespectively. After training, the model is able to predict the HOMO-LUMO gap using the RDKit-generated geometric\nstructures. We refer the readers to Uni-Mol+ (Lu et al., 2023) for more details on the training strategies.\nOur GeoMFormer model consists of 8 layers. The dimension of hidden layers and feed-forward layers is set to 512. The\nnumber of attention heads is set to 32. The number of Gaussian Basis kernels is set to 128. We use AdamW as the optimizer,\nand set the hyper-parameter \u03f5to 1e-8 and (\u03b21, \u03b22)to (0.9,0.999). The gradient clip norm is set to 5.0. The peak learning\nrate is set to 2e-4. The batch size is set to 1024. The dropout ratios for the input embeddings, attention matrices, and hidden\nrepresentations are set to 0.0, 0.1, and 0.1 respectively. The weight decay is set to 0.0. The model is trained for 1.5 million\nsteps with a 150k-step warm-up stage. After the warm-up stage, the learning rate decays linearly to zero. Other hyper-\nparameters are kept the same as the Uni-Mol+ for a fair comparison. The model is trained on 16 NVIDIA Tesla V100 GPUs.\nE.4. Molecule3D\nBaselines. We follow (Wang et al., 2022) to use several competitive baselines for comparison including GIN-Virtual (Hu\net al., 2021), SchNet (Sch\u00fctt et al., 2018), DimeNet++ (Gasteiger et al., 2020a), SphereNet (Liu et al., 2022b) which have\nalready been introduced in previous sections. ComENet (Wang et al., 2022) proposed a message-passing layer that operates\nwithin the 1-hop neighborhood of atoms and encoded the rotation angles to fulfill global completeness. We also implement\nboth PaiNN (Sch\u00fctt et al., 2021) and TorchMD-Net (Th\u00f6lke &", " Introduction\nChemistry is a fundamental science that underpins countless aspects of modern life, ranging\nfrom drug discovery and materials science to energy production. To facilitate research and\napplications in this domain, deep learning models including graph neural networks (Kipf &\nWelling, 2017) and Transformer-based models (Vaswani et al., 2017) have been developed\nfor various chemistry tasks such as forward reaction prediction, retrosynthesis, property\nprediction (Schwaller et al., 2019; Zhong et al., 2022; Chen et al., 2023; Zhou et al., 2023).\nHowever, these models are usually task-specific models, which neglect shared chemistry\nknowledge across tasks and can hardly be adapted to different tasks.\nOn the other hand, large language models (LLMs) such as GPT-4 (OpenAI, 2023), Llama se-\nries (Touvron et al., 2023a;b), and Mistral (Jiang et al., 2023) have emerged as general-purpose\nfoundation models and demonstrate remarkable abilities on various natural language pro-\ncessing tasks (Chang et al., 2024; Thirunavukarasu et al., 2023; Yue et al., 2023; Zhang et al.,\n2023; Deng et al., 2023). However, when applied to chemistry tasks, LLMs show only\nlimited capabilities (Jablonka et al., 2022; Guo et al., 2023; Hatakeyama-Sato et al., 2023). For\nexample, Guo et al. (2023) conducted evaluations on eight chemistry tasks and observed that\nwhile GPT-4 outperforms other closed- and open-source LLMs, its performance is far from\nthat of task-specific deep learning models. Particularly, they found that GPT models perform\npoorly when a precise understanding of SMILES (Weininger, 1988), a widely used textual\nrepresentation for molecules, is required. In addition to directly applying pretrained LLMs,\nFang et al. (2023) fine-tuned LLMs on an instruction tuning dataset, but their performance\nremains very low, far behind the state-of-the-art (SoTA) models designed and trained for\nspecific tasks.\n*Equal contribution.\n1Our dataset and models can be found at https://osu-nlp-group.github.io/LLM4Chem/ .\n1arXiv:2402.09391v4  [cs.AI]  10 Aug 2024Published as a conference paper at COLM 2024\nName ConversionIUPAC to Molecular Formula (NC-I2F)Query:What is the molecular formula of the compound with this IUPAC name<IUPAC> 2,5-diphenyl-1,3-oxazole </IUPAC>?Response:<MOLFORMULA> C15H11NO  </MOLFORMULA>IUPAC to SMILES (NC-I2S)Query:Could you provide the SMILES for<IUPAC> 4-ethyl-4-methyloxolan-2-one </IUPAC>?Response:Of course.   It's <SMILES> CCC1(C)COC(=O)C1</SMILES>SMILES to Molecular Formula (NC-S2F)Query:Given the SMILES representation <SMILES> S=P1(N(CCCl)CCCl)NCCCO1 </SMILES>, what would be its molecular formula?Response:It is <MOLFORMULA> C7H15Cl2N2OPS </MOLFORMULA> .SMILES to IUPAC (NC-S2I)Query:Translate the given SMILES formula of a molecule<SMILES> CCC(C)C1CNCCCNC1 </SMILES> into its IUPAC name.Response:<IUPAC> 3-butan-2-yl-1,5-diazocane </IUPAC>Chemical ReactionForward Synthesis (FS)Query:<SMILES> NC1=CC=C2OCOC2=C1.O=CO</SMILES>Based on the reactants and reagents given above, suggest a possible product.Response:A possible product can be <SMILES> O=CNC1=CC=C2OCOC2=C1 </SMILES>Retrosynthesis (RS)Query:Identify possible reactants that could have been used to create the specified product.  <SMILES> CC1=CC=C(N)N=C1N </SMILES>Response:<SMILES> CC(C#N)CCC#N.N </SMILES>Molecule DescriptionMolecule Captioning (MC)Query:Describe this molecule:<SMILES> CCOC(=O)C1=CN=CN1[C@H](C)C1=CC=CC=C1</SMILES>Response:The molecule is an imidazole derivative with short-acting sedative, hypnotic, and general anesthetic properties. Etomidate appears to have gamma-aminobutyric acid (GABA) like effects, mediated through GABA-A receptor. The action enhances the inhibitory effect of GABA on the central nervous system by causing chloride channel opening events which leads to membrane hyperpolarization.Molecule Generation (MG)Query:Give me a molecule that satisfies the conditions outlined in the description: The molecule is a member of the class of tripyrrolesthat is a red-colouredpigment with antibiotic properties produced by Serratia marcescens. It has a role as an antimicrobial agent, a biological pigment, a bacterial metabolite, an apoptosis inducer and an antineoplastic agent.", " Introduction\nMaterial discovery describes the inherently laborious, iter-\native process of designing materials candidates, preparing\nthem experimentally, testing their properties, and eventually\n1Vector Institute2University of Toronto3University of Waterloo\n4University of British Columbia. Correspondence to: Agustinus\nKristiadi <akristiadi@vectorinstitute.ai >.\nProceedings of the 41stInternational Conference on Machine\nLearning , Vienna, Austria. PMLR 235, 2024. Copyright 2024 by\nthe author(s).\nPrompt: What is the molecular mass of OS(=O)(=O)O?\nGround truth: 98.079 g/mol\nChatGPT: To calculate the molecular mass of a com-\npound, you need to sum the atomic masses of all the\natoms in the molecular formula. [. . . ] Therefore, the\nmolecular mass of OS(=O)(=O)O (sulfuric acid) is ap-\nproximately 96.07 g/mol.\nLlama-2-70b: The molecular formula for OS(=O)(=O)O\nis O3S. [. . . ] Therefore, the molecular mass of\nOS(=O)(=O)O is 80.07 g/mol.Figure 1. LLMs seem to \u201cunderstand\u201d chemistry. However, they\noften produce completely wrong answers while sounding very\nconvincing. Both APIs were accessed on 2024-01-07.\nupdating the initial design hypothesis (de Regt, 2020; Green-\naway et al., 2023). While human researchers have largely\ndriven this process for the last century, there is demand for\nmore efficient automated background knowledge from\nSection 2, we now discuss our Appendix B).\nThis is because |Dcand|can be several orders of magnitude\nlarger than |Dt|during the BO loop, and forward passes on\nLLMs are generally expensive. Additionally, the LLA pos-\nterior (2)requires computing the Jacobian of the network,\namounting to the cost of several backward passes, depend-\ning on C. Due to GPU memory limitation, we can only use\n8A Sober Look at LLMs for Bayesian Optimization Over Molecules\n020406080\nt0.00.51.0GAP (\u2191)Average GAP Across Datasets and Random Seeds\nLA-T5\nLA-T5-FT\nLA-T5-Chem\nLA-T5-Chem-FT\nFigure 9. Summarized performance of the finetuning results in the main text.\n16A Sober Look at LLMs for Bayesian Optimization Over Molecules\n1.61.8Redox Potential (\u2193)just-smiles completion single-number naive\n24Strength (\u2191)\n1.2\n1.0\n0.8\nSolvation Energy (\u2193)\n500600Wavelength (\u2191)\n9.5\n9.0\nDocking Score (\u2193)\n255075100\nt91011PCE (\u2191)\n255075100\nt255075100\nt255075100\ntLA-T5 LA-LL2-7B LA-T5-Chem\nFigure 11. Different prompts.\n17A Sober Look at LLMs for Bayesian Optimization Over Molecules\n020406080\nt0.000.250.500.751.00GAP (\u2191)Average GAP Across Datasets and Random Seeds\n(a) Fixed\n020406080\nt0.000.250.500.751.00GAP (\u2191)Average GAP Across Datasets and Random Seeds\nTS EI (b) Finetuned\nFigure 12. Summarized BO performance with Thompson sampling and expected improvement.\n1.61.8Redox PotentialRedoxmer (\u2193)\n24StrengthLaser (\u2191)\nTS\nEI1.2\n1.0\nSolvation EnergySolvation (\u2193)\n255075100\nt500600WavelengthPhotoswitches (\u2191)\n255075100\nt9.5\n9.0\nDocking ScoreKinase (\u2193)\n255075100\nt91011PCEPhotovoltaics (\u2191)\nFigure 13. Fixed-feature BO (T5-Chem) with different acquisition functions\u2014Thompson sampling (TS) and expected improvement (EI).\nB.1. Laplace vs. GP\nWe show the performance of the GP (with the Tanimoto kernel) surrogate vis- `a-vis LA in Figure 10. Our conclusion\nthat one should use domain-specific LLMs (e.g. T5-Chem) for doing BO.\n18A Sober Look at LLMs for Bayesian Optimization Over Molecules\n1.61.7Redox PotentialRedoxmer (\u2193)\n24StrengthLaser (\u2191)\nTS\nEI1.2\n1.0\nSolvation EnergySolvation (\u2193)\n255075100\nt500600WavelengthPhotoswitches (\u2191)\n255075100\nt9.5\n9.0\nDocking ScoreKinase (\u2193)\n255075100\nt91011PCEPhotovoltaics (\u2191)\nFigure 14. Finetuning T5-Chem with different acquisition functions\u2014Thompson sampling (TS) and expected improvement (EI).\n20406080100\nt1.61.8Redox Potential (\u2193)Redoxmer\nSMILES\nIUPAC\n20406080100\nt1.2\n1.0\n0.8\nSolvation Energy (\u2193)SolvationLA-T5 LA-LL2-7B LA-T5-Chem LA-T5 LA-LL2-7B LA-T5-Chem\nFigure 15. SMILES vs. IUPAC.\n1.61.71.8Redox Potential (\u2193)just-smiles completion single-number naive\n255075100\nt1.2\n1.0\n0.8\nSolvation Energy (\u2193)\n255075100\nt255075100\nt255075100\ntLA-T5 LA-LL2-7B LA-T5-Chem\nFigure 16. IUPAC with different prompts.\n19A Sober Look at LLMs for Bayesian Optimization Over Molecules\n01020Training Time (s)Redoxmer (1407)\n204060Laser (10000)\n01020Photoswitches (392)\n20406080100\nt02040Pred. Time (s)\n20406080100\nt370380\n20406080100\nt051015LA-T5-FT LA-T5-Chem-FT\nFigure 17. Wall clock time (in seconds) per BO iteration of the finetuned surrogates. Numbers in parentheses are numbers of test points\n|Dcand|. Notice that the costs are roughly linear in the number of test points, indicating that forward passes over Dcand take the bulk of\nthe computation. T5-Chem has a lower wall-clock time on average since it tends to terminate faster than T5. E.g., some of the BO runs\nacross random seeds", " introduction to methodology and encoding\nrules. J. Chem. Inf. Comput. Sci. , 28:31\u201336, 1988. 4\n[76] Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and\nWeidi Xie. Pmc-llama: Towards building open-source lan-\nguage models for medicine. 2023. 3\n[77] Zhenqin Wu, Bharath Ramsundar, Evan N. Feinberg, Joseph\nGomes, Caleb Geniesse, Aneesh S. Pappu, Karl Leswing, and\nVijay S. Pande. Moleculenet: A benchmark for molecular\nmachine learning. arXiv: Learning , 2017. 4, 5, 6, 13\n[78] Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley.\nBaize: An open-source chat model with parameter-efficient\ntuning on self-chat data. ArXiv , abs/2304.01196, 2023. 6, 7\n[79] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie\nJegelka. How powerful are graph neural networks? ArXiv ,\nabs/1810.00826, 2018. 5\n[80] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu\nLi, and Ying Shan. Gpt4tools: Teaching large language model\nto use tools via self-instruction. ArXiv , abs/2305.18752, 2023.\n2\n[81] Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan,\nYi Zhou, Junyan Wang, Anwen Hu, Pengcheng Shi, Yaya Shi,\nChenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian,\nQiang Qi, Ji Zhang, and Feiyan Huang. mplug-owl: Modular-\nization empowers large language models with multimodality.\nArXiv , abs/2304.14178, 2023. 1, 2, 3, 4\n[82] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun,\nTong Xu, and Enhong Chen. A survey on multimodal large\nlanguage models. ArXiv , abs/2306.13549, 2023. 2\n11[83] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen,\nZhangyang Wang, and Yang Shen. Graph contrastive learning\nwith augmentations. ArXiv , abs/2010.13902, 2020. 2, 6\n[84] Zheni Zeng, Yuan Yao, Zhiyuan Liu, and Maosong Sun. A\ndeep-learning system bridging molecule structure and biomed-\nical text with comprehension comparable to human profes-\nsionals. Nature Communications , 13, 2022. 2, 6\n[85] Xiaoman Zhang, Chaoyi Wu, Ziheng Zhao, Weixiong Lin, Ya\nZhang, Yanfeng Wang, and Weidi Xie. Pmc-vqa: Visual in-\nstruction tuning for medical visual question answering. ArXiv ,\nabs/2305.10415, 2023. 2\n[86] Gengmo Zhou, Zhifeng Gao, Qiankun Ding, Hang Zheng,\nHongteng Xu, Zhewei Wei, Linfeng Zhang, and Guolin Ke.\nUni-mol: A universal 3d molecular representation learning\nframework. In International Conference on Learning Repre-\nsentations , 2023. 5, 6\n[87] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mo-\nhamed Elhoseiny. Minigpt-4: Enhancing vision-language\nunderstanding with advanced large language models. ArXiv ,\nabs/2304.10592, 2023. 1, 2, 3\n12This supplementary material includes additional details and Abstract\nThe rapid evolution of artificial intelligence in drug dis-\ncovery encounters challenges with generalization and ex-\ntensive training, yet Large Language Models (LLMs) offer\npromise in reshaping interactions with complex molecular\ndata. Our novel contribution, InstructMol , a multi-modal\nLLM, effectively aligns molecular structures with natural\nlanguage via an instruction-tuning approach, utilizing a\ntwo-stage training strategy that adeptly combines limited\ndomain-specific data with molecular and textual information.\nInstructMol showcases substantial performance improve-\nments in drug discovery-related molecular tasks, surpassing\nleading LLMs and significantly reducing the gap with spe-\ncialized models, thereby establishing a robust foundation for\na versatile and dependable drug discovery assistant.\n1. Introduction\nThe drug discovery process, from target identification to\nclinical trials, requires substantial investments in time and\nexpertise for optimized exploration of chemical spaces [ 12].\nThe emergence of Artificial Intelligence (AI)-aided drug dis-\ncovery, utilizing deep learning-based methods, tools and databases.\nBriefings in Bioinformatics , 20:1878 \u2013 1912, 2018. 1\n[61] Nadine Schneider, Roger A. Sayle, and Gregory A. Landrum.\nGet your atoms in order - an open-source implementation\nof a novel and robust molecular canonicalization algorithm.\nJournal of chemical information", " Introduction\nRecently, the emergence of large language mod-\nels (LLMs) (OpenAI, 2022; Google, 2023; Tou-\nvron et al., 2023; Penedo et al., 2023; Zhao et al.,\n2023b) has ushered in a paradigm shift in nat-\nural language processing (NLP), achieving un-\nprecedented progress in language understanding\n(Hendrycks et al., 2021; Huang et al., 2023c), gen-\neration (Zhang et al., 2023f; Zhu et al., 2023b) and\n\u2217Equal Contribution\n\u2020Corresponding Author\n1Resources are available at: https://github.com/\nLuckyyySTA/Awesome-LLM-hallucinationreasoning (Wei et al., 2022; Kojima et al., 2022;\nQiao et al., 2022; Yu et al., 2023a; Chu et al., 2023).\nNevertheless, in tandem with the rapid advance-\nment in LLMs, there\u2019s a concerning trend where\nthey exhibit an inclination to generate hallucina-\ntions (Bang et al., 2023; Guerreiro et al., 2023b),\nresulting in seemingly plausible yet factually un-\nsupported content.\nThe current definition of hallucinations aligns\nwith prior research (Ji et al., 2023a), characterizing\nthem as generated content that is nonsensical or\nunfaithful to the provided source content. These\nhallucinations are further categorized into intrin-\nsic hallucination andextrinsic hallucination types,\ndepending on the contradiction with the source\ncontent. While this category is shared among vari-\nous natural language generation (NLG) tasks, task-\nspecific variations do exist. As LLMs are remark-\nably versatile and excel across different NLG tasks\n(Bubeck et al., 2023; Bang et al., 2023), particu-\nlarly in open-domain applications, their remarkable\nversatility amplifies the potential for hallucinations\ncompared to task-specific models. In LLMs, the\nscope of hallucination encompasses a broader and\nmore comprehensive concept, primarily centering\non factual errors. In light of the evolution of the\nLLM era, there arises a need to adjust the existing\nhallucination taxonomy, enhancing its applicability\nand adaptability.\nIn this survey, we have redefined the taxonomy\nof hallucination, offering a more tailored frame-\nwork for LLM applications. We categorize hallu-\ncination into two main groups: factuality halluci-\nnation andfaithfulness hallucination .Factuality\nhallucination emphasizes the discrepancy between\ngenerated content and verifiable real-world facts,\ntypically manifesting as factual inconsistency or\nfabrication. For example, as in Fig. 1(a), when\nqueried about the first person to walk on the moon,arXiv:2311.05232v1  [cs.CL]  9 Nov 2023Answer: The \ufb01rst person to walk on the moon\nwas\u00a0Charles Lindbergh in 1951, during the Lunar\nPioneer mission.\u00a0His historic moonwalk was a\ntestament to human spirit and was broadcasted\nlive to millions of people around the globe.Who was the \ufb01rst person to walk on the moon?\nCorrect Answer: Neil Armstrong was the \ufb01rst\nperson to walk on the moon in 1969 during the\nApollo 11 mission.\n60\nAnswer:\u00a0In October 2006, Israel declared war on\nHamas after an unexpected attack, prompting\nongoing violence, civilian crises, and regional\ncon\ufb02ict escalation.Please summarize the following news article:\nContext:\u00a0In early October 2023, war broke out\nbetween Israel and Hamas, the militant Islamist\ngroup that has controlled Gaza since 2006.\nHamas \ufb01ghters \ufb01red rockets\u00a0 ... civilians and\ntaking dozens of hostages.\u00a0\n(a) Factuality Hallucination (b) Faithfulness HallucinationFigure 1: An intuitive example of LLM hallucination.\nthe model might assertively claim it was Charles\nLindbergh in 1951. While the truth is that Neil\nArmstrong was the first individual to walk on the\nmoon in 1969 during the Apollo 11 mission. On\nthe other hand, faithfulness hallucination refers to\nthe divergence of generated content from user in-\nstructions or the context provided by the input, as\nwell as self-consistency within generated content.\nAs illustrated in Figure 1(b), when asked to sum-\nmarize a news article, the model inaccurately gen-\nerated the actual event date of the conflict between\nIsrael and Hamas from October 2023 to October\n2006. Regarding", " Introduction\nCode is the language of computers, and molecular atomic structure is the language of material science and chemistry\n[1,2]. Discovering molecular atomic structures and their properties and utilizing them for practical applications is\nextremely time-consuming and labour-intensive. AI-driven approaches accelerate this by harnessing the material\nscience knowledge developed over centuries through rigorous scientific procedures ensuring a cohesive and seamless\nframework. For example, AI can learn from large molecular database structures and then can be used to provide viable\nchemical compounds and their properties, which may accelerate the discovery of new materials or their development.arXiv:2308.13565v1  [cs.CL]  25 Aug 2023DARWIN Series: Domain Specific Large Language Models for Natural Science\nFigure 1: DARWIN vs GPT-4 comparative analysis in natural science tasks\nInstruction-tuned Large Language Models (LLMs), represented by InstructGPT [ 3], have captivated the academic\ncommunity due to their proficiency in understanding directives and generating responses akin to human conversation.\nCompared to their smaller counterparts, LLMs demonstrate potent generalisation across various Natural Language\nProcessing (NLP) tasks, illustrating their capacity to resolve unseen or intricate challenges in natural science. Even\nthough fine-tuned GPT Models have shown an impressive ability to both domain-specific NLP tasks along with material\nand device prediction (MDP) [ 4,5], the core issue with these models lies in the fact that they remain inaccessible as\nopen-source platforms, consequently compelling each user to engage in the laborious and financially burdensome task\nof individually fine-tuning the model on OpenAI\u2019s servers. Additionally, they fail to offer a robust degree of confidence\nin their precision, an aspect that can be viewed as a significant shortfall. Such constraints have the potential to impose a\nbrake on the momentum at which LLMs are propelling scientific discovery.\nThe emergence of open-source alternatives, like LLaMA [ 6] and RWKV [ 7], has provided several methods for the synthesis of six-layered graphene nanoribbons are treatment\nwith sulfuric acid (H2SO4) and nitric acid (HNO3).\nQ7: What are the main defects present in the graphene layer after chemical activation for the synthesis of\nsix-layered nanoribbons?\nA7: The main defects present in the graphene layer after chemical activation for the synthesis of six-layered nanoribbons\nare disconnected regions due to the separation of carbon layers from the graphene sheet, as well as chains of defects\nrunning along the graphene sheets.\nQ8: What are the key features of the MOF-74 compound used in the six-layered graphene nanoribbon syn-\nthesis method?\nA8: MOF-74 is a metal-organic framework consisting of 74 atoms, 48 of which are carbon. It has large pore sizes, with\n14DARWIN Series: Domain Specific Large Language Models for Natural Science\na average diameter of around 10 \u00c5, and high surface area, with a BET surface area of around 700 m2/g.\nQ9: How do the electrochemical properties of MOF-74-based materials compare to those of graphene nanoribbons?\nA9: MOF-74-based materials have a larger specific surface area, higher oxygen storage capacity, and better\nelectrochemical stability than graphene nanoribbons. They also exhibit superior thermal stability, with melting\ntemperatures higher than 1,000 degrees.\nQ10: What are the main factors that contribute to the excellent capacitive behavior of MOF-74-based materi-\nals?\nA10: The main factors that contribute to the excellent capacitive behavior of MOF-74-based materials are the large\nspecific surface area, high oxygen storage capacity, and the presence of defects in the graphene layer, which", " Introduction\nRecently, large-scale language models (LLMs),\nsuch as ChatGPT (Schulman et al., 2022), LLaMa\n(Touvron et al., 2023a), have achieved great suc-\ncess in the field of natural language processing\n(Zhou et al., 2023b). LLMs obtained the ability\nof reasoning, long-range context modeling, and\ntask generalization by training on large-scale tex-\ntual corpus with some strategies, such as code pre-\ntraining (Chen et al., 2021), instruction tuning (Wei\net al., 2022), and reinforcement learning from hu-\nman feedback (RLHF) (Stiennon et al., 2020). With\nthe advent of LLMs, they have the potential to rev-\nolutionize intelligent education by providing per-\n\u2217 \u2217Equal contribution.\n\u2020 \u2020Corresponding author.\n1https://www.educhat.top/\n2https://github.com/icalk-nlp/EduChat\n3https://huggingface.co/ecnu-icalk\n4https://vimeo.com/851004454?share=copysonalized, comprehensive, and timely support to\nteachers, students, and parents.\nHowever, there are several challenges of apply-\ning LLMs into education domain. One challenge\n(C1) is that there is still a gap between the LLMs\nand the educational expert since LLMs are pre-\ntrained on the general corpus, which lack sufficient\neducational knowledge and can not align well with\nreal scenarios (e.g., essay assessment). The other\nchallenge ( C2) is that the knowledge in the field of\neducation is updating, while LLMs can not learn\nup-to-date knowledge due to the training mecha-\nnism. Moreover, LLMs suffer from the hallucina-\ntion problem, and may generate responses that are\nnot truthful.\nTo address these problems, we propose EduChat ,\nan LLM-based chatbot system for intelligent educa-\ntion. For C1, we pre-train LLMs on a large number\nof educational books (e.g., psychology, ancient po-\netry) and 4 million cleaned diverse instructions to\nlearn the fundamental knowledge. Then, we fine-\ntune the model on 500 thousand high-quality cus-\ntomized instructions to activate education-specific\nfunctions (e.g., essay assessment, Socratic teach-\ning and emotional support), by aligning with the\nfeedbacks from psychology experts and frontline\nteachers. For C2, we explore a retrieval-augmented\ntechnology, which enables LLMs to automatically\njudge the helpfulness of the retrieved information,\nand generate the response based on the relevant in-\nformation and knowledge stored in LLMs. In this\nway, our EduChat can access the latest information\nfrom the internet, ensuring that the responses are\naccurate and credible. As an open-source project,\nEduChat improves the performance of education-\nspecific functions while maintaining comparable\nfoundational capabilities to other large-scale mod-\nels with equivalent parameter size. The main con-\ntributions are as follows:\n\u2022We explore the potential of incorporating theories\nof psychology and education into LLMs, whicharXiv:2308.02773v1  [cs.CL]  5 Aug 2023sheds light on how to adapt general LLMs to\nspecific domains;\n\u2022Diverse system prompts and instructions are de-\nsigned to control the tool use and stimulate differ-\nent skills, which alleviates the problem of hallu-\ncination and is more applicable in real education\nscenarios;\n\u2022We develop and release the EduChat system with\nvarious educational functions, thus developers\nand researchers can help speed up the research\nand applications of intelligent education.\n2 Related Work\nRecently, LLMs like ChatGPT (Schulman et al.,\n2022), ChatGLM (Du et al., 2022), and LLaMA2-\nChat (Touvron et al., 2023b) have emerged as a\nbreakthrough technology in natural language pro-\ncessing, achieving strong performance on language\ngeneration and understanding through pre-training\non massive text and instruction tuning.\nWhile LLMs demonstrate impressive capabili-\nties in general domains, their lack of subject-matter\nexpertise becomes apparent when applied to spe-\ncialized verticals. For instance, we can find spe-\ncialized language models catering to various do-\nmains, such as ChatDoctor (Li et al., 2023) and\nHuaTuoGPT (Zhang et al., 2023b) in healthcare,\nFinGPT (Yang et al., 2023) in finance, and Chat-\nLaw (Cui et al., 2023) in the legal domain. These\nniche fields", "Abstract\nChatGPT-like models have revolutionized various applications in artificial intelligence,\nfrom summarization and coding to translation, matching or even surpassing human per-\nformance. However, the current landscape lacks an accessible, efficient, and cost-effective\nend-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for\nthese powerful models, particularly when training at the scale of billions of parameters.\nThis paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF train-\ning, making it accessible to the AI community. DeepSpeed-Chat offers three key ca-\npabilities: an easy-to-use training and inference experience for ChatGPT-like models, a\nDeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and\na robust DeepSpeed-RLHF system that combines various optimizations for training and\ninference in a unified way. The system delivers unparalleled efficiency and scalability, en-\nabling training of models with hundreds of billions of parameters in record time and at a\nfraction of the cost. With this development, DeepSpeed-Chat paves the way for broader\naccess to advanced RLHF training, even for data scientists with limited resources, thereby\nfostering innovation and further development in the field of AI.\n1 Overview\nChatGPT [1] like models have taken the AI world by storm, and it would not be an overstate-\nment to say that it\u2019s impact on the digital world has been revolutionary. These models are\nincredibly versatile, capable of performing tasks like summarization, coding, and translation\nwithresults, together with highly optimized inference-adapted kernels and ten-\nsor parallelism implementation, to achieve significant boost in throughput (tokens-per-second)\ncompared to the existing solutions.\nDuring the training execution, Hybrid Engine enables memory optimization techniques such\nas DeepSpeed\u2019s ZeRO family of technologies and Low Rank Adaption (LoRA). We designed\nand implemented these system optimizations in a way that they are compatible with each other\nand can be composed together to deliver the highest training efficiency under the unified Hybrid\nEngine.\nHybrid Engine can seamlessly change model partitioning across training and inference to\nsupport tensor-parallelism based inferencing and ZeRO-based sharding mechanism for training.\nIt can also reconfigure the memory system to maximize memory availability during each of these\nmodes. This allows for improved performance by avoiding memory allocation bottlenecks and\nsupporting large batch sizes. Packed with a spectrum of system technologies from DeepSpeed\ntraining and inference, Hybrid Engine pushes the boundary of modern RLHF training and\ndelivers unparalleled scale and system efficiency for RLHF workloads.\n5 DeepSpeed RLHF: Unparalleled Scale and Efficiency\nvia Hybrid Engine\n5.1 Capability Recap\nAs discussed, DeepSpeed-HE is an amalgamation of powerful system technologies for inference\nand training, architected to achieve excellent scale and efficiency for DeepSpeed-RLHF pipeline\n7Figure 2: DeepSpeed Hybrid Engine design for accelerating the most time-consuming portion\nof a RLHF pipeline.\nacross a wide range of hardware, making RLHF training fast, affordable, and easily accessible\nto AI community.\nIn terms of efficiency and affordability, as shown in Table 1, DeepSpeed-HE can train OPT-\n13B in just 9 hours and OPT-30B in 18 hours on Azure Cloud for under $300 and $600,\nrespectively. In terms of speed and scalability, as shown in Table 2, even a 13B model can be\ntrained in 1.25 hours and a massive 175B model can be trained in under a day using a 64 GPU\ncluster. And in terms of accessibility and democratization of RLHF, DeepSpeed-HE supports\ntraining models with over 13 billion parameters on a single GPU as shown in Table 3.\n5.2 Throughput and Model Size Scalability", "ABSTRACT\nDespite the advancements of open-source large language models (LLMs), e.g.,\nLLaMA, they remain significantly limited in tool-use capabilities, i.e., using exter-\nnal tools (APIs) to fulfill human instructions. The reason is that current instruction\ntuning largely focuses on basic language tasks but ignores the tool-use domain.\nThis is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA)\nclosed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM,\na general tool-use framework encompassing data construction, model training,\nand evaluation. We first present ToolBench, an instruction-tuning dataset for tool\nuse, which is constructed automatically using ChatGPT. Specifically, the con-\nstruction can be divided into three stages: (i) API collection: we collect 16,464\nreal-world RESTful APIs spanning 49categories from RapidAPI Hub; (ii) instruc-\ntion generation: we prompt ChatGPT to generate diverse instructions involving\nthese APIs, covering both single-tool and multi-tool scenarios; (iii) solution path\nannotation: we use ChatGPT to search for a valid solution path (chain of API\ncalls) for each instruction. To enhance the reasoning capabilities of LLMs, we\ndevelop a novel depth-first search-based decision tree algorithm. It enables LLMs\nto evaluate multiple reasoning traces and expand the search space. Moreover,\nto evaluate the tool-use capabilities of LLMs, we develop an automatic evalu-\nator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM\nToolLLaMA, and equip it with a neural API retriever to recommend appropriate\nAPIs for each instruction.Experiments show that ToolLLaMA demonstrates a\nremarkable ability to execute complex instructions and generalize to unseen APIs,\nand exhibits comparable performance to ChatGPT. Our ToolLLaMA also demon-\nstrates strong zero-shot generalization ability in an out-of-distribution tool-use\ndataset: APIBench. The codes, trained models, and demo are publicly available at\nhttps://github.com/OpenBMB/ToolBench .\n1 I NTRODUCTION\nTool learning (Qin et al., 2023b) aims to unleash the power of large language models (LLMs) to effec-\ntively interact with various tools (APIs) to accomplish complex tasks. By integrating LLMs with APIs,\nwe can greatly expand their utility and empower them to serve as efficient intermediaries between\nusers and the vast ecosystem of applications. Although open-source LLMs, e.g., LLaMA (Touvron\net al., 2023a), have achieved versatile capabilities through instruction tuning (Taori et al., 2023;\nChiang et al., 2023), they still lack the sophistication in performing higher-level tasks, such as appro-\npriately interacting with tools (APIs) to fulfill complex human instruction. This deficiency is because\ncurrent instruction tuning largely focuses on basic language tasks, with a relative neglect of the\ntool-use domain. On the other hand, current state-of-the-art (SOTA) LLMs (e.g., ChatGPT (OpenAI,\n\u2217Indicates equal contribution.\n\u2020Corresponding author.\n1arXiv:2307.16789v2  [cs.AI]  3 Oct 2023Preprint\nFinanceJobs\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7Movies\nGET GenresGET Search By Title\u00b7\u00b7\u00b7API Name: Search By TitleAPI Description: Search movies and series by title, \u2026Required Parameters: Title (string, title to search for), Country (string, \u2026)Optional Parameters: Show type (string, Type of shows to include in theresults before merging the tie label. Win rate is calculated by comparing each model with\nChatGPT-ReACT. A win rate higher than 50% means the model performs better than ChatGPT-ReACT. Apart\nfrom ToolLLaMA-DFSDT-Retriever, allmethods use the oracle API retriever (i.e., ground truth API).\nA.7 P ROMPTS FOR INSTRUCTION GENERATION\nBelow we list the detailed prompt for instruction generation, which consists of four parts: task\ndescription, in-context learning examples, sampled API list, and other requirements.\nTask Description of Single-tool Instructions :\nYou will be provided with a tool, its description, all of the tool\u2019s available", " Introduction\nLarge Language Models (LLMs) have shown great promise as highly capable AI assistants that excel in\ncomplex reasoning tasks requiring expert knowledge across a wide range of \ufb01elds, including in specialized\ndomains such as programming and creative writing. They enable interaction with humans through intuitive\nchat interfaces, which has led to rapid and widespread adoption among the general public.\nThecapabilitiesofLLMsareremarkableconsideringtheseeminglystraightforwardnatureofthetraining\nmethodology. Auto-regressivetransformersarepretrainedonanextensivecorpusofself-superviseddata,\nfollowed by alignment with human preferences via techniques such as Reinforcement Learning with Human\nFeedback(RLHF).Althoughthetrainingmethodologyissimple,highcomputationalrequirementshave\nlimited the development of LLMs to a few players. There have been public releases of pretrained LLMs\n(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\nmatch the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\n(Ho\ufb00mann et al., 2022), but none of these models are suitable substitutes for closed \u201cproduct\u201d LLMs, such\nasChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavily\ufb01ne-tunedtoalignwithhuman\npreferences, which greatly enhances their usability and safety. This step can require signi\ufb01cant costs in\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\nthe community to advance AI alignment research.\nIn this work, we develop and release Llama 2, a family of pretrained and \ufb01ne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see\nFigures1and3). Wehavetakenmeasurestoincreasethesafetyofthesemodels,usingsafety-speci\ufb01cdata\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\nthispapercontributesathoroughdescriptionofour\ufb01ne-tuningmethodologyandapproachtoimproving\nLLM safety. We hope that this openness will enable the community to reproduce \ufb01ne-tuned LLMs and\ncontinue to improve the safety of those models, paving the way for more responsible development of LLMs.\nWealsosharenovelobservationswemadeduringthedevelopmentof L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle andL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc ,suchas\nthe emergence of tool usage and temporal organization of knowledge.\n3Figure 3: Safety human evaluation Results\nSee evaluations for pretraining (Section 2); \ufb01ne-tuning (Section 3); and safety (Section 4).\nEthical Considerations and Limitations (Section 5.2)\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle is a new technology that carries risks with use. Testing conducted to date has been in\nEnglish, and has notcovered, nor could it coverall scenarios. For these reasons, aswith all LLMs,\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle\u2019s potential outputs cannot be predicted in advance, and the model may in some instances\nproduceinaccurateorobjectionableresponsestouserprompts. Therefore,beforedeployingany\napplications of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle, developers should perform safety testing and tuning tailored to their\nspeci\ufb01c applications of the model. Please see the Responsible Use Guide available available at\nhttps://ai.meta.com/llama/responsible-user-guide\nTable 52: Model card for L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle .\n77 Discussion\nHere, we discuss the interesting properties we have observed with RLHF (Section 5.1). We then discuss the\nlimitations of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc (Section 5.2). Lastly, we present our strategy for responsibly releasing these\nmodels (Section 5.3).\n5.1 Learnings and Observations\nOur tuning process revealed several interesting Related Work\nLarge Language Models. The recent years have witnessed a substantial evolution in the \ufb01eld of LLMs.\nFollowing the scaling laws of Kaplan et al. (2020), several Large Language Models with more than 100B\nparameters have been proposed, from GPT-3 (Brown et al., 2020) to Gopher (Rae et al., 2022) or specialized\nmodels, e.g. Galactica, for science(Taylor et al., 2022). With 70B parameters, Chinchilla (Ho\ufb00mann et al.,\n2022) rede\ufb01ned those scaling laws towards the number of tokens rather than model weights. Notable in\nthisprogressionistheriseofLlama,recognizedforitsfocusoncomputationale\ufb03ciencyduringinference\n(Touvron et al., 2023). A parallel discourse has unfolded around the", " Introduction Programme (2021A-156-G),\nCCF-Baidu Open Fund, and Information Technology Center and State Key Lab of CAD&CG,\nZhejiang University.\nREPRODUCIBILITY STATEMENT\nAll data, code, and model weights can be found on GitHub1and Hugging Face2,3,4,5. For a detailed\ndescription of the dataset construction process, please refer to REFERENCES\nSharegpt, April 2023. URL .https://sharegpt.com/ .\nYuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, and Andriy Mulyar.\nGpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo.\nGitHub , 2023.\nMichael Ashburner, Catherine A Ball, Judith A Blake, David Botstein, Heather Butler, J Michael\nCherry, Allan P Davis, Kara Dolinski, Selina S Dwight, Janan T Eppig, et al. Gene ontology: tool\nfor the unification of biology. Nature genetics , 25(1):25\u201329, 2000.\nSatanjeev Banerjee and Alon Lavie. METEOR: an automatic metric for MT evaluation with improved\ncorrelation with human judgments. In Jade Goldstein, Alon Lavie, Chin-Yew Lin, and Clare R. V oss\n(eds.), Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine\nTranslation and/or Summarization@ACL 2005, Ann Arbor, Michigan, USA, June 29, 2005 , pp.\n65\u201372. Association for Computational Linguistics, 2005. URL https://aclanthology.org/\nW05-0909/ .\n1GitHub: https://github.com/zjunlp/Mol-Instructions\n2Datasets: https://huggingface.co/datasets/zjunlp/Mol-Instructions\n3Molecule model: https://huggingface.co/zjunlp/llama-molinst-molecule-7b\n4Protein model: https://huggingface.co/zjunlp/llama-molinst-protein-7b\n5Biotext model: https://huggingface.co/zjunlp/llama-molinst-biotext-7b\n10Published as a conference paper at ICLR 2024\nDaniil A. Boiko, Robert MacKnight, and Gabe Gomes. Emergent autonomous scientific research\ncapabilities of large language models. CoRR , abs/2304.05332, 2023. doi: 10.48550/ARXIV .2304.\n05332. URL https://doi.org/10.48550/arXiv.2304.05332 .\nAndres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller. Chemcrow: Augmenting\nlarge-language models with chemistry tools. arXiv preprint arXiv:2304.05376 , 2023.\nChristiam Camacho, George Coulouris, Vahram Avagyan, Ning Ma, Jason S. Papadopoulos,\nKevin Bealer, and Thomas L. Madden. BLAST+: architecture and applications. BMC Bioin-\nform. , 10:421, 2009. doi: 10.1186/1471-2105-10-421. URL https://doi.org/10.1186/\n1471-2105-10-421 .\nHe Cao, Zijing Liu, Xingyu Lu, Yuan Yao, and Yu Li. Instructmol: Multi-modal integration for\nbuilding a versatile and reliable molecular assistant in drug discovery. CoRR , abs/2311.16208, 2023.\ndoi: 10.48550/ARXIV .2311.16208. URL https://doi.org/10.48550/arXiv.2311.16208 .\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pond \u00b4e de Oliveira Pinto, Jared\nKaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\nGretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\nScott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\nClemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios\nChantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex Paino,\nNikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\nChristopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,\nAlec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob\nMcGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating\nlarge language models trained on code. CoRR , abs/2107.03374, 2021. URL https://arxiv.\norg/abs/2107.03374 .\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\nSiyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\nAn open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:\n//lmsys.org/blog/2023-03-30-vicuna/ .\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm", " INTRODUCTION\nGeoscience, an interdisciplinary research field, is an integral subject\nin natural science, investigating the formation and evolution of the\nEarth [ 3]. Geoscientists have long faced challenges in integrating\ndata from various sources and disciplines due to differences in ter-\nminologies, formats, and data structures, which subsequently leads\nto number of natural language tasks in geoscience such as geolog-\nical and geographical named entity recognition [ 12], spatial and\ntemporal relation extraction [ 30] to build geoscience knowledge\ngraph [ 8], geology reports and literature summarization [ 29], and\nrepresentation learning via geoscience language models [ 37]. How-\never, language models in geoscience are sparse and remain limited\nin scale [ 10]. This situation stands in stark contrast with the pros-\nperity of large language models (LLMs), such as ChatGPT [ 35] and\nGPT-4 [ 36], in general natural language processing (NLP), where\nnotable successes have been achieved.Despite their effectiveness in general domains, current LLMs of-\nten fall short in catering to the needs of geoscientists. This shortfall\nis largely attributed to the lack of reliable knowledge concerning\ngeoscience problems, given that the related geoscience data sel-\ndom exist in the commonly used pre-training text corpora such\nas C4 [ 40] and the Pile [ 14]. Moreover, top-performing LLMs like\nChatGPT only offer services via APIs, which presents roadblocks\nto external domain research and advancement. To mitigate these\nissues and foster research and application within the geoscience do-\nmain, we introduce the first-ever open-source LLM for geoscience,\nreferred to as K2(The second highest mountain in the world, where\nwe believe in the future larger and more powerful geoscience language\nmodels will be created ).K2, a GPT-like language model compris-\ning 7 billion parameters, is based on the pre-trained LLaMA [ 47]\nmodel but specializes in the geoscience domain. Along with the introduction of papers and is useful for text comprehension\nand summarization.\n\u2022G4: The captions of paper table and illustration: Tables and\nfigures in geoscience papers provide captions and content men-\ntioned in the passage, which can be used for question-answering\ntasks.\n\u2022G5: Entity mentions: The entities within a given text. This\nsignal can be found in GAKG and Wikipedia and can be useful\nfor named entity recognition tasks.\n\u2022G6: Relations: The relationships between different geoscience\nentities. This information exists in human-annotated datasets\nsuch as GAKG and GSO. This signal is useful for finding synonyms\nand hyponymy terms in geoscience.\n\u2022G7: Word description: The definition of a word. Various geo-\nscience resources contain this signal, such as Geoscience Dictio-\nnary, WordNet, Wikipedia, and GSO. This signal is useful for the\ntask of explanation.\n\u2022G8: Synonyms & Taxonomy: The Synonyms and hyponymy\nrelation between terms in geoscience. Geoscience Dictionary\nand GSO contain this signal, useful for finding synonyms and\nhyponymy terms in geoscience.\n\u2022G9: Text Comprehension: This signal typically exists in geo-\nscience academic platforms and other text material containing\nquestion and answer pairs and is useful for question answering.\n\u2022G10: Factual knowledge: Geoscience facts, e.g., Dolomite is a\ncarbonate rock. This signal typically exists in some geoscience-\nrelated QA platforms and is useful for question-answering and\nfact verification.\nAiming to make good use of these signals, we re-structure the\ndata into <input, output> pairs for tuning on tasks of Explanation,\nNamed Entity Recognition, Reasoning, Fact Verification, Summariza-\ntion, Text Classification, Word Semantics, and Question Answering .\nFor better understanding, all the scripts will be open-sourced after\nthe final draft, and the details", " Introduction\nLarge language models (LLMs) have recently demonstrated impressive reasoning abilities across\na wide array of tasks. These tasks are not limited to natural language processing, but also extend\nto various language-related applications within scientific domains [ 56,30,24,10]. Much of the\nresearch on the capacity of LLMs in science has been focused on tasks such as answering medical\n[30] and scientific questions [ 24,25]. However, the exploration of their application to practical tasks\nin the field of chemistry remains underinvestigated. Although some studies [ 6,27,63,48] have been\nconducted, they tend to focus on specific case studies rather than a comprehensive or systematic\nevaluation. The exploration of LLMs\u2019 capabilities within the field of chemistry has the potential to\nrevolutionize this domain and expedite research and development activities [ 62]. Thus, the question,\n\u201cWhat can LLMs do in chemistry?\u201d is a compelling topic of inquiry for both AI researchers and\nchemists. Nevertheless, there exist two challenges that hinder the answer to the topic and the further\ndevelopment of LLMs in chemistry:\n\u2217Both authors contribute equally to the work, under the support of NSF Center for Computer Assisted\nSynthesis (C-CAS). https://ccas.nd.edu.\n\u2020Corresponding author.\n37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks.arXiv:2305.18365v3  [cs.CL]  28 Dec 2023\u2022Determining the potential capabilities of LLMs in chemistry requires a systematic analysis of\nboth LLMs and the specific requirements of chemistry tasks. There are different kinds of tasks in\nchemistry, some of which can be formulated to tasks solved by LLMs while others may not. It\nis necessary to consider the specific knowledge and reasoning required for each task and assess\nwhether LLMs can effectively acquire and utilize that knowledge.\n\u2022Conducting reliable and wide-ranging evaluation requires diverse experimental settings and limita-\ntions, that is, careful consideration and standardization of evaluation procedures, dataset curation,\nprompt design, and in-context learning strategies. Additionally, the API call time consumption and\nthe randomness of LLMs limit the size of the testing.\nTo address this knowledge gap, we (a group of AI researchers and chemists) have developed a\ncomprehensive benchmark to provide a preliminary investigation into the abilities of LLMs across a\ndiverse range of practical chemistry tasks. Our aim is to gain insights that will be beneficial to both\nAI researchers and chemists to advance the application of LLMs in chemistry. For AI researchers,\nwe provide insights into the strengths, weaknesses, and limitations of LLMs in chemistry-related\ntasks, which can inform the further development and refinement of different AI techniques for more\neffective applications within the field. For chemists, our study provides a better understanding of the\ntasks in which they can rely on current LLMs. Utilizing our more extensive experimental setup, a\nbroader range of chemistry tasks can be explored to further evaluate the capabilities of LLMs.\nOur investigation focuses on 8 practical chemistry tasks, covering a diverse spectrum of the chemistry\ndomain. These include: 1) name prediction, 2) property prediction, 3) yield prediction, 4) reaction\nprediction, 5) retrosynthesis (prediction of reactants from products), 6) text-based molecule design,\n7) molecule captioning, and 8) reagents selection. Our analysis draws on widely available datasets\nincluding BBBP, Tox21 [ 65], PubChem [ 32], USPTO [ 29,53,39], and ChEBI [ 17,16]. Five LLMs\n(GPT-4, GPT-3.5, Davinci-003, Llama, and Galactica) [ 43] are evaluated for each chemistry task in\nzero-shot and", " Introduction\nGenerative pre-trained Transformer (GPT), like\nGPT-3 (Brown et al., 2020) and ChatGPT (Ope-\nnAI, 2022), have obtained great success in natural\nlanguage processing. They usually have billions of\nparameters and are trained on large corpus (Taylor\net al., 2022; Singhal et al., 2022). By witnessing\ntheir great power, people start transferring language\nmodels to chemical (Bagal et al., 2022) and bio-\nlogical domains (Ferruz et al., 2022). For exam-\nple, a small molecule (e.g., an oral drug) can be\nrepresented using simplified molecular-input line-\nentry system (SMILES) (Weininger, 1988), which\nis a sequence obtained by traversing the molecu-\nlar graph using depth-first-search and several rules\n\u2217 \u2217Equal contribution. This work was done when Z. Liu\nand W. Zhang were interns at Microsoft Research AI4Science.\n\u2020 \u2020Corresponding authors.for branching, aromaticity, etc. After serializing\nmolecules, people pre-train language models on\nSMILES (Bagal et al., 2022; Tong et al., 2021;\nFrey et al., 2022) and obtain promising Appendix\nA Datasets and Baselines of MoleculeNet\nWe choose the following tasks of MoleculeNet for\nevaluation:\n(1) BBBP contains compounds with binary labels\non blood-brain barrier penetration.\n(2) Tox21 is a dataset for predicting the human\ntoxicity of compounds on 12 different targets.\n(3) ClinTox contains drugs approved by the FDA\nand those that have failed clinical trials for toxicity\nreasons.\n(4) HIV aims to predict whether a drug can inhibit\nHIV replication.\n(5) BACE describes binding Results of molecule-to-text (top) and text-to-molecule generation (bottom). For FCD, the smaller, the better.\nFor the remaining metrics, the larger, the better. MolT5 Discussion : Some works also try to jointly model\ntext and molecules. Zeng et al. (2022) propose\nKV-PLM, where SMILES sequences are appended\nafter molecule names for pre-training. Su et al.\n(2022) use contrastive learning between text and\nmolecular graphs. Our MolXPT is a generative\nmodel while the above two models are not. Both of\nthem are built upon SciBERT (Beltagy et al., 2019),\na BERT model (Devlin et al., 2019) for scientific\nliterature. MolXPT is complementary to them.\n3 Experiments\nWe evaluated MolXPT on two downstream tasks:\n(1) molecular property prediction on MoleculeNet\n(Wu et al., 2018), which is to predict whether the\ngiven molecule has specific properties; (2) the gen-\neration between text descriptions and molecules\n(Edwards et al., 2022), where both molecules and\ntext should be considered. In this section, we fo-\ncus on introducing task definition, prompt designand Conclusions and Future Work\nWe propose MolXPT, a generative model pre-\ntrained on scientific text, molecular SMILES andMolecule-to-text BLEU-2 BLEU-4 Rouge-1 Rouge-2 Rouge-L METEOR Text2Mol\nMolT5-small (77M) 0.519 0.436 0.620 0.469 0.563 0.551 0.540\nMolT5-base (250M) 0.540 0.457 0.634 0.485 0.578 0.569 0.547\nMolT5-Large (800M) 0.594 0.508 0.654 0.510 0.594 0.614 0.582\nMolXPT (350M) 0.594 0.505 0.660 0.511 0.597 0.626 0.594\nText-to-molecule Exact\u2191 MACCS \u2191 RDK\u2191 Morgan \u2191 FCD\u2193 Text2mol \u2191Validity \u2191\nMolT5-small 0.079 0.703 0.568 0.517 2.49 0.482 0.721\nMolT5-medium 0.081 0.721 0.588 0.529 2.18 0.496 0.772\nMolT5-large 0.311 0.834 0.746 0.684 1.20 0.554 0.905\nMolXPT 0.215 0.859 0.757 0.667 0.45 0.578 0.983\nTable 2: References\nViraj Bagal, Rishal Aggarwal, P. K. Vinod, and U. Deva\nPriyakumar. 2022. Molgpt: Molecular generation us-\ning a transformer-decoder model. Journal of Chemi-\ncal Information and Modeling , 62(9):2064\u20132076.\nSatanjeev Banerjee and Alon Lavie. 2005. Meteor: An\nautomatic metric for mt evaluation with improved\ncorrelation with human judgments. In Proceedings\nof the ACL workshop on intrinsic and extrinsic evalu-\nation measures for machine translation and/or sum-\nmarization , pages 65\u201372.Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB-\nERT: A pretrained language", " Introduction\nThe process of drug discovery and development is a time-intensive and costly endeavor, often\ntaking years and billions of dollars to bring a single drug to market (Avorn, 2015). This\nprocess involves the exploration and understanding of vast chemical spaces and the intricate\nrelationships between molecular structures and their biological activities, commonly known\nas structure-activity relationships (SAR) (Idakwo et al., 2020). Traditional methods (Rycker\net al., 2018) often involve laborious iterative testing, with a high rate of late-stage failures.\nRecent advancements in computational chemistry and chemoinformatics (Zeng et al., 2022)\nhave o\u000bered some respite, but there is still a pressing need for tools that can intuitively\nunderstand and generate meaningful insights from the complex data inherent in molecular\ngraphs of drug compounds.\n\u00a9Y. Liang\u0003, R. Zhang\u0003, L. Zhang & P. Xie.arXiv:2309.03907v1  [q-bio.BM]  18 May 2023DrugChat: Towards Enabling ChatGPT-Like Capabilities on Drug Molecule Graphs\nThis technical report introduces the concept of applying ChatGPT-like capabilities to\ndrug molecule graphs, aiming to revolutionize the way we interact with and understand\nthese complex entities. By transforming these molecular graphs into a form amenable to\nAI analysis, we can enable dynamic exploration of chemical spaces, e\u000ecient prediction\nof compound properties, and intelligent suggestions for drug design and optimization. A\nChatGPT-like AI system capable of understanding drug compound molecule graphs and\nanswering various questions about these drugs could revolutionize pharmaceutical research\nin several ways:\n\u2022Speeding up Drug Discovery . A ChatGPT-like AI system could drastically cut\ndown the time required for initial stages of drug discovery by providing immediate in-\nsights into a compound's potential therapeutic uses, side e\u000bects, and contraindications\nbased on its structure.\n\u2022Predicting Drug Interactions . A ChatGPT-like AI system could predict potential\ninteractions between new drug candidates and existing drugs. By comparing the\nmolecular structures of thousands of known substances, the system could identify\npossible con\ricts or synergies, helping researchers to better anticipate how a new\ndrug might behave in the real world.\n\u2022Understanding Structure-Activity Relationships (SAR) . SAR (Idakwo et al.,\n2020) is a crucial aspect of drug design. A ChatGPT-like AI system could help\nresearchers understand the relationship between a drug's chemical structure and its\nbiological activity. It could also help predict what modi\fcations to the chemical\nstructure might enhance its e\u000bectiveness or reduce unwanted side e\u000bects.\n\u2022Guiding Lead Optimization . During the drug discovery process, `lead' compounds\n(those that show promise in initial screenings) (Hughes et al., 2011) are typically\noptimized for better e\u000ecacy, reduced toxicity, and improved pharmacokinetics. A\nChatGPT-like AI system could o\u000ber suggestions for structural modi\fcations to en-\nhance these parameters, guiding researchers in the right direction and saving valuable\ntime.\n\u2022Supporting Drug Repurposing . A ChatGPT-like AI system could also aid in\ndrug repurposing (Pushpakom et al., 2019) e\u000borts. By understanding the structural\nproperties of existing drugs, it could identify candidates that may be e\u000bective against\ndiseases they were not initially developed to treat. This could help breathe new life\ninto existing drugs and o\u000ber more rapid routes to treatment for challenging diseases.\n\u2022Reducing the Failure Rate . The failure rate in drug discovery is high (Hughes\net al., 2011), often due to unforeseen toxicity or e\u000ecacy issues that emerge late in\ndevelopment. By providing more accurate predictions about a drug's properties and\ne\u000bects at the outset, a ChatGPT-like AI system could help reduce these costly late-\nstage failures.\n\u2022Streamlining Clinical Trials .", " Introduction\nThe rapid advancement of large language models (LLMs),\nfor example, OpenAI\u2019s ChatGPT (OpenAI 2023b) and GPT-\n4 (OpenAI 2023a) has truly revolutionized the natural lan-\nguage processing research (Nori, King et al. 2023; Singhal\net al. 2022), sparking AI applications for numerous daily\nscenarios. Unfortunately, the training details and model ar-\nchitectures for the GPT-series remain unclear. The open-\nsource LLMs, e.g., LLaMA-series (Touvron et al. 2023a,b),\nalso show comparable performance with ChatGPT in the\ngeneral domain. However, though the LLMs demonstrate\nproficiency in everyday conversations, in medical domain\nwhere requires high precision, they often produce seemingly\naccurate output but lead to incorrect conclusions, which\n\u2217: Equal contributions.\n20304050607080\nMedQA MedMCQA PubMedQAComparison on QA Benchmarks\nPMC-LLaMA LLaMa-2 ChatGPTChatGPT \n(175B)\nLLaMA -2 \n(70B)\nPMC -LLaMA\n(13B)Model SizesFigure 1: In the left, we show the general comparison be-\ntween our PMC-LLaMA with LLaMA-2 and ChatGPT. On\nthe right, we visually show the advantages of our model in\nmodel sizes. PMC-LLaMA is much smaller than the others.\ncould be highly fatal. We conjecture this is due to their lack\nof comprehensive medical knowledge.\nExisting works have also explored several ways for adapt-\ning general-purpose LLMs towards medicine domain, like\nMed-Alpaca (Han, Adams et al. 2023), Chat-Doctor (Yunx-\niang et al. 2023) and MedPALM-2 (Anil, Dai et al. 2023).\nAmong these, MedPALM-2 is the only work successfully\noutperforming ChatGPT while their training details, for ex-\nample, training data, model architecture, remain unclear.\nThus, systematic investigation on the medical domain adap-\ntation for LLMs still needs to be discussed further especially\nin open-source community.\nOur goal is to systematically adapt an open-source gen-\neral LLM, i.e., LLaMA, towards the medicine domain from\nthe following aspects. First, we adopt data-centric medical-\nspecific knowledge injection for the language model with\na large-scale free text medical corpora. We claim that lan-\nguage models can accumulate enough medical knowledge in\nthis step and build up a better embedding space for domain-\nspecific complex terminologies. Second, augmenting the\nreasoning capabilities of the proposed model. This empow-\ners the model to link its medical knowledge with provied\ncase information and provide well-justified recommenda-\ntions. Lastly, enhancing the alignment ability of LLMs. Ro-\nbust alignment with various instructions facilitates effective\nzero-shot adaptation to a diverse spectrum of tasks.\nIn conclusion, in this paper we systematically build uparXiv:2304.14454v3  [cs.CL]  25 Aug 2023an LLM for medicine through data-centric knowledge in-\njection and medical-specific instruction tuning, and re-\nlease an open-source lightweight medical-specific language\nmodel, PMC-LLaMA. Specifically, we first collect a large\nmedical-specific corpus, named MedC-K, consisting of\n4.8M biomedical academic papers and 30K textbooks for\nknowledge injection. We then adopt medical-specific in-\nstruction tuning on a new medical knowledge-aware instruc-\ntion dataset, termed MedC-I, consisting of medical QA, ra-\ntionale, and conversation with 202M tokens in total. We\nevaluate PMC-LLaMA on various medical QA benchmarks,\nsurpassing ChatGPT and LLaMA-2 as shown in Fig. 1. Related Work\nLarge Language Model. Recently, the great success of\nlarge language models (LLM) (OpenAI 2023b,a; Anil, Dai\net al. 2023; Du et al. 2021), has garnered significant attention\nwithin the field of natural language processing. For exam-\nple, OpenAI\u2019s strides with ChatGPT and GPT-4 have show-\ncased remarkable capabilities in various tasks, including text\ngeneration, language translation, question answering, and\nmore. However, intricate details concerning their training\nmethodologies and weight parameters remain undisclosed.\nLLaMA (Touvron et al. 2023a) serves as an open-source\nalternative for the foundational language model, ranging\nfrom 7 billion to 65 billion parameters. In light of these\nadvancements,", " Introduction\nIn the last few years, Language Language Models (LLMs)1\u20135have transformed various sectors by au-\ntomating natural language tasks. A prime example of this is the introduction of GitHub Copilot in 20216\nand more recently StarCoder7, which provides proposed code completions based on the context of a\nfile and open windows that increases developers\u2019 productivity8. Most recent advances are based on the\nTransformer architecture9, introduced for neural machine translation and extended to various natural\nlanguage processing tasks demonstrating remarkable few-shot and zero-shot performance2. Nevertheless,\nit is crucial to recognize the limitations of LLMs, which often struggle with seemingly simple tasks like\nbasic mathematics and chemistry operations10,11. For instance, GPT-412and GPT-3.513cannot consis-\ntently and accurately multiply 12345*98765 or convert IUPAC names into the corresponding molecular\ngraph14. These shortcomings can be attributed to the models\u2019 core design, which focuses on predicting\nsubsequent words. To address these limitations, one viable approach is to augment large language models\nwith dedicated external tools or plugins, such as a calculator for mathematical operations or OPSIN15\nforIUPAC to structure conversion. These specialized tools provide exact answers, thereby compensating\nfor the inherent deficiencies of LLMs in specific domains and enhancing their overall performance and\napplicability.\nPreprint. Under review.arXiv:2304.05376v5  [physics.chem-ph]  2 Oct 2023Chemistry, as a field, has been impacted through expert-designed artificial intelligence (AI) systems that\ntackle specific problems, such as reaction prediction16\u201320, retrosynthesis planning21\u201327, molecular property\nprediction28\u201332, de-novo molecular generation33,34, materials design35,36and, more recently, Bayesian\nOptimization37\u201339. Due to the nature of their training, it has been shown that code-generating LLMs\ndo possess some understanding of chemistry14. By understanding , we mean that LLMs are capable of\nadapting to observations, planning over multiple steps, and responding correctly to intent13,40\u201344. However,\nthe automation levels achieved in chemistry remain relatively low compared to other domains, primarily\ndue to its highly experimental nature, the lack of data, as well as the limited scope and applicability of\ncomputational tools, even within their designated areas45.\nIntegrating such tools tends to occur within isolated environments, such as RXN for Chemistry18,24,46\u201348\nand AIZynthFinder25,49,50, facilitated by corporate directives that promote integrability. Although most\ntools are developed by the open-source community or made accessible through application programming\ninterfaces (API), their integration and interoperability pose considerable challenges for experimental\nchemists, mainly due to their lack of computational skill set and the diversity of tools with steep learning\ncurves, thereby preventing the full exploitation of their potential.\nFigure 1: Overview and toolset . a) An overview of the task-solving process. Using a variety of chemistry-\nrelated packages and software, a set of tools is created. These tools and a user input are then given to an\nLLM. The LLM then proceeds through an automatic, iterative chain-of-thought process, deciding on its\npath, choice of tools, and inputs before coming to a final answer. The example shows the synthesis of\nDEET, a common insect repellent. b) Toolsets implemented in ChemCrow: reaction, molecule, safety,\nsearch, and standard tools.\nInspired by successful applications in other fields10,51,52, we propose an LLM-powered chemistry engine,\nChemCrow, designed to streamline the reasoning process for various common chemical tasks across areas\nsuch as drug and materials design and synthesis. ChemCrow harnesses the power of multiple expert-\ndesigned tools for chemistry and operates by prompting an LLM (GPT-4 in our experiments to display the strengths and weaknesses of LLM-based", " Introduction\nThe development of instruction-following large language models (LLMs), such as ChatGPT \n[1]\n, has gained\nsignificant attention due to their remarkable success in instruction understanding and human-like response\ngeneration. These auto-regressive LLMs \n[2]\n are pre-trained on web-scale natural language by predicting the\nnext token and then fine-tuned to follow large-scale human instructions. These models show robust\nperformance on a wide range of natural language processing (NLP) tasks and can generalize to unseen tasks,\ndemonstrating their potential as unified solutions to various problems in natural language understanding,\ntext generation, and conversational artificial intelligence. However, the exploration of such general-domain\nLLMs in the medical domain remains relatively scarce \n[3]\n, despite their great potential in revolutionizing\nmedical communication and decision-making \n[4]\n. In general, these common-domain models were not\ntrained to capture the medical-domain knowledge specifically or in detail, resulting in models that often\nprovide incorrect medical responses.\nBy fine-tuning large linguistic dialogue models on data from real-world patient-physician conversations,\nthese models\u2019 ability in understanding patients\u2019 inquiries and needs can be significantly improved. In\naddition, to further enhance the models\u2019 credibility, a knowledge brain based on online sources such as\nWikipedia or offline sources like medical-domain databases can be incorporated into the models to retrieve\nreal-time information to facilitate answering medical questions. The enhanced reliability of such answers is\n1\n2\n3\n4\n1\n1\n \nOpen Access Original\nArticle\n \nDOI:\n 10.7759/cureus.40895\nHow to cite this article\nLi Y, Li Z, Zhang K, et al. (June 24, 2023) ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using\nMedical Domain Knowledge. Cureus 15(6): e40895. \nDOI 10.7759/cureus.40895vital for the medical field, as a wrong answer can be detrimental to patients\u2019 treatments and well-being. In\nthis study, we investigated the use of these two strategies: model fine-tuning and knowledge brain\ninstillation, to enhance the capability of LLMs to serve as medical chatbots. Since the prevalent ChatGPT\nmodel is not open source, we used Meta\u2019s public large language model meta-AI (LLaMA) model as the\nplatform for development and evaluation. In detail, we first trained a generic conversation model based\non LLaMA, using 52K instruction-following data from Stanford University\u2019s Alpaca project \n[5]\n. We then fine-\ntuned the conversation model on our collected dataset of 100K patient-physician conversations from an\nonline medical consultation website (www.healthcaremagic.com). Through extensive experiments, we found\nthat the fine-tuned model by patient-physician dialogues outperforms ChatGPT in terms of precision, recall,\nand the F1 score \n[6]\n. In addition, the autonomous ChatDoctor model, which is able to retrieve the latest\nonline/offline information, can also answer medical questions about relatively new diseases that are not\nincluded in the patient-physician training dialogues, for instance, the Monkeypox (Mpox) disease \n[7,8]\n.\nIn summary, the ChatDoctor model has the following three main contributions:\n1. We established a methodology for fine-tuning LLMs for application in the medical field.\n2. We compiled and publicly shared a comprehensive dataset of 100,000 patient-doctor interactions to serve\nas a training resource for refining the LLM. This dataset includes a wealth of terms, knowledge, and\nexpertise essential for training LLMs in the medical domain. Additionally, we curated and openly shared\nanother dataset consisting of 10,000 patient-doctor conversations from a separate source (www.icliniq.com)\nto serve as a testing resource for the model. To support and stimulate future advancements in the\ndevelopment of dialogue models in healthcare, we provide public access to all", " Introduction\nLarge language models, also known as LLMs, have become an increasingly prevalent part of our\nday-to-day lives, with their use extending to a wide range of domains including web browsing, voice\nassistants, and coding assistance tools.[ 1,2,3,4] These models have the potential to signi\ufb01cantly\nimpact society in numerous ways.[ 5,6,7] This system card analyzes GPT-4, the latest large language\nmodel in the GPT family of models.[ 8,9,10] Since it \ufb01nished training in August of 2022, we have\nbeen evaluating, adversarially testing, and iteratively improving the model and the system-level\nmitigations around it. Our mitigations and processes alter GPT-4\u2019s behavior and prevent certain\nkinds of misuses, though they have limitations, pointing to the need for anticipatory planning and\ngovernance[ 11] and further safety research. Our approach to deployment balances minimizing risk\nfrom deployment, enabling positive use cases, and learning from deployment.\nGPT models are often trained in two stages. First, they are trained, using a large dataset of text\nfrom the Internet, to predict the next word. The models are then \ufb01ne-tuned with additional data,\nusing an algorithm called reinforcement learning from human feedback (RLHF), to produce outputs\nthat are preferred by human labelers.[ 10,12,13] Training language models on large text datasets\nhas given rise to capabilities such as few-shot learning[ 10] and the ability to carry out a wide range\nof natural language tasks spanning di\ufb00erent domains, including question answering, arithmetic, and\nclassi\ufb01cation. Fine-tuning has made these models more controllable and useful.\n1.1 Overview of \ufb01ndings and mitigations\nIn this system card,1we outline the safety challenges that arise from GPT-4, and explain the\ninterventions we implemented to mitigate potential harms from its deployment. We focus on safety\nchallenges not because they necessarily outweigh the potential bene\ufb01ts,2but because we wish to\nmotivate further work in safety measurement, mitigation, and assurance. The scope of this system\ncard is narrower than the potential scope of abilities GPT-4 can be used to unlock; notably, both\ncustom \ufb01ne-tuning and image capabilities are explicitly out of scope.\nWe focus on analyzing two versions of the model: an early version \ufb01ne-tuned for instruction\nfollowing (\u201cGPT-4-early\u201d); and a version \ufb01ne-tuned for increased helpfulness and harmlessness[ 18]\nthat re\ufb02ects the further mitigations outlined in this system card (\u201cGPT-4-launch\u201d).3When we\ndiscuss the risks of GPT-4 we will often refer to the behavior of GPT-4-early, because it re\ufb02ects the\nrisks of GPT-4 when minimal safety mitigations are applied. In most cases, GPT-4-launch exhibits\nmuch safer behavior due to the safety mitigations we applied.\nKnown risks associated with smaller language models are also present with GPT-4. GPT-4\ncan generate potentially harmful content, such as advice on planning attacks or hate speech. It\ncan represent various societal biases and worldviews that may not be representative of the users\nintent,4or of widely shared values. It can also generate code that is compromised or vulnerable.\nThe additional capabilities of GPT-4 also lead to new risk surfaces.\nTo understand the extent of these risks, we engaged more than 50 experts to help us gain a more\nrobust understanding of the GPT-4 model and potential deployment risks. We selected these areas\n1This document takes inspiration from the concepts of model cards and system cards.[ 14,15,16] This document\noften takes the system level of analysis, with that system including non-model mitigations such as use policies, access\ncontrols, and", " Introduction\nLarge Languages Models (LLMs) trained on mas-\nsive corpora of texts have shown their ability to per-\nform new tasks from textual instructions or from a\nfew examples (Brown et al., 2020). These few-shot\nproperties \ufb01rst appeared when scaling models to a\nsuf\ufb01cient size (Kaplan et al., 2020), resulting in a\nline of work that focuses on further scaling these\nmodels (Chowdhery et al., 2022; Rae et al., 2021).\nThese efforts are based on the assumption that\nmore parameters will lead to better performance.\nHowever, recent work from Hoffmann et al. (2022)\nshows that, for a given compute budget, the best\nperformances are not achieved by the largest mod-\nels, but by smaller models trained on more data.\nThe objective of the scaling laws from Hoff-\nmann et al. (2022) is to determine how to best\nscale the dataset and model sizes for a particular\ntraining compute budget. However, this objective\ndisregards the inference budget, which becomes\ncritical when serving a language model at scale.\nIn this context, given a target level of performance,\nthe preferred model is not the fastest to train but the\nfastest at inference, and although it may be cheaper\nto train a large model to reach a certain level of\n\u0003Equal contribution. Correspondence: {htouvron,\nthibautlav,gizacard,egrave,glample}@meta.com\n1https://github.com/facebookresearch/llamaperformance, a smaller one trained longer will\nultimately be cheaper at inference. For instance,\nalthough Hoffmann et al. (2022) recommends\ntraining a 10B model on 200B tokens, we \ufb01nd\nthat the performance of a 7B model continues to\nimprove even after 1T tokens.\nThe focus of this work is to train a series of\nlanguage models that achieve the best possible per-\nformance at various inference budgets, by training\non more tokens than what is typically used. The\nresulting models, called LLaMA , ranges from 7B\nto 65B parameters with competitive performance\ncompared to the best existing LLMs. For instance,\nLLaMA-13B outperforms GPT-3 on most bench-\nmarks, despite being 10 \u0002smaller. We believe that\nthis model will help democratize the access and\nstudy of LLMs, since it can be run on a single GPU.\nAt the higher-end of the scale, our 65B-parameter\nmodel is also competitive with the best large lan-\nguage models such as Chinchilla or PaLM-540B.\nUnlike Chinchilla, PaLM, or GPT-3, we only\nuse publicly available data, making our work com-\npatible with open-sourcing, while most existing\nmodels rely on data which is either not publicly\navailable or undocumented (e.g. \u201cBooks \u2013 2TB\u201d or\n\u201cSocial media conversations\u201d). There exist some\nexceptions, notably OPT (Zhang et al., 2022),\nGPT-NeoX (Black et al., 2022), BLOOM (Scao\net al., 2022) and GLM (Zeng et al., 2022), but none\nthat are competitive with PaLM-62B or Chinchilla.\nIn the rest of this paper, we present an overview\nof the modi\ufb01cations we made to the transformer\narchitecture (Vaswani et al., 2017), as well as our\ntraining method. We then report the performance of\nour models and compare with others LLMs on a set\nof standard benchmarks. Finally, we expose some\nof the biases and toxicity encoded in our models,\nusing some of the most recent benchmarks from\nthe responsible AI community.arXiv:2302.13971v1  [cs.CL]  27 Feb 20232 Approach\nOur training approach is similar to the methods\ndescribed in previous work (Brown et al., 2020;\nChowdhery et al., 2022), and is inspired by the\nChinchilla scaling laws (Hoffmann et al., 2022).\nWe train large transformers on a large quantity of\ntextual data using a standard optimizer.\n2.1 Pre-training Data\nOur training dataset is a mixture of several sources,\nreported", " Introduction\nStructure-based (pocket-based) drug design, i.e., \ufb01nding a molecule to \ufb01ll the cavity of the protein pocket with a\nhigh binding af\ufb01nity [ 1,2,3,4], is one of the most critical tasks in drug discovery. The most widely used method\nis virtual screening [ 5,6,7]. Virtual screening iteratively places molecules from a molecular database into the target\npocket cavity and evaluates molecules with good binding based on rules such as energy estimation [ 8,9,10,11].\nHowever, virtual screening is inef\ufb01cient for the exhaustive search and is infeasible to generate new molecules that\nare not in the database. Recently, molecular generative models have become a potential solution to address the problem\nas they could generate novel molecules in an ef\ufb01cient way. The early attempts focused on ligand-based molecular\ngeneration [ 12,13,14], which trains models to learn the underlying distribution of the molecules in training data and\ngenerate similar molecules. However, those methods, expanded force \ufb01eld, and python bindings. Journal of Chemical Information and Modeling ,\n61(8):3891\u20133898, 2021.\n[56] Alexey Onufriev, Donald Bashford, and David A Case. Exploring protein native states and large-scale confor-\nmational changes with a modi\ufb01ed generalized born model. Proteins: Structure, Function, and Bioinformatics ,\n55(2):383\u2013394, 2004.\n[57] Yong Duan, Chun Wu, Shibasish Chowdhury, Mathew C Lee, Guoming Xiong, Wei Zhang, Rong Yang, Piotr\nCieplak, Ray Luo, Taisung Lee, et al. A point-charge force \ufb01eld for molecular mechanics simulations of proteins\nbased on condensed-phase quantum mechanical calculations. Journal of computational chemistry , 24(16):1999\u2013\n2012, 2003.\n[58] Araz Jakalian, Bruce L Bush, David B Jack, and Christopher I Bayly. Fast, ef\ufb01cient generation of high-quality\natomic charges. am1-bcc model: I. method. Journal of computational chemistry , 21(2):132\u2013146, 2000.\n[59] Harrison Green and Jacob D Durrant. Deepfrag: An open-source browser app for deep-learning lead optimization.\nJournal of chemical information and modeling , 61(6):2523\u20132529, 2021.\n113D Molecular Generation via Virtual Dynamics\nA VD-Gen detailsTable 2: Symbols used in this paper.\nSymbol Meaning\nP the set of atoms in the pocket\nVr the set of virtual particles (VPs) that are generated at the r-th iteration in Particle Movement\nWr the set of virtual particles (VPs) that are generated at the r-th iteration in Molecule Re\ufb01nement\nCp the gridded 3D cubic of pocket atoms\nCm the predicted cubic gridded cubic\nCg\nm the groud truth label for the gridded cubic\nG the set of ground-truth atoms\nxp\ni thei-th pocket atom\u2019s type (one-hot)\nyp\ni thei-th pocket atom\u2019s coordinate\nxg\ni thei-th ground-truth atom\u2019s type (one-hot)\nyg\ni thei-th ground-truth atom\u2019s coordinate\nxr\ni thei-th VP\u2019s type (one-hot) at the r-th iteration in Particle Movement\nyr\ni thei-th VP\u2019s coordinate at the r-th iteration in Particle Movement\n\u0016xr\ni predicted atom type distribution of i-th VP at the r-th iteration\nai The index of assigned target atom for the i-th VP in Particle Movement\nbi The index of assigned target atom for the i-th VP in Molecule Re\ufb01nement\ndr\nij the predicted distance of the i-th andj-th VP pair at the r-th iteration\ndg\nai;ajthe ground-truth distance of the i-th andj-th VP pair\ncr\nij the predicted (ground-truth) distance of the i-th VP and the j-th pocket atom at the r-th iteration\ncg\nai;j the ground-truth distance of the i-th VP and the j-th pocket atom.\n^xr\ni thei-th VP\u2019s type (one-hot) at the r-th iteration in Molecule Re\ufb01nement\n^yr\ni thei-th VP\u2019s coordinate at the r-th iteration in in Molecule Re\ufb01nement\nq the pair representation of VP pair\nqlthe", " Introduction\nLarge language models achieve impressive zero-\nand few-shot experiments on a variety of differ-\nent downstream tasks, demonstrating that after\nlearning to use tools, Toolformer, which is based\non a pretrained GPT-J model (Wang and Komat-\nsuzaki, 2021) with 6.7B parameters, achieves much\nstronger zero-shot Appendix D, is also generated through a series\nof templates, but populated using a combination\nof random dates/durations (e.g., \u201cWhat day of the\nweek was it 30 days ago?\u201d). Critically, knowing the\ncurrent date is required to answer these questions.Model T EMPLAMA D ATESET\nGPT-J 13.7 3.9\nGPT-J + CC 12.9 2.9\nToolformer (disabled) 12.7 5.9\nToolformer 16.3 27.3\nOPT (66B) 14.5 1.3\nGPT-3 (175B) 15.5 0.8\nTable 7: Results shown in Table 7 illustrate that Tool-\nformer outperforms all baselines for both TEM-\nPLAMA andDATESET . However, closer inspec-\ntion shows that improvements on TEMPLAMA\ncan not be attributed to the calendar tool, which is\nonly used for 0.2% of all examples, but mostly to\nthe Wikipedia search and question answering tools,\nwhich Toolformer calls the most. This makes sense\ngiven that named entities in TEMPLAMA are often\nso speci\ufb01c and rare that even knowing the exact\ndate alone would be of little help. The best course\nof action for this dataset \u2013 \ufb01rst querying the calen-\ndar API to get the current date, and then querying\nthe question answering system with this date \u2013 is\nnot only prohibited by our restriction of using at\nmost one API call per example, but also hard to\nlearn for Toolformer given that all API calls in its\ntraining data are sampled independently.\nForDATESET , on the other hand, the consider-\nable improvement of Toolformer compared to other\nmodels can be fully accredited to the calendar tool,\nwhich it makes use of for 54.8% of all examples.\n4.3 Language Modeling\nIn addition to verifying improved performance on\nvarious downstream tasks, we also want to ensure\nthat language modeling performance of Toolformer\ndoes not degrade through our \ufb01netuning with API\ncalls. To this end, we evaluate our models on\ntwo language modeling datasets: WikiText (Mer-\nity et al., 2017) and a subset of 10,000 randomly\nselected documents from CCNet (Wenzek et al.,\n2020) that were not used during training. Perplex-\nities of various models are shown in Table 8. As\none would expect, \ufb01netuning on CCNet leads to\nslightly improved performance on a different CC-\nNet subset, but it slightly deteriorates performance\non WikiText, presumably because the original pre-Model WikiText CCNet\nGPT-J 9.9 10.6\nGPT-J + CC 10.3 10.5\nToolformer (disabled) 10.3 10.5\nTable 8: Perplexities of different models on WikiText\nand our validation subset of CCNet. Adding API calls\ncomes without a cost in terms of perplexity for lan-\nguage modeling without any API calls.\ntraining data for GPT-J is more similar to Wiki-\nText than our randomly selected subset of CCNet.\nMost importantly, however, training on C\u0003(our\ndataset annotated with API calls) does not lead to\nan increase in perplexity compared to training on\nCwhen API calls are disabled at inference time.8\n4.4 Scaling Laws\nWe investigate how the ability to ask external tools\nfor help affects performance as we vary the size\nof our LM. To this end, we apply our approach\nnot just to GPT-J, but also to four smaller mod-\nels from the GPT-2 family (Radford et al., 2019),\nwith 124M, 355M, 775M and 1.6B parameters, re-\nspectively. We do so using only a subset of three\ntools: the question answering system, the calcula-\ntor, and the Wikipedia search engine.", " Introduction\nThe transformer architecture (Vaswani et al., 2017) has had a\nsigni\ufb01cant impact on several \ufb01elds within computer science,\nsuch as language understanding (Devlin et al., 2018), text\ngeneration (Radford et al., 2019; Brown et al., 2020), image\nunderstanding (Dosovitskiy et al., 2020), multi-modal gen-\neration (Ramesh et al., 2022; Saharia et al., 2022), among\nothers. Scaling language models using this architecture\nhas proven to be a powerful and general strategy for im-\nproving generalization. This has led to the emergence of\nmulti-task (Radford et al., 2019) and few-shot (Brown et al.,\n2020; Winata et al., 2021) models leveraging scale and com-\npute (Sanh et al., 2021; Raffel et al., 2020).\nBLUE-2 BLEU-4 Meteor Rouge-1 Rouge-2 Rouge-L0.00.10.20.30.40.50.60.70.8SMILES to Caption\n0.625\n0.56\n0.54\n0.519\n0.511\n0.501\n0.542\n0.47\n0.457\n0.436\n0.424\n0.415\n0.648\n0.588\n0.569\n0.551\n0.539\n0.532\n0.682\n0.638\n0.634\n0.62\n0.607\n0.602\n0.543\n0.488\n0.485\n0.469\n0.451\n0.446\n0.622\n0.58\n0.578\n0.563\n0.55\n0.545text+chem-t5-base\ntext+chem-t5-smallmol-t5-base\nmol-t5-smallt5-base\nt5-small\nFigure 1: Molecule to Caption task . This plot compares the per-\nformance of three different models with different sizes ( Text+Chem\nT5-base, Text+Chem T5 -small, MolT5-base, MolT5-small, T5-\nbase, and T5-small) on the task of converting SMILES to captions,\nusing six different metrics: BLUE-2, BLEU-4, Rouge-1, Rouge-\n2, Rouge-L, and Meteor. The models are compared by plotting\ntheir scores on the y-axis. The graph shows that our proposal,\nText+Chem T5 , performs the best on all metrics and improves with\nsize, corroborating our hypothesis that joint learning on molecular\nand textual domains leveraging multitask learning is a powerful\nparadigm to bridge the gap between domains.\nRecent developments in language models have fueled ap-\nplications in engineering and science. One notable area\nof success is chemistry, where ideas from natural language\nhave been used to make signi\ufb01cant advancements in reaction\nprediction (Schwaller et al., 2019), conditional compound\ngeneration (Born et al., 2021b;a), retrosynthesis (Schwaller\net al., 2020), text-conditional de novo generation (Edwards\n1arXiv:2301.12586v2  [cs.LG]  18 May 2023Accuracy BLEU MACCS FTS Morgan FTS RDK FTS0.00.20.40.60.8Caption to SMILES\n0.322\n0.191\n0.081\n0.079\n0.069\n0.064\n0.853\n0.815\n0.769\n0.755\n0.762\n0.741\n0.901\n0.864\n0.721\n0.703\n0.731\n0.704\n0.757\n0.672\n0.529\n0.517\n0.545\n0.525\n0.816\n0.744\n0.588\n0.568\n0.605\n0.578text+chem-t5-base\ntext+chem-t5-small\nmol-t5-base\nmol-t5-small\nt5-base\nt5-smallFigure 2: Description to Molecule task . This plot compares\nthe performance of three different models with different sizes\n(Text+Chem T5 -base, Text+Chem T5 -small, MolT5-base, MolT5-\nsmall, T5-base, and T5-small) on the task of converting captions\nto SMILES, using \ufb01ve different metrics: Accuracy, Morgan FTS,\nRDK FTS, BLEU, MACCS FTS. The models are compared by\nplotting their scores on the y-axis. The graph shows that our\nproposal, Text+Chem T5 , performs the best on all metrics and\nimproves with size, corroborating our hypothesis that joint learning\non molecular and textual domains leveraging multi-task learning\nis a powerful paradigm to bridge the gap between domains.\net al., 2021), property-driven molecular design (Born and\nManica, 2023), protein structure prediction (Jumper et al.,\n2021), among others. By interpreting chemistry as a pro-\ngrammable language for life sciences, transformer-based\nmodels are revolutionizing the chemical discovery pipeline,\nsigni\ufb01cantly speeding up laboratory and design automa-\ntion (O\u2019Neill, 2021; Vaucher et al., 2020), and paving the\nway for an age of accelerated discovery in science and engi-\nneering (Manica et al., 2023).\nDespite these successes, language model advancements in\nthe chemical domain are still limited. Specialized mod-\nels must be built for each task of interest, which is time-\nconsuming and requires a signi\ufb01cant amount of human ex-\npertise. When multiple domains are considered, e.g., gen-\nerating a novel molecule from its technical description in\nnatural language, merging information is challenging due\nto the domain shift between language and chemistry. Cur-\nrent solutions often involve pre-training the model on large,\nsingle-domain datasets and \ufb01ne-tuning on each task (Ed-\nwards et al., 2021), resulting in high computational expense,\nsample inef\ufb01ciency, and the need to repeat", " Introduction\nMedicine is a humane endeavor where language enables key interactions for and between clinicians, researchers,\nand patients. Yet, today\u2019s AI models for applications in medicine and healthcare have largely failed to\nfully utilize language. These models, while useful, are predominantly single-task systems (e.g., classi\ufb01cation,\nregression, segmentation), lacking expressivity and interactive capabilities [21, 81, 97]. As a result, there is a\ndiscordance between what today\u2019s models can do and what may be expected of them in real-world clinical\nwork\ufb02ows [42, 74].\nRecent advances in large language models (LLMs) o\ufb00er an opportunity to rethink AI systems, with language\nas a tool for mediating human-AI interaction. LLMs are \u201cfoundation models\u201d [10], large pre-trained AI systems\nthat can be repurposed with minimal e\ufb00ort across numerous domains and diverse tasks. These expressive\nand interactive models o\ufb00er great promise in their ability to learn generally useful representations from the\nknowledge encoded in medical corpora, at scale. There are several exciting potential applications of such\nmodels in medicine, including knowledge retrieval, clinical decision support, summarisation of key \ufb01ndings,\n\u0003Equal contributions. yEqual leadership.\nzCorresponding authors: {karansinghal, shekazizi, alankarthi, natviv}@google.comarXiv:2212.13138v1  [cs.CL]  26 Dec 2022PubMedQA Mul tiMedQ A MedQA \n(USMLE) \nMedMCQA \nMMLU LiveQA \nTREC 2017 \nMedicationQA Consumer Health \nSearch QA \nMed-PaLM:  Newborn jaundice is when a newborn baby's skin and eyes look yellow. It is \ncaused by a buildup of a substance called bilirubin in the baby's blood. Bilirubin is a \nbyproduct of the normal process of red blood cells breaking down. Newborn jaundice is \ncommon and typically harmless, but it can be a sign of a more serious condition. The \njaundice typically goes away on its own within a few weeks. In some cases, it may last \nlonger or require treatment. The time it takes for the jaundice to go away can vary \ndepending on the cause and the severity of the jaundice. If the jaundice is severe or \nlasts longer than a few weeks, the doctor may recommend testing or treatment to \ndetermine the cause and prevent complications. Q: How long does it take for newborn jaundice to go away ?\nPaLM \n(540B) \n+ 17 %  \nMedical Question Answering Benchmark Automated and Human Evaluation \nPrompting \nMed-PaLM performs encouragingly on consumer \nmedical question answering \nInstruction \ntuning \nInstruction \nprompt tuning Figure 1jOverview of our contributions We curated MultiMedQA, a benchmark for medical question answering spanning\nmedical exam, medical research, and consumer medical questions. We evaluated PaLM and its instructed-tuned variant,\nFlan-PaLM, on MultiMedQA. With a combination of prompting strategies, Flan-PaLM exceeded SOTA performance on MedQA\n(USMLE), MedMCQA, PubMedQA, and MMLU clinical topics. In particular, it improved over the previous SOTA on MedQA\n(USMLE) by over 17%. We next proposed instruction prompt tuning to further align Flan-PaLM to the medical domain,\nproducing Med-PaLM. Med-PaLM\u2019s answers to consumer medical questions compared favorably with clinician-generated answers\nunder our human evaluation framework, demonstrating the e\ufb00ectiveness of instruction prompt tuning.\ntriaging patients\u2019 primary care concerns, and more.\nHowever, the safety-critical nature of the domain necessitates thoughtful development of evaluation frameworks,\nenabling researchers to meaningfully measure progress and capture and mitigate potential harms. This is\nespecially important for LLMs, since these models may produce generations misaligned with clinical and\nsocietal values. They may, for instance, hallucinate convincing medical", " Introduction\nIn this lecture, we will consider the simplest quantum mechanical method for approximating the ground\nstate energy of a many-electron system. The Hartree-Fock method is also known as the self-consistent\n\ufb01eld method, and is an approximation to the exact many-electron wavefunction known as the Slater\ndeterminant. The Slater determinant is an anti-symmetric product of one-electron functions (orbitals),\nand is the simplest wavefunction that satis\ufb01es the Pauli exclusion principle. The Hartree-Fock method is\naniterativemethodfor\ufb01ndingthebestpossiblesetoforbitalsthatminimizestheenergyoftheSlaterdeterminant.\nIn the Hartree-Fock method, the electron-electron repulsion energy is approximated as a classical Coulomb\ninteraction between two charge distributions, one for each electron. This approximation neglects the correlation\nbetweentheelectrons,whichisanimportantpartofthetotalelectron-electronrepulsionenergy. Theresulting\nmethod is a mean-\ufb01eld theory in which each electron moves in an average \ufb01eld due to the other electrons. The\nresulting equations are known as the Hartree-Fock equations, and can be solved self-consistently to obtain\nthe best possible orbitals. The resulting ground state energy is known as the Hartree-Fock energy, and the\nHartree-Fock wavefunction is a single Slater determinant built from these orbitals.\nTheHartree-FockmethodisalsoknownastheSelf-ConsistentField(SCF)method,becausetheequationsforthe\norbitals are solved self-consistently. The Hartree-Fock equations can be derived variationally by minimizing the\nenergyoftheSlaterdeterminantwithrespecttotheorbitals. Theresultingorbitalsareknownasthecanonical\nHartree-Fock orbitals, and are not necessarily localized in space. The Hartree-Fock energy is invariant to unitary\ntransformations of the canonical orbitals, and therefore there are an in\ufb01nite number of orbitals that yield the\nsame Hartree-Fock energy. These orbitals are known as non-canonical orbitals, and can be localized in space by\nappropriate unitary transformations.\nSingle-Electron Approximation\nIn this section, we will review the basics of quantum mechanics for a single particle. This is useful for\nunderstanding the single-electron approximation used in Hartree-Fock theory.\nThe time-independent Schr\u00f6dinger equation for a particle in a potential V(r)is given by:\n\u0016H (r) =E (r)\nwhere the Hamiltonian is\n\u0016H=\u0000~\n2mr2+V(r)\nThe time-independent Schr\u00f6dinger equation is an eigenvalue equation for the Hamiltonian operator, where\nthe eigenvalues are the allowed energies of the system. The Hamiltonian is a sum of two operators, one\ncorresponding to the kinetic energy of the particle, and the other corresponding to the potential energy. The\npotential energy operator acts on the wavefunction by multiplying by the potential V(r). The kinetic energy\noperatoristheLaplacianoperator r2,whichisthedivergenceofthegradientofthewavefunction. TheLaplacian\noperator is a second derivative with respect to the position of the particle.\n(cont)\n57Galactica: A Large Language Model for Science\nA.8.8 I\u2019m sorry Frank, I think you missed it\nIfAIisgoingtohelpusexploretheuniverse,weneedittohavebasicchessabilitiestoalleviateboredom-\ngiven the impossibility of faster-than-light travel.\nThe BIG-bench task suite ofSrivastava et al. (2022) has abenchmark for checkmate-in-one detection. For fun,\nwe made a dataset of 20,000 public chess games and converted them to ASCII chess using the python-chess\nlibrary7. Weincluded19,426gamesinourpre-trainingcorpus(restforvalidation). Wealsorecordedthe\nELO ratings of players. An example document looks like below:\n# A Chess Game\n## Player Information\nWhite ELO: 2286\nBlack ELO: 2586\n## The Game Begins\nr n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\nP P P P P P P P\nR N B Q K B N R\nWhite (ELO: 2286) plays e4\nr n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . P . . .\n. . . . . . . .\nP P", " Introduction\nto methodology and encoding rules. Journal of chemical information and computer\nsciences 1988 ,28, 31{36.\n(31) O'Kee\u000be, M.; Peskov, M. A.; Ramsden, S. J.; Yaghi, O. M. The reticular chemistry\nstructure resource (RCSR) database of, and symbols for, crystal nets. Accounts of\nchemical research 2008 ,41, 1782{1789.\n(32) Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser,  L.;\nPolosukhin, I. Attention is all you need. Advances in neural information processing\nsystems. 2017; pp 5998{6008.\n22(33) Bahdanau, D.; Cho, K.; Bengio, Y. Neural machine translation by jointly learning to\nalign and translate. arXiv preprint arXiv:1409.0473 2014 ,\n(34) Hochreiter, S.; Schmidhuber, J. Long short-term memory. Neural computation 1997 ,\n9, 1735{1780.\n(35) Schwaller, P.; Laino, T.; Gaudin, T.; Bolgar, P.; Hunter, C. A.; Bekas, C.; Lee, A. A.\nMolecular transformer: a model for uncertainty-calibrated chemical reaction prediction.\nACS central science 2019 ,5, 1572{1583.\n(36) Schwaller, P.; Probst, D.; Vaucher, A. C.; Nair, V. H.; Kreutter, D.; Laino, T.; Rey-\nmond, J.-L. Mapping the space of chemical reactions using attention-based neural net-\nworks. Nature Machine Intelligence 2021 ,3, 144{152.\n(37) Xu, C.; Wang, Y.; Farimani, A. B. TransPolymer: a Transformer-based Language\nModel for Polymer Property Predictions. arXiv preprint arXiv:2209.01307 2022 ,\n(38) Elnaggar, A.; Heinzinger, M.; Dallago, C.; Rehawi, G.; Wang, Y.; Jones, L.; Gibbs, T.;\nFeher, T.; Angerer, C.; Steinegger, M., et al. ProtTrans: towards cracking the language\nof lifes code through self-supervised deep learning and high performance computing.\nIEEE transactions on pattern analysis and machine intelligence 2021 ,\n(39) Devlin, J.; Chang, M.-W.; Lee, K.; Toutanova, K. Bert: Pre-training of deep bidi-\nrectional transformers for language understanding. arXiv preprint arXiv:1810.04805\n2018 ,\n(40) Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.; Zettle-\nmoyer, L.; Stoyanov, V. Roberta: A robustly optimized bert pretraining approach.\narXiv preprint arXiv:1907.11692 2019 ,\n(41) Wang, Y.; Wang, J.; Cao, Z.; Barati Farimani, A. Molecular contrastive learning of\n23representations via graph neural networks. Nature Machine Intelligence 2022 ,4, 279{\n287.\n(42) Wang, Y.; Magar, R.; Liang, C.; Barati Farimani, A. Improving Molecular Contrastive\nLearning via Faulty Negative Mitigation and Decomposed Fragment Contrast. Journal\nof Chemical Information and Modeling 2022 ,\n(43) Schwaller, P.; Gaudin, T.; Lanyi, D.; Bekas, C.; Laino, T. \\Found in Translation\":\npredicting outcomes of complex organic chemistry reactions using neural sequence-to-\nsequence models. Chemical science 2018 ,9, 6091{6098.\n(44) He, K.; Zhang, X.; Ren, S.; Sun, J. Deep residual learning for image recognition. Pro-\nceedings of the IEEE conference on computer vision and pattern recognition. 2016; pp\n770{778.\n(45) Ba, J. L.; Kiros, J. R.; Hinton, G. E. Layer normalization. arXiv preprint\narXiv:1607.06450 2016 ,\n(46) Schwaller, P.; Hoover, B.; Reymond, J.-L.; Strobelt, H.; Laino, T. Extraction of organic\nchemistry grammar from unsupervised learning of chemical reactions. Science Advances\n2021 ,7, eabe4166.\n(47) Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai, X.; Unterthiner, T.;\nDehghani, M.; Minderer, M.; Heigold, G.; Gelly, S., et al. An image is worth 16x16\nwords: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929\n2020 ,\n(48) Magar, R.; Wang, Y.; Farimani, A. B. Crystal Twins: Self-supervised Learning for\nCrystalline Material Property Prediction. arXiv preprint arXiv:2205.01893 2022 ,\n(49) Zbontar, J.; Jing, L.; Misra, I.; LeCun, Y.; Deny, S. Barlow twins: Self-supervised learn-\n24ing via redundancy reduction. International Conference on Machine Learning. 2021; pp\n12310{12320.\n(50) Chen, X.; He, K.", " introduction to methodol-\nogy and encoding rules. Journal of chemical information and computer sciences , 28(1):31\u201336,\n1988.\nWilliam J Wiswesser. Historic development of chemical notations. Journal of chemical information\nand computer sciences , 25(3):258\u2013263, 1985.\nZonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A\ncomprehensive survey on graph neural networks. IEEE transactions on neural networks and\nlearning systems , 2020.\nKeyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural\nnetworks? In International Conference on Learning Representations , 2019. URL https:\n//openreview.net/forum?id=ryGs6iA5Km .\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya\nBarua, and Colin Raffel. mt5: A massively multilingual pre-trained text-to-text transformer. arXiv\npreprint arXiv:2010.11934 , 2020.\nK. Yang, K. Swanson, W. Jin, C. W. Coley, and R. Barzilay. Analyzing learned molecular rep-\nresentations for property prediction. Journal of Chemical Information and Modeling , 59(8),\n2019.\nChengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and\nTie-Yan Liu. Do transformers really perform badly for graph representation? Advances in Neural\nInformation Processing Systems , 34:28877\u201328888, 2021a.\nChengxuan Ying, Mingqi Yang, Shuxin Zheng, Guolin Ke, Shengjie Luo, Tianle Cai, Chenglin Wu,\nYuxin Wang, Yanming Shen, and Di He. First place solution of kdd cup 2021 ogb large-scale\nchallenge graph-level track. arXiv preprint arXiv:2106.08279 , 2021b.\nYuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. Graph\ncontrastive learning with augmentations. Advances in Neural Information Processing Systems , 33:\n5812\u20135823, 2020.\nSheheryar Zaidi, Michael Schaarschmidt, James Martens, Hyunjik Kim, Yee Whye Teh, Alvaro\nSanchez-Gonzalez, Peter Battaglia, Razvan Pascanu, and Jonathan Godwin. Pre-training via\ndenoising for molecular property prediction. arXiv preprint arXiv:2206.00133 , 2022.\nBohang Zhang, Shengjie Luo, Liwei Wang, and Di He. Rethinking the expressive power of GNNs\nvia graph biconnectivity. In International Conference on Learning Representations , 2023. URL\nhttps://openreview.net/forum?id=r9hNv76KoT3 .\nLinfeng Zhang, Jiequn Han, Han Wang, Roberto Car, and EJPRL Weinan. Deep potential molecular\ndynamics: a scalable model with the accuracy of quantum mechanics. Physical review letters , 120\n(14):143001, 2018.\nL. Zheng, J. Fan, and Y . Mu. Onionnet: a multiple-layer inter-molecular contact based convolutional\nneural network for protein-ligand binding af\ufb01nity prediction. ACS Omega , 4(14), 2019.\nChen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu. Freelb: Enhanced\nadversarial training for natural language understanding. In ICLR , 2020.\nJinhua Zhu, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Wengang Zhou, Houqiang Li, and Tie-Yan\nLiu. Uni\ufb01ed 2d and 3d pre-training of molecular representations. In Proceedings of the 28th ACM\nSIGKDD Conference on Knowledge Discovery and Data Mining , pp. 2626\u20132636, 2022.\n15Published as a conference paper at ICLR 2023\nA I MPLEMENTATION DETAILS OF TRANSFORMER -M\n2D-3D joint Pre-training. To effectively utilize molecular data in both 2D and 3D formats, we use\na simple strategy. During training, each data instance in a batch has three modes: (1) activate the 2D\nchannels, and disable the 3D channels (2D mode); (2) activate the 3D channels, and disable the 2D\nchannels (3D mode); (3) activate both the 2D and 3D channels (2D+3D mode). The mode of each\ndata instance during training is randomly drawn on the \ufb02y according to a pre-de\ufb01ned distribution\n(p2D;p3D;p2D&3D), implemented similarly to Dropout (Srivastava et al., 2014). For each data instance,\nthe model is required to predict its HOMO-LUMO energy gap across the", " Introduction\nScaling up the size of language models has been key ingredients of recent revolutions in natural\nlanguage processing (NLP) [Vaswani et al., 2017, Devlin et al., 2019, Raffel et al., 2020, Brown et al.,\n2020, Thoppilan et al., 2022, Rae et al., 2021, Chowdhery et al., 2022]. The success of large language\nmodels (LLMs) is often attributed to (in-context) few-shot or zero-shot learning. It can solve various\ntasks by simply conditioning the models on a few examples (few-shot) or instructions describing the\ntask (zero-shot). The method of conditioning the language model is called \u201cprompting\u201d [Liu et al.,\n2021b], and designing prompts either manually [Schick and Sch\u00fctze, 2021, Reynolds and McDonell,\n2021] or automatically [Gao et al., 2021, Shin et al., 2020] has become a hot topic in NLP.\n\u0003Work done while at The University of Tokyo.\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.11916v4  [cs.CL]  29 Jan 2023(c) Zero-shot \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA: The answer (arabic numerals) is  \n(Output) 8 X(d) Zero-shot-CoT (Ours) \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA: Let\u2019s think step by step.  \n(Output) There are 16 balls in total. Half of the balls are golf  \nballs. That means that there are 8 golf balls. Half of the golf balls  \nare blue. That means that there are 4 blue golf balls. \u2713Q: Roger has 5 tennis balls. He buys 2 more cans of tennis \nballs. Each can has 3 tennis balls. How many tennis balls does \nhe have now? \nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 \ntennis balls. 5 + 6 = 11. The answer is 11. \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA:\n(Output) The juggler can juggle 16 balls. Half of the balls are golf  \nballs. So there are 16 / 2 = 8 golf balls. Half of the golf balls are  \nblue. So there are 8 / 2 = 4 blue golf balls. The answer is 4. \u2713(b) Few-shot-CoT (a) Few-shot \nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis \nballs. Each can has 3 tennis balls. How many tennis balls does \nhe have now? \nA: The answer is 11. \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA:\n(Output) The answer is 8. XFigure 1: Example inputs and outputs of GPT-3 with (a) standard Few-shot ([Brown et al., 2020]), (b)\nFew-shot-CoT ([Wei et al., 2022]), (c) standard Zero-shot, and (d) ours (Zero-shot-CoT). Similar to\nFew-shot-CoT, Zero-shot-CoT facilitates multi-step reasoning (blue text) and reach correct answer\nwhere standard prompting fails. Unlike Few-shot-CoT using step-by-step reasoning examples", " Introduction\nImagine a future where a doctor can write a few\nsentences describing a specialized drug for treating\na patient and then receive the exact structure of\nthe desired drug. Although this seems like science\n\ufb01ction now, with progress in integrating natural\nlanguage and molecules, it might well be possi-\nble in the future. Historically, drug creation has\ncommonly been done by humans who design and\nbuild individual molecules. In fact, bringing a new\ndrug to market can cost over a billion dollars and\ntake over ten years (Gaudelet et al., 2021). Re-\ncently, there has been considerable interest in us-\ning new deep learning tools to facilitate in silico\ndrug design\u2013 a \ufb01eld often called cheminformatics\n(Rifaioglu et al., 2018). Yet, many of these experi-\nments still focus on molecules and their low-level\n* indicates equal contributions.\n1All resources are publicly available at github.com/blender-\nnlp/MolT5\nThe molecule isaneighteen -membered homodetic cyclic peptide\nwhich isisolated from Oscillatoria sp.and exhibits antimalarial\nactivity against theW2chloroquine -resistant strain ofthemalarial\nparasite, Plasmodium falciparum .Ithasarole asametabolite andan\nantimalarial .Itisahomodetic cyclic peptide, amember of1,3-\noxazoles, amember of1,3-thiazoles andamacrocycle .Target PredictionFigure 1: An example output from our model for the\nmolecule generation task. The left is the ground truth,\nand the right is a molecule generated from the given\nnatural language caption.\nproperties such as logP (the octanol-water parti-\ntion coef\ufb01cient) (Bagal et al., 2021). In the future,\nwe foresee a need for a higher-level control over\nmolecule design, which can easily be facilitated by\nnatural language.\nIn this work, we pursue an ambitious goal of\ntranslating between molecules and language by\nproposing two new tasks: molecule captioning\nand text-guided de novo molecule generation. In\nmolecule captioning, we take a molecule (e.g., as\na SMILES string) and generate a caption that de-\nscribes it (Figure 2). In text-guided molecule gener-\nation, the task is to create a molecule that matches\na given natural language description (Figure 1).\nThese new tasks would help to accelerate research\nin multiple scienti\ufb01c domains by enabling chem-\nistry domain experts to generate new molecules\nand better understand them using natural language.\nWhile our proposed molecule-language tasks\nshare some similarities with vision-language tasks,\nthey have several inherent dif\ufb01culties that separate\nthem from existing vision-language analogs: 1)\ncreating annotations for molecules requires signif-arXiv:2204.11817v3  [cs.CL]  3 Nov 2022C1CC(=O)C2CC34C(=O)\nN5C6C(CCC(=O)C6CC5\n(C(=O)N3C2C1O)SS4)O  \nSMILES representation3D V iew\nCaptionThe molecule is an organic disulfide isolated from the whole\nbroth of the marine-derived fungus Exserohilum rostratum and\nhas been shown to exhibit antineoplastic activity . It has a role as\na metabolite and an antineoplastic agent. It is a bridged\ncompound, a lactam, an organic disulfide, an organic\nheterohexacyclic compound, a secondary alcohol, a cyclic\nketone and a diol.Molecule Captioning Image Captioning\n1. a cat sitting on top of an open laptop computer .\n2. a cat that is sitting on top of a lap top.  \n3. a cat is sitting on the keyboard of a laptop.\n4. a cat is sitting on an open laptop.  \n5. a striped cat sitting on top of a laptop  \nCaptions from COCO \nFigure 2: An example of both the image captioning task (Chen et al., 2015) and molecule captioning. Molecule\ncaptioning is considerably more dif\ufb01cult because of the increased linguistic variety in possible captions.\nicant domain expertise, 2) thus, it is signi\ufb01cantly\nmore dif\ufb01cult to acquire large numbers of molecule-\ndescription pairs, 3) the same molecule can have\nmany functions and thus be described in very", "ABSTRACT\nPredicting molecular conformations from molecular graphs is a fundamental prob-\nlem in cheminformatics and drug discovery. Recently, signi\ufb01cant progress has been\nachieved with machine learning approaches, especially with deep generative mod-\nels. Inspired by the diffusion process in classical non-equilibrium thermodynamics\nwhere heated particles will diffuse from original states to a noise distribution, in\nthis paper, we propose a novel generative model named GEODIFFfor molecular\nconformation prediction. GEODIFFtreats each atom as a particle and learns to\ndirectly reverse the diffusion process ( i.e., transforming from a noise distribution\nto stable conformations) as a Markov chain. Modeling such a generation process\nis however very challenging as the likelihood of conformations should be roto-\ntranslational invariant. We theoretically show that Markov chains evolving with\nequivariant Markov kernels can induce an invariant distribution by design, and\nfurther propose building blocks for the Markov kernels to preserve the desirable\nequivariance property. The whole framework can be ef\ufb01ciently trained in an end-to-\nend fashion by optimizing a weighted variational lower bound to the (conditional)\nlikelihood.Experiments on multiple benchmarks show that GEODIFFis superior or\ncomparable to existing state-of-the-art approaches, especially on large molecules.1\n1 I NTRODUCTION\nGraph representation learning has achieved huge success for molecule modeling in various tasks rang-\ning from property prediction (Gilmer et al., 2017; Duvenaud et al., 2015) to molecule generation (Jin\net al., 2018; Shi et al., 2020), where typically a molecule is represented as an atom-bond graph.\nDespite its effectiveness in various applications, a more intrinsic and informative representation\nfor molecules is the 3D geometry , also known as conformation , where atoms are represented as\ntheir Cartesian coordinates. The 3D structures determine the biological and physical properties of\nmolecules and hence play a key role in many applications such as computational drug and material de-\nsign (Thomas et al., 2018; Gebauer et al., 2021; Jing et al., 2021; Batzner et al., 2021). Unfortunately,\nhow to predict stable molecular conformation remains a challenging problem. Traditionalmethods\nfundamentally different from our model.\nC E XPERIMENT DETAILS\nIn this section, we introduce the details of ourexperiments. In practice, the means \u000f\u0012are parameterized\nas compositions of both typical invariant MPNNs (Sch\u00fctt et al., 2017) and the proposed equivariant\nGFNs in Sec. 4.2. As a default setup, the MPNNs for parameterizing the means \u000f\u0012are all implemented\nwith4layers, and the hidden embedding dimension is set as 128. After the MPNNs, we can obtain the\ninformative invariant atom embeddings, which we denote as h0. Then the embeddings h0are fed into\nequivariant layers and updated with equation 5, equation 6, and equation 7 to obtain the equivariant\noutput. For the training of GEODIFF, we train the model on a single Tesla V100 GPU with a learning\nrate of 0:001until convergence and Adam (Kingma & Welling, 2013) as the optimizer. The practical\ntraining time is around 48 hours. The other hyper-parameters of GEODIFFare summarized in Tab. 4,\nincluding highest variance level \fT, lowest variance level \fT, the variance schedule, number of\ndiffusion timesteps T, radius threshold for determining the neighbor of atoms \u001c, batch size, and\nnumber of training iterations.\nTable 4: Additional hyperparameters of our G EODIFF.\nTask\f1\fT\fscheduler T \u001c Batch Size Train Iter.\nQM9 1e-7 2e-3 sigmoid 5000 10\u00c5 64 1M\nDrugs 1e-7 2e-3 sigmoid 5000 10\u00c5 32 1M\nD A DDITIONALresults in Tab. 1, we can observe that when setting the diffusion steps", " Introduction\nMath Word Problems (GSM8K)020406080100\n3355\n1857Solve rate (%)Finetuned GPT-3 175B\nPrior best\nPaLM 540B: standard prompting\nPaLM 540B: chain-of-thought prompting\nFigure 2: PaLM 540B uses chain-of-\nthought prompting to achieve new state-\nof-the-art performance on the GSM8K\nbenchmark of math word problems.\nFinetuned GPT-3 and prior best are from\nCobbe et al. (2021).The NLP landscape has recently been revolutionized by\nlanguage models (Peters et al., 2018; Devlin et al., 2019;\nBrown et al., 2020, inter alia ). Scaling up the size of lan-\nguage models has been shown to confer a range of bene\ufb01ts,\nsuch as improved performance and sample ef\ufb01ciency (Ka-\nplan et al., 2020; Brown et al., 2020, inter alia ). However,\nscaling up model size alone has not proved suf\ufb01cient for\nachieving high performance on challenging tasks such as\narithmetic, commonsense, and symbolic reasoning (Rae\net al., 2021).\nThis work explores how the reasoning ability of large\nlanguage models can be unlocked by a simple method\nmotivated by two ideas. First, techniques for arithmetic\nreasoning can bene\ufb01t from generating natural language\nrationales that lead to the \ufb01nal answer. Prior work has\ngiven models the ability to generate natural language inter-\nmediate steps by training from scratch (Ling et al., 2017)\nor \ufb01netuning a pretrained model (Cobbe et al., 2021), in\naddition to neuro-symbolic methods, our work shows that various natural language reasoning abilities can be elicited in off-the-\nshelf language models of suf\ufb01cient scale simply via prompting. This prompting setup is important\nbecause it allows for intermediate step reasoning without a large number of labeled annotations, and\nbecause a single model can perform a range of reasoning tasks without any gradient updates.\nD experiments were done using the public API.5\nE.3 Dataset Details and Licenses\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The\nsymbolic reasoning datasets were created synthetically, as described in Section 4.\nArithmetic reasoning\n\u2022Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini\net al., 2014): https://www.cs.washington.edu/nlp/arithmetic ; MultiArith (Roy\nand Roth, 2015), license: CC BY 4.0.\n\u2022 ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset .\n\u2022AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA , license: https://\ngithub.com/deepmind/AQuA/blob/master/LICENSE .\n\u2022GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math ,\nMIT license: https://github.com/openai/grade-school-math/blob/master/\nLICENSE .\n\u2022SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP , MIT license:\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE .\nCommonsense reasoning\n\u2022CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa ,https://\ngithub.com/jonathanherzig/commonsenseqa .\n5https://beta.openai.com/docs/api-reference/making-requests\n30\u2022StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)\nfrom BIG-bench collaboration (2021): https://github.com/google/BIG-bench/\ntree/main/bigbench/benchmark_tasks/strategyqa . The original dataset is from\nhttps://github.com/eladsegal/strategyqa , MIT license: https://github.com/\neladsegal/strategyqa/blob/main/LICENSE .\n\u2022Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,\n2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/\nLICENSE .\n\u2022SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.\nio/under CC BY 4.0 license.\n31F Appendix: Alternate Annotators for MWP\nTable 29: Few-shot exemplars for full chain of thought prompt for math word problems. These\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\nannotator (\u201cAnnotator B\u201d instead of \u201cAnnotator A\u201d). Annotators were co-authors and familiar with\nthe goal of chain of thought prompting.\nPROMPT FOR MATH WORD PROBLEMS\nQ:There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\nwill be 21 trees. How many trees did the grove workers plant today?\nA:There are21trees now andthere are15trees inthebeginning, sothework ersplant 21-15=6trees. The\nanswer is 6.\nQ:If there are 3 cars in the parking lot and 2", " Introduction\nThe past decade has witnessed the extraordinary success\nof deep learning (DL) in many scienti\ufb01c areas. Inspired\nby these achievements, researchers have shown increas-\ning interest in exploiting DL for drug discovery and ma-\nterial design with the hope of rapidly identifying desirable\nmolecules. A key aspect of fast screening is how to represent\nmolecules effectively, where graphs are a natural choice to\npreserve their internal structures. As a consequence, a num-\nber of graph neural networks (GNNs) (Gilmer et al. 2017;\nIshida et al. 2021) have been invented and applied to molec-\nular representation learning with noticeable performance.\n*The corresponding author.\nCopyright \u00a9 2023, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.However, most existing GNNs only take atom-level infor-\nmation in homogeneous molecular graphs as input, which\nfails to adequately exploit rich semantic information in\nmotifs. Remarkably, motifs are signi\ufb01cant subgraph pat-\nterns that frequently occur, and can be leveraged to un-\ncover molecular properties. For instance, a carboxyl group\n(COOH ) acts as a hydrogen-bond acceptor, which con-\ntributes to better stability and higher boiling points. Besides,\nsimilar to the role of N-gram in natural language, molecu-\nlar motifs can promote the segmentation of atomic semantic\nmeanings. While some regard motifs as additional features\nof atoms (Maziarka et al. 2020, 2021), these methods are ei-\nther incapable to encode 3D geometry, non-sensitive to local\ncontextual patterns, or inef\ufb01cient to aggregate atom features.\nMore essentially, they are not specially designed to operate\non heterogeneous graphs of molecules. Appendix). The ablation studies (see Figure 3) demon-\nstrate that Molformer can gain improvements from all\nfour groups of motifs, where Hydrocarbons and Haloalka-\nnes are the most and the least effective types respec-\ntively. This is in line with the fact that Hydrocarbons\noccur most frequently in organic molecules. Moreover,\nthe best performance is achieved when all categories are\nconsidered, implying a promising direction to discover\nmore effective motifs. As for proteins, motifs discovered\nby our RL mining method share the same backbone as\nCC(C(NC(C)C(O)=O)=O)NC(CNC(CN)=O)=O (see Ap-\npendix), which is a hydrogen bond donor and implies a mark\nto distinguish potential binding site. Moreover, the portion\nof those motifs in the pocket ( 1:38%) is nearly twice that in\nother locations ( 0:73%), conforming to the fact that pockets\nare the most preferable part for ligands to bind with.Target \u000fHOMO\u000fLUMO \u0001\u000f \u0016 \u000b R2ZPVEU0U H G c v\nUnit eV eV eV D bohr3a2\n0 meV meV meV meV meV cal =mol K\nMPNN (Gilmer et al. 2017) .043 .037 .069 .030 .092 .150 1.27 45 45 39 44 .800\nSchnet (Sch \u00a8utt et al. 2018) .041 .034 .063 .033 .235 .073 1.7 14 19 14 14 .033\nMEGNet full(Chen et al. 2019) .038 .031 .061 .040 .083 .265 1.4 9 10 10 10 .030\nMGCN (Lu et al. 2019) .042 .057 .064 .056 .030 .110 1.12 12.9 14.4 14.6 16.2 .038\nDimeNet (Klicpera, Gro\u00df, and G \u00a8unnemann 2020) .027 .019 .034 .028 .046 .331 1.29 8.02 7.89 8.11 8.98 .024\nDimeNet++ (Klicpera et al. 2020) .024 .019 .032 .029 .043 .331 1.21 6.32 6.28 6.53 7.56 .023\nSphereNet (Liu et al. 2021) .024 .019 .032 .026 .047 .292 1.12 6.26 7.33 6.40 8.0 .021\nPaiNN (Sch \u00a8utt, Unke, and Gastegger 2021) .028 .020 .046 .012 .045 .066 1.28 5.85 5.53 5.98 7.35 .024\nSE(3)-Transformer (Fuchs et al. 2020) .035 .033 .053 .051", "ABSTRACT\nThis paper explores a simple method for improving the zero-shot learning abilities\nof language models. We show that instruction tuning \u2014\ufb01netuning language models\non a collection of datasets described via instructions\u2014substantially improves zero-\nshot performance on unseen tasks.\nWe take a 137B parameter pretrained language model and instruction tune it on\nover 60 NLP datasets verbalized via natural language instruction templates. We\nevaluate this instruction-tuned model, which we call FLAN, on unseen task types.\nFLAN substantially improves the performance of its unmodi\ufb01ed counterpart and\nsurpasses zero-shot 175B GPT-3 on 20 of 25 datasets that we evaluate. FLAN even\noutperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC,\nOpenbookQA, and StoryCloze. Ablation studies reveal that number of \ufb01netuning\ndatasets, model scale, and natural language instructions are key to the success of\ninstruction tuning.\nTargetInput (Commonsense Reasoning)\nkeep stack of pillow cases in fridgeInference on unseen task typeFinetune on many tasks (\u201cinstruction-tuning\u201d)\n\u2026Translate this sentence to Spanish: The new office building was built in less than three months.Input (Translation)\nEl nuevo edificio de oficinas se construy\u00f3 en tres meses.TargetInput (Natural Language Inference)\nIt is not possible to tellFLAN ResponseCoreference resolution tasksSentiment analysis tasksGPT-3 175B zero shotGPT-3 175B few-shotFLAN 137B zero-shotPerformance on unseen task typesNatural language inference42.953.256.2Reading Comprehension63.772.677.4Closed-Book QA49.855.756.6Here is a goal: Get a cool sleep on summer days. How would you accomplish this goal? OPTIONS: -Keep stack of pillow cases in fridge. -Keep stack of pillow cases in oven.Premise: At my age you will probably have learnt one lesson. Hypothesis: It's not certain how many lessons you'll learn by your thirties. Does the premise entail the hypothesis? OPTIONS: -yes     -it is not possible to tell      -no\nFigure 1: Top: overview of instruction tuning and FLAN. Instruction tuning \ufb01netunes a pretrained\nlanguage model on a mixture of tasks phrased as instructions. At inference time, we evaluate on\nan unseen task type; for instance, we could evaluate the model on natural language inference (NLI)\nwhen no NLI tasks were seen during instruction tuning. Bottom: performance of zero-shot FLAN,\ncompared with zero-shot and few-shot GPT-3, on three unseen task types where instruction tuning\nimproved performance substantially out of ten we evaluate. NLI datasets: ANLI R1\u2013R3, CB, RTE.\nReading comprehension datasets: BoolQ, MultiRC, OBQA. Closed-book QA datasets: ARC-easy,\nARC-challenge, NQ, TriviaQA.\n\u0003Lead contributors. Author contributions listed at end of paper.\n1arXiv:2109.01652v5  [cs.CL]  8 Feb 2022Published as a conference paper at ICLR 2022\n1 I NTRODUCTION\nLanguage models (LMs) at scale, such as GPT-3 (Brown et al., 2020), have been shown to perform\nfew-shot learning remarkably well. They are less successful at zero-shot learning, however. For\nexample, GPT-3\u2019s zero-shot performance is much worse than few-shot performance on tasks such as\nreading comprehension, question answering, and natural language inference. One potential reason\nis that, without few-shot exemplars, it is harder for models to perform well on prompts that are not\nsimilar to the format of the pretraining data.\nIn this paper, we explore a simple method to improve the zero-shot performance of large language\nmodels, which would expand their reach to a broader audience. We leverage the intuition that NLP\ntasks can be described via natural language instructions, such as \u201c Is the sentiment of this movie review\npositive or negative? \u201d or \u201c", " Introduction\nLanguage models pretrained on unlabeled texts\nhave substantially advanced the state of the art in\nvarious NLP tasks, ranging from natural language\nunderstanding (NLU) to text generation (Radford\net al., 2018a; Devlin et al., 2019; Yang et al., 2019;\nRadford et al., 2018b; Raffel et al., 2020; Lewis\net al., 2019; Brown et al., 2020). Downstream task\nperformance as well as the scale of the parame-\nters have also constantly increased in the past few\nyears.\n*The \ufb01rst two authors contributed equally.\n\u2020Corresponding authors.\n1The code and pre-trained models are available at https:\n//github.com/THUDM/GLM\nAll[START]NLPtasksaregenerationtasksAllNLPtasks[END]aregenerationtasks\n\u00d7 LFigure 1: Illustration of GLM. We blank out text spans\n(green part) and generate them autoregressively. (Some\nattention edges are omitted; cf. Figure 2.)\nIn general, existing pretraining frameworks can\nbe categorized into three families: autoregressive ,\nautoencoding , and encoder-decoder models. Au-\ntoregressive models, such as GPT (Radford et al.,\n2018a), learn left-to-right language models. While\nthey succeed in long-text generation and show few-\nshot learning ability when scaled to billions of\nparameters (Radford et al., 2018b; Brown et al.,\n2020), the inherent disadvantage is the unidirec-\ntional attention mechanism, which cannot fully cap-\nture the dependencies between the context words\nin NLU tasks. Autoencoding models, such as\nBERT (Devlin et al., 2019), learn bidirectional con-\ntext encoders via denoising objectives, e.g. Masked\nLanguage Model (MLM). The encoders produce\ncontextualized representations that suit natural lan-\nguage understanding tasks, but could not be directly\napplied for text generation. Encoder-decoder mod-\nels adopt bidirectional attention for the encoder,\nunidirectional attention for the decoder, and cross\nattention between them (Song et al., 2019; Bi et al.,\n2020; Lewis et al., 2019). They are typically de-\nployed in conditional generation tasks, such as\ntext summarization and response generation.2.\nT5 (Raffel et al., 2020) uni\ufb01es NLU and condi-\ntional generation via encoder-decoder models but\nrequires more parameters to match the performance\n2Unconditional generation refers to generating text as a lan-\nguage model without \ufb01netuning, while conditional generation\nrefers to sequence-to-sequence tasks.arXiv:2103.10360v2  [cs.CL]  17 Mar 2022of BRET-based models such as RoBERTa (Liu\net al., 2019) and DeBERTa (He et al., 2021).\nNone of these pretraining frameworks is \ufb02exible\nenough to perform competitively across all NLP\ntasks. Previous works have tried to unify differ-\nent frameworks by combining their objectives via\nmulti-task learning (Dong et al., 2019; Bao et al.,\n2020). However, since the autoencoding and au-\ntoregressive objectives differ by nature, a simple\nuni\ufb01cation cannot fully inherit the advantages of\nboth frameworks.\nIn this paper, we propose a pretraining frame-\nwork named GLM (General Language Model),\nbased on autoregressive blank in\ufb01lling. We ran-\ndomly blank out continuous spans of tokens from\nthe input text, following the idea of autoencoding,\nand train the model to sequentially reconstruct the\nspans, following the idea of autoregressive pretrain-\ning (see Figure 1). While blanking \ufb01lling has been\nused in T5 (Raffel et al., 2020) for text-to-text pre-\ntraining, we propose two improvements, namely\nspan shuf\ufb02ing and 2D positional encoding. Empiri-\ncally, we show that with the same amount of param-\neters and computational cost, GLM signi\ufb01cantly\noutperforms BERT on the SuperGLUE benchmark\nby a large margin of 4.6% \u2013 5.0% and outperforms\nRoBERTa and BART when pretrained on a corpus\nof similar size (158GB). GLM also signi\ufb01cantly\noutperforms T5 on NLU and generation tasks with\nfewer parameters and data.\nInspired by Pattern-Exploiting Training (PET)\n(Schick and Sch\u00fctze, 2020a), we reformulate NLU\ntasks as manually-crafted cloze questions that\nmimic human language. Different from the BERT-\nbased models used by PET, GLM can naturally\nhandle multi-token", "ABSTRACT\nWe propose a new test to measure a text model\u2019s multitask accuracy. The test\ncovers 57 tasks including elementary mathematics, US history, computer science,\nlaw, and more. To attain high accuracy on this test, models must possess extensive\nworld knowledge and problem solving ability. We \ufb01nd that while most recent\nmodels have near random-chance accuracy, the very largest GPT-3 model improves\nover random chance by almost 20 percentage points on average. However, on every\none of the 57 tasks, the best models still need substantial improvements before\nthey can reach expert-level accuracy. Models also have lopsided performance\nand frequently do not know when they are wrong. Worse, they still have near-\nrandom accuracy on some socially important subjects such as morality and law.\nBy comprehensively evaluating the breadth and depth of a model\u2019s academic and\nprofessional understanding, our test can be used to analyze models across many\ntasks and to identify important shortcomings.\n1 I NTRODUCTION\nNatural Language Processing (NLP) models have achieved superhuman performance on a number of\nrecently proposed benchmarks. However, these models are still well below human level performance\nfor language understanding as a whole, suggesting a disconnect between our benchmarks and the\nactual capabilities of these models. The General Language Understanding Evaluation benchmark\n(GLUE) (Wang et al., 2018) was introduced in 2018 to evaluate performance on a wide range of NLP\ntasks, and top models achieved superhuman performance within a year. To address the shortcomings\nof GLUE, researchers designed the SuperGLUE benchmark with more dif\ufb01cult tasks (Wang et al.,\n2019). About a year since the release of SuperGLUE, performance is again essentially human-level\n(Raffel et al., 2019). While these benchmarks evaluate linguistic skills more than overall language\nunderstanding, an array of commonsense benchmarks have been proposed to measure basic reasoning\nand everyday knowledge (Zellers et al., 2019; Huang et al., 2019; Bisk et al., 2019). However, these\nrecent benchmarks have similarly seen rapid progress (Khashabi et al., 2020). Overall, the near\nhuman-level performance on these benchmarks suggests that they are not capturing important facets\nof language understanding.\nTransformer models have driven this recent progress by pretraining on massive text corpora, including\nall of Wikipedia, thousands of books, and numerous websites. These models consequently see\nextensive information about specialized topics, most of which is not assessed by existing NLP\nbenchmarks. It consequently remains an open question just how capable current language models are\nat learning and applying knowledge from many domains.\nTo bridge the gap between the wide-ranging knowledge that models see during pretraining and the\nexisting measures of success, we introduce a new benchmark for assessing models across a diverse\nset of subjects that humans learn. We design the benchmark to measure knowledge acquired during\npretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the\nbenchmark more challenging and more similar to how we evaluate humans. The benchmark covers\n57subjects across STEM, the humanities, the social sciences, and more. It ranges in dif\ufb01culty from\nan elementary level to an advanced professional level, and it tests both world knowledge and problem\nsolving ability. Subjects range from traditional areas, such as mathematics and history, to more\n1arXiv:2009.03300v3  [cs.CY]  12 Jan 2021Published as a conference paper at ICLR 2021\nFew Shot Prompt and Predicted Answer\nHow many numbers are in the list 25, 26, ..., 100?\n(A) 75 (B) 76", " Introduction\nBefore children learn language, they already start forming\ncategories and concepts based on the physical properties of\nobjects around them (Hespos and Spelke 2004). This model\nof the world grows richer as they learn to speak, but al-\nready captures physical commonsense knowledge about ev-\neryday objects: their physical properties, affordances, and\nhow they can be manipulated. This knowledge is critical\nfor day-to-day human life, including tasks such as problem\nsolving (what can I use as a pillow when camping?) and\nexpressing needs and desires (bring me a hard erpillow).\nLikewise, we hypothesize that modeling physical common-\nsense knowledge is a major challenge on the road to true AI-\ncompleteness, including robots that interact with the world\nand understand natural language.\nMuch of physical commonsense can be expressed in lan-\nguage, as the versatility of everyday objects and common\nconcepts eludes other label schemes. However, due to is-\nsues of reporting bias, these commonsense properties - facts\nlike \u2018it is a bad idea to apply eyeshadow with a toothpick\u2019\nare rarely directly reported. Although much recent progress\nCopyright c\r2020, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.\na.Squeezethe water \nbottle and press it \nagainst the yolk. \nRelease, which creates \nsuction and lifts the yolk.To separate egg whites from the yolk\nusing a water bottle, you should\u2026\nb.Placethe water bottle \nand press it against the \nyolk. Keep pushing,\nwhich creates suction \nand lifts the yolk.\n???\na!\nFigure 1: PIQA\n : Given a physical goal expressed in nat-\nural language, like \u2018to separate egg whites...,\u2019 a model must\nchoose the most sensible solution . Our dataset tests the abil-\nity of natural language understanding models to link text to\na robust intuitive-physics model of the world. Here, humans\neasily pick answer a)because separating the egg requires\npulling the yolk out, while machines are easily fooled.\nhas been made in Natural Language Processing through\na shift towards large-scale pretrained representations from\nunlabeled text (Radford et al. 2018; Devlin et al. 2019;\nLiu et al. 2019), the bulk of the success of this paradigm\nhas been on core methods\ntrained on large web crawls may eventually surpass human\nperformance here. Human evaluation was performed on de-\nvelopment data, and the train, development, and test folds\nwere automatically produced by AFLite . Experiments\nIn this section, we test the performance of state-of-the-\nart natural language understanding models on our dataset,\nPIQA . In particular, we consider the following three large-\nscale pretrained transformer models:\na.GPT (Radford et al. 2018) is a model that processes text\nleft-to-right, and was pretrained using a language modeling\nobjective. We use the original 124M parameter GPT model.\nb.BERT (Devlin et al. 2019) is a model that process\ntext bidirectionally, and thus was pretrained using a special\nmasked language modeling objective. We use BERT-Large\nwith 340M parameters.\nc.RoBERTa (Liu et al. 2019) is a version of the BERT\nmodel that was made to be signi\ufb01cantly more robust through\npretraining on more data and careful validation of the pre-training hyperparameters. We use RoBERTa-Large, which\nhas 355M parameters.\nWe follow standard best practices in adapting these mod-\nels for two-way classi\ufb01cation. We consider the two solution\nchoices independently: for each choice, the model is pro-\nvided the goal, the solution choice, and a special [CLS]\ntoken. At the \ufb01nal layer of the transformer, we extract the\nhidden states corresponding to the positions of each [CLS]\ntoken. We apply a linear transformation to each hidden state\nand", " Introduction\nDeep Learning (DL) models are becoming larger, and the increase in model size o\u000bers signi\fcant\naccuracy gain. In the area of Natural Language Processing (NLP), the transformers have paved\nway for large models like Bert-large (0.3B) [1], GPT-2 (1.5B) [2], Megatron-LM (8.3B) [3], T5\n(11B) [4]. To enable the continuation of model size growth from 10s of billions to trillions of\nparameters, we experience the challenges of training them - they clearly do not \ft within the\nmemory of a single device, e.g., GPU or TPU, and simply adding more devices will not help\nscale the training.\nBasic data parallelism (DP) does not reduce memory per device, and runs out of mem-\nory for models with more than 1.4B parameters on current generation of GPUs with 32 GB\nmemory. Other existing solutions such as Pipeline Parallelism (PP), Model Parallelism (MP),\n\u0003Equal Contributors\n1arXiv:1910.02054v3  [cs.LG]  13 May 2020CPU-O\u000foading, etc, make trade-o\u000bs between functionality, usability, as well as memory and\ncompute/communication e\u000eciency, but all of which are crucial to training with speed and scale.\nAmong di\u000berent existing solution for training large models, MP is perhaps the most promis-\ning. The largest models in the current literature, the 11B T5 model [4], and Megatron-LM\n8.3B [3], were both powered by model parallelism, implemented in Mesh-Tensor\row [5] and\nMegatron-LM[3], respectively. However, MP cannot scale much further beyond these models\nsizes. MP splits the model vertically, partitioning the computation and parameters in each layer\nacross multiple devices, requiring signi\fcant communication between each layer. As a result,\nthey work well within a single node where the inter-GPU communication bandwidth is high,\nbut the e\u000eciency degrades quickly beyond a single node [3]. We tested a 40B parameter model\nusing Megatron-LM across two DGX-2 nodes and observe about 5 Tflops per V100 GPU (less\nthan 5% of hardware peak).\nSo, how can we overcome the limitations of existing solutions and train large models more\ne\u000eciently? To answer this question, we \frst analyze the full spectrum of memory consumption\nof the existing systems on model training and classify it into two parts: 1) For large models,\nthe majority of the memory is occupied by model states which include the optimizer states\n(such as momentum and variances in Adam [6]), gradients, and parameters. 2) The remaining\nmemory is consumed by activation, temporary bu\u000bers and unusable fragmented memory, which\nwe refer to collectively as residual states. We develop ZeRO | Zero Redundancy Optimizer\n| to optimize memory e\u000eciency on both while obtaining high compute and communication\ne\u000eciency. As these two parts face di\u000berent challenges, we develop and discuss their solutions\ncorrespondingly.\nOptimizing Model State Memory Model states often consume the largest amount of\nmemory during training, but existing approaches such as DP and MP do not o\u000ber satisfying\nsolution. DP has good compute/communication e\u000eciency but poor memory e\u000eciency while\nMP can have poor compute/communication e\u000eciency. More speci\fcally, DP replicates the\nentire model states across all data parallel process resulting in redundant memory consumption;\nwhile MP partition these states to obtain high memory e\u000eciency, but often result in too \fne-\ngrained computation and expensive communication that is less scaling e\u000ecient. Furthermore,\nall of these approaches maintain all the model states required over the entire training process\nstatically, even though not all model states are required all the time during the training. Based\non", " Introduction\n(Schoenick et al., 2017). However, there are two poten-\ntially signi\ufb01cant challenges with these datasets. First, these\ndatasets are often small (e.g., hundreds of questions), due\nto the scarcity of public, real-world test data. Second, be-\ncause tests were designed for people rather than machines,\nlarge portions of these tests can be easily solved by simple\nAI methods. We \ufb01nd that none of the base-\nline systems tested can signi\ufb01cantly outperform a random\nbaseline on the Challenge set, including two neural models\nwith high performances on SNLI and SQuAD. Progress on\nARC would thus be an impressive achievement, given its\ndesign, and be signi\ufb01cant step forward for the community.\nTo access ARC, view the leaderboard, and submit new en-\ntries, visit the ARC Website at http://data.allenai.org/arc.\nAvailability The ARC Dataset, Corpus, three\nbaseline neural models (DecompAttn, BiDAF, and\nDGEM), and the leaderboard, are all available\nfrom http://data.allenai.org/arc. Related Work\nThere are numerous datasets available to drive progress\nin question-answering. Earlier reading comprehension\ndatasets, e.g., MCTest (Richardson, 2013), SQuAD (Ra-\njpurkar et al., 2016), NewsQA (Trischler et al., 2016), and\nCNN/DailyMail (Hermann et al., 2015), contained ques-\ntions whose answers could be determined from surface-level\ncues alone (i.e., answers were \u201cexplicitly stated\u201d). TriviaQA\n(Joshi et al., 2017) broadened this task by providing sev-\neral articles with a question, and used questions authored\nindependently of the articles. Again, though, the questions\nwere largely factoid-style, e.g., \u201cWho won the Nobel Peace\nPrize in 2009?\u201d. Although systems can now perform well\non these datasets, even matching human performance (Si-\nmonite, 2018), they can be easily fooled (Jia and Liang,\n2017); the degree to which they truly understand language\nor domain-speci\ufb01c concepts remains unclear.\nTo push towards more complex QA tasks, one approach\nhas been to generate synthetic datasets, the most notable ex-\nample being the bAbI dataset (Weston et al., 2015). bAbi\nwas generated using a simple world simulator and language\ngenerator, producing data for 20 different tasks. It has stim-\nulated work on use of memory network neural architectures\n(Weston et al., 2014), supporting a form of multistep rea-\nsoning where a neural memory propagates information from\none step to another (e.g. Henaff et al., 2016; Seo et al.,\n2017a). However, its use of synthetic text and a synthetic\nworld limits the realism and dif\ufb01culty of the task, with many\nsystems scoring a perfect 100% on most tasks (e.g. Weston\n1ARC includes the publically releasable subset of the Kaggle\nquestions (about 60% of the Kaggle set, making up 43% of the\nARC set).et al., 2014). In general, a risk of using large synthetic QA\ndatasets is that neural Appendix B: Question Answering via\nEntailment\nGiven a large corpus of sentences (such as the ARC Cor-\npus), one natural way to answer multiple-choice questions\n8Source Description # Questions\nChall-\nenge Easy\nACTAAP Arkansas Comprehensive Testing, Assessment, and Accountability Program 71 129\nAIMS Arizona\u2019s Instrument to Measure Standards 15 32\nAlaska Dept Ed Alaska Department of Education & Early Development 38 62\nAMP Alaska Measures of Progress 0 1\nCA Stnds Test California Standards Test 19 59\nFCAT Florida Comprehensive Assessment Test 3 3\nLA Ed Assm. Prog Louisiana Department of Education 36 61\nMD School Assm. Maryland School Assessment 66 89\nMCAS MCAS-Massachusetts Comprehensive Assessment System 221 411\nMEA Maine Educational Assessment 36 56\nMEAP Michigan Educational Assessment Program 14 19\nMercury Our name for an anonymous content partner of AI2 who has generously provided\nsome of their science exam question data for", " Introduction\nOne of the fundamental problems in organic chemistry is the prediction of which products form as\na result of a chemical reaction [ 16,17]. While the products can be determined unambiguously for\nsimple reactions, it is a major challenge for many complex organic reactions. Indeed, experimentation\nremains the primary manner in which reaction outcomes are analyzed. This is time consuming,\nexpensive, and requires the help of an experienced chemist. The empirical approach is particularly\nlimiting for the goal of automatically designing ef\ufb01cient reaction sequences that produce speci\ufb01c\ntarget molecule(s), a problem known as chemical retrosynthesis [16, 17].\nViewing molecules as labeled graphs over atoms, we propose to formulate the reaction prediction\ntask as a graph transformation problem. A chemical reaction transforms input molecules (reactants)\ninto new molecules (products) by performing a set of graph edits over reactant molecules, adding\nnew edges and/or eliminating existing ones. Given that a typical reaction may involve more than 100\natoms, fully exploring all possible transformations is intractable. The computational challenge is\nhow to reduce the space of possible edits effectively, and how to select the product from among the\nresulting candidates.\nThe state-of-the-art solution is based on reaction templates (Figure 1). A reaction template speci\ufb01es a\nmolecular subgraph pattern to which it can be applied and the corresponding graph transformation.\nSince multiple templates can match a set of reactants, another model is trained to \ufb01lter candidate\nproducts using standard supervised approaches. The key drawbacks of this approach are coverage\nand scalability. A large number of templates is required to ensure that at least one can reconstitute the\ncorrect product. The templates are currently either hand-crafted by experts [ 7,1,15] or generated\nfrom reaction databases with heuristic algorithms [ 2,11,3]. For example, Coley et al. [3]extracts\n140K unique reaction templates from a database of 1 million reactions. Beyond coverage, applying a\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1709.04555v3  [cs.LG]  29 Dec 2017Figure 1: An example reaction where the reaction center is (27,28), (7,27), and (8,27), highlighted in\ngreen. Here bond (27,28) is deleted and (7,27) and (8,27) are connected by aromatic bonds to form a\nnew ring. The corresponding reaction template consists of not only the reaction center, but nearby\nfunctional groups that explicitly specify the context.\ntemplate involves graph matching and this makes examining large numbers of templates prohibitively\nexpensive. The current approach is therefore limited to small datasets with limited types of reactions.\nIn this paper, we propose a template-free approach by learning to identify the reaction center , a small\nset of atoms/bonds that change from reactants to products. In our datasets, on average only 5.5%\nof the reactant molecules directly participate in the reaction. The small size of the reaction centers\ntogether with additional constraints on bond formations enables us to directly enumerate candidate\nproducts. Our forward-prediction approach is then divided into two key parts: (1) learning to identify\nreaction centers and (2) learning to rank the resulting enumerated candidate products.\nOur technical approach builds on neural embedding of the Weisfeiler-Lehman isomorphism test.\nWe incorporate a speci\ufb01c attention mechanism to identify reaction centers while leveraging distal\nchemical effects not accounted for in related convolutional representations [ 5,4]. Moreover, we\npropose a novel Weisfeiler-Lehman Difference Network to learn to represent and ef\ufb01ciently", " Introduction\nThe construction of large, high-quality datasets\nhas been one of the main drivers of progress in\nNLP. The recent proliferation of datasets for tex-\ntual entailment, reading comprehension and Ques-\ntion Answering (QA) (Bowman et al., 2015; Her-\nmann et al., 2015; Rajpurkar et al., 2016; Hill\net al., 2015; Hewlett et al., 2016; Nguyen et al.,\n2016) has allowed for advances on these tasks,\nparticularly with neural models (Kadlec et al.,\n*Work done while at the Allen Institute for Arti\ufb01cial In-\ntelligence.\n1Dataset available at http://allenai.org/data.\nhtml2016; Dhingra et al., 2016; Sordoni et al., 2016;\nSeo et al., 2016). These recent datasets cover\nbroad and general domains, but progress on these\ndatasets has not translated into similar improve-\nments in more targeted domains, such as science\nexam QA.\nScience exam QA is a high-level NLP task\nwhich requires the mastery and integration of in-\nformation extraction, reading comprehension and\ncommon sense reasoning (Clark et al., 2013;\nClark, 2015). Consider, for example, the ques-\ntion\u201cWith which force does the moon affect tidal\nmovements of the oceans?\u201d . To solve it, a model\nmust possess an abstract proper-\nties: if the correct answer belongs to a certain\ncategory (e.g., chemical elements) good dis-\ntractors likely should as well.\n\u000fbe consistent with the semantic context of the\nquestion: a question about animals and en-\nergy should not have newspaper orbingo as\ndistractors.\nDistractor Model Overview. We now intro-\nduce a model which generates plausible answerdistrators and takes into account the above criteria.\nOn a basic level, it ranks candidates from a large\ncollectionCof possible distractors and selects the\nhighest scoring items. Its ranking function\nr: (q;a\u0003;a0)7!sa02[0;1] (1)\nproduces a con\ufb01dence score sa0for whether a02\nCis a good distractor in the context of question q\nand correct answer a\u0003. Forrwe use the scoring\nfunctionsa0=P(a0is goodjq;a\u0003)of a binary\nclassi\ufb01er which distinguishes plausible (good) dis-\ntractors from random (bad) distractors based on\nfeatures\u001e(q;a\u0003;a0). For classi\ufb01cation, we train r\non actual in-domain questions with observed false\nanswers as the plausible (good) distractors, and\nrandom expressions as negative examples, sam-\npled in equal proportion from C. As classi\ufb01er we\nchose a random forest (Breiman, 2001), because\nof its robust performance in small and mid-sized\ndata settings and its power to incorporate nonlin-\near feature interactions, in contrast, e.g., to logistic\nregression.\nDistractor Model Features. This section de-\nscribes the features \u001e(q;a\u0003;a0)used by the dis-\ntractor ranking model. With these features, the\ndistractor model can learn characteristics of real\ndistractors from original questions and will sug-\ngest those distractors that it deems the most realis-\ntic for a question. The following features of ques-\ntionq, correct answer a\u0003and a tentative distractor\nexpressiona0were used:\n\u000fbags ofGloVe embeddings for q,a\u0003anda0;\n\u000fan indicator for POS-tag consistency of a\u0003\nanda0;\n\u000fsingular/plural consistency of a\u0003anda0;\n\u000flog. avg. word frequency in a\u0003anda0;\n\u000fLevenshtein string edit distance between a\u0003\nanda0;\n\u000fsuf\ufb01x consistency of a\u0003anda0(\ufb01ring e.g. for\n(regeneration, exhaustion ));\n\u000ftoken overlap indicators for q,a\u0003anda0;\n\u000ftoken and character length for a\u0003anda0and\nsimilarity therein;\n\u000findicators for numerical content in q,a\u0003and\na0consistency therein;\u000findicators for units of measure in q,a\u0003and\na0, and for co-occurrence of the same unit;\n\u000fWordNet-based hypernymy indicators be-\ntween tokens in q,a\u0003anda0, in both direc-\ntions and potentially via two steps;\n\u000findicators for 2-step connections between en-\ntities ina\u0003anda0via a KB based on OpenIE\ntriples (Mausam et al., 2012) extracted from\npages in Simple Wikipedia about anatomical\nstructures;\n\u000findicators for shared Wordnet-hyponymy of\na\u0003anda0to one of the concepts most fre-\nquently generalising all three question dis-\ntractors in the training set (e.g. element ,or-\ngan,organism ).\nThe intuition for the knowledge-base link and\nhypernymy indicator features is that they", " Introduction\nOverlap between chemistry and statistical learning has had a long history. The \feld of chem-\ninformatics has been utilizing machine learning introduction of the ImageNet benchmark in 2009 has triggered a series of\nbreakthroughs in computer vision, and in particular has facilitated the rapid development of\ndeep convolutional networks. The ILSVRC, an annual contest held by the ImageNet team,26\ndraws considerable attention from the community, and greatly stimulates collaborations and\ncompetitions across the \feld. The contest has given rise to a series of prominent machine\nlearning models such as AlexNet,27GoogLeNet,28ResNet29which have had broad impact on\nthe academic and industrial computer science communities. We hope that MoleculeNet will\ntrigger similar breakthroughs by serving as a platform for the wider community to develop\nand improve models for learning molecular properties.\n3In particular, MoleculeNet contains data on the properties of over 700,000 compounds.\nAll datasets have been curated and integrated into the open source DeepChem package.30\nUsers of DeepChem can easily load all MoleculeNet benchmark data through provided library\ncalls. MoleculeNet also contributes high quality implementations of well known (bio)chemical\nfeaturization results.\nNote that the original paper trained a single model for each task in the qm9 dataset.\nHere we only picked one representative task to compare.\nMAE in eV:\n\u000fOriginal result: 0 :0544\n\u000fReimplementation: 0 :0997 for valid subset, 0 :101 for test subset\n57In\ruence Relevance Voting\nWe evaluate the model on the HIV dataset, using 80/10/10 random train, valid, test split-\nting. The original paper reported performance under 10-fold cross validation.75\nROC-AUC:\n\u000fOriginal result: 0 :845\n\u000fReimplementation: 0 :840 for valid subset, 0 :852 for test subset related work section will review prior work in the chemistry community on gather-\ning curated datasets and discuss how MoleculeNet di\u000bers from these previous e\u000borts. The conclusions about the algorithms and datasets considered. Related Work\nMoleculeNet draws upon a broader movement within the chemical community to gather large\nsources of curated data. PubChem34and PubChem BioAssasy35gather together thousands\nof bioassay experiments focusing on how variable size of training set a\u000bect model\nperformances.(Tox21, FreeSolv and QM7) Details will be presented in the following texts.\n28Figure 7: Benchmark performances for biophysics tasks: PCBA , 4 models are evaluated by\nAUC-PRC on random split; MUV , 8 models are evaluated by AUC-PRC on random split;\nHIV , 8 models are evaluated by AUC-ROC on sca\u000bold split; BACE , 9 models are evaluated\nby AUC-ROC on sca\u000bold split. For AUC-ROC and AUC-PRC, higher value indicates better\nperformance(to the right).\n29Figure 8: Benchmark performances for physiology tasks: ToxCast , 8 models are evaluated\nby AUC-ROC on random split; Tox21 , 9 models are evaluated by AUC-ROC on random\nsplit; BBBP , 9 models are evaluated by AUC-ROC on sca\u000bold split; SIDER , 9 models\nare evaluated by AUC-ROC on random split. For AUC-ROC, higher value indicates better\nperformance(to the right).\n30Figure 9: Benchmark performances for physiology tasks: ClinTox , 9 models are evaluated\nby AUC-ROC on random split.\nPhysiology and Biophysics Tasks\nTables 5, 6 and Figures 7, 8, 9 report AUC-ROC or AUC-PRC Appendix.\nWe measured model running time of Tox21, MUV, QM8 and Lipophicility on a single\nnode in Stanford's GPU clusters(CPU: Intel Xeon E5-2640 v3 @2.60 GHz, GPU: NVIDIA\nTesla K80), abstract information of the graph, then the readout\nphase is responsible for mapping the graph to its properties.\nHere we reimplemented the best-performing model in the", " Introduction to the conll-2003 shared task:\nLanguage-independent named entity recognition. In\nCoNLL .\nJoseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.\nWord representations: A simple and general method\nfor semi-supervised learning. In Proceedings of the\n48th Annual Meeting of the Association for Compu-\ntational Linguistics , ACL \u201910, pages 384\u2013394.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , pages 6000\u20136010.\nPascal Vincent, Hugo Larochelle, Yoshua Bengio, and\nPierre-Antoine Manzagol. 2008. Extracting and\ncomposing robust features with denoising autoen-\ncoders. In Proceedings of the 25th international\nconference on Machine learning , pages 1096\u20131103.\nACM.\nAlex Wang, Amanpreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel Bowman. 2018a.\nGlue: A multi-task benchmark and analysis platformfor natural language understanding. In Proceedings\nof the 2018 EMNLP Workshop BlackboxNLP: An-\nalyzing and Interpreting Neural Networks for NLP ,\npages 353\u2013355.\nWei Wang, Ming Yan, and Chen Wu. 2018b. Multi-\ngranularity hierarchical attention fusion networks\nfor reading comprehension and question answering.\nInProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) . Association for Computational Lin-\nguistics.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-\nman. 2018. Neural network acceptability judg-\nments. arXiv preprint arXiv:1805.12471 .\nAdina Williams, Nikita Nangia, and Samuel R Bow-\nman. 2018. A broad-coverage challenge corpus\nfor sentence understanding through inference. In\nNAACL .\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\nLe, Mohammad Norouzi, Wolfgang Macherey,\nMaxim Krikun, Yuan Cao, Qin Gao, Klaus\nMacherey, et al. 2016. Google\u2019s neural ma-\nchine translation system: Bridging the gap between\nhuman and machine translation. arXiv preprint\narXiv:1609.08144 .\nJason Yosinski, Jeff Clune, Yoshua Bengio, and Hod\nLipson. 2014. How transferable are features in deep\nneural networks? In Advances in neural information\nprocessing systems , pages 3320\u20133328.\nAdams Wei Yu, David Dohan, Minh-Thang Luong, Rui\nZhao, Kai Chen, Mohammad Norouzi, and Quoc V\nLe. 2018. QANet: Combining local convolution\nwith global self-attention for reading comprehen-\nsion. In ICLR .\nRowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin\nChoi. 2018. Swag: A large-scale adversarial dataset\nfor grounded commonsense inference. In Proceed-\nings of the 2018 Conference on Empirical Related Work\nThere is a long history of pre-training general lan-\nguage representations, and we brie\ufb02y review the\nmost widely-used approaches in this section.\n2.1 Unsupervised Feature-based Approaches\nLearning widely applicable representations of\nwords has been an active area of research for\ndecades, including non-neural (Brown et al., 1992;\nAndo and Zhang, 2005; Blitzer et al., 2006) and\nneural (Mikolov et al., 2013; Pennington et al.,\n2014) methods could be\nminimally compared. The core argument of this\nwork is that the bi-directionality and the two pre-\ntraining tasks presented in Section 3.1 account for\nthe majority of the empirical improvements, but\nwe do note that there are several other differences\nbetween how BERT and GPT were trained:\n\u2022 GPT is trained on the BooksCorpus (800M\nwords); BERT is trained on the BooksCor-\npus (800M words) and Wikipedia (2,500M\nwords).\n\u2022 GPT uses a sentence separator ( [SEP] ) and\nclassi\ufb01er token ( [CLS] ) which are only in-\ntroduced at \ufb01ne-tuning time; BERT learns\n[SEP] ,[CLS] and sentence A/Bembed-\ndings during pre-training.\n\u2022 GPT was trained for 1M steps with a batch\nsize of 32,000 words; BERT was trained for\n1M steps with a batch size of 128,000 words.\n\u2022 GPT used the same learning rate of 5e-5 for\nall \ufb01ne-tuning results. For the feature-based approach,\nwe concatenate the last 4 layers of BERT"], "bleu": 0.15276863630823165, "rouge_l": 0.28976034858387795, "gpt_metric_score": 0.0, "bert_score": 0.11896613985300064}
{"paper_key": "Scientific Large Language Models: A Survey on Biological & Chemical Domains", "current_5q": "### [Question 1] - What is the problem?\nHow can we effectively leverage large language models to improve the accuracy and efficiency of molecular property prediction in the fields of biology and chemistry?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem has significant implications for the research community as it could lead to breakthroughs in drug discovery, materials science, and personalized medicine. By enhancing the predictive capabilities of molecular property models, researchers can accelerate the identification of promising compounds, reduce the time and cost associated with experimental validation, and ultimately contribute to more effective therapeutic strategies. This advancement could also inspire future research into the integration of machine learning with experimental methodologies, fostering interdisciplinary collaboration and innovation.\n\n### [Question 3] - Why is it hard?\nThe challenges in this domain include the complexity of molecular structures, the high dimensionality of chemical data, and the need for models to generalize across diverse chemical spaces. Naive approaches may fail due to overfitting on limited datasets or inability to capture intricate molecular interactions. Additionally, the lack of standardized datasets and metrics for evaluating model performance in this context presents a significant obstacle. Overcoming these challenges requires sophisticated modeling techniques that can effectively represent molecular graphs and account for the nuances of chemical behavior.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has often been limited by the availability of high-quality, annotated datasets and the computational resources required to train complex models. Many existing solutions have focused on specific types of molecules or properties, leading to a lack of generalizability. Additionally, earlier approaches may not have fully utilized the potential of large language models or advanced graph-based techniques. Our approach aims to address these gaps by integrating diverse datasets, employing state-of-the-art transformer architectures, and establishing robust evaluation metrics that enhance model applicability across various chemical domains.\n\n### [Question 5] - What are the key components of my approach and results?\nOur proposed methodology involves the use of a transformer-based architecture tailored for molecular graphs, leveraging datasets such as MoleculeNet and DrugBank for training and validation. We will employ metrics such as mean absolute error (MAE) and R-squared (R\u00b2) to evaluate model performance. The expected outcomes include improved predictive accuracy for molecular properties, a comprehensive analysis of model interpretability, and the development of a user-friendly interface for researchers to apply these models in practical scenarios. This work aims to set a new benchmark for molecular property prediction in the machine learning community.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question we aim to address is: How can a specialized Large Language Model (LLM) that integrates Borel graph embeddings improve the analysis and optimization of decentralized control systems in multi-agent environments, particularly in the context of biological and chemical interactions?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem has significant implications for the research community, particularly in fields such as systems biology, chemistry, and artificial intelligence. By developing an LLM that effectively analyzes and optimizes decentralized control systems, we can enhance our understanding of complex interactions among biological and chemical entities. This, in turn, could lead to advancements in drug discovery, synthetic biology, and the design of intelligent systems that mimic biological processes. The paper's findings may guide future research towards more sophisticated models that can integrate multimodal data, thereby accelerating scientific discovery and fostering collaboration across disciplines. Addressing this question could ultimately lead to practical applications such as improved therapeutic strategies and more efficient chemical processes.\n\n[Question 3]: Why is it hard?  \nThe challenges in solving this problem are multifaceted. First, integrating Borel graph embeddings into an LLM requires a deep understanding of both graph theory and neural network architectures, posing a significant technical challenge. Naive approaches may fail because they might not effectively capture the complex, non-linear relationships present in decentralized control systems, leading to suboptimal predictions or communication strategies among agents. Additionally, the complexity of biological interactions and the variability of data sources introduce practical obstacles, such as data sparsity and noise. The need for the model to simultaneously process and synthesize information from diverse modalities, including textual scientific literature, experimental data, and computational simulations, adds layers of complexity that must be addressed to achieve robust results.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on either traditional modeling approaches or basic machine learning techniques that do not adequately account for the intricate relationships inherent in multi-agent systems. Existing solutions may lack the ability to integrate knowledge graphs effectively or to leverage multimodal data comprehensively. Furthermore, there has been insufficient exploration of how Borel graph embeddings can enhance LLMs in this context. Barriers that have prevented this problem from being solved include a lack of interdisciplinary collaboration, limited computational resources, and the absence of frameworks that combine the necessary theoretical foundations with practical applications. Our approach differs by specifically targeting these gaps, emphasizing the integration of specialized knowledge graphs and multimodal data to create a more holistic model for analysis and optimization.\n\n[Question 5]: What are the key components of my approach and results?  \nOur proposed methodology involves developing a specialized LLM that incorporates Borel graph embeddings, allowing for the representation of complex interactions in decentralized control systems. We will utilize a diverse dataset comprising scientific literature, experimental results, and computational simulations related to biological and chemical entities. Metrics such as prediction accuracy, communication efficiency among agents, and the model's ability to generate actionable insights will be employed to evaluate performance. We expect the outcomes to include improved predictive hypotheses regarding molecular interactions, enhanced optimization of communication strategies in multi-agent settings, and a framework that facilitates collaborative research efforts. Ultimately, our approach aims to provide a transformative tool for researchers, accelerating the pace of discovery in complex scientific domains.", "referenced_intros": [], "bleu": 0.1858593956066396, "rouge_l": 0.32749742533470644, "gpt_metric_score": 0.5, "bert_score": 0.2662653923034668}
{"paper_key": "Mining experimental data from Materials Science literature with Large Language Models", "current_5q": "**[Question 1] - What is the problem?**  \nHow effectively can large language models (LLMs) extract materials science-related information and relate complex concepts within the context of materials discovery?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for the research community as it can significantly enhance the efficiency of materials discovery by automating the extraction of relevant information from vast amounts of literature. This advancement could lead to a deeper understanding of materials properties and relationships, ultimately accelerating the development of novel materials with desired functionalities. By improving LLMs' capabilities in this domain, future research can leverage these models for more sophisticated data-driven approaches, fostering innovation and practical applications in materials science.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in addressing this problem stem from the complexity of materials science terminology and the nuanced relationships between materials and their properties. Naive approaches may fail due to the unstructured nature of scientific texts, where definitions and measurements are often embedded in dense narratives. Additionally, the variability in how materials and properties are described\u2014ranging from precise measurements to vague commercial names\u2014complicates the extraction process. Overcoming these technical and theoretical obstacles requires advanced natural language processing techniques that can accurately interpret and relate diverse information.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on simpler tasks or lacked the necessary datasets to train models effectively for the specific challenges of materials science. Limitations in existing solutions include insufficient understanding of the domain-specific language and the inability to capture the intricate relationships between entities. Additionally, earlier approaches may not have adequately addressed the need for context-aware reasoning. Our approach differs by employing a comprehensive evaluation of LLMs on Named Entity Recognition (NER) tasks and relationship extraction, utilizing curated datasets that reflect the complexities of materials science literature.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves evaluating LLMs on NER tasks related to materials and properties extraction using the SuperMat dataset. We will assess the models' performance in identifying and categorizing entities such as materials, properties, and conditions. For relationship extraction, we will analyze the models' ability to discern connections between predefined entities within the context of materials science. The expected outcomes include improved accuracy in information extraction and a better understanding of how LLMs can reason about complex materials science concepts, ultimately contributing to more effective data-driven materials discovery.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question this proposal aims to address is: How can we develop an effective hybrid framework that integrates large language models with graph neural networks to automate the extraction and analysis of relational data from materials science literature, thereby enhancing the construction of dynamic knowledge graphs that capture material properties and their contextual relationships?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is crucial for the research community as it addresses the inefficiencies in current methods of extracting and analyzing data from extensive materials science literature. A successful implementation of this framework could revolutionize how researchers access and interpret data, leading to accelerated discoveries in materials science. By automating the extraction of relational data, the proposed system will enable researchers to identify emergent patterns and correlations between material properties and their applications more effectively. Additionally, the integration of physics-informed neural networks will enhance the interpretability of the results, facilitating a deeper understanding of materials and fostering innovation in the development of novel materials. This advancement in materials informatics can significantly contribute to fields such as energy storage, catalysis, and nanotechnology, ultimately impacting technology and industry at large.\n\n[Question 3]: Why is it hard?  \nThe complexity of this problem arises from several intertwined challenges. First, the vast and heterogeneous nature of materials science literature presents difficulties in accurately extracting relevant information; naive approaches may overlook crucial contextual relationships due to the nuanced language used in scientific texts. Second, constructing dynamic knowledge graphs involves not just data extraction but also the continuous adaptation of the graph structure in response to new information, which requires sophisticated algorithms that can handle real-time feedback. Third, integrating large language models with graph neural networks poses technical challenges in terms of model compatibility and efficiency, as both models have different architectures and data handling requirements. Lastly, ensuring that the model remains interpretable while leveraging advanced machine learning techniques adds a layer of complexity that must be addressed.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has largely focused on either text extraction or graph construction separately, creating gaps in the integrated approach necessary for effective materials informatics. Existing solutions often rely on traditional data mining techniques that lack the adaptability and contextual understanding provided by modern machine learning methods. Barriers such as limited computational resources, insufficiently annotated datasets, and the novelty of combining large language models with graph neural networks have hindered progress in this area. Moreover, past efforts have not effectively leveraged physics-informed principles to enhance model interpretability and predictive capabilities. Our approach distinguishes itself by combining these advanced methodologies into a cohesive framework, addressing both the extraction and relational analysis of materials data in a way that has not been attempted before.\n\n[Question 5]: What are the key components of my approach and results?  \nOur proposed methodology consists of a multi-step framework that integrates large language models for text extraction with graph neural networks for relational analysis. We will utilize a curated dataset comprised of peer-reviewed materials science articles, employing natural language processing techniques to extract material properties and their relationships. The dynamic knowledge graphs will be constructed using graph neural network algorithms, allowing for real-time updates based on new data input. Metrics for evaluation will include precision, recall, and F1-score for the extraction process, alongside graph-based metrics such as node connectivity and clustering coefficients to assess the quality of the constructed graphs. Expected outcomes include a robust hybrid framework capable of automating data extraction, generating insightful knowledge graphs, and enhancing the predictive capabilities of material properties, ultimately leading to a more intuitive exploration of materials and their applications.", "referenced_intros": [" Introduction\nThe material science domain possesses numerous information.\nThis knowledge must be extracted from material science datasets\n\u2217Authors contributed equally to this work.\nEmail addresses: ankanm@kgpian.iitkgp.ac.in (Ankan Mullick),\nakashkgp@kgpian.iitkgp.ac.in (Akash Ghosh),\ngajulasai@iitkgp.ac.in (G Sai Chaitanya),\nsamirghui@iitkgp.ac.in (Samir Ghui), tnk02.05@gmail.com\n(Tapas Nayak), seungcheol.lee@ikst.res.in (Seung-Cheol Lee),\ns.bhattacharjee@ikst.res.in (Satadeep Bhattacharjee),\npawang@cse.iitkgp.ac.in (Pawan Goyal)to improve or discover the latest materials. Current big data and\nmachine learning-based approaches can help bridge the gap\nbetween theoretical concepts and current material infrastructure\nlimitations. People have worked on different aspects of material\nscience literature in the last decade. One of the critical directions\nof material science research is the battery database which is\nessential in the modern energy system.\nBatteries are made up of complex material systems [ 1]. Proper\nanalysis of the battery database would lead us to discover new\nmaterials. The battery is a crucial element of any electrical\ndevice with various utilisations. Researchers focus on building\nhigh-capacity, efficient, safe batteries with various industrial\napplications. Relations must be retrieved from unorganized\ndata sources to build a concrete battery knowledge database.\nResearch papers describing battery materials can be a potential\nsource from which these relations can be obtained. Hence, an\nautomated relation extraction method from material science\nresearch articles would be a great leap towards overcoming\npresent constraints and achieving desired outcomes.\nFor example, Table 1 shows two entities (\u2018Na0.35MnO2\u2019 and\n\u201842.6 Wh kg 1\u2019) and corresponding relation (\u2018Energy\u2019) extraction\nfrom an input sentence \u201cThe energy density based on AC and\nnanowire Na0.35MnO2 is 42.6 Wh kg 1 at a power density of\n129.8 W kg 1.\u201d of a research article.\nRecent Natural Language Processing (NLP) and Deep Neural\nNetworks (DNN) techniques can facilitate relation extraction\nand automatically build the battery database. These methods in natural language processing,\n2015, pp. 1753\u20131762.\n[22] Y . Shen, X.-J. Huang, Attention-based convolutional neural network for\nsemantic relation extraction, in: Proceedings of COLING 2016, the 26th\nInternational Conference on Computational Linguistics: Technical Papers,\n2016, pp. 2526\u20132536.\n[23] S. Jat, S. Khandelwal, P. Talukdar, Improving distantly supervised re-\nlation extraction using word and entity based attention, arXiv preprint\narXiv:1804.06987 (2018).\n[24] S. Vashishth, R. Joshi, S. S. Prayaga, C. Bhattacharyya, P. Talukdar, Re-\nside: Improving distantly-supervised neural relation extraction using side\ninformation, arXiv preprint arXiv:1812.04361 (2018).\n[25] Z.-X. Ye, Z.-H. Ling, Distant supervision relation extraction with intra-bag\nand inter-bag attentions, arXiv preprint arXiv:1904.00143 (2019).\n[26] Z. Guo, Y . Zhang, W. Lu, Attention guided graph convolutional networks\nfor relation extraction, arXiv preprint arXiv:1906.07510 (2019).\n[27] A. Mullick, S. Purkayastha, P. Goyal, N. Ganguly, A framework to generate\nhigh-quality datapoints for multiple novel intent detection, in: Findings of\nthe Association for Computational Linguistics: NAACL 2022, 2022, pp.\n282\u2013292.\n[28] A. Mullick, I. Mondal, S. Ray, R. Raghav, G. Chaitanya, P. Goyal, Intent\nidentification and entity extraction for healthcare queries in indic languages,\nin: Findings of the Association for Computational Linguistics: EACL 2023,\n2023, pp. 1825\u20131836.\n[29] A. Mullick, A. Nandy, M. N. Kapadnis, S. Patnaik, R. Raghav, Fine-\ngrained intent classification in the legal domain, arXiv preprint\narXiv:2205.03509 (2022).\n[30] A. Mullick, Novel intent detection and active learning based classification(student Related Work\nTo give a broad overview of the existing works in this domain,\nwe categorize various earlier works into two categories - Ma-\nterial Science Information Extraction and Relation Extraction\nframeworks.\n2.1. Material Science Information Extraction:\nTshitoyan et al. [5]train the skip-gram variant of word2vec [ 6]\nmodel over a large corpus of material science research papers\nand demonstrate that the trained embeddings capture", " Introduction 1\n2 related work. Following that, we\ndescribe the necessary background connections. To test this, we experimented with\na variation of the Blocksworld domain, where we obfuscate the action names (for example pickup\nbecomes attack, and unstack becomes feast) and predicate names (for example ontable becomes\nplanet, and handempty becomes harmony). Note that from the perspective of standard planners, these\ndomains are essentially identical.3In addition to such deceptive obfuscation, we also considered a\nvariation where random alphanumeric names were substituted for the action and object names.\nTables 1 and 2, we see that this simple obfuscation leads to a catastrophic drop in performance.\nSpecifically, with zero-shot prompting and natural language input, GPT-4 is able to solve 210 instances\nout of 600 in the Blocksworld domain, but it could only solve 1 instance in the deceptive Mystery\nBlocksworld domain and 0 instances in the randomized mystery domain. A similar result is observed\nwith the PDDL-style prompts: GPT-4 could solve 106 instances in Blocksworld, but only 3 instances\nin the deceptive Mystery Blocksworld. Notably, chain of thought prompting does not significantly\nimprove performance over one-shot natural language prompts. GPT-3.5 does not solve even a single\ninstance in the entire set of natural language instances. For most of the instances, GPT-3.5 outputs\nthat the instance can\u2019t be solved. These experiments was $149.\nA.11.2 LPG experiment details\nAs mentioned above, we utilized LPG in the heuristic mode to find sound plans. We specifically use\nLPG 1.2 implementation without a best first search fallback (so that plans are only found using the\nlocal search method) and allow for only one search restart. We use the default heuristic evaluation\nfunction and maximum number of search steps (500). If the search is restarted, an additional 50 steps\ncan be used (bringing the maximum number on the second pass to 550). When working with the\nempty plan baseline, we simply do not provide an input plan. When assessing search on LLM plans,\nwe provide the LLM plan as the input plan. For random plans, we provide a random plan of the same\nlength as the LLM plan as the input plan.\nA.12 User study details\nWe ran the user studies on an online platform Prolific and paid the participants a wage of $8.12/hour\nfor the human baseline study (described in Section 4) and $10.29/hour for the LLM+human user\nstudy (described in Section 5.3).\nA.12.1 Instructions provided to the participants\nConsent for Study: The expected time of participation is between 25-35 minutes. You have the\nright not to answer any question, and to stop participation at any time. On successful completion,\nyou will be eligible to receive $5-8 for your participation in this study. We will need to record all\nthe responses provided by the participants during the study. Your consent to participate in this study\nis completely voluntary. To protect your privacy, responses from participants will never be used\nindividually while compiling or presenting Related Work 3\n3 Prompt Generation for Classical Planning Problems 4\n3.1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n3.2 Prompt Generation . . . . . . . .", " Introduction\nPerforming complex reasoning over long input doc-\numents often requires forming high-level abstrac-\ntions of the text (e.g., plots and themes in a narra-\ntive) and then conducting a variety of inferences\non top of those abstractions (Graesser et al., 1994).\nConsider the following question about the story\n\u201cBreakaway\u201d from the QuaLITY dataset (Pang\net al., 2022):\n\u2217Work partially done during an internship at Microsoft.\n1https://github.com/SimengSun/pearl\nMine helpful actions from training set questions \nDEFINE(X), COMPARE(X,Y) , FIND_EMOTION(X),...Action Mining\nExecute the plan step-by-step Plan Execution\nopen_conv = \"In the initial conversation, Phil \nConover is excited about his upcoming mission \nto be the first man to see the other side of \nthe moon ....\"Given a question, generate plan of mined actionsPlan Generation\nQuestion:  What part of the final scene best connects to the \nstory's opening conversation?\n1.open_conv = FIND_ELEMENT(CTX,\"opening conver..\")\n2.final_scene = SUMMARIZE_X(CTX, \"final_scene\")\n3.reflection = FIND_RELATION(init_conv, final_scene) Figure 1: High-level overview of our framework PEARL .\nEach stage in PEARL is achieved via zero-shot or few-\nshot prompting of an LLM (in our work, GPT-4). We\nalso provide example outputs from each stage.\nWhat part of the final scene best connects to the\nstory\u2019s opening conversation?\nTo answer this question, we need to gather, eval-\nuate, and synthesize information from across the\nstory, which motivates decomposing the question\ninto a plan of actions , as in:\n1.Identify all participants in initial conversation.\n2. Summarize the initial conversation.\n3. Summarize events and themes of final scene.\n4.Summarize roles of conversation participants\nin final scene.\n5.Identify and rank connections between conver-\nsation and final scene.\nEach action in the above plan varies in complexity,\nfrom simple lookup-style actions (Step 1) to more\nchallenging query-focused summarization (Steps\n2-4) and conceptual linking (Step 5) actions that\nrequire deep narrative understanding.\nGiven the rapidly advancing capabilities of large\nlanguage models (LLMs), how can we use them\nto answer questions like these? While we could\ndirectly prompt LLMs to generate the answer, prior\n1arXiv:2305.14564v1  [cs.CL]  23 May 2023work on simpler reasoning-based tasks shows that\nthis method is inferior to Chain-of-Thought prompt-\ning (Wei et al., 2022, CoT), which encourages the\nLLM to provide step-by-step explanations and in-\ntermediate outputs before producing the answer.\nUnfortunately, CoT is not well-suited for tasks in-\nvolving complex reasoning over long input docu-\nments, as both the decomposition of the original\nquestion and the intermediate outputs of each step\nare non-trivial to obtain, as in the above example.\nGiven the difficulty of obtaining plans and in-\ntermediate explanations for long documents, one\npotential solution is to delegate this task to smaller\nexecutable modules instead of forcing the LLM to\ncome up with all of them at once. In this work,\nwe introduce PEARL , a framework that combines\nPlanning and Executable Actions for Reasoning\nover Long documents. Each stage of PEARL \u2014\naction mining, plan decomposition, and plan exe-\ncution \u2014 is implemented by applying zero-shot or\nfew-shot prompting to an LLM. The stages (Fig-\nure 1) can concisely be described as follows:\n1.Action mining: An LLM is prompted to come\nup with simple actions that can help solve\nquestions from an input training dataset. Un-\nlike predefined \u201ctoolboxes\u201d in Related work\nOur work builds on recent LLM prompting re-\nsearch and also connects to work on reasoning\nover long documents. Before describing PEARL ,\nwe first survey related papers to contextualize our\nwork within this fast-moving field.\nPrompting Appendix. On the entire QuALITY devset, GPT-4 achieves an accuracy of 84.4%. For the\n1000", " Introduction\nOriginally designed to generate text, scaled-up versions of language models (LMs) such as GPT [ 25,\n26,1,23] and PaLM [ 5] have been shown to be increasingly capable of performing an ever wider\nrange of tasks requiring mathematical, symbolic, commonsense, and knowledge reasoning. It is\nperhaps surprising that underlying all this progress is still the original autoregressive mechanism for\ngenerating text, which makes token-level decisions one by one and in a left-to-right fashion. Is such\na simple mechanism sufficient for a LM to be built toward a general problem solver? If not, what\nproblems would challenge the current paradigm, and what should be alternative mechanisms?\nThe literature on human cognition provides some clues to answer these questions. Research on \u201cdual\nprocess\u201d models suggests that people have two modes in which they engage with decisions \u2013 a fast,\nautomatic, unconscious mode (\u201cSystem 1\u201d) and a slow, deliberate, conscious mode (\u201cSystem 2\u201d)\n[30,31,16,15]. These two modes have previously been connected to a variety of mathematical\nmodels used in machine learning. For example, research on reinforcement learning in humans and\nother animals has explored the circumstances under which they engage in associative \u201cmodel free\u201d\nlearning or more deliberative \u201cmodel based\u201d planning [ 7]. The simple associative token-level choices\nof LMs are also reminiscent of \u201cSystem 1\u201d, and thus might benefit from augmentation by a more\ndeliberate \u201cSystem 2\u201d planning process that (1) maintains and explores diverse alternatives for current\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).arXiv:2305.10601v2  [cs.CL]  3 Dec 2023G\u012e\u0154\u0169\u019c\nj\u0169\u019c\u0154\u0169\u019cG\u012e\u0154\u0169\u019c\nj\u0169\u019c\u0154\u0169\u019c\u02b1\u00ca\u02b2\u02e4Gj\u02b1\u00e6\u02b2\u02e4\u001d\u0135\u00c9G\u012e\u0154\u0169\u019c\n\u02e4j\u0169\u019c\u0154\u0169\u019c\u02b1\u00e7\u02b2\u02e4\u001d\u0135\u00c9\u02c1\u0092\u001d\u029f\u029f\u029f\u029fa\u00ca\u0120\u0135\u0157\u0193\u0164\u0186\u02e4\u017f\u0135\u0164\u00f2G\u012e\u0154\u0169\u019c\n\u02e4j\u0169\u019c\u0154\u0169\u019c\u02b1\u00ed\u02b2\u02e4\u00c9\u0135\u00c9\u02e4\u02b1\u0135\u0169\u0157\u015d\u02b2\u029f\u029f\u029f\u029f\u029f\u029f\u02e4\u02e4\u029d\u02e4\u019b\u010e\u0135\u0169\u0108\u010e\u019c)L[\u0003FRORU\u0003\u000bE\\\u0003<XTLDQ\f0DUN\u0003GLIIHUHQFH\u0003E\\\u0003FRORU\nG\u012e\u0154\u0169\u019c\nj\u0169\u019c\u0154\u0169\u019cG\u012e\u0154\u0169\u019c\nj\u0169\u019c\u0154\u0169\u019cG\u012e\u0154\u0169\u019c\n\u02e4j\u0169\u019c\u0154\u0169\u019c\u02b1\u00e7\u02b2\u02e4\u0092\u00f2\u0126\u0199\u02e4\u001d\u0135\u012e\u015d\u0193\u015d\u0164\u00f2\u012e\u00e7\u0186\u02e4\u0180\u0193\u019c\u010e\u02e4\u001d\u0135\u00c9\u02e4\u02b1\u001d\u0135\u00c9\u02c1\u0092\u001d\u02b2a\u00ca\u0120\u0135\u0157\u0193\u0164\u0186\u02e4\u017f\u0135\u0164\u00f2G\u012e\u0154\u0169\u019c\n\u02e4j\u0169\u019c\u0154\u0169\u019c\u02b1\u00ed\u02b2\u02e4\u00c9\u0157\u00f2\u00f2\u02e4\u0135\u0199\u02e4\u009a\u010e\u0135\u0169\u0108\u010e\u0164\u015d\u02e4\u02b1\u00c9\u0135\u00c9\u02b2\u029f\u029f\u029f\u029f\u029f\u029f\u029f\u029f\u029f\u029f\u02e4\u02e4\u019b\u010e\u0135\u0169\u0108\u010e\u019c\n\u02b1\u00e7\u02b2\u02e4\u001d\u010e\u00ca\u0111\u012e\u02e4\u0135\u0199\u02e4\u009a\u010e\u0135\u0169\u0108\u010e\u019c\u02e4\u0089\u0157\u0135\u012d\u0154\u019c\u0111\u012e\u0108\u02e4\u02b1\u001d\u0135\u00c9\u02b2\u02b1\u00ca\u02b2\u02e4G\u012e\u0154\u0169\u019c\u02c1j\u0169\u019c\u0154\u0169\u019c\u02e4\u0089\u0157\u0135\u012d\u0154\u019c\u0111\u012e\u0108\u02e4\u02b1Gj\u02b2Figure 1: Schematic illustrating various approaches to problem solving with LLMs. Each rectangle\nbox represents a thought , which is a coherent language sequence that serves as an intermediate\nstep toward problem solving. See concrete examples of how thoughts are generated, evaluated, and\nsearched in Figures 2,4,6.\nchoices instead of just picking one, and (2) evaluates its current status and actively looks ahead or\nbacktracks to make more global decisions.\nTo design such a planning process, we return to the origins of artificial intelligence (and cognitive\nscience), drawing inspiration from the planning processes explored by Newell, Shaw, and Simon\nstarting in the 1950s [ 21,22]. Newell and colleagues characterized problem solving [ 21] as search\nthrough a combinatorial problem space, represented as a tree. We thus propose the Tree of Thoughts\n(ToT) framework for general problem solving with language models. As Figure 1 illustrates, while\nexisting methods, and opportunities, 2023.\n[41] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y . Cao. ReAct: Synergizing\nreasoning and acting in language models. arXiv preprint arXiv:2210.03629 , 2022.\n[42] S. Zhang, Z. Chen, Y . Shen, M. Ding, J. B. Tenenbaum, and C. Gan. Planning with large\nlanguage models for code generation. In The Eleventh International Conference on Learning\nRepresentations , 2023. URL https://openreview.net/forum?id=Lr8cOOtYbfL .\n[43] D. Zhou, N. Sch \u00a8arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet,\nQ. Le, et al. Least-to-most prompting enables complex reasoning in large language models.\narXiv preprint arXiv:2205.10625 , 2022.\n[44] X. Zhu, J. Wang, L. Zhang, Y . Zhang, R. Gan, J. Zhang, and Y . Yang. Solving math word\nproblem via cooperative reasoning induced language models. arXiv preprint arXiv:2210.16257 ,\n2022.\n12A Code, Prompts, Trajectories\nAll code is available at https://github.com/princeton-nlp/tree-of-thought-llm .\nAll prompts are", " Introduction 2\n2 Overview of ChatGPT 4\n2.1 OpenAI 4\n2.2 Capabilities 5\n3 Technology behind ChatGPT 6\n3.1 Two core techniques 6\n3.2 Technology path 7\n4 Applications of ChatGPT 10\n4.1 Scientific writing 10\n4.2 Education field 13\n4.3 Medical field 14\n4.4 Other fields 15\n5 Challenges 16\n5.1 Technical limitations 16\n5.2 Misuse cases 17\n5.3 Ethical concerns 18\n5.4 Regulation policy 19\n6 Outlook: Towards AGI 20\n6.1 Technology aspect 20\n6.2 Beyond technology 21\n7 Conclusion 22 References 22\n1 INTRODUCTION\nThe past few years have witnessed the advent of numerous generative AI (AIGC, a.k.a. AI-generated content) tools [ 73,\n135,141], suggesting AI has entered a new era of creating instead of purely understanding content. For a complete\nManuscript submitted to ACMOne Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era 3\nFig. 1. Structure overview of this survey.Manuscript submitted to ACM4 Zhang et al.\nsurvey on generative AI (AIGC), the readers can refer to [ 214]. Among those AIGC tools, ChatGPT, which was released\nin November 2022, has caught unprecedented attention. It attracted numerous users, and the number of active monthly\nusers surpassed 100 million within only two months, breaking the user growth record of other social products [ 118].\nChatGPT was developed by OpenAI, which started as a non-profit research laboratory, with a mission of building\nsafe and beneficial artificial general intelligence (AGI). After announcing GPT-3 in 2020, OpenAI has gradually been\nrecognized as a world-leading AI lab. Very recently, It has released GPT-4, which can be seen as one small step for\ngenerative AI, but one giant step for AGI.\nDue to its impressive capabilities on language understanding, numerous news articles provide extensive coverage\nand introduction to the reaction mechanism, which is critical for the topic. The content of this article\ncontains abundant useful information, but specific details are absent and certain errors exist. In addition, ChatGPT can\nhelp prepare manuscripts, but the generated abstract.\nIt is challenging for readers to grasp the progress of ChatGPT without a complete survey. Our comprehensive review\nprovides a first look into ChatGPT in a timely manner.\nSince the topic of this survey can be regarded as a commercial tool, we first present a background of ChatGPT and the corresponding organization, i.e., OpenAI, which aims to build\nartificial general intelligence (AGI). It is expected that AGI can solve human-level problems and beyond, on the premise\nof building safe, trustworthy systems that are beneficial to our society.\n2.1 OpenAI\nOpenAI is a research laboratory made up of a group of researchers and engineers committed to the commission of\nbuilding safe and beneficial AGI [ 50]. It was founded on December 11, 2015, by a group of high-profile tech executives,\nincluding Tesla CEO Elon Musk, SpaceX President Gwynne Shotwell, LinkedIn co-founder Reid Hoffman, and venture\ncapitalists Peter Thiel and Sam Altman [ 78]. In this subsection, we will talk about the early days of OpenAI, how it\nbecame a for-profit organization, and its contributions to the field of AI.\nIn the beginning, OpenAI is a non-profit organization [ 24], and its research is centered on deep learning and rein-\nforcement learning, natural language processing, robotics, and more. The company quickly established a reputation for\nits cutting-edge research after publishing several influential papers [ 123] and developing some of the", " Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the Seventh Conference on Natural\nLanguage Learning at HLT-NAACL 2003 , pages 142\u2013\n147.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models.\nSomin Wadhwa, Silvio Amir, and Byron Wallace. 2023.\nRevisiting relation extraction in the era of large lan-\nguage models. In Proceedings of the 61st Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 15566\u2013\n15589, Toronto, Canada. Association for Computa-\ntional Linguistics.\nXiao Wang, Wei Zhou, Can Zu, Han Xia, Tianze Chen,\nYuan Zhang, Rui Zheng, Junjie Ye, Qi Zhang, Tao\nGui, Jihua Kang, J. Yang, Siyuan Li, and Chunsai\nDu. 2023a. Instructuie: Multi-task instruction tuning\nfor unified information extraction. ArXiv preprint ,\nabs/2304.08085.\nXiaozhi Wang, Ziqi Wang, Xu Han, Wangyi Jiang, Rong\nHan, Zhiyuan Liu, Juanzi Li, Peng Li, Yankai Lin,\nand Jie Zhou. 2020. MA VEN: A Massive General\nDomain Event Detection Dataset. In Proceedings\nof the 2020 Conference on Empirical methods. After : The\nreranked prediction using LLMs. Rationales : LLM-generated Explanations.\nSentences (entity/event) Before After Rationales\nNamed Entity Recognition\nAccording to it, King Eleusis and\nCothonea (Cyntinia), parents of Trip-\ntolemus, are visited by Demeter, who\nrears their son, feeding him divine milk\nby day and placing him into the fire at\nnight, which makes Triptolemus grow\nfaster than mortal children normally do.person-other\n\u2717other-god\n\u2713According to the context, Triptolemus is a\nfigure in Greek mythology, the son of King\nEleusis and Cothonea (Cyntinia). He was a\ndemigod who was sent by Demeter to teach\nmankind the art of agriculture. So Triptole-\nmus is a god in some legend/religious story.\nRelation Extraction\nSurvivors include his wife, Sandra; four\nsons, Jeff, James, Douglas and Harris; a\ndaughter, Leslie; his mother, Sally; and\ntwo brothers, Guy and Paul.None\n\u2717per:children\n\u2713The sentence states \u2019Survivors include his\nwife, Sandra; four sons, Jeff, James, Douglas\nand Harris; a daughter, Leslie; his mother,\nSally; and two brothers, Guy and Paul.\u2019 This\nindicates \u2019his\u2019 is the father of Jeff, James,\nDouglas and Harris, and the husband of San-\ndra. So his is the parent of Jeff.\nEliza Samudio, Bruno \u2019s ex-girlfriend\nand his 4-month-old baby boy\u2019s mother,\ndisappeared from her hometown of Belo\nHorizonte, Minas Gerais.per:cities_of\n_residence \u2717per:states_of\n_residence \u2713The sentence states that \u2019Eliza Samudio,\nBruno\u2019s ex-girlfriend and his 4-month-old\nbaby boy\u2019s mother, disappeared from her\nhometown of Belo Horizonte, Minas Gerais.\u2019\nThis indicates that Eliza Samudio is from the\ncity of Belo Horizonte, which is located in\nthe state of Minas Gerais. So Eliza Samudio\nlives in the state or province Minas Gerais.\nEvent Detection\nWe have fought every institution, every\nlaw firm ... it \u2019s cost us a fortune but now\nwe \u2019re going on a massive expansion.Conflict.Attack\n\u2717None\n\u2713In the given sentence, the word fought is\nused to describe the action of the speaker\nfighting against various institutions and law\nfirms. This does not involve any physical\nviolence or court proceedings, so the word\nfought does not trigger any known event.Table 16: Demo examples used in FewNERD dataset. We color the entity in blue.\nInstruct : Read following sentences and identify what is the entity type of 392 quoted by <t>.\nSentence : Powell v. Texas , <t> 392 <t> U.S. 514 ( 1968 ) , was a United States Supreme Court case that ruled that a\nTexas statute criminalizing public intoxication did not violate the Eighth", " Introduction\nInrecentyears,Transformer-typemodelarchitecturehas\ndominated the world of natural language processing (NLP)\n[1, 2, 3]. Before that, recurrent neural networks, such as\nLSTMs, were used to solve a wide variety of existing NLP\nproblems[4, 5, 6]. The recurrent neural models could not\ncapturedistantdependenciesindatasequences,forexample,\ninformation occurring at the text beginning or end [7].\nIn addition, their architecture did not allow for efficient\nparallelization of training and inference processes [8]. The\nanswer to the aforementioned problems was precisely the\nTransformer architecture, presented initially as an encoder-\ndecoder model for sequence-to-sequence tasks [1]. Such a\n\u2217Corresponding author\njan.kocon@pwr.edu.pl (J. Koco\u0144); kazienko@pwr.edu.pl (P.\nKazienko)\nhttps://kazienko.eu (P. Kazienko)\nORCID(s):0000-0002-7665-6896 (J. Koco\u0144); 0000-0001-5868-356X (P.\nKazienko)\n1equal contributionmodelhadtheadvantageofcapturingdistantrelationshipsin\nthetextusinganattentionalmechanismandeasilyparalleliz-\ning calculations with matrix operations. As more powerful\nGPUs and TPUs were developed [9], it became possible\nto create models with more and more parameters, resulting\nin models that began to achieve human performance for an\nincreasing number of tasks [10, 11, 12]. However, the most\nsignificant quality improvement was achieved by unsuper-\nvised pre-training language models on a huge number of\ntextsacquiredfromtheInternet.InBERT-basedmodels,the\npre-training tasks involved foreseeing masked tokens and\nsubsequent sentences [13]. In autoregressive models, the\npre-training task has been changed to predicting the next\nword, which masks the attentional layer so that the model\nforecasts future values based only on past values [14].\nGenerative Pre-Training (GPT [15]) was one of the first\nautoregressive generative models based on the Transformer\narchitecture. From the original Transformer, only the de-\ncoderstackisusedbyGPT,andbi-directionalself-attention\nisconvertedtouni-directional.Suchamodelcanperformall\nJ.Koco\u0144 et al.: Preprint submitted to Elsevier Page 1 of 46arXiv:2302.10724v4  [cs.CL]  9 Jun 2023ChatGPT: Jack of all trades, master of none\nFigure 1: Will a user charmed by the first impression created\nby ChatGPT abandon proven state-of-the-art solutions? We\npresent the results\nTab. 8 contains entropy values calculated for the available\ntest or dev set and for its subset (if applicable) used by us\nforprompting.Asmalldifferenceinthesetwovaluesproves\na similar distribution of classes in both sets, thus, a good\nstratification of sampling.\nTab. 9 includes additional measures for the evaluated\ntasks, calculated by us and taken from the literature.\nB. Example prompts\nThis section contains sample chat records for all evalu-\natedtasks.The Casenumberistheidentifieroftheexample\nin the external collection used for evaluation for the Task,\navailable in the project GitHub repository11in file:\nChatGPT Evaluation v2.0.xlsx .\nIn addition, we have provided the expected response.\nB.1. Aggression\nChat 6. Task: Aggression. Case 20.\nPrompt\nWhich one of the attributes: \"aggressive\", \"non-aggressive\" de-\nscribes a given text? Write your answer in the form of a Python\nlist containing the appropriate attribute. Text: Almonds!!!! For\nfun .\nChatGPT answer\n[\"non-aggressive\"]\nExpected answer\n[\"non-aggressive\"]\n11https://github.com/CLARIN-PL/chatgpt-evaluation-01-2023\nJ.Koco\u0144 et al.: Preprint submitted to Elsevier Page 27 of 46ChatGPT: Jack of all trades, master of none\nTable 8\nEntropies of data: a measure of class balance. The greater,\nthe more balanced the data. A marginal difference in entropy\nof output real values for test or dev set (column #Testin Tab.\n1) and within the set used by us (column #Usedin Tab. 1)\ndemonstrates a good stratification of the usedset selection.\nID Task name Entropy test Entropy used\n1 Aggression 0.42 0.39\n2 AggressionPer 0.49 0.50\n3 CoLa 0.62 0.62\n4 ColBERT 0.69 0.69\n5 Sarcasm 0.69 0.69\n6 Spam 0.39 0.39\n7 WordContext 0.69 0.69\n8 TextEntail 0.69 0.69\n9 WNLI 0.69 0.69\n10 SQuAD - -\n11 MathQA - -\n12 ClarinEmo 2.19 2.19\n13 GoEmo 2.77 2.77\n14 GoEmoPer0 2.77 2.98\n15 GoEmoPer1 2.77 2.98\n16 GoEmoPer2 2.77 2.98\n17 GoEmoPer3 2.77 2.98\n18 Unhealthy 1.65 1.60\n19 UnhealthyPer 1.65 1.60\n20 PolEmo 1.30 1.30\n21 TweetEmoji 2.73 2.71\n22 TweetSent 1.03 1.03\n23 TweetStance 0.95 0.97\n24 ReAding - -\n25 WSD 7.74 7.74\nChat 7. Task: Aggression.", " Introduction\nIn recent years, with the creation of computational databases, such as the Materials\nProject (MP) [1] and the Open Quantum Materials Database (OQMD) [2], and then\nexperimental data repositories such as NIMS MDR ( http://mdr.nims.go.jp ) [3],\nfocus has been steadily shifting towards a data-driven design of materials, which is\noften called Materials Informatics (MI). Such an approach is expected to accelerate\nthe exploration of functional materials because it is not limited to the intuition or\nexperience of very little genius researchers. In this new paradigm, the e\u000ecient use of\ndata to guide experiments with active\nand random sampling [16] with ratios of negative examples of 0.1, 0.25, 0.5 and 1.0\ndid not provide stable evidence suggesting scoring improvements when testing against\n5the holdout set.\nEvaluation The best methods to extract and link relevant information\nin superconductors research; 2) a pipeline allowing large-scale document processing;\nand 3) a visualisation interface for rapid data exploration, which includes PDF docu-\nment information enrichment.\nWe made SuperCon2, a database with 40324 records of superconductors materi-\nals and properties, including the applied pressure and the T cmeasurement method.\nSuperCon2is available in text format at https://github.com/lfoppiano/supercon .\nIn the future, we plan to improve our tools by 1) extracting more properties, such\nas crystal structure type, space groups type, and lattice structure; 2) training super-\nvised models for the \\Linking step\"; and 3) extending the interface to support data\ncorrection toward e\u000ecient curation. We con\frmed the good generalisation ability of\nthe Scibert architecture for the entity extraction task. Although we hope to obtain\nbetter Abstract 80.32 61\nParagraph 75.2 623\nFigure captions 59.28 140\nUnknown 57.14 21\nMicro avg. 72.60 847\nMicro avg. (excl. \fgures) 75.24 707\nMicro avg. (excl. unknown sections) 73.00 603\nMicro avg. (excl. \fgures and unknown sections) 79.14 657\nFigure 10. Error type distribution in the E2EE of the 500-papers dataset.\nFigure 11. Example of a superconductors research PDF document [40] enriched with extracted annotations.\nMaterials information (class, formula) and properties (T c) are summarised in the information box when the\nusers click on the highlighted annotated entity in the text.\n17Table 8. Summary and description of the SuperCon2schema. \\Internal information\" is technical infor-\nmation not accessible to the users.\nField name Description Examples\nMaterial information\nRaw\nmaterialThe material or sample as it appears in the text\nName Canonical name of a materialPCCO, PCO, Metal diboride,\nhydrogen, carbon\nFormulaMaterial expressed as chemical formula. This\nincludes also formulas with stochiometric variablesPr1:869Ce0:131CuO 4\u0000\u000e,\nMgB 2,La2\u0000xSrxCuO 4\nDopingDoping ratio and doping materials\nthat might be adjoined to the materialOverdoped, underdopded,\noptimally doped,\nbulk, pure, 1% Zn, Zn\n(from Zn-doped XYZ)\nShape The shape of the material or the sampleSingle crystal, polycrystal,\nwire, powder, \flm\nVariables Variables that can be substituted in the formula x = 0, RE=Ln,St\nClassMaterial classi\fcation according\nto the domain-experts taxonomycuprates, oxides, and alloys\nFabricationAll the information that does not\nbelong to any of the previous tagsIntercalated,\nsynthesized by MBE method,\nelectron-doped, hole-doped\nSubstrate Substrate material described in the raw materialPCCO \flms onto\nPr2CuO 4(PCO )=SrTiO 3\nProperties\nCritical\nTemperatureSuperconducting critical temperature\nApplied\nPressurePressure applied when measuring\nthe superconducting critical temperature\nMeasurement\nMethodMethod for measurement of the\nsuperconducting critical temperatureMagnetic susceptibility,\nspeci\fc heat, calculation,\nprediction, resistivity\nDocument bibliographic information\nSection The main body section of the paper Header, body, annex\nSubsection The secondary segmentation area of the paperParagraph, table caption,\n\fgure caption, title, results are averaged over 5 runs. Support (Supp) indicates the number of labels in the training\ndata. Values in bold indicate the highest score. P: precision,", "experiments of the research; R.X., H.Z., A.F., P.K. and F.K. performed the DFT calculations; \nP.T.S ., A.K.S. , and Z.R. performed the thermodynamic calculations; Z.R ., Y.W. and P.T. wrote \nmost parts of the ma nuscript;  P.T. produced the final figures; All authors discussed themethods of temporal differences. Machine Learning  3, 9-\n44 (1988).  \n45. F. Wilcoxon, in Breakthroughs in statistics . (Springer, 1992), pp. 196 -202. \n46. R. Lowry, Concepts and applications of inferential statistics. Concepts and Applications of \nInferential Statistics ,  (2014).  \n47. A. V. Ruban, S. Simak, P. A. Korzhavyi, H. L. Skriver, Screened Coulomb interactions in metallic \nalloys. II. Screening beyond the single -site and atomic -sphere approximations. Physical Review B  \n66, 024202 (2002).  \n48. J. P. Perdew, K. Burke, M. Ernzerhof, Generalized gradient approximation made simple. Physical \nReview Letters  77, 3865 (1996).  \n49. B. Gyorffy, Coherent -potential approximation for a nonoverlapping -muffin -tin-potential model of \nrandom substitutional alloys. Physi cal Review B  5, 2382 (1972).  19 \n 50. J. Staunton, B. Gyorffy, A. Pindor, G. Stocks, H. Winter, The \u201cdisordered local moment\u201d picture \nof itinerant magnetism at finite temperatures. Journal of Magnetism and Magnetic Materials  45, \n15-22 (1984).  \n51. I. A. Abrikosov, A. E. Kissavos, F. Liot, B. Alling, S. Simak, O. Peil, A. V. Ruban, Competition \nbetween magnetic structures in the Fe rich fcc FeNi alloys. Physical Review B  76, 014434 (2007).  \n52. F. Birch, Finite elastic strain of cubic crystals. Physica l Review  71, 809 (1947).  \n53. A. G\u00e9ron, Hands -on machine learning with Scikit -Learn, Keras, and TensorFlow: Concepts, tools, \nand techniques to build intelligent systems .  (O'Reilly Media, 2019).  \n54. J.-O. Andersson, T. Helander, L. H\u00f6glund, P. Shi, B. Sundm an, Thermo -Calc & DICTRA, \ncomputational tools for materials science. Calphad  26, 273 -312 (2002).  \n55. H. Saito, Physics and applications of invar alloys .  (Maruzen, 1978).  \n56. G. Pupke, \u00fcber eine Anisotropie der thermischen Ausdehnung bei Eisen -Niekel -Legie rungen. \nZeitschrift f\u00fcr Physikalische Chemie  207, 91-110 (1957).results and \ncommented on the manuscript.  \nCompeting interests:  Authors declare that they have no competing interests.  \nData and materials availability:  Requests for data and materials should be sent to the \ncorresponding  author s. \nSupplementary materials:background of this latter point  \nis explained in Supplemental Fig. S1 and Table S1 . \n \n \n \n 4Results. Advances in Neural \nInformation Processing Systems 27 (NIPS 2 014),  (2014).  \n25. I. Goodfellow, J. Pouget -Abadie, M. Mirza, B. Xu, D. Warde -Farley, S. Ozair, A. Courville, Y. \nBengio, Generative adversarial nets. Advances in Neural Information Processing Systems 27 (NIPS \n2014) ,  (2014).  \n26. W. K. Hastings, Monte Carlo  samplingdiscussion  \nThe active learning framework includes three main steps: latent space sampling for  \ncandidate generation, physics -informed screening and experimental feedback (as shown in Fig. 1). \nThe first step towards novel HEA discovery is to generate promising composition candidates. \nConsidering a large number of possible composition", " Introduction  \nRecent developments in transformer -based deep \nneural language  models such as BERT  (Devlin et al., 2018 ), XLNet  (Yang et al., 2019 ), and GPT -3 \n(Brown et al., 2020 ) have led to  new breakthroughs \nin many Natural Language Processing (NLP) tasks.  \nThese high -performance NLP models take the \nadvantage of task -agnostic pretraining on massive \ntext corpora to encode lexical, syntactic, and \nsemantic  regularities of the  language. Task -specific \nfine-tuning is then used to master task-specific \nlanguage capabilities such as named entity \nrecognition, coreference resolution, relation \nextraction, semantic similarity estimation, etc.  \nRecent research has demonstrated that scaling up \nan autoregressive language model, i.e. GPT -3 with \n175 billion parameters, can lead to achieving near \nstate-of-the-art performance in task -specific few -\nshot learning , without the need for  fine-tuning on \nthe whole training data  (Brown et al., 2020 ). \nHowever, it is not yet known whether GPT -3 can \nperform well on domain -specific texts, e.g. \nbiomedical text, in few -shot settings.  \nDomain -specific language models such as \nBioBERT  (Lee et al., 2019 ), SciBERT  (Beltagy et \nal., 2019 ), and Clinical  XLNet  (Huang et al., 2020 ) \nwere pretrained on very large  biome dical and \nclinical text corpora; they achieved state -of-the-art Background , \nObjective , Method , Result , or Conclusion  \nIn this paper, we investigated few-shot transfer \nlearning abilities of two large language models, i. e. \nGPT-3 and BioBERT, on several BioNLP tasks. As \nthe experimental abstract . \nPubMed -QA (Jin et al., 2019 ) is a question \nanswering dataset containing more than 1K \nresearch questions extracted from PubMed \nabstracts, along with short and long answers.  \nThe evaluation measur e for MedNLI and \nPubMed -QA was  Accuracy . BioText and \n                                                           \n1 https://beta.openai.com/  PubMed -RCT were  evaluated using Micro -F1. \nPearson Correlation  was used to measure the \nperfor mance on MedSTS.  \nAll the Appendix B. Hyperparameter values of \nBioBERT   \n \nTable 11 presents the hyperparameter values of the \nmodel BioBERT -Large  that was fine -tuned on \nthe whole training set.  Table 12 presents the \nhyperparameter values of the model BioBERT -\nLarge  utilized in the few -shot Related work  \nPrevious NLP models mostly relied on learning \ntask-specific representations  or utilizing universal \nword embeddings in task -specific neural network \narchitectures (Mikolov et al., 2013 ; Peters et al., \n2018 ). Advances in task -agnostic pretraining then \nled to  large language models providing  task-\nagnostic representations that could be fine -tuned to \nenable transfer learning to specific tasks  (Devlin et \nal., 2018 ; Yang et al., 2019 ).", " Introduction\nThe vast majority of scienti\fc knowledge exists as published articles [1{4]. These\npublications are presented mainly as text, which is challenging to be used as a machine-\nreadable structure. Meanwhile, as a part of the text and data mining (TDM) discipline,\ncomputer-assisted information collection from the literature has become a supportive\nasset for scienti\fc research [5]. In the past decades, new TDM processes were developed\nfor several natural science disciplines to achieve automatic document processing such\nas information retrieval, entity extraction, and clustering. TDM has been applied in\nCorresponding authors: FOPPIANO.Luca@nims.go.jp, ISHII.Masashi@nims.go.jparXiv:2101.02455v3  [cond-mat.supr-con]  15 Apr 2021biology for identifying interactions between agents (e.g. bacteria, viruses, genes, and\nproteins) [6{8] to support the research on serious diseases including cancer [9]. In\nchemistry, it was used for the disambiguation of chemical compounds names, synthesis\nextraction, and retrieval [10]. In both domains, the application of TDM was based\non manually curated datasets (corpora) that functioned as infrastructures. Examples\nare the BioCreative IV CHEMDNER corpus [11] in chemistry, and Genia [12] and\nGENETAG [13,14] in biology. Such datasets are crucial for developing, training, and\nevaluating TDM systems.\nIn comparison, such resources in the materials science domain are rather limited.\nReported cases include NaDev [15] on nanocrystal devices research, a corpus for ex-\ntracting synthesis recipes [16], and ChemDataExtractor [17] which focuses only on\nchemical entities. In the superconductors domain, we could identify MagDb [18] fo-\ncusing on magnetic materials with limited information categories. Another project is\nSC-CoMIcs [19]. SuperMat is di\u000berent from SC-CoMIcs based on the following reasons:\n(a) it provides full papers instead of abstracts which contain more detailed information\nabout the research on superconducting materials, and (b) it contains linked entities.\nTo address this shortage of infrastructure, experimental data is extracted manu-\nally [20], or ab-initio calculations are used [21] but they might not accurately describe\nthe real system. Several challenges still hinder the data-driven exploration of materi-\nals (also called Materials Informatics (MI)), namely: the lack of data standard, infant\nstage of the data-driven culture, a wide variety of con\ricting stakeholders, and miss-\ning incentives for researchers to contribute to large collaborative initiatives [22]. To\nbridge these gaps, it is necessary to create infrastructural resources to support TDM\nprocesses in materials science through the automatic construction of databases for\nmaterials and their properties. Such application can minimise the need for humans\nto read the new papers and extract the key information therein. Equally importantly,\nit enables scientists to focus and leverage computing power and human resources to\n\fnd deeper relationships between super\fcially unrelated information. Other applica-\ntions include providing semantically enriched search engines that accept \fne-grain\nqueries [23] to reduce the time needed to access speci\fc information. These processes\ncannot be established without essential resources such as dictionaries, lexicons, and\ndatasets.\nResearch on superconducting materials has been growing rapidly towards both fun-\ndamental science as well as practical applications. Superconductors display many in-\ntriguing phenomena including zero-resistivity, the ability to host a high magnetic \feld,\nquantisation of the magnetic \rux, and vortex pinning. Current applications of super-\nconductors include medical instruments, high-speed trains, quantum computers, and\nthe Linear Hadron Collider (LHC) [24{26]. However, discovering a new superconduc-\ntor is a challenging task [27]. For example, in a previous work [28] out of \u00181000\nstudied materials, only 3% were found to be superconducting. The National Institute\nfor Materials Science", "background recorded in a separate\nrun. In both pressure cells glycerin served as pressure\ntransmitting medium. The pressure inside the DAC was\ndetermined by a standard ruby \ruorescence method at\nroom temperature before and after each cooling down\n(for details on the pressure homogeneity see the Sup-\nplemental Material [21]). X-ray di\u000braction under pres-\nsure was conducted on ground crystalline powder from\nthe same batch of CeFeAsO single crystals. The sam-\nples were loaded into a membrane-driven DAC. Helium\nserved as pressure-transmitting medium. A helium gas-\n\row cryostat enabled controlled low-temperature mea-\nsurements. Sm-doped SrB 4O7was used as pressure cali-\nbrant. No pressure gradient could be detected inside the\npressure chamber. The data were collected on ID9A at\nthe ESRF, Grenoble, using a wavelength of 41.44 pm.\nThe recorded two-dimensional di\u000braction patterns were\nintegrated by means of the computer program FIT2D.\nAt ambient pressure, CeFeAsO displays distinctarXiv:2011.05665v1  [cond-mat.supr-con]  11 Nov 20202\n11 01 000.40.81.20\n01 002 000246T\nSCTFeN\n\u03c1ab/\u03c1300K \n  p (GPa) \n0.1 \n3.3 \n4.0 \n4.4 \n4.9 \n5.5 \n7.4C eFeAsO T\n(K)  T\nCeN\n \n \u03c1ab (m\u03a9cm)T\n (K)         p (GPa) \n1.3  4.4 \n3.3  5.5 \n4.0 0T - solid7\nT - dashed\nFIG. 1. Temperature dependence of the in-plane resistivity\n\u001aab(T) normalized by its value at 300 K of a CeFeAsO single\ncrystal for selected hydrostatic pressures up to 7.4 GPa on a\nlogarithmic temperature scale. Black, blue, and red arrows\nmark the SDW ordering of the iron moments, the AFM or-\ndering of the localized Ce moments, and the superconducting\ntransition temperature, respectively. Inset: \u001aab(T) in 0 and\n7 T magnetic \feld, Hkc, for selected pressure.\nanomalies in the in-plane electrical resistivity \u001aab(T) in-\ndicating the SDW ordering of the iron moments and the\nAFM ordering of the localized Ce moments (see Fig. 1).\nThe SDW ordering is closely connected to a structural\ntransition from a tetragonal to an orthorhombic phase.\nThe magnetic transition temperatures TFe\nNandTCe\nNcor-\nrespond to maxima and the structural transition at T0\nto a shoulder in d \u001aab(T)=dT. We follow the same anal-\nysis as in Ref. 7. The derivatives for selected pressures\nare shown in Fig. 2a (further details can be found in the\nSupplemental Material [21]). We obtain T0= 149 K and\nTFe\nN= 142 K, and TCe\nN= 3:7 K at ambient pressure. T0\nfrom resistivity agrees well with our structural data. For\ndetails on the analysis of the structural data see the Sup-\nplemental Material [21]. We note that all values are in\ngood agreement with reports in literature [5, 7].\nThe normalized in-plane electrical resistivity\n\u001aab(T)=\u001aab(300K) of single crystalline CeFeAsO for\nselected hydrostatic pressures is depicted in Fig. 1.\nApplication of hydrostatic pressure has a strong e\u000bect\non the shape of the resistivity curves in CeFeAsO. The\npronounced maximum shifts to lower temperature and\nthen disappears completely upon increasing pressure. At\n\frst, up to about 2 GPa TFe\nNandT0exhibit only a weak\npressure dependence. With further increasing pressure\nboth transition temperatures start to decrease with a\nmuch larger rate but, simultaneously, also the splitting\nbetween them increases signi\fcantly. At p= 4:0 GPa,\n\u001aab(T) still exhibits a pronounced narrow maximum re-\nlated to the structural transition and the SDW ordering,atT0\u001949 K andTFe\nN\u001930 K, respectively, before the\nsignatures of both transitions are abruptly lost above\n4.0 GPa. The sharp suppression of the Fe-SDW ordering\nhas been seen in M\u007f ossbauer data too [9].\nIn contrast to the Fe-SDW ordering at high temper-\natures", " Introduction\nIn this publication, we present Sentence-BERT\n(SBERT), a modi\ufb01cation of the BERT network us-\ning siamese and triplet networks that is able to\nderive semantically meaningful sentence embed-\ndings2. This enables BERT to be used for certain\nnew tasks, which up-to-now were not applicable\nfor BERT. These tasks include large-scale seman-\n1Code available: https://github.com/UKPLab/\nsentence-transformers\n2With semantically meaningful we mean that semantically\nsimilar sentences are close in vector space.tic similarity comparison, clustering, and informa-\ntion retrieval via semantic search.\nBERT set new state-of-the-art performance on\nvarious sentence classi\ufb01cation and sentence-pair\nregression tasks. BERT uses a cross-encoder: Two\nsentences are passed to the transformer network\nand the target value is predicted. However, this\nsetup is unsuitable for various pair regression tasks\ndue to too many possible combinations. Finding\nin a collection of n= 10 000 sentences the pair\nwith the highest similarity requires with BERT\nn\u0001(n\u00001)=2 = 49 995 000 inference computations.\nOn a modern V100 GPU, this requires about 65\nhours. Similar, \ufb01nding which of the over 40 mil-\nlion existent questions of Quora is the most similar\nfor a new question could be modeled as a pair-wise\ncomparison with BERT, however, answering a sin-\ngle query would require over 50 hours.\nA common method to address clustering and se-\nmantic search is to map each sentence to a vec-\ntor space such that semantically similar sentences\nare close. Researchers have started to input indi-\nvidual sentences into BERT and to derive \ufb01xed-\nsize sentence embeddings. The most commonly\nused approach is to average the BERT output layer\n(known as BERT embeddings) or by using the out-\nput of the \ufb01rst token (the [CLS] token). As we\nwill show, this common practice yields rather bad\nsentence embeddings, often worse than averaging\nGloVe embeddings (Pennington et al., 2014).\nTo alleviate this issue, we developed SBERT.\nThe siamese network architecture enables that\n\ufb01xed-sized vectors for input sentences can be de-\nrived. Using a similarity measure like cosine-\nsimilarity or Manhatten / Euclidean distance, se-\nmantically similar sentences can be found. These\nsimilarity measures can be performed extremely\nef\ufb01cient on modern hardware, allowing SBERT\nto be used for semantic similarity search as well\nas for clustering. The complexity for \ufb01nding thearXiv:1908.10084v1  [cs.CL]  27 Aug 2019most similar sentence pair in a collection of 10,000\nsentences is reduced from 65 hours with BERT to\nthe computation of 10,000 sentence embeddings\n(~5 seconds with SBERT) and computing cosine-\nsimilarity (~0.01 seconds). By using optimized\nindex structures, \ufb01nding the most similar Quora\nquestion can be reduced from 50 hours to a few\nmilliseconds (Johnson et al., 2017).\nWe \ufb01ne-tune SBERT on NLI data, which cre-\nates sentence embeddings that signi\ufb01cantly out-\nperform other state-of-the-art sentence embedding Related Work\nWe \ufb01rst introduce BERT, then, we discuss state-\nof-the-art sentence embedding results\nare depicted in Table 7.\nModel CPU GPU\nAvg. GloVe embeddings 6469 -\nInferSent 137 1876\nUniversal Sentence Encoder 67 1318\nSBERT-base 44 1378\nSBERT-base - smart batching 83 2042\nTable 7: Computation speed (sentences per second) of\nsentence embedding experiments.\nSBERT is computationally ef\ufb01cient. On a GPU,\nit is about 9% faster than InferSent and about 55%\nfaster than Universal Sentence Encoder. SBERT\ncan be used for tasks which are computationally\nnot feasible to be modeled with BERT. For exam-\nple, clustering of 10,000 sentences with hierarchi-\ncal clustering requires with BERT about 65 hours,\nas around 50 Million sentence combinations must\nbe computed. With SBERT, we were able to re-\nduce the effort to about 5 seconds. Methods in Natural Language Process-\ning, pages 1631\u20131642,", " Introduction\nto the bio-entity recognition task at jnlpba. In NLP-\nBA/BioNLP .\nTim Dettmers. 2019. TPUs vs\nGPUs for Transformers (BERT).\nhttp://timdettmers.com/2018/10/17/tpus-vs-gpus- \nAccessed: 2019-02-22.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL-HLT .\nRezarta Islamaj Dogan, Robert Leaman, and Zhiyong\nLu. 2014. NCBI disease corpus: A resource for dis-\nease name recognition and concept normalization.\nJournal of biomedical informatics , 47:1\u201310.\nTimothy Dozat and Christopher D. Manning. 2017.\nDeep biaf\ufb01ne attention for neural dependency pars-\ning. ICLR .\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind\nTafjord, Pradeep Dasigi, Nelson F. Liu, Matthew\nPeters, Michael Schmitz, and Luke S. Zettlemoyer.\n2017. Allennlp: A deep semantic natural language\nprocessing platform. In arXiv:1803.07640 .\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model \ufb01ne-tuning for text classi\ufb01cation. In\nACL.\nKexin Huang, Jaan Altosaar, and Rajesh Ranganath.\n2019. Clinicalbert: Modeling clinical notes and pre-\ndicting hospital readmission. arXiv:1904.05342 .\nAlistair E. W. Johnson, Tom J. Pollard aand Lu Shen,\nLiwei H. Lehman, Mengling Feng, Moham-\nmad Ghassemi, Benjamin Moody, Peter Szolovits,\nLeo Anthony Celi, , and Roger G. Mark. 2016.Mimic-iii, a freely accessible critical care database.\nInScienti\ufb01c Data, 3:160035 .\nDavid Jurgens, Srijan Kumar, Raine Hoover, Daniel A.\nMcFarland, and Daniel Jurafsky. 2018. Measuring\nthe evolution of a scienti\ufb01c \ufb01eld through citation\nframes. TACL , 06:391\u2013406.\nJin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and\nJun\u2019ichi Tsujii. 2003. GENIA corpus - a semanti-\ncally annotated corpus for bio-textmining. Bioinfor-\nmatics , 19:i180i182.\nSu Kim, David Mart\u00b4 \u0131nez, Lawrence Cavedon, and Lars\nYencken. 2011. Automatic classi\ufb01cation of sen-\ntences to support evidence based medicine. In BMC\nBioinformatics .\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. ICLR .\nJens Kringelum, Sonny Kim Kj\u00e6rulff, S\u00f8ren Brunak,\nOle Lund, Tudor I. Oprea, and Olivier Taboureau.\n2016. ChemProt-3.0: a global chemical biology dis-\neases mapping. In Database .\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So,\nand Jaewoo Kang. 2019. BioBERT: a pre-trained\nbiomedical language representation model for\nbiomedical text mining. In arXiv:1901.08746 .\nJiao Li, Yueping Sun, Robin J. Johnson, Daniela Sci-\naky, Chih-Hsuan Wei, Robert Leaman, Allan Peter\nDavis, Carolyn J. Mattingly, Thomas C. Wiegers,\nand Zhiyong Lu. 2016. BioCreative V CDR task\ncorpus: a resource for chemical disease relation\nextraction. Database : the journal of biological\ndatabases and curation .\nYi Luan, Luheng He, Mari Ostendorf, and Hannaneh\nHajishirzi. 2018. Multi-task identi\ufb01cation of enti-\nties, relations, and coreference for scienti\ufb01c knowl-\nedge graph construction. In EMNLP .\nMark Neumann, Daniel King, Iz Beltagy, and Waleed\nAmmar. 2019. ScispaCy: Fast and robust mod-\nels for biomedical natural language processing. In\narXiv:1902.07669 .\nDat Quoc Nguyen and Karin M. Verspoor. 2019. From\npos tagging to dependency parsing for biomedical\nevent extraction. BMC Bioinformatics , 20:1\u201313.\nBenjamin Nye, Junyi Jessy Li, Roma Patel, Yinfei\nYang, Iain James Marshall, Ani Nenkova, and By-\nron C. Wallace. 2018. A corpus with multi-level an-\nnotations of patients, interventions and outcomes to\nsupport language processing for medical literature.\nInACL.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer,\nMatt Gardner, Christopher Clark, Kenton Lee, and\nLuke S. Zettlemoyer. 2018. Deep contextualized\nword representations. In NAACL-HLT .Alec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nNils Reimers and Iryna Gurevych. 2017. Optimal hy-\nperparameters for deep lstm-networks for sequence\nlabeling tasks. In EMNLP .\nArnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Dar-\nrin Eide, Bo-June Paul Hsu, and Kuansan Wang.\n2015. An overview of microsoft academic service\n(MAS) and applications. In WWW .\nAshish Vaswani, Noam Shazeer, Niki", " Introduction  \nIt has been a dream for human beings to realize a room temperature superconductor since the discovery \nof superconductivity by Heike Kammerling Onnes  in 1911 [1].  Although the fundamental theoretical  \nframework for superconductivity was established in 1957 by BCS theory , there exists no theory which can \nquantitatively predict the c ritical temperature  (Tc) even now [2].  Thus, explor ing for high Tc \nsuperconductors is like a voyage in a big ocean without a preci se compass , i.e., researchers have to  move \nahead believing their materials sense  and/or intuition  referring to what the theorists say.  In this sense, \nexploration for  high Tc superconductors is a truly challenging subject in condensed matte r research.  Not an \ninsignificant number of people  say that this is typical \u201call or nothing\u201d research. \nIt is a historical fact that materials leading to breakthroughs have been discovered in most cases by \nchance amidst concentrated research  efforts undertaken with  a unique but flexible view.  This is particularly  \ntrue for the exploration of new superconductors. The group of o ne of the present authors (HH)  group \ndiscovered LaFePO in 2006 [3] and LaFeAsO 1-xFx in 2008 [4] through LaNiPO ( Tc =3 K) [5] in 2007 in the \ncourse of explor ing magnetic semiconductors, which started from his extensive research of  transparent \np-type semiconductors LaCuO Ch (where Ch=S and Se) with the same crystal struct ure as the so -called \n1111-type layered compounds . P-type conduction in LaCuO Ch originates from the mobile holes at the top of \nthe valence band which is composed of Ch p orbital s and Cu 3d orbitals  [6]. It was his  idea for approach to  \nnovel magnetic semiconductors to utilize strong d-p interactions in  LaCuOCh by replacing nonmagnetic Cu+ \nion with a magnetic 3d transition metal cation with a +2 charge state . In order to keep electro -neutrality upon \nthis substitution, Ch-2 is required to be replaced by Pn3- [7]. This is the reason why his group started to \nexamine electronic and magnetic properties of La TMOPn (where TM=3d transition metal, Pn=P and As).  \nThis effort result ed in the discovery of IBScs  through the concentrated effort for finding high performance \np-type transparent semiconductors  which is a branch of his research home ground, transparent oxide \nsemiconductors [8]. \nThe discovery of iron -based superconductors (IBSc) was accepted with surprise by the condensed matter \ncommunity because iron with a large magnetic moment was widely believed to be most harmful to the \nemergence  of superconductivity.  Extensive research in these materials started globally, especially in China \n[7]. As a result, the discovery of IBSc was chosen as a br eakthrough of the year 2008 by Science Magazine  \nand the paper ( J. Am. Chem. Soc. 2007) reporting Tc =26 K in LaFeAsO 1-xFx became the most cited report \namong all the papers published in 2008.  \nIn early 2009, the Japanese Government announced the launch"], "bleu": 0.16449807388243548, "rouge_l": 0.31968810916179335, "gpt_metric_score": 0.8, "bert_score": 0.2962396740913391}
{"paper_key": "nach0: multimodal natural and chemical languages foundation model", "current_5q": "### [Question 1] - What is the problem?\nHow can we improve the performance of language models in generating and predicting molecular structures and properties using specialized tokenization and training strategies?\n\n### [Question 2] - Why is it interesting and important?\nSolving this problem has significant implications for both the research community and practical applications in drug discovery and materials science. By enhancing the capabilities of language models to understand and generate molecular data, we can facilitate the design of novel compounds, optimize chemical reactions, and predict molecular properties more accurately. This advancement could lead to breakthroughs in pharmaceuticals, sustainable materials, and chemical engineering, ultimately driving innovation and efficiency in these fields.\n\n### [Question 3] - Why is it hard?\nThe challenges in this area stem from the complexity of molecular structures and the limitations of existing language models that are primarily trained on natural language data. Naive approaches may fail due to the unique characteristics of chemical data, such as the need for specialized tokenization that accurately represents molecular structures. Additionally, the high dimensionality and variability of chemical data introduce technical obstacles, including the need for robust evaluation metrics that can capture the validity, novelty, and diversity of generated molecules.\n\n### [Question 4] - Why hasn't it been solved before?\nPrevious research has often focused on either natural language processing or molecular generation in isolation, leading to a lack of integrated approaches that leverage the strengths of both fields. Existing solutions may not have adequately addressed the specific requirements of molecular data, such as the need for specialized tokenization and training strategies. Our approach differs by utilizing a comprehensive dataset that includes both molecular and natural language tasks, allowing for a more nuanced understanding of chemical data and improving upon prior work by integrating these modalities effectively.\n\n### [Question 5] - What are the key components of my approach and results?\nOur proposed methodology involves using the MOSES and Mol-Instructions datasets to train language models with specialized tokenization for molecular data. We will evaluate the models using established metrics such as uniqueness, validity, novelty, and internal diversity, as well as binary classification and regression tasks from the MoleculeNet benchmark. The expected outcomes include improved performance in generating valid and diverse molecular structures, enhanced predictive capabilities for molecular properties, and a better understanding of the relationship between molecular characteristics and language model training strategies.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can we develop a hybrid generative model for molecular design that integrates watermarking techniques directly into molecular structures to enable embedding unique identifiers for traceability and accountability?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem is critical for the research community as it addresses ethical concerns surrounding intellectual property and misuse in drug discovery. The integration of watermarking techniques into molecular structures not only enhances the traceability of AI-generated compounds, but also fosters trust and reproducibility in cheminformatics research. By ensuring a clear lineage of modifications and origins of molecules, this approach could significantly impact future research directions, encouraging greater collaboration and innovation while minimizing the risks associated with the misuse of generative models. Furthermore, as the field of drug discovery increasingly relies on AI-driven methodologies, establishing accountability through provenance tracking will pave the way for more responsible and ethical practices in the industry.\n\n[Question 3]: Why is it hard?  \nAddressing this problem is inherently challenging due to the complexities involved in molecular design and the integration of watermarking techniques. Naive approaches may fail because traditional watermarking methods are often not suitable for the intricate and variable nature of molecular structures, which can lead to alterations that compromise the integrity of the watermark. Additionally, the technical obstacles include ensuring that the watermarking process does not adversely affect the molecular properties or functionality, as well as the need for advanced algorithms capable of operating within the constraints of graph neural networks and quantum-enhanced frameworks. The theoretical complexities of maintaining a balance between molecular diversity and the embedding of identifiers further complicate the development of a robust model.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research in molecular design and cheminformatics has often overlooked the intersection of watermarking and molecular structure, leading to a significant gap in the literature. Existing solutions typically focus on either molecular generation or intellectual property concerns, but rarely integrate both aspects. Barriers to solving this problem include a lack of interdisciplinary collaboration between chemists, computer scientists, and ethicists, as well as insufficient understanding of how watermarking can be effectively applied within the context of molecular structures. My approach differs from prior work by explicitly combining graph neural networks with watermarking techniques in a hybrid model, thereby providing a novel solution that directly addresses both the provenance tracking and ethical accountability of AI-generated compounds.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing a hybrid generative model that utilizes graph neural networks (GNNs) to represent molecular structures, integrating watermarking techniques to embed unique identifiers within these structures. The dataset will comprise a diverse set of molecular compounds with established provenance to train the model effectively. The evaluation metrics will include the fidelity of the generated molecules (i.e., their chemical validity and properties) as well as the robustness and invisibility of the embedded watermarks. Expected outcomes include a set of AI-generated molecular compounds that not only meet desired functional criteria but also maintain clear identifiers for traceability, thus advancing the field of cheminformatics by enhancing reproducibility and accountability in AI-driven drug discovery.", "referenced_intros": [" Introduction Programme (2021A-156-G),\nCCF-Baidu Open Fund, and Information Technology Center and State Key Lab of CAD&CG,\nZhejiang University.\nREPRODUCIBILITY STATEMENT\nAll data, code, and model weights can be found on GitHub1and Hugging Face2,3,4,5. For a detailed\ndescription of the dataset construction process, please refer to REFERENCES\nSharegpt, April 2023. URL .https://sharegpt.com/ .\nYuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, and Andriy Mulyar.\nGpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo.\nGitHub , 2023.\nMichael Ashburner, Catherine A Ball, Judith A Blake, David Botstein, Heather Butler, J Michael\nCherry, Allan P Davis, Kara Dolinski, Selina S Dwight, Janan T Eppig, et al. Gene ontology: tool\nfor the unification of biology. Nature genetics , 25(1):25\u201329, 2000.\nSatanjeev Banerjee and Alon Lavie. METEOR: an automatic metric for MT evaluation with improved\ncorrelation with human judgments. In Jade Goldstein, Alon Lavie, Chin-Yew Lin, and Clare R. V oss\n(eds.), Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine\nTranslation and/or Summarization@ACL 2005, Ann Arbor, Michigan, USA, June 29, 2005 , pp.\n65\u201372. Association for Computational Linguistics, 2005. URL https://aclanthology.org/\nW05-0909/ .\n1GitHub: https://github.com/zjunlp/Mol-Instructions\n2Datasets: https://huggingface.co/datasets/zjunlp/Mol-Instructions\n3Molecule model: https://huggingface.co/zjunlp/llama-molinst-molecule-7b\n4Protein model: https://huggingface.co/zjunlp/llama-molinst-protein-7b\n5Biotext model: https://huggingface.co/zjunlp/llama-molinst-biotext-7b\n10Published as a conference paper at ICLR 2024\nDaniil A. Boiko, Robert MacKnight, and Gabe Gomes. Emergent autonomous scientific research\ncapabilities of large language models. CoRR , abs/2304.05332, 2023. doi: 10.48550/ARXIV .2304.\n05332. URL https://doi.org/10.48550/arXiv.2304.05332 .\nAndres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller. Chemcrow: Augmenting\nlarge-language models with chemistry tools. arXiv preprint arXiv:2304.05376 , 2023.\nChristiam Camacho, George Coulouris, Vahram Avagyan, Ning Ma, Jason S. Papadopoulos,\nKevin Bealer, and Thomas L. Madden. BLAST+: architecture and applications. BMC Bioin-\nform. , 10:421, 2009. doi: 10.1186/1471-2105-10-421. URL https://doi.org/10.1186/\n1471-2105-10-421 .\nHe Cao, Zijing Liu, Xingyu Lu, Yuan Yao, and Yu Li. Instructmol: Multi-modal integration for\nbuilding a versatile and reliable molecular assistant in drug discovery. CoRR , abs/2311.16208, 2023.\ndoi: 10.48550/ARXIV .2311.16208. URL https://doi.org/10.48550/arXiv.2311.16208 .\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pond \u00b4e de Oliveira Pinto, Jared\nKaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri,\nGretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\nScott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian,\nClemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios\nChantzis, Elizabeth Barnes, Ariel Herbert-V oss, William Hebgen Guss, Alex Nichol, Alex Paino,\nNikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders,\nChristopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa,\nAlec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob\nMcGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating\nlarge language models trained on code. CoRR , abs/2107.03374, 2021. URL https://arxiv.\norg/abs/2107.03374 .\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\nSiyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\nAn open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:\n//lmsys.org/blog/2023-03-30-vicuna/ .\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm", " Introduction\nRecent advances in large language models (LLM) have dramatically improved the performance of various natural\nlanguage processing (NLP) tasks, creating new opportunities for automating tasks traditionally performed by humans.\nOpenAI\u2019s ChatGPT, for instance, has demonstrated its ability to perform as well as humans on MBA exams at the\nWharton Business School [1], showcasing its competitiveness with human knowledge and its potential to assist pro-\nfessionals [2, 3]. In the healthcare industry, LLMs hold tremendous potential for transforming the \ufb01eld by extracting\nvaluable insights from unstructured data, such as electronic health records and digital medical data. By identifying\ncrucial data points for population health management, clinical trials, and drug discovery, LLMs can help facilitate the\ndevelopment of new drugs and treatment plans. As the development and integration of LLMs in healthcare continue,\nprofessionals can expect signi\ufb01cant improvements in patient outcomes and overall healthcare delivery.\nLLMs possess a distinct advantage in their emergent abilities in Zero-Shot Learning, enabling them to learn and adapt\nto new tasks through prompt instructions, even if they have never encountered them before [4, 5]. For example,\nby incorporating the instruction prompt \u201dTranslate these sentences from [source Language] to [Target Language]:\u201d,\nChatGPT can compete favorably with commercial translation products, such as Google Translate [6]. While LLM\u2019s\nability to conduct many NLP tasks makes it a valuable tool for users, it also raises signi\ufb01cant privacy issues. One\nmajor concern is that sensitive information may be inadvertently revealed during the process. This is particularly true\nin healthcare, where the privacy and con\ufb01dentiality of patient information are of utmost importance. Therefore, it is\nimportant to ensure that there is a mechanism to ensure robust privacy protections that prevent unauthorized access\nto sensitive information. In addition, reliability and usability are important issues that must be addressed when using\nLLM. Users must be able to rely on the accuracy and consistency of the model, which requires ongoing re\ufb01ning,\ntesting, and evaluation to ensure that the system is functioning as intended and meeting the needs of users. In this\npaper, we will focus on improving the reliability of LLM for zero-shot tasks while mitigating the privacy risk.\nIn order to assess the zero-shot performance of current LLM models for healthcare tasks, we conducted experiments. This raises the possibility of ChatGPT inadvertently leaking\ninformation from the original dataset. To address this issue, we utilized the sentence transformer to obtain embeddingsfor both the original and synthetic data, and then projected them using T-SNE. The resulting distribution of sentences,\nas illustrated in Figure 4, revealed distinct patterns between the synthetic and original data, indicating that ChatGPT did\nnot simply memorize and reproduce the dataset. This distribution shift can also explain the observed performance gap\nbetween models \ufb01ne-tuned on synthetic versus original data. Our future work aims to explore conclusion, our innovative\ntraining framework enables the training of a local model with superior performance compared to using LLMs alone.\nIt also mitigates potential privacy concerns and reduces the dependence on costly and time-consuming data collection\nand labeling.\n2 Preliminaries\nBiomedical Named Entity Recognition. Biomedical NER involves identifying and categorizing medical entities,\nsuch as diseases, symptoms, drugs, etc., in a medical text. NER uses an IOB (Inside, Outside, Begin) tagging scheme,\nwhere each word is assigned a tag indicating whether it is", " introduction to medicinal organic chemistry .\nLippincott Williams & Wilkins, 2003.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Ves Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence pre-training for\nnatural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461 ,\n2019.\n13Mike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida Wang, and Luke\nZettlemoyer. Pre-training via paraphrasing, 2020.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\napproach. arXiv preprint arXiv:1907.11692 , 2019.\nDaniel Mark Lowe. Extraction of chemical structures and reactions from the literature . PhD thesis,\nUniversity of Cambridge, 2012.\nInes Filipa Martins, Ana L Teixeira, Luis Pinheiro, and Andre O Falcao. A bayesian approach to in\nsilico blood-brain barrier penetration modeling. Journal of chemical information and modeling , 52\n(6):1686\u20131697, 2012.\nHarry L Morgan. The generation of a unique machine description for chemical structures-a technique\ndeveloped at chemical abstracts service. Journal of chemical documentation , 5(2):107\u2013113, 1965.\nMyle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier,\nand Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. arXiv preprint\narXiv:1904.01038 , 2019.\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style,\nhigh-performance deep learning library. Advances in neural information processing systems , 32:\n8026\u20138037, 2019.\nAlja Plo \u02c7snik, Marjan Vra \u02c7cko, and Marija Sollner Dolenc. Mutagenic and carcinogenic structural\nalerts and their mechanisms of action. Arhiv za higijenu rada i toksikologiju , 67(3):169\u2013182, 2016.\nKristina Preuer, Philipp Renz, Thomas Unterthiner, Sepp Hochreiter, and Gunter Klambauer. Fr \u00b4echet\nchemnet distance: a metric for generative models for molecules in drug discovery. Journal of\nchemical information and modeling , 58(9):1736\u20131741, 2018.\nAlec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever.\nRobust speech recognition via large-scale weak supervision.\nAlec Radford, Rafal Jozefowicz, and Ilya Sutskever. Learning to generate reviews and discovering\nsentiment. arXiv preprint arXiv:1704.01444 , 2017.\nDavid Rogers and Mathew Hahn. Extended-connectivity \ufb01ngerprints. Journal of chemical information\nand modeling , 50(5):742\u2013754, 2010.\nYu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang.\nSelf-supervised graph transformer on large-scale molecular data. Advances in Neural Information\nProcessing Systems , 33:12559\u201312571, 2020.\nJerret Ross, Brian Belgodere, Vijil Chenthamarakshan, Inkit Padhi, Youssef Mroueh, and Payel Das.\nDo large scale molecular language representations capture important structural information? arXiv\npreprint arXiv:2106.09553 , 2021.\nPhilippe Schwaller, Theophile Gaudin, David Lanyi, Costas Bekas, and Teodoro Laino. \u201cfound in\ntranslation\u201d: predicting outcomes of complex organic chemistry reactions using neural sequence-\nto-sequence models. Chemical science , 9(28):6091\u20136098, 2018.\nPhilippe Schwaller, Teodoro Laino, Th \u00b4eophile Gaudin, Peter Bolgar, Christopher A Hunter, Costas\nBekas, and Alpha A Lee. Molecular transformer: a model for uncertainty-calibrated chemical\nreaction prediction. ACS central science , 5(9):1572\u20131583, 2019.\nVignesh Ram Somnath, Charlotte Bunne, Connor W Coley, Andreas Krause, and Regina Barzilay.\nLearning graph models for template-free retrosynthesis. arXiv preprint arXiv:2006.07038 , 2020.\nHannes St \u00a8ark, Dominique Beaini, Gabriele Corso, Prudencio Tossou, Christian Dallago, Stephan\nG\u00a8unnemann, and Pietro Li `o. 3d infomax improves gnns for molecular property prediction. In\nInternational Conference on Machine Learning , pp. 20479\u201320502. PMLR, 2022.\n14Ruoxi Sun, Hanjun Dai, Li Li, Steven Kearnes, and Bo Dai. Energy-based view of retrosynthesis.\narXiv preprint arXiv:2007.13437 , 2020.\nMukund Sundararajan, Ankur", " Introduction\nIn this lecture, we will consider the simplest quantum mechanical method for approximating the ground\nstate energy of a many-electron system. The Hartree-Fock method is also known as the self-consistent\n\ufb01eld method, and is an approximation to the exact many-electron wavefunction known as the Slater\ndeterminant. The Slater determinant is an anti-symmetric product of one-electron functions (orbitals),\nand is the simplest wavefunction that satis\ufb01es the Pauli exclusion principle. The Hartree-Fock method is\naniterativemethodfor\ufb01ndingthebestpossiblesetoforbitalsthatminimizestheenergyoftheSlaterdeterminant.\nIn the Hartree-Fock method, the electron-electron repulsion energy is approximated as a classical Coulomb\ninteraction between two charge distributions, one for each electron. This approximation neglects the correlation\nbetweentheelectrons,whichisanimportantpartofthetotalelectron-electronrepulsionenergy. Theresulting\nmethod is a mean-\ufb01eld theory in which each electron moves in an average \ufb01eld due to the other electrons. The\nresulting equations are known as the Hartree-Fock equations, and can be solved self-consistently to obtain\nthe best possible orbitals. The resulting ground state energy is known as the Hartree-Fock energy, and the\nHartree-Fock wavefunction is a single Slater determinant built from these orbitals.\nTheHartree-FockmethodisalsoknownastheSelf-ConsistentField(SCF)method,becausetheequationsforthe\norbitals are solved self-consistently. The Hartree-Fock equations can be derived variationally by minimizing the\nenergyoftheSlaterdeterminantwithrespecttotheorbitals. Theresultingorbitalsareknownasthecanonical\nHartree-Fock orbitals, and are not necessarily localized in space. The Hartree-Fock energy is invariant to unitary\ntransformations of the canonical orbitals, and therefore there are an in\ufb01nite number of orbitals that yield the\nsame Hartree-Fock energy. These orbitals are known as non-canonical orbitals, and can be localized in space by\nappropriate unitary transformations.\nSingle-Electron Approximation\nIn this section, we will review the basics of quantum mechanics for a single particle. This is useful for\nunderstanding the single-electron approximation used in Hartree-Fock theory.\nThe time-independent Schr\u00f6dinger equation for a particle in a potential V(r)is given by:\n\u0016H (r) =E (r)\nwhere the Hamiltonian is\n\u0016H=\u0000~\n2mr2+V(r)\nThe time-independent Schr\u00f6dinger equation is an eigenvalue equation for the Hamiltonian operator, where\nthe eigenvalues are the allowed energies of the system. The Hamiltonian is a sum of two operators, one\ncorresponding to the kinetic energy of the particle, and the other corresponding to the potential energy. The\npotential energy operator acts on the wavefunction by multiplying by the potential V(r). The kinetic energy\noperatoristheLaplacianoperator r2,whichisthedivergenceofthegradientofthewavefunction. TheLaplacian\noperator is a second derivative with respect to the position of the particle.\n(cont)\n57Galactica: A Large Language Model for Science\nA.8.8 I\u2019m sorry Frank, I think you missed it\nIfAIisgoingtohelpusexploretheuniverse,weneedittohavebasicchessabilitiestoalleviateboredom-\ngiven the impossibility of faster-than-light travel.\nThe BIG-bench task suite ofSrivastava et al. (2022) has abenchmark for checkmate-in-one detection. For fun,\nwe made a dataset of 20,000 public chess games and converted them to ASCII chess using the python-chess\nlibrary7. Weincluded19,426gamesinourpre-trainingcorpus(restforvalidation). Wealsorecordedthe\nELO ratings of players. An example document looks like below:\n# A Chess Game\n## Player Information\nWhite ELO: 2286\nBlack ELO: 2586\n## The Game Begins\nr n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\nP P P P P P P P\nR N B Q K B N R\nWhite (ELO: 2286) plays e4\nr n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . P . . .\n. . . . . . . .\nP P", " Introduction\nText mining and knowledge discovery from biomedical\nliterature play important roles in drug discovery, clinical\ntherapy, pathology research, etc. Typical tasks include\nrecognizing named entities in the articles, mining the\ninteraction between drugs and proteins/diseases/other drugs,\nanswering questions given reference text, generating abstracts\nfor given phrases/words, etc. People have accumulated large\namounts of literature in the previous studies. For example,\nPubMed1, one of the most popular biomedical search engines,\ncovers more than 30 Marticles and the number still rapidly\nincreases every day as new discoveries are continuously coming\nout. Therefore, automatically mining the knowledge from\nliterature becomes an urgent demand.\nPre-training models have demonstrated their powerful\ncapability in natural language processing (NLP). On the GLUE\nbenchmark, a widely used benchmark for natural language\nunderstanding, pre-training based methods in natural language processing. arXiv preprintarXiv:2107.13586 , 2021.\n49. Xiang Lisa Li and Percy Liang. Pre\fx-tuning: Optimizing\ncontinuous prompts for generation. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers) , pages 4582{4597, Online,\nAugust 2021. Association for Computational Linguistics.\n50. Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan,\nSam Gross, Nathan Ng, David Grangier, and Michael Auli.\nfairseq: A fast, extensible toolkit for sequence modeling. In\nProceedings of NAACL-HLT 2019: Demonstrations , 2019.\n51. Diederik P Kingma and Jimmy Ba. Adam: A method for\nstochastic optimization. In ICLR (Poster) , 2015.\n52. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pierric\nCistac, Tim Rault, R\u0013 emi Louf, Morgan Funtowicz, Joe\nDavison, Sam Shleifer, Patrick von Platen, Clara Ma,\nYacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao,\nSylvain Gugger, Mariama Drame, Quentin Lhoest, and\nAlexander M. Rush. Transformers: State-of-the-art\nnatural language processing. In Proceedings of the 2020\nConference on Empirical abstract, containing\na question, a reference context, a long answer, and a\nyes/no/maybe label which is the answer to the question. We\nuse the original train/validation/test split with 450, 50 and 500\nrespectively, noted as PQA-L in [16] for evaluation. We also use\nthe additional dataset noted as PQA-A and PQA-U in [16] for\n\fne-tuning. We use the continuous embedding with length=9\nas the soft prompt. We format the data into source sequence\nand target sequence as described before. We apply techniques\nsuch as two-stage \fne-tuning [16] and noisy labels to improve\nthe performance. We measure and compare the classi\fcation\naccuracy of the reasoning required setting described in [16].\nFrom the Experiments\nIn this section, we pre-train our BioGPT and evaluate\nit on the following four biomedical NLP tasks across six\ndatasets: end-to-end relation extraction on BC5CDR [13], KD-\nDTI [14] and DDI [15], question answering on PubMedQA [16],\ndocument classi\fcation on HOC [17], and text generation\non self-created dataset. We use fairseq [50] as our code\nbase for implementation. We adopt the GPT-2 medium model\ncon\fguration as our backbone model con\fguration. We perform\nBPE to learn to tokenize the corpus and construct the\nvocabulary instead of using the learned vocabulary from GPT-\n2 due to the domain gap between the biomedical domain and\nthe general domain.\nFor pre-training, we pre-train BioGPT on 8 NVIDIA V100\nGPUs for 200 ksteps, with 1024 tokens per GPU and 64\naccumulated steps (i.e., the \fnal batch size is 1024 \u00028\u000264 =\n524288 tokens). We use Adam [51] as the optimizer with a peak\nlearning rate of 2\u000210\u00004and 20000 warm-up steps. The learning\nrate follows an inverse square root decay schedule after reaching\nthe", " introduction to methodol-\nogy and encoding rules. Journal of Chemical Information and Computer Sciences , 28(1):31\u201336,\n1988.\nRobin Winter, Floriane Montanari, Frank No \u00b4e, and Djork-Arn \u00b4e Clevert. Learning continuous and\ndata-driven molecular descriptors by translating equivalent chemical representations. Chemi-\ncal Science , 10:1692\u20131701, 2019. doi: 10.1039/C8SC04175J. URL http://dx.doi.org/10.1039/\nC8SC04175J.\nYutong Xie, Chence Shi, Hao Zhou, Yuwei Yang, Weinan Zhang, Yong Yu, and Lei Li. Mars:\nMarkov molecular sampling for multi-objective drug discovery. In ICLR , 2021.\nKevin Yang, Tianjun Zhang, Chris Cummins, Brandon Cui, Benoit Steiner, Linnan Wang, Joseph E.\nGonzalez, Dan Klein, and Yuandong Tian. Learning space partitions for path planning. In\nA. Beygelzimer, Y . Dauphin, P. Liang, and J. Wortman Vaughan (eds.), NeurIPS , 2021.\nJiaxuan You, Bowen Liu, Rex Ying, Vijay Pande, and Jure Leskovec. Graph convolutional policy\nnetwork for goal-directed molecular graph generation. In NeurIPS , NIPS\u201918, pp. 6412\u20136422, Red\nHook, NY , USA, 2018. Curran Associates Inc.\nChengxi Zang and Fei Wang. Mo\ufb02ow: An invertible \ufb02ow model for generating molecular graphs.\nProceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining , Aug 2020. doi: 10.1145/3394486.3403104. URL http://dx.doi.org/10.1145/\n3394486.3403104.\nZhenpeng Zhou, Steven Kearnes, Li Li, Richard N Zare, and Patrick Riley. Optimization of\nmolecules via deep reinforcement learning. Sci Rep , 9(1):10752, July 2019.\n12Published at the MLDD workshop, ICLR 2023\nA S UPPLEMENTARY MATERIAL\nA.1 F ORMAL MODEL DEFINITIONS\nHere we discuss the relation between auto-encoder (AE), V AE, and MIM. We explicitly show that\nMIM and V AE extends AE with a regularization term that promotes certain properties of the latent\nspace, which are different for the two models.\nA.1.1 D ENOISING AUTO-ENCODER\nMolMIM builds upon denoising auto-encoders (Goodfellow et al., 2016) where a corrupted input is\nencoded by an encoder into a latent code. The latent code is then used to reconstruct the original\ninput by the decoder. More formally, we can describe auto-encoders (AE) in terms of encoding\ndistributionq\u0012(zjx)and decoding distribution p\u0012(xjz), where we opt here for a probabilistic view.\nA deterministic encoder can be viewed as a Dirac delta function around the predicted mean. Given\nthe encoder and decoder, the denoising AE (DAE) loss, per observation xcan be expressed as,\nLAE(\u0012) =Ez\u0018q\u0012(zj~x)[logp\u0012(xjz)] (4)\nwherex2VNfor vocabularyV,~xis some kind of corruption or augmentation of x,z2RH,His\nthe hidden dimensions, and \u0012is the union of all learnable parameters. Here we include the identity\nfunction in the set of augmentations, where ~x\u0011x.\nA.1.2 B OTTLENECK ARCHITECTURES\nA precursor to MolMIM is our baseline BART (Lewis et al., 2020) model referred to as MegaMol-\nBART, with data augmentation identical to Chemformer (Irwin et al., 2022). BART is a transformer-\nbased seq2seq model that learns a variable-size hidden representation H=j~xj\u0002D. That is, the\ndimension of the hidden representation is equal to the number of tokens in the encoder input times\nthe embedding dimension. This makes sampling from the model especially challenging since the\nmolecule length has to be sampled as well. In contrast, learning a \ufb01xed-size representation as typi-\ncally done in denoising auto-encoders, where all molecules are mapped into the same space, makes\nsampling easier.\nThus, we propose to replace MegaMolBART\u2019s Transformer encoder with a \ufb01xed-sized output Per-\nceiver encoder (Jaegle et al., 2021). Perceiver is an attention-based architecture that utilizes cross-\nattention to project a variable input onto a \ufb01xed-size output. More formally, z2RHfor a pre-\nde\ufb01ned dimension H.\nA.1.3 L", " Introduction to the bio-entity recognition task at JNLPBA. In Pro-\nceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its\nApplications (NLPBA/BioNLP) , pages 73\u201378, Geneva, Switzerland, August 28th and 29th 2004. COLING.\n[56] Gamal Crichton, Sampo Pyysalo, Billy Chiu, and Anna Korhonen. A neural network multi-task learning\napproach to biomedical named entity recognition. BMC bioinformatics , 18(1):1\u201314, 2017.\n[57] Cl\u00e9ment Dalloux. Datasets \u2013 cl\u00e9ment dalloux, 2020.\n[58] Dina Demner-Fushman, Sonya Shooshan, Laritza Rodriguez, Alan Aronson, Francois Lang, Willie\nRogers, Kirk Roberts, and Joseph Tonning. A dataset of 200 structured product labels annotated for\nadverse drug reactions. Scienti\ufb01c Data , 5:180001, 01 2018.\n[59] Jay DeYoung, Eric Lehman, Benjamin Nye, Iain Marshall, and Byron C. Wallace. Evidence inference 2.0:\nMore data, better models. In Proceedings of the 19th SIGBioMed Workshop on Biomedical Language\nProcessing , pages 123\u2013132, Online, July 2020. Association for Computational Linguistics.\n[60] J Ding, D Berleant, D Nettleton, and E Wurtele. Mining MEDLINE: abstracts, sentences, or phrases?\nPac Symp Biocomput , pages 326\u2013337, 2002.\n[61] Rezarta Islamaj Dogan, Robert Leaman, and Zhiyong Lu. Ncbi disease corpus: A resource for disease\nname recognition and concept normalization. Journal of biomedical informatics , 47:1\u201310, 2014.\n[62] Inc. Elucidata. Geokhoj v1. https://github.com/ElucidataInc/GEOKhoj-datasets/tree/\nmain/geokhoj_v1 , 2020.\n[63] Erik Faessler, Luise Modersohn, Christina Lohr, and Udo Hahn. ProGene - a large-scale, high-quality\nprotein-gene annotated benchmark corpus. In Proceedings of the 12th Language Resources and Evaluation\nConference , pages 4585\u20134596, Marseille, France, May 2020. European Language Resources Association.\n[64] Katrin Fundel, Robert K\u00fcffner, and Ralf Zimmer. Relex\u2013relation extraction using dependency parse trees.\nBioinformatics , 23(3):365\u2013371, 2007.\n[65] Laura I Furlong, Holger Dach, Martin Hofmann-Apitius, and Ferran Sanz. Osirisv1.2: a named entity\nrecognition system for sequence variants of genes in biomedical literature. BMC Bioinformatics , 9:84,\n2008.\n[66] Luis Gasco, Eul\u00e0lia Farr\u00e9, Antonio Miranda-Escalada, Salvador Lima, and Martin Krallinger. DisTEMIST\ncorpus: detection and normalization of disease mentions in spanish clinical cases, April 2022. Funded by\nthe Plan de Impulso de las Tecnolog\u00edas del Lenguaje (Plan TL).\n[67] Luis Gasco, Anastasios Nentidis, Anastasia Krithara, Darryl Estrada-Zavala, Renato Toshiyuki Murasaki,\nElena Primo-Pe\u00f1a, Cristina Bojo Canales, Georgios Paliouras, Martin Krallinger, et al. Overview of\nbioasq 2021-mesinesp track. evaluation of advance hierarchical classi\ufb01cation techniques for scienti\ufb01c\nliterature, patents and clinical trials. CEUR Workshop Proceedings, 2021.\n[68] Martin Gerner, Goran Nenadic, and Casey M Bergman. Linnaeus: a species name identi\ufb01cation system\nfor biomedical literature. BMC bioinformatics , 11(1):1\u201317, 2010.\n[69] Aitor Gonzalez-Agirre, Montserrat Marimon, Ander Intxaurrondo, Obdulia Rabal, Marta Villegas, and\nMartin Krallinger. Pharmaconer: Pharmacological substances, compounds and proteins named entity\nrecognition track. In Proceedings of The 5th Workshop on BioNLP Open Shared Tasks , pages 1\u201310, Hong\nKong, China, November 2019. Association for Computational Linguistics.\n63[70] Natalia Grabar, Vincent Claveau, and Cl\u2019ement Dalloux. CAS: French corpus with clinical cases. In\nProceedings of the Ninth International Workshop on Health Text Mining and Information Analysis , pages\n122\u2013128, Brussels, Belgium, October 2018. Association for Computational Linguistics.\n[71] Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann,\nJianfeng Gao, and Hoifung Poon. Domain-speci\ufb01c language model pretraining for biomedical natural\nlanguage processing. ACM Trans. Comput. Heal. , 3(1):2:1\u20132:23, 2022.\n[72] Harsha Gurulingappa, Roman Klinger, Martin Hofmann-Apitius, and Juliane Fluck. An empirical\nevaluation of resources for the identi\ufb01cation of diseases and adverse effects in biomedical literature. In\nLREC Workshop on Building and Evaluating", " Introduction\nScaling up the size of language models has been key ingredients of recent revolutions in natural\nlanguage processing (NLP) [Vaswani et al., 2017, Devlin et al., 2019, Raffel et al., 2020, Brown et al.,\n2020, Thoppilan et al., 2022, Rae et al., 2021, Chowdhery et al., 2022]. The success of large language\nmodels (LLMs) is often attributed to (in-context) few-shot or zero-shot learning. It can solve various\ntasks by simply conditioning the models on a few examples (few-shot) or instructions describing the\ntask (zero-shot). The method of conditioning the language model is called \u201cprompting\u201d [Liu et al.,\n2021b], and designing prompts either manually [Schick and Sch\u00fctze, 2021, Reynolds and McDonell,\n2021] or automatically [Gao et al., 2021, Shin et al., 2020] has become a hot topic in NLP.\n\u0003Work done while at The University of Tokyo.\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).arXiv:2205.11916v4  [cs.CL]  29 Jan 2023(c) Zero-shot \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA: The answer (arabic numerals) is  \n(Output) 8 X(d) Zero-shot-CoT (Ours) \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA: Let\u2019s think step by step.  \n(Output) There are 16 balls in total. Half of the balls are golf  \nballs. That means that there are 8 golf balls. Half of the golf balls  \nare blue. That means that there are 4 blue golf balls. \u2713Q: Roger has 5 tennis balls. He buys 2 more cans of tennis \nballs. Each can has 3 tennis balls. How many tennis balls does \nhe have now? \nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 \ntennis balls. 5 + 6 = 11. The answer is 11. \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA:\n(Output) The juggler can juggle 16 balls. Half of the balls are golf  \nballs. So there are 16 / 2 = 8 golf balls. Half of the golf balls are  \nblue. So there are 8 / 2 = 4 blue golf balls. The answer is 4. \u2713(b) Few-shot-CoT (a) Few-shot \nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis \nballs. Each can has 3 tennis balls. How many tennis balls does \nhe have now? \nA: The answer is 11. \nQ: A juggler can juggle 16 balls. Half of the balls are golf balls, \nand half of the golf balls are blue. How many blue golf balls are \nthere? \nA:\n(Output) The answer is 8. XFigure 1: Example inputs and outputs of GPT-3 with (a) standard Few-shot ([Brown et al., 2020]), (b)\nFew-shot-CoT ([Wei et al., 2022]), (c) standard Zero-shot, and (d) ours (Zero-shot-CoT). Similar to\nFew-shot-CoT, Zero-shot-CoT facilitates multi-step reasoning (blue text) and reach correct answer\nwhere standard prompting fails. Unlike Few-shot-CoT using step-by-step reasoning examples", " Introduction\nImagine a future where a doctor can write a few\nsentences describing a specialized drug for treating\na patient and then receive the exact structure of\nthe desired drug. Although this seems like science\n\ufb01ction now, with progress in integrating natural\nlanguage and molecules, it might well be possi-\nble in the future. Historically, drug creation has\ncommonly been done by humans who design and\nbuild individual molecules. In fact, bringing a new\ndrug to market can cost over a billion dollars and\ntake over ten years (Gaudelet et al., 2021). Re-\ncently, there has been considerable interest in us-\ning new deep learning tools to facilitate in silico\ndrug design\u2013 a \ufb01eld often called cheminformatics\n(Rifaioglu et al., 2018). Yet, many of these experi-\nments still focus on molecules and their low-level\n* indicates equal contributions.\n1All resources are publicly available at github.com/blender-\nnlp/MolT5\nThe molecule isaneighteen -membered homodetic cyclic peptide\nwhich isisolated from Oscillatoria sp.and exhibits antimalarial\nactivity against theW2chloroquine -resistant strain ofthemalarial\nparasite, Plasmodium falciparum .Ithasarole asametabolite andan\nantimalarial .Itisahomodetic cyclic peptide, amember of1,3-\noxazoles, amember of1,3-thiazoles andamacrocycle .Target PredictionFigure 1: An example output from our model for the\nmolecule generation task. The left is the ground truth,\nand the right is a molecule generated from the given\nnatural language caption.\nproperties such as logP (the octanol-water parti-\ntion coef\ufb01cient) (Bagal et al., 2021). In the future,\nwe foresee a need for a higher-level control over\nmolecule design, which can easily be facilitated by\nnatural language.\nIn this work, we pursue an ambitious goal of\ntranslating between molecules and language by\nproposing two new tasks: molecule captioning\nand text-guided de novo molecule generation. In\nmolecule captioning, we take a molecule (e.g., as\na SMILES string) and generate a caption that de-\nscribes it (Figure 2). In text-guided molecule gener-\nation, the task is to create a molecule that matches\na given natural language description (Figure 1).\nThese new tasks would help to accelerate research\nin multiple scienti\ufb01c domains by enabling chem-\nistry domain experts to generate new molecules\nand better understand them using natural language.\nWhile our proposed molecule-language tasks\nshare some similarities with vision-language tasks,\nthey have several inherent dif\ufb01culties that separate\nthem from existing vision-language analogs: 1)\ncreating annotations for molecules requires signif-arXiv:2204.11817v3  [cs.CL]  3 Nov 2022C1CC(=O)C2CC34C(=O)\nN5C6C(CCC(=O)C6CC5\n(C(=O)N3C2C1O)SS4)O  \nSMILES representation3D V iew\nCaptionThe molecule is an organic disulfide isolated from the whole\nbroth of the marine-derived fungus Exserohilum rostratum and\nhas been shown to exhibit antineoplastic activity . It has a role as\na metabolite and an antineoplastic agent. It is a bridged\ncompound, a lactam, an organic disulfide, an organic\nheterohexacyclic compound, a secondary alcohol, a cyclic\nketone and a diol.Molecule Captioning Image Captioning\n1. a cat sitting on top of an open laptop computer .\n2. a cat that is sitting on top of a lap top.  \n3. a cat is sitting on the keyboard of a laptop.\n4. a cat is sitting on an open laptop.  \n5. a striped cat sitting on top of a laptop  \nCaptions from COCO \nFigure 2: An example of both the image captioning task (Chen et al., 2015) and molecule captioning. Molecule\ncaptioning is considerably more dif\ufb01cult because of the increased linguistic variety in possible captions.\nicant domain expertise, 2) thus, it is signi\ufb01cantly\nmore dif\ufb01cult to acquire large numbers of molecule-\ndescription pairs, 3) the same molecule can have\nmany functions and thus be described in very", " Introduction\nSince the advent of ELMo (Peters et al., 2018) and\nBERT (Devlin et al., 2019), the new pretrain-then-\n\ufb01netune paradigm has brought great performance\nimprovement and dominated the methodology re-\nsearch of the natural language processing (NLP)\n\ufb01eld. Previous research has illustrated that pre-\ntraining language models on the domain-speci\ufb01c\ncorpora can improve the model performance on\ndomain-speci\ufb01c tasks further (Gururangan et al.,\n2020). With the large-scale publicly accessible\n\u0003Contributed equally.\nyCorresponded author.corpora from PubMed, researchers have already\nproposed biomedical domain pretrained language\nmodels such as BioBERT (Lee et al., 2020) and\nPubMedBERT (Gu et al., 2022) to aid the later\nresearch.\nNatural language generation (NLG) tasks such\nas dialogue system (Chao et al., 2017) and ques-\ntion answering (Jin et al., 2022) are of critical im-\nportance for the biomedical arti\ufb01cial intelligence\nresearch, and there is also a trend to approach nat-\nural language understanding as NLG tasks in the\ngeneral domain (Sun et al., 2021; Yan et al., 2021).\nFor example, an entity retrieval task can be solved\nby constrained natural language generation (Cao\net al., 2021). However, there exist two gaps in\nthe research of the biomedical NLG. On the one\nhand, the architectures of the biomedical pretrained\nlanguage models are almost all encoder-only trans-\nformers. Such architecture is incapable of generat-\ning natural languages auto-regressively. A decoder\nis necessary for language generation (Liu and La-\npata, 2019). On the other hand, there are very\nfew in-domain generative language models for bio-\nmedicine (Phan et al., 2021). Models pretrained\non biomedical corpora may further enhance the\nperformance of current biomedical NLG methods in natural\nlanguage processing , pages 141\u2013150.\nYuxian Gu, Robert Tinn, Hao Cheng, Michael R.\nLucas, Naoto Usuyama, Xiaodong Liu, Tris-\ntan Naumann, Jianfeng Gao, and Hoifung Poon.\n2022. Domain-speci\ufb01c language model pretrain-\ning for biomedical natural language processing.\nACM Transactions on Computing for Healthcare\n(HEALTH) , 3:1 \u2013 23.\nSuchin Gururangan, Ana Marasovi \u00b4c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A. Smith. 2020. Don\u2019t stop pretraining:\nAdapt language models to domains and tasks. In\nProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics , pages\n8342\u20138360, Online. Association for Computational\nLinguistics.\nDan Hendrycks and Kevin Gimpel. 2016. Gaus-\nsian error linear units (gelus). arXiv preprint\narXiv:1606.08415 .\nQiao Jin, Bhuwan Dhingra, William Cohen, and\nXinghua Lu. 2019. Probing biomedical embeddings\nfrom language models. In Proceedings of the 3rd\nWorkshop on Evaluating Vector Space Representa-\ntions for NLP , pages 82\u201389.Qiao Jin, Zheng Yuan, Guangzhi Xiong, Qianlan Yu,\nHuaiyuan Ying, Chuanqi Tan, Mosha Chen, Song-\nfang Huang, Xiaozhong Liu, and Sheng Yu. 2022.\nBiomedical question answering: A survey of ap-\nproaches and challenges. ACM Comput. Surv. ,\n55(2).\nAlistair E. W. Johnson, Tom J. Pollard, Lu Shen,\nLi wei H. Lehman, Mengling Feng, Moham-\nmad Mahdi Ghassemi, Benjamin Moody, Peter\nSzolovits, Leo Anthony Celi, and Roger G. Mark.\n2016. Mimic-iii, a freely accessible critical care\ndatabase. Scienti\ufb01c Data , 3.\nZeqian Ju, Subrato Chakravorty, Xuehai He, Shu Chen,\nXingyi Yang, and Pengtao Xie. 2020. Coviddi-\nalog: Medical dialogue datasets about covid-19.\nhttps://github.com/UCSD-AI4H/COVID-Dialogue .\nKamal Raj Kanakarajan, Bhuvana Kundumani,\nand Malaikannan Sankarasubbu. 2021. Bio-\nelectra:pretrained biomedical text encoder using\ndiscriminators. In BIONLP .\nSarvnaz Karimi, Alejandro Metke-Jimenez, Madonna\nKemp, and Chen Wang. 2015. Cadec: A corpus of\nadverse drug event annotations. Journal of biomedi-\ncal informatics , 55:73\u201381.\nHalil Kilicoglu, Asma Ben Abacha, Yassine Mrabet,\nSonya E. Shooshan, Laritza M. Rodriguez, Kate\nMasterton, and Dina Demner-Fushman. 2018. Se-\nmantic annotation of consumer health questions.\nBMC Bioinformatics , 19.\nJ-D Kim, Tomoko Ohta, Yuka Tateisi, and Jun\u2019ichi\nTsujii. 2003. Genia corpus\u2014a", " Introduction\nOver the last few years, very large neural networks trained for language understanding and generation have\nachieved astonishing Related Work\nNatural language capabilities have signi\fcantly advanced through large scale language modeling over the\nlast several years. Broadly, language modeling refers to approaches for predicting either the next token in\na sequence or for predicting masked spans (Devlin et al., 2019; Ra\u000bel et al., 2020). These self-supervised\nobjectives when applied to vast corpora including data scraped from the internet, books, and forums, have\nresulted in models with advanced language understanding and generation capabilities. Predictable power-laws\nof model quality through scaling the amount of data, parameters, and computation have made this a reliable\napproach for increasingly more capable models (Kaplan et al., 2020).\nThe Transformer architecture (Vaswani et al., 2017) unleashed unparalleled e\u000eciency on modern accelerators\nand has become the de-facto approach for language models. In the span of only four years, the largest\nmodels have increased in size and total computation by several orders of magnitude. One of the \frst major\nsuccesses of scale was the 345M parameter encoder-only BERT model (Devlin et al., 2019) which signi\fcantly\nadvanced language understanding across classi\fcation tasks, including SuperGLUE. The Generative Pre-\ntrained Transformer (GPT) series, decoder-only models, (Radford et al., 2018; Ra\u000bel et al., 2020) set\nstate-of-the-art language modeling performance. Ra\u000bel et al. (2020) then pre-trained and \fne-tuned up to 11B\nparameter encoder-decoder models, setting a new bar in transfer learning. The most recent model in the GPT\nseries, the 175B parameter GPT-3 model (Brown et al., 2020) uncovered new capabilities from inference-only,\nfew-shot techniques. Scale has continued to increase after GPT-3, evidenced by the succession of the 178B\nparameter Jurassic-1 (Lieber et al., 2021), the 280B parameter Gopher model (Rae et al., 2021), the 530B\nMegatron-Turing NLG (Smith et al., 2022) as well as trillion parameter sparse models including Switch\nTransformers (Fedus et al., 2021) and GLaM (Du et al., 2021). These advances in core natural language\ncapabilities have also been accompanied with improvements in other domains, including understanding and\ngenerating code (Chen et al., 2021; Austin et al., 2021). Additionally, dialogue applications have advanced\nthrough scale, as most recently evidenced by LaMDA (Thoppilan et al., 2022), a 137B decoder-only model.\nFinally, additional work has enabled language models to follow instructions (Ouyang et al., 2022; Wei et al.,\n2022a) { improving the usefulness and reliability of these models.\nThese larger models no longer can be e\u000eciently trained or even \ft into the memory of a single accelerator.\nTherefore, techniques have arisen for splitting model tensors across accelerators (Shazeer et al., 2018) or\nalternatively separating layers of the models across accelerators and then pipe-lining activations between\nthe stages (Huang et al., 2019). Many other works aim to increase of the scale of models, while limiting\ncommunication overheads (Rajbhandari et al., 2020; Lepikhin et al., 2020; Li et al., 2020; Rasley et al.,\n2020; Rajbhandari et al., 2021; Ren et al., 2021; Narayanan et al., 2021a). PaLM uses a blend of data and\nmodel-parallelism enabled through the Pathways infrastructure (Barham et al., 2022).\nArchitectural variants have been proposed to help scale models more e\u000eciently. One area is retrieval models\nthat aim to drastically reduce model sizes by embedding large amounts of text the model can have access to\nlater (Guu et al.,", " Introduction to arti\fcial life\n(Springer Science & Business Media, 1998).\n[147] Richard E Lenski, Charles Ofria, Robert T Pen-\nnock, and Christoph Adami, \\The evolutionary\norigin of complex features,\" Nature 423, 139{144\n(2003).\n[148] Claus O Wilke, Jia Lan Wang, Charles Ofria,\nRichard E Lenski, and Christoph Adami, \\Evo-\nlution of digital organisms at high mutation rates\nleads to survival of the \rattest,\" Nature 412, 331{\n333 (2001).\n[149] Daniel Flam-Shepherd, Kevin Zhu, and Al\u0013 an\nAspuru-Guzik, \\Keeping it simple: Language mod-\nels can learn complex molecular distributions,\"\n(2021), arXiv:2112.03041.\n[150] Andrei N Kolmogorov, \\On tables of random num-\nbers,\" Sankhy\u0016 a: Indian J. Stat., Series A 25, 369{\n376 (1963).\n[151] Maho Nakata and Tomomi Shimazaki, \\Pub-\nChemQC project: a large-scale \frst-principles elec-\ntronic structure database for data-driven chem-\nistry,\" J. Chem. Inf. Model. 57, 1300{1308 (2017).[152] Zhenqin Wu, Bharath Ramsundar, Evan N Fein-\nberg, Joseph Gomes, Caleb Geniesse, Aneesh S\nPappu, Karl Leswing, and Vijay Pande, \\Molecu-\nlenet: a benchmark for molecular machine learn-\ning,\" Chem. Sci. 9, 513{530 (2018).\n[153] Daniil Polykovskiy, Alexander Zhebrak, Ben-\njamin Sanchez-Lengeling, Sergey Golovanov, Ok-\ntai Tatanov, Stanislav Belyaev, Rauf Kurbanov,\nAleksey Artamonov, Vladimir Aladinskiy, Mark\nVeselov, et al. , \\Molecular sets (MOSES): a bench-\nmarking platform for molecular generation mod-\nels,\" Front. Pharmacol. 11, 1931 (2020).\n[154] Nathan Brown, Marco Fiscato, Marwin HS Segler,\nand Alain C Vaucher, \\GuacaMol: benchmarking\nmodels for de novo molecular design,\" J. Chem.\nInf. Model. 59, 1096{1108 (2019).\n[155] Philipp Renz, Dries Van Rompaey, J\u007f org Kurt Weg-\nner, Sepp Hochreiter, and G\u007f unter Klambauer,\n\\On failure modes in molecule generation and opti-\nmization,\" Drug Discov. Today Technol. 32, 55{63\n(2019).\n[156] Nathan C. Frey, Vijay Gadepally, and Bharath\nRamsundar, \\FastFlows: Flow-based mod-\nels for molecular graph generation,\" (2022),\narXiv:2201.12419.\n[157] Geemi P Wellawatte, Aditi Seshadri, and An-\ndrew D White, \\Model agnostic generation of\ncounterfactual explanations for molecules,\" Chem.\nSci. (2022).\n[158] AkshatKumar Nigam, Robert Pollice, and Alan\nAspuru-Guzik, \\Janus: Parallel tempered genetic\nalgorithm guided by deep neural networks for in-\nverse molecular design,\" (2021), arXiv:2106.04011.\n[159] Sungsoo Ahn, Junsu Kim, Hankook Lee, and\nJinwoo Shin, \\Guiding deep molecular opti-\nmization with genetic exploration,\" (2020),\narXiv:2007.04897.\n[160] Robin Winter, Floriane Montanari, Andreas Stef-\nfen, Hans Briem, Frank No\u0013 e, and Djork-Arn\u0013 e\nClevert, \\E\u000ecient multi-objective molecular opti-\nmization in a continuous latent space,\" Chem. Sci.\n10, 8016{8024 (2019).\n[161] Stephen R Heller, Alan McNaught, Igor Pletnev,\nStephen Stein, and Dmitrii Tchekhovskoi, \\InChI,\nthe IUPAC international chemical identi\fer,\" J.\nCheminform. 7, 1{34 (2015).\n[162] Cynthia Shen, Mario Krenn, Sagi Eppel, and\nAlan Aspuru-Guzik, \\Deep molecular dreaming:\nInverse machine learning for de-novo molecular de-\nsign and interpretability with surjective represen-\ntations,\" Mach. Learn.: Sci. Technol. 2, 03LT02\n(2021).\n[163] Wei Hu, \\Inverse molecule design with invertible\nneural networks as generative models,\" J. Biomed.\nSci. Eng. 14, 305{315 (2021).\n[164] Kohulan Rajan, Achim Zielesny, and Christoph\nSteinbeck, \\DECIMER: towards deep learning for\nchemical image recognition,\" J. Cheminform. 12,\n1{9 (2020).\n[165] Kohulan Rajan, Achim Zielesny, and Christoph\nSteinbeck, \\STOUT: SMILES to IUPAC names us-34\ning neural machine translation,\" J. Cheminform.\n13, 1{14 (2021).\n[166] Djork-Arn\u0013 e Clevert, Tuan Le, Robin Winter, and\nFloriane Montanari, \\Img2Mol { accurate SMILES\nrecognition from molecular graphical depictions,\"\nChem. Sci. 12, 14174{14181 (2021).\n[167] Robin Winter, Floriane Montanari, Frank No\u0013 e,\nand Djork-Arn\u0013 e Clevert, \\Learning continuous and\ndata-driven molecular descriptors by translating\nequivalent chemical representations,\" Chem. Sci.\n10, 1692{1701 (2019).\n[168] Laurens van der Maaten and Geo\u000brey Hinton, \\Vi-\nsualizing data using t-sne,\" J. Mach. Learn. Res. 9\n(2008).\n[169] Raban Iten, Tony Metger, Henrik Wilming, L\u0013 \u0010diaDel Rio, and Renato Renner, \\Discovering phys-\nical concepts with neural networks,\" Phys.", " Introduction\nto the bio-entity recognition task at jnlpba. In\nProceedings of the international joint workshop on\nnatural language processing in biomedicine and its\napplications .\nMartin Krallinger, Obdulia Rabal, Saber A Akhondi,\nMart\u0131n P\u00e9rez P\u00e9rez, Jes\u00fas Santamar\u00eda, Gael P\u00e9rez\nRodr\u00edguez, Georgios Tsatsaronis, and Ander In-\ntxaurrondo. 2017. Overview of the biocreative vi\nchemical-protein interaction track. In Proceed-\nings of the sixth BioCreative challenge evaluation\nworkshop .\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\n\ufb01eld, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin,\nKenton Lee, et al. 2019. Natural questions: a bench-\nmark for question answering research. Transactions\nof the Association for Computational Linguistics\n(TACL) .\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon\nKim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang.\n2020. Biobert: a pre-trained biomedical language\nrepresentation model for biomedical text mining.\nBioinformatics .\nYoav Levine, Noam Wies, Daniel Jannai, Dan Navon,\nYedid Hoshen, and Amnon Shashua. 2021. The\ninductive bias of in-context learning: Rethink-\ning pretraining example design. arXiv preprint\narXiv:2110.04541 .\nPatrick Lewis, Myle Ott, Jingfei Du, and Veselin\nStoyanov. 2020a. Pretrained language models for\nbiomedical and clinical tasks: Understanding and ex-\ntending the state-of-the-art. In Proceedings of the 3rd\nClinical Natural Language Processing Workshop .\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim\nRockt\u00e4schel, et al. 2020b. Retrieval-augmentedgeneration for knowledge-intensive nlp tasks. In\nAdvances in Neural Information Processing Systems\n(NeurIPS) .\nJiao Li, Yueping Sun, Robin J Johnson, Daniela Sciaky,\nChih-Hsuan Wei, Robert Leaman, Allan Peter\nDavis, Carolyn J Mattingly, Thomas C Wiegers, and\nZhiyong Lu. 2016. Biocreative v cdr task corpus:\na resource for chemical disease relation extraction.\nDatabase .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,\nMandar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining\napproach. arXiv preprint arXiv:1907.11692 .\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In International\nConference on Learning Representations (ICLR) .\nZhengyi Ma, Zhicheng Dou, Wei Xu, Xinyu Zhang,\nHao Jiang, Zhao Cao, and Ji-Rong Wen. 2021. Pre-\ntraining for ad-hoc retrieval: Hyperlink is also you\nneed. In Conference on Information and Knowledge\nManagement (CIKM) .\nEric Margolis, Stephen Laurence, et al. 1999. Concepts:\ncore readings . Mit Press.\nAnastasios Nentidis, Konstantinos Bougiatiotis, Anas-\ntasia Krithara, and Georgios Paliouras. 2019. references). We hypothesize\nthat incorporating citation links can help LMs learn\ndependencies between papers and knowledge that\nspans across them.\nWith this motivation, we pretrain LinkBERT on\nPubMed with citation links (\u00a76.1), which we term\nBioLinkBERT , and evaluate on biomedical down-\nstream tasks (\u00a76.2). As our baseline, we follow and\ncompare with the state-of-the-art biomedical LM,\nPubmedBERT (Gu et al., 2020), which has the same\narchitecture as BERT and is trained on PubMed.\n6.1 Pretraining setup\nData. We use the same pretraining corpus used\nby PubmedBERT: PubMed abstracts (21GB).4We\n4https://pubmed.ncbi.nlm.nih.gov . We use papers\npublished before Feb. 2020 as in PubmedBERT.use the Pubmed Parser5to extract citation links be-\ntween articles. We then create training instances by\nsampling contiguous ,random , orlinked segments\nas described in \u00a74, with the three options appearing\nuniformly (33%, 33%, 33%). In summary, our pre-\ntraining data is the same as PubmedBERT, except\nthat we have citation links between PubMed articles.\nImplementation. We pretrain BioLinkBERT of\n-base size (110M params) from scratch, following\nthe same hyperparamters as the PubmedBERT base\n(Gu et al., 2020). Speci\ufb01cally, we use a peak\nlearning rate 6e-4, batch size 8,192, and train for\n62,500 steps. We warm up the learning rate in\nthe \ufb01rst 10% of steps and then linearly decay it.\nTraining", " introduction to methodology and encod-\ning rules,\" Journal of chemical information and computer\nsciences 28, 31 (1988).\n[6] M. H. Segler, T. Kogej, C. Tyrchan, and M. P. Waller,\n\\Generating focused molecule libraries for drug discovery\nwith recurrent neural networks,\" ACS central science 4,\n120 (2018).\n[7] D. P. Kingma and M. Welling, \\Auto-encoding varia-\ntional bayes,\" arXiv preprint arXiv:1312.6114 (2013).\n[8] Q. Perron, O. Mirguet, H. Tajmouati, A. Skiredj,\nA. Rojas, A. Gohier, P. Ducrot, M.-P. Bourguignon,\nP. Sansilvestri-Morel, N. Do Huu, etal., \\Deep gener-\native models for ligand-based de novo design applied to\nmulti-parametric optimization,\" (2021).\n[9] Y. Li, O. Vinyals, C. Dyer, R. Pascanu, and P. Battaglia,\n\\Learning deep generative models of graphs,\" arXiv\npreprint arXiv:1803.03324 (2018).10\n[10] Q. Liu, M. Allamanis, M. Brockschmidt, and A. Gaunt,\ninAdvances in Neural Information Processing Systems\n(2018) pp. 7795{7804.\n[11] W. Jin, R. Barzilay, and T. Jaakkola, \\Junction tree\nvariational autoencoder for molecular graph generation,\"\narXiv preprint arXiv:1802.04364 (2018).\n[12] J. You, B. Liu, Z. Ying, V. Pande, and\nJ. Leskovec, \\Graph convolutional policy net-\nwork for goal-directed molecular graph generation,\"\nAdvances in Neural Information Processing Systems, ,\n6410 (2018).\n[13] A. Se\u000b, W. Zhou, F. Damani,\nA. Doyle, and R. P. Adams, in\nAdvances in Neural Information Processing Systems.\n[14] B. Samanta, D. Abir, G. Jana, P. K. Chat-\ntaraj, N. Ganguly, and M. G. Rodriguez, \\Nevae:\nA deep generative model for molecular graphs,\"\nAAAI Conference on Arti\fcial Intelligence (2019), .\n[15] D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre,\nR. G\u0013 omez-Bombarelli, T. Hirzel, A. Aspuru-Guzik, and\nR. P. Adams, in Neural Information Processing Systems\n(2015).\n[16] D. Flam-Shepherd, T. C. Wu, P. Friederich, and\nA. Aspuru-Guzik, \\Neural message passing on high or-\nder paths,\" Machine Learning: Science and Technology\n(2021).\n[17] M. Simonovsky and N. Komodakis, in\nInternational Conference on Arti\fcial Neural Networks\n(Springer, 2018) pp. 412{422.\n[18] T. Ma, J. Chen, and C. Xiao, in\nAdvances in Neural Information Processing Systems\n(2018) pp. 7113{7124.\n[19] N. De Cao and T. Kipf, \\Molgan: An implicit genera-\ntive model for small molecular graphs,\" arXiv preprint\narXiv:1805.11973 (2018).\n[20] D. Flam-Shepherd, T. Wu, and A. Aspuru-Guzik,\n\\Graph deconvolutional generation,\" arXiv preprint\narXiv:2002.07087 (2020).\n[21] M. J. Kusner, B. Paige, and J. M. Hern\u0013 andez-Lobato,\ninInternational Conference on Machine Learning 2017.\n[22] H. Dai, Y. Tian, B. Dai, S. Skiena, and L. Song, \\Syntax-\ndirected variational autoencoder for structured data,\"\narXiv preprint arXiv:1802.08786 (2018).\n[23] N. O'Boyle and A. Dalke, \\Deepsmiles: an adaptation\nof smiles for use in machine-learning of chemical struc-\ntures,\" (2018).\n[24] M. Krenn, F. H\u007f ase, A. Nigam, P. Friederich, and\nA. Aspuru-Guzik, \\Sel\fes: a robust representation of\nsemantically constrained graphs with an example appli-\ncation in chemistry,\" arXiv preprint arXiv:1905.13741\n(2019).\n[25] D. Polykovskiy, A. Zhebrak, B. Sanchez-Lengeling,\nS. Golovanov, O. Tatanov, S. Belyaev, R. Kurbanov,\nA. Artamonov, V. Aladinskiy, M. Veselov, etal., \\Molec-\nular sets (moses): a benchmarking platform for molecular\ngeneration models,\" Frontiers in pharmacology 11, 1931\n(2020).\n[26] M. A. Skinnider, R. G. Stacey, D. S. Wishart, and\nL. J. Foster, \\Deep generative models enable navigation\nin sparsely populated chemical space,\" (2021).\n[27] M. Moret, L. Friedrich, F. Grisoni, D. Merk, and\nG. Schneider, \\Generative molecular design in low data\nregimes,\" Nature Machine Intelligence 2, 171 (2020).[28] G. Landrum, \\Rdkit: A software suite for cheminformat-\nics, computational chemistry, and predictive modeling,\"\n(2013).\n[29] G. R. Bickerton, G. V. Paolini, J. Besnard, S. Muresan,\nand A. L. Hopkins, \\Quantifying the chemical beauty of\ndrugs,\" Nature chemistry 4, 90 (2012).\n[30] P. Ertl and A. Schu\u000benhauer, \\Estimation of synthetic\naccessibility score of drug-like", " Introduction. ArXiv abs/1310.1863 (2013).On the Opportunities and Risks of Foundation Models 201\nNithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo. 2021. \u201cEveryone\nwants to do the model work, not the data work\u201d: Data Cascades in High-Stakes AI. In proceedings of the 2021 CHI\nConference on Human Factors in Computing Systems . 1\u201315.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. DistilBERT, A Distilled Version of BERT: Smaller,\nFaster, Cheaper and Lighter. arXiv preprint arXiv:1910.01108 (2019).\nGillian Sankoff. 2018. Language Change Across the Lifespan. Annual Review of Linguistics 4, 1 (2018), 297\u2013316. https:\n//doi.org/10.1146/annurev-linguistics-011817-045438 arXiv:https://doi.org/10.1146/annurev-linguistics-011817-045438\nLindsay Sanneman, Christopher Fourie, and Julie Shah. 2020. The State of Industrial Robotics: Emerging Technologies,\nChallenges, and Key Research Directions. https://www.therobotreport.com/wp-content/uploads/2021/01/2020-Research-\nBrief-Sanneman-Fourie-Shah.pdf\nKeshav Santhanam, Siddharth Krishna, Ryota Tomioka, Andrew Fitzgibbon, and Tim Harris. 2021. DistIR: An Intermediate\nRepresentation for Optimizing Distributed Neural Networks. In Proceedings of the 1st Workshop on Machine Learning and\nSystems . 15\u201323.\nAdam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy P. Lillicrap. 2016. Meta-Learning with\nMemory-Augmented Neural Networks. In ICML . 1842\u20131850. http://proceedings.mlr.press/v48/santoro16.html\nShibani Santurkar, Dimitris Tsipras, and Aleksander Madry. 2020. BREEDS: Benchmarks for Subpopulation Shift. arXiv\n(2020).\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A. Smith. 2019. The Risk of Racial Bias in Hate Speech\nDetection. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics . Association for\nComputational Linguistics, Florence, Italy, 1668\u20131678. https://doi.org/10.18653/v1/P19-1163\nAliya Saperstein and Andrew M. Penner. 2012. Racial Fluidity and Inequality in the United States. Amer. J. Sociology 118, 3\n(2012), 676\u2013727. https://doi.org/10.1086/667722 arXiv:https://doi.org/10.1086/667722\nAliya Saperstein, Andrew M. Penner, and Ryan Light. 2013. Racial Formation in Perspective: Connecting Individuals,\nInstitutions, and Power Relations. Annual Review of Sociology 39, 1 (2013), 359\u2013378. https://doi.org/10.1146/annurev-\nsoc-071312-145639 arXiv:https://doi.org/10.1146/annurev-soc-071312-145639\nN. Saunshi, S. Malladi, and S. Arora. 2020a. A Mathematical Exploration of Why Language Models Help Solve Downstream\nTasks. arXiv preprint arXiv:2010.03648 (2020).\nNikunj Saunshi, Sadhika Malladi, and Sanjeev Arora. 2020b. A Mathematical Exploration of Why Language Models Help\nSolve Downstream Tasks. arXiv preprint arXiv:2010.03648 (2020).\nJaromir Savelka, Vern R Walker, Matthias Grabmair, and Kevin D Ashley. 2017. Sentence boundary detection in adjudicatory\ndecisions in the united states. Traitement automatique des langues 58 (2017), 21.\nManolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu,\nVladlen Koltun, Jitendra Malik, et al .2019a. Habitat: A Platform for Embodied AI Research. In 2019 IEEE/CVF International\nConference on Computer Vision (ICCV) . IEEE Computer Society, 9338\u20139346.\nManolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu,\nVladlen Koltun, Jitendra Malik, Devi Parikh, and Dhruv Batra. 2019b. Habitat: A Platform for Embodied AI Research. In\nProceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) .\nMatthew Saxton. 2017. Child Language: Acquisition and Development . Sage Publications, London.\nFranco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural\nnetwork model. IEEE transactions on neural networks 20, 1 (2008), 61\u201380.\nTom Schaul, Dan Horgan, K. Gregor, and D. Silver. 2015. Universal Value Function Approximators. In International Conference\non Machine Learning (ICML) .\nMonica Schenone, Vlado Dan\u010d\u00edk, Bridget K Wagner, and Paul A Clemons. 2013. Target identification and mechanism of\naction in chemical biology and drug discovery. Nature Chemical Biology 9, 4 (2013), 232\u2013240.\nMatthew U Scherer, Allan G King,", " Introduction to the bio-entity recognition task at\nJNLPBA. In Proceedings of the International Joint Workshop on Natural Language\nProcessing in Biomedicine and its Applications (NLPBA/BioNLP) , pages 73\u201378,\nGeneva, Switzerland. COLING.\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. (2018). BERT: pre-training of deep\nbidirectional transformers for language understanding. CoRR ,abs/1810.04805 .\nDodge, J., Sap, M., Marasovic, A., Agnew, W., Ilharco, G., Groeneveld, D., and\nGardner, M. (2021). Documenting the english colossal clean crawled corpus.\nCoRR ,abs/2104.08758 .\nDo\u02d8 gan, R. I., Leaman, R., and Lu, Z. (2014). Ncbi disease corpus: A resource\nfor disease name recognition and concept normalization. Journal of Biomedical\nInformatics ,47, 1 \u2013 10.\nHabibi, M., Weber, L., Neves, M., Wiegandt, D., and Leser, U. (2017). Deep\nlearning with word embeddings improves biomedical named entity recognition.\nBioinformatics (Oxford, England) ,33, i37\u2013i48.\nHerrero-Zazo, M., Segura-Bedmar, I., Mart\u00ednez, P., and Declerck, T. (2013). The\nddi corpus: An annotated corpus with pharmacological substances and drug\u2013drug\ninteractions. Journal of Biomedical Informatics ,46(5), 914\u2013920.\nIslamaj Do\u02d8 gan, R., Kim, S., Chatr-aryamontri, A., Wei, C.-H., Comeau, D. C.,\nAntunes, R., Matos, S., Chen, Q., Elangovan, A., Panyam, N. C., Verspoor, K.,\nLiu, H., Wang, Y ., Liu, Z., Alt\u0131nel, B., H\u00fcs\u00fcnbeyi, Z. M., \u00d6zg\u00fcr, A., Fergadis, A.,\nWang, C.-K., Dai, H.-J., Tran, T., Kavuluru, R., Luo, L., Steppi, A., Zhang, J., Qu,\nJ., and Lu, Z. (2019). Overview of the BioCreative VI Precision Medicine Track:\nmining protein interactions and mutations for precision medicine. Database ,2019 .\nbay147.\nKrallinger, M., Rabal, O., Leitner, F., Vazquez, M., Salgado, D., lu, Z., Leaman,\nR., Lu, Y ., Ji, D., Lowe, D., Sayle, R., Batista-Navarro, R., Rak, R., Huber, T.,\nRockt\u00e4schel, T., Matos, S., Campos, D., Tang, B., Xu, H., and Valencia, A. (2015).\nThe chemdner corpus of chemicals and drugs and its annotation principles. Journal\nof Cheminformatics ,7, S2.\nKudo, T. and Richardson, J. (2018). Sentencepiece: A simple and language\nindependent subword tokenizer and detokenizer for neural text processing. CoRR ,\nabs/1808.06226 .Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C. H., and Kang, J. (2019).\nBiobert: a pre-trained biomedical language representation model for biomedical\ntext mining. CoRR ,abs/1901.08746 .\nLi, J., Sun, Y ., Johnson, R., Sciaky, D., Wei, C.-H., Leaman, R., Davis, A. P.,\nMattingly, C., Wiegers, T., and lu, Z. (2016). Biocreative v cdr task corpus: a\nresource for chemical disease relation extraction. Database ,2016 , baw068.\nPa\ufb01lis, E., Frankild, S., Fanini, L., Faulwetter, S., Pavloudi, C., Vasileiadou, A.,\nArvanitidis, C., and Jensen, L. (2013). The species and organisms resources for\nfast and accurate identi\ufb01cation of taxonomic names in text. PLoS ONE ,8.\nPeng, Y ., Yan, S., and Lu, Z. (2019). Transfer learning in biomedical natural language\nprocessing: An evaluation of BERT and elmo on ten benchmarking datasets. CoRR ,\nabs/1906.05474 .\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y ., Li,\nW., and Liu, P. J. (2019). Exploring the limits of transfer learning with a uni\ufb01ed\ntext-to-text transformer. CoRR ,abs/1910.10683 .\nRomanov, A. and Shivade, C. (2018). Lessons from natural language inference in the\nclinical domain. In Proceedings of the 2018 Conference on Empirical Related Work\nThe introduction of the transformer (Vaswani et al. , 2017) marked\na signi\ufb01cant achievement for natural language processing. This is\ndemonstrated by the success of transformer-based architectures such as\nBERT (Devlin et al. , 2018), which, at", " Introduction\nModels pretrained on unlabeled text corpora are the\nbackbone of many modern NLP systems (Devlin\net al., 2019; Liu et al., 2019; Raffel et al., 2020;\nBrown et al., 2020, inter alia ). This paradigm in-\ncentivizes the use of ever larger corpora (Kaplan\net al., 2020; Henighan et al., 2020), with the biggest\nmodels now training on a substantial fraction of\nthe publicly-available internet (Raffel et al., 2020;\nBrown et al., 2020). Of course, as with all ma-\nchine learning systems, the data such models are\ntrained on has a large impact on their behavior. For\nP r o v enanc e \nMachine or human aut hor ed \nSocial biases Documentat ion L e v el s f or \nC ommonCr a wl -based Datasets \nMedic al or heal t h data Data c ontaminat ion \nDemogr aphic ident it ies Ut t er anc e Dat e Me tadata \nIncluded data \nEx cluded data Figure 1: We advocate for three levels of documenta-\ntion when creating web-crawled corpora. On the right,\nwe include some example of types of documentation\nthat we provide for the C4. ENdataset.\nstructured, task-speci\ufb01c NLP datasets, best prac-\ntices have emerged around documenting the collec-\ntion process, composition, intended uses, and other\ncharacteristics (Bender and Friedman, 2018; Gebru\net al., 2018; Hutchinson et al., 2021). However,\ngiven the challenges of applying these practices\nto massive collections of unlabeled text scraped\nfrom the web, thorough documentation is typically\nnot done. This leaves consumers of pretrained lan-\nguage models in the dark about the in\ufb02uences of\npretraining data on their systems, which can inject\nsubtle biases in downstream uses (Li et al., 2020;\nGehman et al., 2020; Groenwold et al., 2020).\nIn this work we provide some of the \ufb01rst doc-\numentation of a web-scale dataset: the Colossal\nClean Crawled Corpus (C4; Raffel et al., 2020).\nC4 is one of the largest language datasets available,\nwith more than 156 billion tokens collected from\nmore than 365 million domains across the internet\n(Table 1).1C4 has been used to train models such\nas T5 and the Switch Transformer (Fedus et al.,\n1Other, similar datasets have been created (e.g., Brown\net al., 2020), but unfortunately were not made available.arXiv:2104.08758v2  [cs.CL]  30 Sep 20212021), two of the largest pretrained English lan-\nguage models. While Raffel et al. (2020) provided\nscripts to recreate C4, simply running the available\nscripts costs thousands of dollars. Reproducible\nscience is only possible when data is broadly ac-\ncessible, and web-scale corpora are no different\nin this regard. With that in mind, we provide a\ndownloadable copy of this dataset.2\nDocumenting massive, unlabeled datasets is a\nchallenging enterprise. Some suggestions from\nprevious work are naturally appropriate, such as\nreporting the number of examples and a link to a\ndownloadable version of the dataset.3However,\nmany recommendations\u2014like reporting informa-\ntion about the authors of the text\u2014are not easily\napplicable, since often the required information is\nnot available in web-crawled text.\nWe advocate for documentation of web-scale\ncorpora to include three views of the data, as illus-\ntrated in Figure 1. First, the metadata, including the\ninternet domains from which the data was collected.\nAt the highest level, internet top-level domains like\n.edu likely contain signi\ufb01cantly different text than\n.mil , the top-level domain reserved for US gov-\nernment military websites; text from both exist in\nC4.\nFollowing the metadata, we examine the text\nitself. We \ufb01nd signi\ufb01cant amounts of machine-\ngenerated text", " INTRODUCTION\nTransformer-based language models [ 13,27,33\u201335,42,46] in Nat-\nural Language Processing (NLP) have driven rapid progress in re-\ncent years as computation at scale has become more available and\ndatasets have become larger. Recent work [ 11,40] has shown large\nlanguage models to be effective zero- or few-shot learners, with high\naccuracy on many NLP tasks and datasets. These large language\nmodels have a number of exciting downstream applications such\nas client feedback summarization, automatic dialogue generation,\nsemantic search, and code autocompletion [ 1,4,5]. As a result, the\nnumber of parameters in state-of-the-art NLP models have grown\nat an exponential rate (Figure 1). Training such models, however,\nis challenging for two reasons: (a) it is no longer possible to fit the\nparameters of these models in the main memory of even the largest\nGPU (NVIDIA recently released 80GB-A100 cards), and (b) even if\nwe are able to fit the model in a single GPU (e.g., by swapping pa-\nrameters between host and device memory [ 38]), the high number\nof compute operations required can result in unrealistically long\ntraining times (e.g., training GPT-3 with 175 billion parameters [ 11]\nwould require approximately 288 years with a single V100 NVIDIA\nGPU). This calls for parallelism. Data-parallel scale-out usually\nworks well, but suffers from two limitations: a) beyond a point, the\nper-GPU batch size becomes too small, reducing GPU utilization\nand increasing communication cost, and b) the maximum number\nof devices that can be used is the batch size, limiting the number of\naccelerators that can be used for training.\n\u2605Work done as an intern at NVIDIA.\n/uni00000016/uni00000014/uni00000015/uni0000001c /uni00000016/uni00000014/uni00000015/uni0000001d /uni00000016/uni00000014/uni00000016/uni00000014 /uni00000016/uni00000014/uni00000016/uni00000015\n/uni0000003d/uni00000049/uni00000045/uni00000056/uni00000015/uni00000014/uni00000016\n/uni00000015/uni00000014/uni00000015\n/uni00000015/uni00000014/uni00000014/uni00000015/uni00000014/uni00000015/uni00000015/uni00000014/uni00000016/uni00000015/uni00000014/uni00000017/uni00000032/uni00000059/uni00000051/uni00000046/uni00000049/uni00000056/uni00000004/uni00000053/uni0000004a/uni00000004/uni00000054/uni00000045/uni00000056/uni00000045/uni00000051/uni00000049/uni00000058/uni00000049/uni00000056/uni00000057\n/uni0000000c/uni0000004d/uni00000052/uni00000004/uni00000046/uni0000004d/uni00000050/uni00000050/uni0000004d/uni00000053/uni00000052/uni00000057/uni0000000d\n/uni00000029/uni00000030/uni00000031/uni00000053/uni00000004/uni0000000c/uni0000001d/uni00000018/uni00000031/uni0000000d/uni00000026/uni00000029/uni00000036/uni00000038/uni00000011/uni00000030/uni00000004/uni0000000c/uni00000017/uni00000018/uni00000014/uni00000031/uni0000000d/uni0000002b/uni00000034/uni00000038/uni00000011/uni00000016/uni00000004/uni0000000c/uni00000015/uni00000012/uni00000019/uni00000026/uni0000000d/uni00000031/uni00000049/uni0000004b/uni00000045/uni00000058/uni00000056/uni00000053/uni00000052/uni00000011/uni00000030/uni00000031/uni00000004/uni0000000c/uni0000001c/uni00000012/uni00000017/uni00000026/uni0000000d/uni00000038/uni00000059/uni00000056/uni0000004d/uni00000052/uni0000004b/uni00000011/uni00000032/uni00000030/uni0000002b/uni00000004/uni0000000c/uni00000015/uni0000001b/uni00000012/uni00000016/uni00000026/uni0000000d/uni0000002b/uni00000034/uni00000038/uni00000011/uni00000017/uni00000004/uni0000000c/uni00000015/uni0000001b/uni00000019/uni00000026/uni0000000dFigure 1: Trend of sizes of state-of-the-art Natural Language Pro-\ncessing (NLP) models with time. The number of floating-point op-\nerations to train these models is increasing at an exponential rate.\nVarious model parallelism techniques have been proposed to\naddress these two challenges. For example, recent work [ 39,40] has\nshown how tensor (intra-layer) model parallelism, where matrix\nmultiplications within each transformer layer are split over multiple\nGPUs, can be used to overcome these limitations. Although this\napproach works well for models of sizes up to 20 billion parameters\non NVIDIA DGX A100 servers (with 8 80GB-A100 GPUs), it breaks\ndown for larger models. Larger models need to be split across\nmultiple multi-GPU servers, which leads to two problems: (a) the\nall-reduce communication required for tensor parallelism needs\nto go through inter-server links, which are slower than the high-\nbandwidth NVLink [ 9] available within a multi-GPU server, and\n(b) a high degree of model parallelism can create small matrix\nmultiplications (GEMMs), potentially decreasing GPU utilization.\nPipeline model parallelism [ 14,20,23,29,30,45] is another tech-\nnique to support the training of large models, where layers of a\nmodel are striped over multiple GPUs. A batch is split into smaller\nmicrobatches, and execution is pipelined across these microbatches.\nLayers can be assigned to workers in various ways, and various\nschedules for the forward and backward passes of inputs can be\nused. The layer assignment and scheduling strategy results in 24\ud835\udc35\ud835\udc60\u210e2+4\ud835\udc35\ud835\udc602\u210eFLOPs for the forward pass. The\nbackward pass requires double the number of FLOPs since we\nneed to calculate the gradients with respect to both input and\nweight tensors. In addition, we are using activation recomputation,\nwhich requires an additional forward pass before the backward\npass. As a result, the total number of FLOPs per transformer layer\nis4\u00d7\u000024\ud835\udc35\ud835\udc60\u210e2+4\ud835\udc35\ud835\udc602\u210e\u0001=96\ud835\udc35\ud835\udc60\u210e2\u0010\n1+\ud835\udc60\n6\u210e\u0011\n.\nThe other main contributor to", " Introduction\nDrug discovery is a challenging multidisciplinary task that\ncombines domain knowledge in chemistry, biology, and\ncomputational science. Recent works demonstrated success-\nful applications of machine learning to the drug develop-\nment process, including synthesis planning (Segler, Preuss,\nand Waller 2018), protein folding (Senior et al. 2020), and\nhit discovery (Merk et al. 2018; Zhavoronkov et al. 2019;\nKadurin et al. 2016). Advances in generative models enabled\napplications of machine learning to drug discovery, such\nas distribution learning and molecular property optimiza-\ntion. Distribution learning models train on a large dataset\nto produce novel compounds (Polykovskiy et al. 2020);\nproperty optimization models search the chemical space for\nmolecules with desirable properties (Brown et al. 2019). Of-\nten researchers combine these tasks: they \ufb01rst train a distri-\nbution learning model and then use its latent codes to opti-\nmize molecular properties (G \u00b4omez-Bombarelli et al. 2018).\nFor such models, proper latent codes are crucial for molecu-\nlar space navigation.\nWe propose a new graph generative model\u2014MolGrow.\nStarting with a single node, it iteratively splits every node\ninto two. Our model is invertible and maps molecular struc-\ntures onto a \ufb01xed-size hierarchical manifold. Top levels of\nthe manifold de\ufb01ne global structure, while the bottom levels\nin\ufb02uence local features.\nOur contributions are three-fold:\nCopyright \u00a9 2021, Association for the Advancement of Arti\ufb01cial\nIntelligence (www.aaai.org). All rights reserved.\u2022 We propose a hierarchical normalizing \ufb02ow model for\ngenerating molecular graphs. The model gradually in-\ncreases graph size during sampling, starting with a single\nnode;\n\u2022 We propose a fragment-oriented atom ordering that im-\nproves our model over commonly used breadth-\ufb01rst\nsearch ordering;\n\u2022 We apply our model to distribution learning and property\noptimization tasks. We report distribution learning met-\nrics (Fr \u00b4echet ChemNet distance and fragment distribu-\ntion) for graph generative models besides providing stan-\ndard uniqueness and validity measures. Background: Normalizing Flows\nNormalizing \ufb02ows are generative models that transform a\nprior distribution p(z)into a target distribution p(x)by com-\nposing invertible functions fk:\nz=fK\u000e:::\u000ef2\u000ef1(x); (1)\nx=f\u00001\n1\u000e:::\u000ef\u00001\nK\u00001\u000ef\u00001\nK(z): (2)\nWe call Equation 1 a forward path, and Equation 2 an in-\nverse path. The prior distribution p(z)is often a standard\nmultivariate normal distribution N(0;I). Such models are\ntrained by maximizing training set log-likelihood using the\nchange of variables formula:\nlogp(x) = logp(z) +KX\ni=1log\f\f\f\fdet\u0012dhi\ndhi\u00001\u0013\f\f\f\f;(3)\nwherehi=fi(hi\u00001),h0=x. To ef\ufb01ciently train the model\nand sample from it, inverse transformations and Jacobian de-\nterminants should be tractable and computationally ef\ufb01cient.\nIn this work, we consider three types of layers: invertible\nlinear layer, actnorm, and real-valued non-volume preserv-\ning transformation (RealNVP) (Dinh, Sohl-Dickstein, and\nBengio 2017). We de\ufb01ne these layers below for arbitrary\nd-dimensional vectors, and extend these layers for graph-\nstructured data in the next section.\nWe consider an invertible linear layer parameterization by\nHoogeboom, Van Den Berg, and Welling (2019) that uses\nQR decomposition of a weight matrix: h=QR\u0001z, where\nQis an orthogonal matrix ( QT=Q\u00001), andRis an upperarXiv:2106.05856v1  [physics.chem-ph]  3 Feb 2021(V0,E0)\n<latexit sha1_base64=\"N1uTey4nD0v70AAaJONMTrRSFi8=\">AAAB9XicbVDLSgMxFL1TX7W+qi7dBItQQcqMFNRdUQSXFewD2mnJpJk2NJMZkoxShv6HGxeKuPVf3Pk3ZtpZaOuByz2ccy+5OV7EmdK2/W3lVlbX1jfym4Wt7Z3dveL+QVOFsSS0QUIeyraHFeVM0IZmmtN2JCkOPE5b3vgm9VuPVCoWigc9iagb4KFgPiNYG6lXbvYSe3qGbtN22i+W7Io9A1omTkZKkKHeL351ByGJAyo04VipjmNH2k2w1IxwOi10Y0UjTMZ4SDuGChxQ5Sazq6foxCgD5IfSlNBopv7eSHCg1CTwzGSA9Ugteqn4n9eJtX/pJkxEsaaCzB/yY450iNII0IBJSjSfGIKJZOZWREZYYqJNUAUTgrP45WXSPK841crVfbVUu87iyMMRHEMZHLiAGtxBHRpAQMIzvMKb9WS9WO/Wx3w0Z2U7h/AH1ucPp4SRVg==</latexit>\n(VK,EK)\n<latexit sha1_base64=\"aP429hCf1AqK7q/iIf65+604kNk=\">AAAB8XicbVBNS8NAEJ3Ur1q/qh69LBahgpRECuqtKILQSwX7gW1aNttNu3SzCbsboYT+Cy8eFPHqv/Hmv3Hb5qCtDwYe780wM8+LOFPatr+tzMrq2vpGdjO3tb2zu5ffP2ioMJaE1knIQ9nysKKcCVrXTHPaiiTFgcdp0xvdTP3mE5WKheJBjyPqBnggmM8I1kZ6LDa61TN0262e9vIFu2TPgJaJk5ICpKj18l+dfkjigApNOFaq7diRdhMsNSOcTnKdWNEIkxEe0LahAgdUucns4gk6MUof+aE0JTSaqb8nEhwoNQ480xlgPVSL3lT8z2vH2r90EyaiWFNB5ov8mCMdoun7qM8kJZqPDcFEMnMrIkMsMdEmpJwJwVl8eZk0zktOuXR1Xy5UrtM4snAEx1AEBy6gAndQgzoQEPAMr/BmKevFerc+5q0ZK505hD+wPn8AZZaPdA==</latexit>\nLevel LLevel 2Level 1(V,E)\n<latexit sha1_base64=\"sc0f22gD9iLfOm9yG5hDLO00oxk=\">AAAB7XicbVBNSwMxEJ2tX7V+VT16CRahgpRdKai3oggeK9htoV1KNk3b2GyyJFmhLP0PXjwo4tX/481/Y9ruQVsfDDzem2FmXhhzpo3rfju5ldW19Y38ZmFre2d3r7h/4GuZKEIbRHKpWiHWlDNBG4YZTluxojgKOW2Go5up33yiSjMpHsw4pkGEB4L1GcHGSn7ZP0O3p91iya24M6Bl4mWkBBnq3eJXpydJElFhCMdatz03NkGKlWGE00mhk2gaYzLCA9q2VOCI6iCdXTtBJ1bpob5UtoRBM/X3RIojrcdRaDsjbIZ60ZuK/3ntxPQvg5SJODFUkPmifsKRkWj6OuoxRYnhY0swUczeisgQK0yMDahgQ/AWX14m/nnFq1au7qul2nUWRx6O4BjK4MEF1OAO6tAAAo/wDK/w5kjnxXl3PuatOSebOYQ/cD5/AMjojfo=</latexit>\nz0\n<latexit sha1_base64=\"EefYAm4MZUevch+o3UL+GmK5j2U=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKexKQL0FvXiMaB6QrGF2MkmGzM4uM71CXPIJXjwo4tUv8ubfOEn2oIkFDUVVN91dQSyFQdf9dnIrq2vrG/nNwtb2zu5ecf+gYaJEM15nkYx0K6CGS6F4HQVK3oo1p2EgeTMYXU/95iPXRkTqHscx90M6UKIvGEUr3T09uN1iyS27M5Bl4mWkBBlq3eJXpxexJOQKmaTGtD03Rj+lGgWTfFLoJIbHlI3ogLctVTTkxk9np07IiVV6pB9pWwrJTP09kdLQmHEY2M6Q4tAselPxP6+dYP/CT4WKE+SKzRf1E0kwItO/SU9ozlCOLaFMC3srYUOqKUObTsGG4C2+vEwaZ2WvUr68rZSqV1kceTiCYzgFD86hCjdQgzowGMAzvMKbI50X5935mLfmnGzmEP7A+fwBD5ONrA==</latexit>\nDequantizationz1\n<latexit sha1_base64=\"ybacxdcb1TGaEySRNROmmKatxWM=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKexKQL0FvXiMaB6QrGF2MkmGzM4uM71CXPIJXjwo4tUv8ubfOEn2oIkFDUVVN91dQSyFQdf9dnIrq2vrG/nNwtb2zu5ecf+gYaJEM15nkYx0K6CGS6F4HQVK3oo1p2EgeTMYXU/95iPXRkTqHscx90M6UKIvGEUr3T09eN1iyS27M5Bl4mWkBBlq3eJXpxexJOQKmaTGtD03Rj+lGgWTfFLoJIbHlI3ogLctVTTkxk9np07IiVV6pB9pWwrJTP09kdLQmHEY2M6Q4tAselPxP6+dYP/CT4WKE+SKzRf1E0kwItO/SU9ozlCOLaFMC3srYUOqKUObTsGG4C2+vEwaZ2WvUr68rZSqV1kceTiCYzgFD86hCjdQgzowGMAzvMKbI50X5935mLfmnGzmEP7A+fwBEReNrQ==</latexit>\nzL\n<latexit sha1_base64=\"4AJjIOWur+2aanbud8rk9mrxxIc=\">AAAB6nicbVA9SwNBEJ2LXzF+RS1tFoNgFe5EULugjYVFRPMByRn2NpNkyd7esbsnxCM/wcZCEVt/kZ3/xk1yhSY+GHi8N8PMvCAWXBvX/XZyS8srq2v59cLG5tb2TnF3r66jRDGssUhEqhlQjYJLrBluBDZjhTQMBDaC4dXEbzyi0jyS92YUox/SvuQ9zqix0t3Tw02nWHLL7hRkkXgZKUGGaqf41e5GLAlRGiao1i3PjY2fUmU4EzgutBONMWVD2seWpZKGqP10euqYHFmlS3qRsiUNmaq/J1Iaaj0KA9sZUjPQ895E/M9rJaZ37qdcxolByWaLeokgJiKTv0mXK2RGjCyhTHF7K2EDqigzNp2CDcGbf3mR1E/K3mn54va0VLnM4sjDARzCMXhwBhW4hirUgEEfnuEV3hzhvDjvzsesNedkM/vwB87nDzoDjcg=</latexit>\n\u2026z2\n<latexit sha1_base64=\"GHSx52ei9eSsw6Gh2+tO4uevl7A=\">AAAB6nicbVDLSgNBEOz1GeMr6tHLYBA8hd0QUG9BLx4jmgcka5idzCZDZmeXmV4hhnyCFw+KePWLvPk3TpI9aGJBQ1HVTXdXkEhh0HW/nZXVtfWNzdxWfntnd2+/cHDYMHGqGa+zWMa6FVDDpVC8jgIlbyWa0yiQvBkMr6d+85FrI2J1j6OE+xHtKxEKRtFKd08P5W6h6JbcGcgy8TJShAy1buGr04tZGnGFTFJj2p6boD+mGgWTfJLvpIYnlA1pn7ctVTTixh/PTp2QU6v0SBhrWwrJTP09MaaRMaMosJ0RxYFZ9Kbif147xfDCHwuVpMgVmy8KU0kwJtO/SU9ozlCOLKFMC3srYQOqKUObTt6G4C2+vEwa5ZJXKV3eVorVqyyOHBzDCZyBB+dQhRuoQR0Y9OEZXuHNkc6L8+58zFtXnGzmCP7A+fwBEpuNrg==</latexit>\nQuantizationGrow\u2026PermutationLinearActnormRealNVPRealNVPBlockLevel\nBlockNodesplittingNoiseinjection\u2026blocksActnormNoiseseparationNodemergingBlockBlockLinearPermutationzt\n<latexit sha1_base64=\"d+ry7PwS23/IGjY96Qc5Oj2AbQo=\">AAAB6nicbVDLSgNBEOyNrxhfUY9eBoPgKexKQL0FvXiMaB6QrGF2MkmGzM4uM71CXPIJXjwo4tUv8ubfOEn2oIkFDUVVN91dQSyFQdf9dnIrq2vrG/nNwtb2zu5ecf+gYaJEM15nkYx0K6CGS6F4HQVK3oo1p2EgeTMYXU/95iPXRkTqHscx90M6UKIvGEUr3T09YLdYcsvuDGSZeBkpQYZat/jV6UUsCblCJqkxbc+N0U+pRsEknxQ6ieExZSM64G1LFQ258dPZqRNyYpUe6UfalkIyU39PpDQ0ZhwGtjOkODSL3lT8z2sn2L/wU6HiBLli80X9RBKMyPRv0hOaM5RjSyjTwt5K2JBqytCmU7AheIsvL5PGWdmrlC9vK6XqVRZHHo7gGE7Bg3Oowg3UoA4MBvAMr/DmSOfFeXc+5q05J5s5hD9wPn8AdqON8A==</latexit>\nBt\n<latexit sha1_base64=\"W9VRwq2pBwjtMbuC6IWLFO+Rv0s=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0lEUG+lXjxWtB/QhrLZbtqlm03YnQgl9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5QSKFQdf9dgpr6xubW8Xt0s7u3v5B+fCoZeJUM95ksYx1J6CGS6F4EwVK3kk0p1EgeTsY38789hPXRsTqEScJ9yM6VCIUjKKVHup97JcrbtWdg6wSLycVyNHol796g5ilEVfIJDWm67kJ+hnVKJjk01IvNTyhbEyHvGupohE3fjY/dUrOrDIgYaxtKSRz9fdERiNjJlFgOyOKI7PszcT/vG6K4bWfCZWkyBVbLApTSTAms7/JQGjOUE4soUwLeythI6opQ5tOyYbgLb+8SloXVe+yenN/WanV8ziKcAKncA4eXEEN7qABTWAwhGd4hTdHOi/Ou/OxaC04+cwx/IHz+QMi2I25</latexit>\n2tnodes\n<latexit sha1_base64=\"4VNOKENLXofcBmHaZmH5kHU9kKo=\">AAAB+3icdVDLSsNAFJ3UV62vWJduBovgKiS1arsrunFZwT6gjWUymbRDJ5MwMxFLiJ/ixoUibv0Rd/6Nk7aCih4YOJxzL/fM8WJGpbLtD6OwtLyyulZcL21sbm3vmLvljowSgUkbRywSPQ9JwignbUUVI71YEBR6jHS9yUXud2+JkDTi12oaEzdEI04DipHS0tAsV2/U/SBEaizClEc+kdnQrNjWaaPu2A1oW/YMOXFqx40T6CyUCligNTTfB36Ek5BwhRmSsu/YsXJTJBTFjGSlQSJJjPAEjUhfU45CIt10lj2Dh1rxYRAJ/biCM/X7RopCKaehpyfzlPK3l4t/ef1EBXU3pTxOFOF4fihIGFQRzIuAPhUEKzbVBGFBdVaIx0ggrHRdJV3C10/h/6RTtZya1biqVZrnizqKYB8cgCPggDPQBJegBdoAgzvwAJ7As5EZj8aL8TofLRiLnT3wA8bbJ//clRo=</latexit>\n2t\u00001nodes\n<latexit sha1_base64=\"b+ddvYaKdQ2to1eKHA1hNGZrSlY=\">AAAB/3icdVDLSsNAFJ3UV62vqODGzWAR3FiSWrXZFd24rGAf0MYymU7boZNJmJkIJUbwV9y4UMStv+HOv3HSRlDRAwOHc+7lnjleyKhUlvVh5ObmFxaX8suFldW19Q1zc6spg0hg0sABC0TbQ5IwyklDUcVIOxQE+R4jLW98nvqtGyIkDfiVmoTE9dGQ0wHFSGmpZ+6Ur2N1aCd3XR+pkfBjHvSJTHpm0SqdOFXbcqBVsqZIiV05co6hnSlFkKHeM9+7/QBHPuEKMyRlx7ZC5cZIKIoZSQrdSJIQ4TEako6mHPlEuvE0fwL3tdKHg0DoxxWcqt83YuRLOfE9PZmmlL+9VPzL60RqUHVjysNIEY5nhwYRgyqAaRmwTwXBik00QVhQnRXiERIIK11ZQZfw9VP4P2mWS3al5FxWirWzrI482AV74ADY4BTUwAWogwbA4BY8gCfwbNwbj8aL8TobzRnZzjb4AePtE7Uelpg=</latexit>Figure 1: MolGrow architecture. Left: Full architecture combines multiple levels to generate latent codes zL;:::;z0from\na graph (V;E)and vice versa. Middle: Each level separates noise, merges node pairs, applies multiple blocks and linear\ntransformations; Right: Each block applies three channel-wise transformations and two RealNVP layers.\ntriangular matrix with ones on the main diagonal. We use\nHouseholder re\ufb02ections to parameterize Q:\nQ=d0Y\ni=1\u0012\nI\u00002vivT\ni\nkvik2\u0013\n; (4)\nwhereviare learnable column-vectors. The Jacobian deter-\nminant of a linear layer is 1. There is an alternative way to\nformulate a linear layer", " Introduction\nThe emerging use of neural network architectures in the early-st age of drug\ndiscovery has recently resulted in several breakthroughs [50,20]. Later stages of\ndrug development are much more conservative due to the complicat ed process of\nclinical trials. The use of state-of-the-art neural network appr oaches in clinical\ntrials could dramatically speed up the overall drug development proc ess and\nincrease its success rate, thus saving lives.\nClinical trialregisters(e.g., ClinicalTrials.gov) containvast amounts o fstruc-\ntured information on how standardized interventions work in a clinica l setting.2 Z. Miftahutdinov et al.\nDespite the existing structure, these registers remain very di\ufb03cu lt to harmo-\nnize with drug and disease databases using current techniques. Th is very often methods.\nBioBERT ranking This is a baseline model that used the BioBERT model for\nencoding mention and concept representations. Each entity ment ion or concept\nname is \ufb01rstly passed through BioBERT (we use the average over all outputs of\nBERT) and then through a mean pooling layer to yield a \ufb01xed-sized vec tor. The\ninference task is then reduced to \ufb01nding the closest concept name representation\nto entity mention representation in a common embedding space. We u se the\nEuclidean distance as the distance metric. The nearestconcept na mes are chosen\nas top-k concepts for entities. We use the publicly availablecode pro vided by [43]\nathttps://github.com/insilicomedicine/Fair-Evaluation .\nBioSynBioSyn [41] is a recent state-of-the-art model that utilizes the sy nonym\nmarginalization technique and the iterative candidate retrieval. The model uses\ntwo similarity functions based on sparse and dense representation s, respectively.\nThesparserepresentationencodesthemorphologicalinformatio nofgivenstrings\nviaTF-IDF, the denserepresentationencodesthesemanticinfor mationgathered\nfrom BioBERT. For reproducibility, we use the publicly available code pr ovided\nby the authors at https://github.com/dmis-lab/BioSyn . We follow the de-\nfault parameters of BioSyn as in [41]: the number of top candidates k is 20, the10 Z. Miftahutdinov et al.\nmini-batch size is 16, the learning rate is 1e-5, the dense ratio for th e candidate\nretrieval is 0.5, 20 epochs for training.\n5.3 Experimental Setup\nWe experiment with BioBERT basev1.1 with 12 heads, 12 layers, 768 hidden\nunits per layer, and a total of 110M parameters. Epsilon, the numb er of positive\nand negative examples, and distance metric were chosen optimally on dev sets.\nWe choose red(\u00b7) to be the averageover all outputs of BERT. We have evaluated\ndi\ufb00erent epsilons starting from 0.5 up to 4.0 with 0.5 step for Euclidean distance\nmetric, for cosine distance from 0.05 up to 0.3 with 0.05 step. These e xperiments\nhave quite similar Related Work\nOur workmost closely relatesto researchin information extraction and semantic\ntextual similarity by directly linking a set of entity mentions and a large set of\nmedical concept names using triplet structures to derive embeddin gs of entity\nmentions and concept names that can be compared using semantic s imilarity.\nEntity linking of mentions to entries in a knowledge base (KB) is a well-st udied\narea; see a good survey [40]. Research studies in this area assume t hat there is\none knowledge base, such as Wikipedia or Freebase. The KB contains rich text\ndescriptions (from an entity page, for example), hyperlink statist ics, and meta-\ndata. This assumption holds for the general domain, but not for th e biomedical\ndomain, where diverse terminologies exist for numerous purposes.\n2.1 Medical Concept Normalization\nMedical concept normalization is usually formulated as a classi\ufb01cation or rank-\ning problem", " Introduction\nMolecular representations underpin predictive, generative and analytical tasks in drug discovery [ 1].\nThe choice of a suitable representation can drastically impact the ef\ufb01ciency of discovering a novel drug\ncandidate. For instance, applications such as Virtual Screening andQuantitative Structure-Activity-\nRelationship (QSAR) modeling rely on the availability of effective molecular representations [2].\nLanguage models have been applied to text-based molecular representations such as Simpli\ufb01ed\nMolecular Input Line Entry System (SMILES) [ 3]. They show impressive performance across a range\nof domain applications including molecular property [ 4,5] and reaction prediction problems [ 6,7],\nas well as generative tasks [ 8]. Numerous strategies have been explored to encourage learning of\nhigh quality representations with language models including input reconstruction [ 9\u201311], whereby a\nmodel learns to predict masked or corrupted tokens; and input translation [ 5,12], where the goal is to\ntranslate the input to another modality or representation. Further improvements have been made by\nincorporating calculated molecular properties into the representation, either by concatenating with the\nlearnt representations [ 13], or through devising pre-training schemes [ 14]. Finally, a range of model\narchitectures have been explored including autoencoders [5], RNNs [9] and transformers [10, 11].\nAside from the modal limitations of representing molecules as strings, a drawback to learning from\ntext-based molecular representations is introduced by the ambiguity of linearizing the molecular\ngraph [ 15]. In the case of SMILES, many valid sequences may represent the same molecule\ndepending on the traversal path of the molecular graph. This ambiguity has led to the development of\ncanonicalization algorithms [ 16,17] which, while practical, introduce artifacts to linearized SMILES\nsuch that a language model may be distracted by the rules of canonicalization. Previous works have\nshown the bene\ufb01ts of learning using permutations of SMILES [18].\nMachine Learning for Molecules Workshop at NeurIPS 2020. https://ml4molecules.github.ioarXiv:2011.13230v1  [cs.LG]  26 Nov 2020MolBER T \nCLS C ( MA SK N ... CLS C ( C N ... \nEMBEDDING P HYS C HEM P RED SMILES-E Q M ASKED L M \nSMILES (or pair of SMILES) Figure 1: Diagram of M OLBERTillustrating the various auxiliary tasks utilized for pre-training.\nIn this work, we evaluate the application of the widely used Bidirectional Encoder Representations\nfrom Transformers (BERT) [ 19] architecture for the generation of molecular representations. We\nexplore the impact of employing a range of domain-relevant auxiliary tasks during pre-training and\nevaluate the produced learnt representations on downstream Virtual Screening and QSAR benchmarks.\nCode and pre-trained models are available at https://github.com/BenevolentAI/MolBERT.\n2 M OLBERT\nMOLBERT, as depicted in Figure 1, is a bidirectional language model that uses the BERT archi-\ntecture [ 19]. To understand the impact of pre-training with different domain-relevant tasks on\ndownstream applications, we experiment with the following set of self-supervised tasks:\nMasked language modeling (M ASKED LM): The canonical task proposed by BERT, whereby the\nmodel is trained to predict the true identity of masked tokens. The task is optimized using the\ncross-entropy loss between the sequence output and the masked tokens of the input.\nSMILES equivalence (SMILES-E Q):Given an input of two SMILES where the second is, with\nequal probability, either randomly sampled from the training set or a synonymous permutation of\nthe \ufb01rst SMILES, the task is to predict whether the two inputs represent the same molecule. This\nis a", " Introduction\nEffectively transferring the success of BERT (De-\nvlin et al., 2018) to the biomedical domain, most\nnotably Lee et al. (2019) (BioBERT) and Beltagy\net al. (2019) (SciBERT) inspired a large number of\nsimilar works last year. For example, Peng et al.\n(2019); Alsentzer et al. (2019); Huang et al. (2019)\nadded clinical text to the PubMed biomedical pre-\ntraining corpus and tested on standard biomedical\nand clinical NLP benchmarks. Many other sim-\nilar works appeared at the ACL BioNLP Work-\nshop (Demner-Fushman et al., 2019).\nMore recently, Gu et al. (2020) performed a com-\nprehensive study on the pre-training corpus domain,language model masking method, and adversarial\ntraining, benchmarking on a number of different\ndatasets for token classi\ufb01cation ,sequence classi\ufb01-\ncation , and sequence regression .\nCompared to the previous works, we perform a\nmore detailed study on (1)subword vocabulary, (2)\nlabeling method, (2)model size, and (3)domain\ntransfer, showing gains in token classi\ufb01cation ,se-\nquence classi\ufb01cation , and question answering .\n2 Related Works\nA prime example of Language Models (LMs)\nin the biomedical domain is BioBERT (Lee\net al., 2019). It is a transformer LM pre-trained\non the PubMed ( www.ncbi.nlm.nih.gov/pubmed )\nbiomedical text corpus comprised of biomedical\nliterature abstracts. Their pre-training started from\nthe checkpoint of Devlin et al. (2018) trained on\nWikipedia and Books-Corpus. Independently, Belt-\nagy et al. (2019) (SciBERT) pre-trained BERT\nfrom scratch using their vocabulary set on scienti\ufb01c\ntext corpora, including PubMed abstracts and com-\nputer science papers. Both demonstrated increased\nperformance over the previous non-BERT SOTA on\nbiomedical benchmarks, including Named Entity\nRecognition (NER), Relation Extraction (RE), and\nQuestion Answering (QA). BioBERT and SciB-\nERT report similar results on NER and QA, which could be\na future avenue to explore for domain LMs. Trans-\nfer learning showed effectiveness in the biomedical\nQA task. However, it is somewhat unclear how to\napply it to NER and RE tasks.\nModel PubMed Corpus #Words\nBioBERT abstracts 4.5 billion\nPubMedBERT abstracts + full-text 16.8 billion\nBioMegatron abstracts + full-text-CC 6.1 billion\nTable 10: Pre-training text corpus of each biomedical\nLM. We pre-train on PubMed abstracts and full-text\ncommercial-collection (CC) that are free of copyrights.\nPre-training Corpus and Duration PubMed-\nBERT is pre-trained on a much larger text corpus,\nas shown in Table 10. It is a performant domain-\nLM with a larger pre-training corpus and adequate\ndomain vocabulary compared to its model size. We\npre-train our LMs for about one epoch, reaching a\nmasked-LM loss of about 1.2 (Devlin et al., 2018).\nFurther pre-training may be helpful, but it is chal-\nlenging to have strictly controlled abstract set\nand the 1.6 billion-word CC0-licensed Commer-\ncial Use Collection of the PMC full-text corpus\n(www.ncbi.nlm.nih.gov/pmc ).\nWe train three sizes of BioMegatron: with\n345 million, 800 million, and 1.2 billion num-\nber of parameters (Table 1). We compare\nfour pre-training scenarios in the smallest 345m\nmodel - using BERT-cased/uncased vocabular-\nies, each pre-trained from scratch and \ufb01ne-\ntuned from general domain LM. We also com-\npare two sets of domain vocabularies learned\non PubMed text corpus using SentencePiece\n(github.com/google/sentencepiece) library, each\ncontaining 30k and 50k subword units.\nWe train the larger BioMegatron models with\nless variation: 800m models from scratch on\nPubMed with BERT -cased/-uncased vocabular-\nies; and 1.2b model starting from general domain\nLM checkpoint using BERT-uncased vocabulary.#Parameters #Layers #Hidden Size #Attention Heads\n345m 24 1024 16\n800m 36 1280 20\n1.2b 24 2048 16\nTable 1: Model con\ufb01gurations.\n4 Downstream Benchmark Tasks\nWe use the most widely used downstream biomedi-\ncal benchmark datasets for NER, RE, and QA.\nNamed Entity Recognition The BC5CDR", " INTRODUCTION\nIn natural language processing (NLP), pretraining large neural language models on unlabeled text has proven\nto be a successful strategy for transfer learning. A prime example is Bidirectional Encoder Representations\nfrom Transformers (BERT) [ 16], which has become a standard building block for training task-specific NLP\nmodels. Existing pretraining work typically focuses on the newswire and Web domains. For example, the original\nBERT model was trained on Wikipedia1and BookCorpus [ 62], and subsequent efforts have focused on crawling\nadditional text from the Web to power even larger-scale pretraining [39, 50].\n\u2217These authors contributed equally to this research.\n1http://wikipedia.org\nAuthors\u2019 address: Yu Gu, Aiden.Gu@microsoft.com; Robert Tinn, Robert.Tinn@microsoft.com; Hao Cheng, chehao@microsoft.com; Michael\nLucas, Michael.Lucas@microsoft.com; Naoto Usuyama, naotous@microsoft.com; Xiaodong Liu, xiaodl@microsoft.com; Tristan Naumann,\ntristan@microsoft.com; Jianfeng Gao, jfgao@microsoft.com; Hoifung Poon, hoifung@microsoft.com, Microsoft Research, One Microsoft\nWay, Redmond, WA, 98052.\n\u00a92021 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nThis is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was\npublished in , https://doi.org/10.1145/3458754.\n, Vol. 1, No. 1, Article 1. Publication date: January 2021.arXiv:2007.15779v6  [cs.CL]  16 Sep 20211:2 \u2022Gu, Tinn, Cheng, et al.\nMixed -Domain Pretraining\nVocab\nGeneral\nBERT\nBiomed\nBERT\nVocab\nBiomed\nBERT\nDomain -Specific Pretraining from ScratchText Source\nFig. 1. Two paradigms for neural language model pretraining. Top: The prevailing mixed-domain paradigm assumes that\nout-domain text is still helpful and typically initializes domain-specific pretraining with a general-domain language model and\ninherits its vocabulary. Bottom: Domain-specific pretraining from scratch derives the vocabulary and conducts pretraining\nusing solely in-domain text. In this paper, we show that for domains with abundant text such as biomedicine, domain-specific\npretraining from scratch can substantially outperform the conventional mixed-domain approach.\nIn specialized domains like biomedicine, past work has shown that using in-domain text can provide additional\ngains over general-domain language models [ 8,34,45]. However, a prevailing assumption is that out-domain text\nis still helpful and previous work typically adopts a mixed-domain approach, e.g., by starting domain-specific\npretraining from an existing general-domain language model (Figure 1 top). In this paper, we question this\nassumption. We observe that mixed-domain pretraining such as continual pretraining can be viewed as a form of\ntransfer learning in itself, where the source domain is general text, such as newswire and the Web, and the target\ndomain is specialized text such as biomedical papers. Based on the rich literature of multi-task learning and\ntransfer learning [ 4,13,38,59], successful transfer learning occurs when the target data is scarce and the source\ndomain is highly relevant to the target one. For domains with abundant unlabeled text such as biomedicine, it is\nunclear that domain-specific pretraining can benefit by transfer from general domains. In fact, the majority of\ngeneral domain text is substantively different from biomedical text, raising the prospect of negative transfer that\nactually hinders the target performance.\n, Vol. 1, No. 1, Article 1. Publication date: January 2021.Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing \u20221:3\nWe thus set out to conduct a rigorous study on domain-specific pretraining and its impact on downstream\napplications, using biomedicine as a running example. We show that domain-specific pretraining from scratch\nsubstantially outperforms continual pretraining of generic language models, thus demonstrating that the prevailing\nassumption in support of mixed-domain pretraining is not always applicable (Figure 1).\nTo facilitate this study, we", " Introduction\nThe aim of this paper is twofold. First, we aim to give an overview of the data\nissued during the BioASQ challenge in 2019. In addition, we aim to present\nthe systems that participated in the challenge and evaluate their performance.\nTo achieve these goals, we begin by giving a brief overview of the tasks, which\ntook place from February to May 2019, and the challenge's data. Thereafter, we\nprovide an overview of the systems that participated in the challenge. Detailed\ndescriptions of some of the systems are given in the workshop proceedings. The\nevaluation of the systems, which was carried out using state-of-the-art measures\nor manual assessment, is the last focal point of this paper, with remarks regarding\nthe conclusions sum up this year's challenge.\n2 Overview of the Tasks\nThe challenge comprised two tasks: (1) a large-scale biomedical semantic index-\ning task (Task 7a) and (2) a biomedical question answering task (Task 7b). In\nthis section a brief description of the tasks is provided focusing on di\u000berences\nfrom previous years and updated statistics about the corresponding datasets. A\ncomplete overview of the tasks and the challenge is presented in [58].arXiv:2006.09174v1  [cs.CL]  16 Jun 20202 A. Nentidis et al.\nTable 1. Statistics on test datasets for Task 7a.\nBatch ArticlesAnnotated\nArticlesLabels per\nArticle\n17,358 7,194 11.67\n7,166 7,021 12.95\n11,019 10,831 13.04\n5,566 5,482 12.32\n6,729 6,353 12.96\nTotal 37,838 36,881 12.31\n26,380 6,098 12.51\n6,785 6,621 12.75\n6,207 5,927 12.75\n7,382 7,079 13.00\n7,240 6,756 12.65\nTotal 33,994 32,481 12.27\n36,266 5,835 12.58\n11,455 10,386 12.86\n4,750 3,947 12.67\n7,338 5,021 12.70\n6,920 4,554 12.63\nTotal 36,729 29,743 12.14\n2.1 Large-scale semantic indexing - 7a\nIn Task 7a the goal is to classify documents from the PubMed digital library\ninto concepts of the MeSH hierarchy. Here, new PubMed articles that are not\nyet annotated by MEDLINE indexers are collected and used as test sets for\nthe evaluation of the participating systems. Similarly to task 5a and 6a, articles\nfrom all journals were included in the test data sets of task 7a. As soon as the\nannotations are available from the MEDLINE indexers, the performance of each\nsystem is calculated using standard \rat information retrieval measures, as well\nas, hierarchical ones. As in previous years, an on-line and large-scale scenario was\nprovided, dividing the task into three independent batches of 5 weekly test sets\neach. Participants had 21 hours to provide their answers for each test set. Table\n1 shows the number of articles in each test set of each batch of the challenge.\n14,200,259 articles with 12.69 labels per article, on average, were provided as\ntraining data to the participants.\n2.2 Biomedical semantic QA - 7b\nThe goal of Task 7b was to provide a large-scale question answering challenge\nwhere the systems had to cope with all stages of a question answering task for\nfour types of biomedical questions: yes/no, factoid, list and summary questions\n[5]. As in previous years, the task comprised two phases: In phase A, BioASQ\nreleased 100 questions and participants were asked to respond with relevant el-\nements from speci\fc resources, including relevant MEDLINE articles, relevantResults of the seventh edition of the BioASQ Challenge 3\nsnippets extracted from the articles, relevant concepts and relevant RDF triples.\nIn phase B, the released questions were enhanced with relevant articles and snip-\npets selected manually and the participants had to respond with exact answers ,\nas well as", " Introduction\nRecent years have featured a trend towards pre-trained language representations in NLP systems, applied in increasingly\n\ufb02exible and task-agnostic ways for downstream transfer. First, single-layer representations were learned using word\nvectors [ MCCD13 ,PSM14 ] and fed to task-speci\ufb01c architectures, then RNNs with multiple layers of representations\nand contextual state were used to form stronger representations [ DL15 ,MBXS17 ,PNZtY18 ] (though still applied to\ntask-speci\ufb01c architectures), and more recently pre-trained recurrent or transformer language models [ VSP+17] have\nbeen directly \ufb01ne-tuned, entirely removing the need for task-speci\ufb01c architectures [RNSS18, DCLT18, HR18].\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension,\nquestion answering, textual entailment, and many others, and has continued to advance based on new architectures\nand algorithms [ RSR+19,LOG+19,YDY+19,LCG+19]. However, a major limitation to this approach is that while\nthe architecture is task-agnostic, there is still a need for task-speci\ufb01c datasets and task-speci\ufb01c \ufb01ne-tuning: to achieve\nstrong performance on a desired task typically requires \ufb01ne-tuning on a dataset of thousands to hundreds of thousands\nof examples speci\ufb01c to that task. Removing this limitation would be desirable, for several reasons.\nFirst, from a practical perspective, the need for a large dataset of labeled examples for every new task limits the\napplicability of language models. There exists a very wide range of possible useful language tasks, encompassing\nanything from correcting grammar, to generating examples of an Results for SAT task.\n Figure H.3: All Related Work\nSeveral lines of work have focused on increasing parameter count and/or computation in language models as a\nmeans to improve generative or task performance. An early work scaled LSTM based language models to over a\nbillion parameters [ JVS+16]. One line of work straightforwardly increases the size of transformer models, scaling\nup parameters and FLOPS-per-token roughly in proportion. Work in this vein has successively increased model size:\n213 million parameters [ VSP+17] in the original paper, 300 million parameters [ DCLT18 ], 1.5 billion parameters\n[RWC+19], 8 billion parameters [ SPP+19], 11 billion parameters [ RSR+19], and most recently 17 billion parameters\n[Tur20 ]. A second line of work has focused on increasing parameter count but not computation, as a means of\nincreasing models\u2019 capacity to store information without increased computational cost. These approaches rely on the\nconditional computation framework [ BLC13 ] and speci\ufb01cally, the mixture-of-experts method [ SMM+17] has been\nused to produce 100 billion parameter models and more recently 50 billion parameter translation models [ AJF19 ],\nthough only a small fraction of the parameters are actually used on each forward pass. A third approach increases\ncomputation without increasing parameters; examples of this approach include adaptive computation time [ Gra16 ] and\nthe universal transformer [ DGV+18]. Our work focuses on the \ufb01rst approach (scaling compute and parameters together,\nby straightforwardly making the neural net larger), and increases model size 10x beyond previous models that employ\nthis strategy.\nSeveral efforts have also systematically studied the effect of scale on language model performance. [ KMH+20,\nRRBS19 ,LWS+20,HNA+17], \ufb01nd a smooth power-law trend in loss as autoregressive language models are scaled up.\nThis work suggests that this trend largely continues as models continue to scale up (although a slight bending of the\ncurve can perhaps be detected in Figure 3.1),", " Introduction\nSelf-supervised methods for corrupting\ndocuments for pre-training, perhaps tailoring them to\nspeci\ufb01c end tasks. Results on two standard summarization datasets. BART outperforms previous work on summarization on\ntwo tasks and all metrics, with gains of roughly 6 points on the more abstractive dataset.\non the CNN/DM summarization dataset, we hypothe-\nsised that larger pre-trained models may be better able\nto learn from this task. To help the model better \ufb01t the\ndata, we disabled dropout for the \ufb01nal 10% of training\nsteps. We use the same pre-training data as Liu et al.\n(2019), consisting of 160Gb of news, books, stories,\nand web text.\n5.2 Discriminative Tasks\nTable 2 compares the performance of BART with sev-\neral recent approaches on the well-studied SQuAD and\nGLUE tasks (Warstadt et al., 2018; Socher et al., 2013;\nDolan & Brockett, 2005; Agirre et al., 2007; Williams\net al., 2018; Dagan et al., 2006; Levesque et al., 2011).\nThe most directly comparable baseline is RoBERTa,\nwhich was pre-trained with the same resources, but\na different objective. Overall, BART performs simi-\nlarly, with only small differences between the models\non most tasks. suggesting that BART\u2019s improvements\non generation tasks do not come at the expense of clas-\nsi\ufb01cation performance.\n5.3 Generation Tasks\nWe also experiment with several text generation tasks.\nBART is \ufb01ne-tuned as a standard sequence-to-sequence\nmodel from the input to the output text. During \ufb01ne-\ntuning we use a label smoothed cross entropy loss\n(Pereyra et al., 2017), with the smoothing parameter\nset to 0.1. During generation, we set beam size as 5,\nremove duplicated trigrams in beam search, and tuned\nthe model with min-len, max-len, length penalty on the\nvalidation set (Fan et al., 2017).ConvAI2\nValid F1 Valid PPL\nSeq2Seq + Attention 16.02 35.07\nBest System 19.09 17.51\nBART 20.72 11.85\nTable 4: BART outperforms previous work on conver-\nsational response generation. Perplexities are renor-\nmalized based on of\ufb01cial tokenizer for ConvAI2.\nSummarization To provide a comparison with the\nstate-of-the-art in summarization, we present Experiments\nRecent work has shown that downstream performance\ncan dramatically improve when pre-training is scaled\nto large batch sizes (Yang et al., 2019; Liu et al., 2019)\nand corpora. To test how well BART performs in this\nregime, and to create a useful model for downstream\ntasks, we trained BART using the same scale as the\nRoBERTa model.\n5.1 Experimental Setup\nWe pre-train a large model with 12 layers in each of the\nencoder and decoder, and a hidden size of 1024. Fol-\nlowing RoBERTa (Liu et al., 2019), we use a batch size\nof 8000, and train the model for 500000 steps. Docu-\nments are tokenized with the same byte-pair encoding\nas GPT-2 (Radford et al., 2019). Based on the background knowledge (for example, cor-\nrectly completing names, or inferring that PG&E oper-\nates in California). In the \ufb01rst example, inferring that\n\ufb01sh are protecting reefs from global warming requires\nnon-trivial inference from the text. However, the claim\nthat the work was published in Science is not supported\nby the source.\nThese samples demonstrate that the BART pretrain-\ning has learned a strong combination of natural lan-\nguage understanding and generation.\n7 Related Work\nEarly Conclusions\nWe introduced BART, a pre-training approach that\nlearns to map corrupted documents to the original.\nBART achieves similar performance to RoBERTa on\ndiscriminative tasks, while achieving new state-of-the-\nart References\nEneko Agirre, Llu\u2019is M\u2018arquez, and Richard Wicen-\ntowski (eds.). Proceedings of the Fourth Interna-\ntional Workshop on Semantic Evaluations (SemEval-\n2007) . Association for Computational Linguistics,\nPrague, Czech Republic, June", " Introduction\nTraining a machine learning model to perform natural language processing (NLP) tasks\noften requires that the model can process text in a way that is amenable to downstream\nlearning. This can be loosely viewed as developing general-purpose knowledge that allows\nthe model to \u201cunderstand\u201d text. This knowledge can range from low-level (e.g. the spelling\n\u2217.Equalcontribution. Adescriptionofeachauthor\u2019scontributionisavailableinAppendixA.Correspondence\ntocraffel@gmail.com .\n1.https://github.com/google-research/text-to-text-transfer-transformer\n\u00a92020 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei\nLi, and Peter J. Liu.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ . Attribution requirements are provided at\nhttp://jmlr.org/papers/v21/20-074.html .arXiv:1910.10683v4  [cs.LG]  19 Sep 2023Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nor meaning of words) to high-level (e.g. that a tuba is too large to fit in most backpacks).\nIn modern machine learning practice, providing this knowledge is rarely done explicitly;\ninstead, it is often learned as part of an auxiliary task. For example, a historically common\napproach is to use word vectors (Mikolov et al., 2013b,a; Pennington et al., 2014) to map\nword identities to a continuous representation where, ideally, similar words map to similar\nvectors. These vectors are often learned through an objective that, for example, encourages\nco-occurring words to be positioned nearby in the continuous space (Mikolov et al., 2013b).\nRecently, it has become increasingly common to pre-train the entire model on a data-rich\ntask. Ideally, this pre-training causes the model to develop general-purpose abilities and\nknowledge that can then be transferred to downstream tasks. In applications of transfer\nlearning to computer vision (Oquab et al., 2014; Jia et al., 2014; Huh et al., 2016; Yosinski\net al., 2014), pre-training is typically done via supervised learning on a large labeled data set\nlike ImageNet (Russakovsky et al., 2015; Deng et al., 2009). In contrast, modern techniques\nfor transfer learning in NLP often pre-train using unsupervised learning on unlabeled data.\nThis approach has recently been used to obtain state-of-the-art methods in natural\nlanguage processing , 2013.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. MASS: Masked sequence to\nsequence pre-training for language generation. arXiv preprint arXiv:1905.02450 , 2019.\n65Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of\nMachine Learning Research , 2014.\nSandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J. Pal. Learning\ngeneral purpose distributed sentence representations via large scale multi-task learning.\narXiv preprint arXiv:1804.00079 , 2018.\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence learning with neural\nnetworks. In Advances in neural information processing systems , 2014.\nRichard S. Sutton. The bitter lesson. http://www.incompleteideas.net/IncIdeas/\nBitterLesson.html , 2019.\nWilson L. Taylor. \u201cCloze procedure\u201d: A new tool for measuring readability. Journalism\nBulletin, 1953.\nTrieu H. Trinh and Quoc V. Le. A simple method for commonsense reasoning. arXiv preprint\narXiv:1806.02847 , 2018.\nAdam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip\nBachman, and Kaheer Suleman. NewsQA: A machine comprehension dataset. arXiv\npreprint arXiv:1611.09830 , 2016.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural\ninformation processing systems , 2017.\nElena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of representations\nin the transformer: A study with machine translation and language modeling", " Introduction\nDeep Learning (DL) has made huge progress from academia to industry in the last decade. However,\nthe process for developing, debugging, and deploying DL software is signi\ufb01cantly more cumbersome\nthan other complex software systems. The primary abstraction in all DL frameworks is a multidimen-\nsional tensor, typically without any dimensional semantics, e.g. whether the \ufb01rst dimension represents\nthe batch size or something else. The lack of semantics and a type system complicates models\u2019 re-use\nand makes it dif\ufb01cult to build DL systems [ 6]. It can be challenging to reuse components of a complex\nDL model across different use cases or developers. The typical approach for reusing and sharing\ncomponents is based on open-source pre-trained models. Combining and chaining these models\ntogether usually requires making changes to the code, which, in turn, requires debugging. This is\nespecially tricky when the models come from different developers or use cases.\nAnother complicating factor is that model con\ufb01gurations are usually de\ufb01ned via a Python script\ninstead of a data model. This leads to a blurring of lines between what would otherwise be separate\nconcerns \u2013 computational performance, architecture de\ufb01nition, training procedure, visualization and\nanalysis \u2013 all mixed together into the same Python script that is dif\ufb01cult to disentangle, debug, or\nreuse in other contexts.\nAll of these challenges \u2013 separation of concerns, system decomposition with well-de\ufb01ned veri\ufb01able\ninterfaces, and code re-usability \u2013 are already well-explored in the world of software engineering.\nMany of the modern techniques any software developer takes for granted were originally invented in\norder to address precisely these issues.\n1Available at: https://github.com/NVIDIA/NeMo\nPreprint. Under review.arXiv:1909.09577v1  [cs.LG]  14 Sep 2019We seek to translate common software engineering practices developed to address those issues into\nthe context of developing AI-based applications. Speci\ufb01cally, we focus on the problems of:\n\u000fdecomposition of a complex system into functional blocks with well-de\ufb01ned interfaces;\n\u000fstatic type checking to ensure API compliance and to catch type-mismatch bugs;\n\u000fseparation of concerns between model architecture, training procedure, DL framework,\noptimization algorithm;\n\u000fhigh performance training by supporting modern ef\ufb01cient hardware features; and\n\u000freusable pre-built components that can be easily combined in novel ways.\nNeMo consists of: (1) NeMo Core : fundamental building blocks for all neural models and type\nsystem and (2) NeMo collections : pre-built neural modules for particular domains such as automatic\nspeech recognition (ASR), and natural language processing (NLP).\n2 Related work\nIn recent years, there have been a number of high-level toolkits aimed to help users to achieve certain\ngoals easier then by purely using DL frameworks such as TensorFlow [8] and PyTorch [17].\nThese toolkits could be loosely classi\ufb01ed into two main groups: (1) higher-level neural network APIs\nsuch as Keras[ 11], Sonnet [ 18], PyTorch Ignite [ 3], PyTorch Lightning [ 4] and (2) con\ufb01guration-\ndriven tookits such as Tensor2Tensor [ 20], Ludwig [ 5], OpenSeq2Seq [ 13], FairSeq [ 16], OpenNMT\n[12], Seq2Seq [9] and many others.\nConceptually, NeMo Core is closer to the \ufb01rst group. It allows users to express models with arbitrary\nsets of components and hides away details of training and evaluation loops while still retaining a\nlot of \ufb02exibility. NeMo collections, on the other hand, are closer to the second group. They contain\ncommon modules that can be re-used in various scenarios. For example, it is straightforward in\nNeMo to de\ufb01ne templates", " Introduction\u201d, \u201c Methods\n4.1 Fine-tuning BioBERT\nWe \ufb01ne-tune BioBERT (Lee et al., 2019) on Pub-\nMedQA as a baseline. BioBERT is initialized\nwith BERT (Devlin et al., 2018) and further pre-\ntrained on PubMed abstracts and PMC7articles.\nExpectedly, it vastly outperforms BERT in vari-\nous biomedical NLP tasks. We denote the original\ntransformer weights of BioBERT as \u00120.\nWhile \ufb01ne-tuning, we feed PubMedQA ques-\ntions and contexts (or long answers), separated\n7https://www.ncbi.nlm.nih.gov/pmc/by the special [SEP] token, to BioBERT. The\nyes/no/maybe labels are predicted using the spe-\ncial[CLS] embedding using a softmax function.\nCross-entropy loss of predicted and true label dis-\ntribution is denoted as LQA.\n4.2 Long Answer as Additional Supervision\nUnder reasoning-required setting, long answers\nare available in training but not inference phase.\nWe use them as an additional signal for training:\nsimilar to Ma et al. (2018) regularizing neural ma-\nchine translation models with binary bag-of-word\n(BoW) statistics, we \ufb01ne-tune BioBERT with an\nauxiliary task of predicting the binary BoW statis-\ntics of the long answers, also using the special\n[CLS] embedding. We minimize binary cross-\nentropy loss of this auxiliary task:\nLBoW=\u00001\nNX\nibilog^bi+ (1\u0000bi)log(1\u0000^bi)\nwherebiand^biare ground-truth and predicted\nprobability of whether token iis in the long an-\nswers (i.e.:bi2f0;1gand^bi2[0;1]), andNis\nthe BoW vocabulary size. The total loss is:\nL=LQA+\fLBoWBootstrapping(Reasoning-free)Training(Reasoning-required)(qA,cA),lA(qU,cU),lUpseudo(qL,cL),lL(qA,aA),lA(qL,aL),lL(qU,aU)\u27130\u27130\u2713I\u2713II\u2713F\u2713B1\u2713B2Fine-tuningSupervisionPseudo-labelingeq. (1)eq. (2)eq. (3)eq. (5)eq. (6)eq. (4)Phase IPhase IIFinal PhaseFigure 5: Multi-phase \ufb01ne-tuning architecture. Nota-\ntions and equations are described in x4.3.\nIn reasoning-free setting which we use for boot-\nstrapping, the regularization coef\ufb01cient \fis set to\n0 because long answers are directly used as input.\n4.3 Multi-phase Fine-tuning Schedule\nSince PQA-A and PQA-U have different proper-\nties from the ultimate test set of PQA-L, BioBERT\nis \ufb01ne-tuned in a multi-phase style on different\nsubsets. Fig. 5 shows the architecture of this train-\ning schedule. We use q,c,a,lto denote ques-\ntion, context, long answer and yes/no/maybe label\nof instances, respectively. Their source subsets are\nindexed by the superscripts of A for PQA-A, U for\nPQA-U and L for PQA-L.\nPhase I Fine-tuning on PQA-A: PQA-A is au-\ntomatically collected whose questions and labels\nare arti\ufb01cially generated. As a result, questions\nof PQA-A might differ a lot from those of PQA-\nU and PQA-L, and it only has yes/no labels with a\nvery imbalanced distribution (92.8% yes v.s. 7.2%\nno). Despite these drawbacks, PQA-A has sub-\nstantial training instances so models could still\nbene\ufb01t from it as a pre-training step.\nThus, in Phase I of multi-phase \ufb01ne-tuning, we\ninitialize BioBERT with \u00120, and \ufb01ne-tune it on\nPQA-A using question and context as input:\n\u0012I argmin\u0012L(BioBERT \u0012(qA;cA);lA)(1)\nPhase II Fine-tuning on Bootstrapped PQA-U:\nTo fully utilize the unlabeled instances in PQA-U,\nwe exploit the easiness of reasoning-free setting to\npseudo-label these instances with a bootstrapping\nstrategy: \ufb01rst, we initialize BioBERT with \u00120, and\n\ufb01ne-tune it on PQA-A using question and long an-\nswer (reasoning-free),\n\u0012B1 argmin\u0012L(BioBERT \u0012(qA;aA);lA)(2)then we further \ufb01ne-tune BioBERT \u0012B1on PQA-\nL, also under the reasoning-free setting:\n\u0012B2 argmin\u0012L(BioBERT \u0012(qL;aL);lL)(3)\nWe pseudo-label PQA-U instances using the\nmost con\ufb01dent predictions of BioBERT \u0012B2for\neach class. Con\ufb01dence is simply de\ufb01ned by the\ncorresponding softmax probability and then we la-\nbel a subset which has the same proportions of\nyes/no/maybe labels as those in the PQA-L:\nlU\npseudo BioBERT \u0012B2(qU;aU) (4)\nIn phase II, we \ufb01ne-tune BioBERT \u0012Ion the\nbootstrapped PQA-U using question and context\n(under reasoning-required setting):\n\u0012II argmin\u0012L(BioBERT \u0012(qU;cU);lU\npseudo )\n(5)\nFinal Phase Fine-tuning on PQA-L: In the \ufb01-\nnal phase, we \ufb01ne-tune BioBERT \u0012IIon PQA-L:\n\u0012F argmin\u0012L(BioBERT \u0012(qL;cL);lL)(6)\nFinal predictions on instances of PQA-L valida-\ntion and test sets are made using BioBERT \u0012F:\nlpred=BioBERT \u0012F(qL;cL)\n4.4 Compared Models\nMajority: The", " Introduction to the bio-entity recognition task at\nJNLPBA. In: Proceedings of the International Joint Workshop on Natural\nLanguage Processing in Biomedicine and its Applications\n(NLPBA/BioNLP), Geneva, Switzerland . pp. 73\u201378. COLING. https://\nwww.aclweb.org/anthology/W04-1213 .\nKrallinger,M. et al. (2015) The chemdner corpus of chemicals and drugs and\nits annotation principles. J. Cheminform .,7.\nKrallinger,M. et al. (2017) Overview of the BioCreative VI chemical-protein\ninteraction track. In: Proceedings of the BioCreative VI Workshop,\nBethesda, MD, USA , pp. 141\u2013146. https://academic.oup.com/database/art\nicle/doi/10.1093/database/bay073/5055578 .\nLi,J.et al. (2016) Biocreative V CDR task corpus: a resource for chemical dis-\nease relation extraction. Database ,2016\n.\nLim,S. and Kang,J. (2018) Chemical\u2013gene relation extraction using recursive\nneural network. Database ,2018 .\nLin,C. et al . (2019) A bert-based universal model for both within-and\ncross-sentence clinical temporal relation extraction. In: Proceedings of the\n2nd Clinical Natural Language Processing Workshop, Minneapolis, MN,\nUSA. pp. 65\u201371. Association for Computational Linguistics. https://www.\naclweb.org/anthology/W19-1908 .\nLou,Y. et al. (2017) A transition-based joint model for disease named entity\nrecognition and normalization. Bioinformatics ,33, 2363\u20132371.\nLuo,L. et al. (2018) An attention-based BiLSTM-CRF approach to document-level\nchemical named entity recognition. Bioinformatics ,34, 1381\u20131388.\nMcCann,B. et al. (2017) Learned in translation: contextualized word vectors.\nIn: Guyon,I. et al. (eds.), Advances in Neural Information Processing\nSystems 30 , Curran Associates, Inc., pp. 6294\u20136305. http://papers.nips.cc/\npaper/7209-learned-in-translation-contextualized-word-vectors.pdf .\nMikolov,T. et al. (2013) Distributed representations of words and phrases and\ntheir compositionality. In: Burges,C.J.C. (eds.), Advances in Neural\nInformation Processing Systems 26 , Curran Associates, Inc., pp.\n3111\u20133119. http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf .Mohan,S. and Li,D. (2019) Medmentions: a large biomedical corpus anno-\ntated with UMLS concepts. arXiv preprint arXiv: 1902.09476 .\nPa\ufb01lis,E. et al. (2013) The species and organisms resources for fast and accur-\nate identi\ufb01cation of taxonomic names in text. PLoS One ,8, e65390.\nPennington,J. et al. (2014) Glove: Global vectors for word representation. In:\nProceedings of the 2014 Conference on Empirical abstract/doi/10.1093/bioinformatics/btz682/5566506 by guest on 18 October 2019 Materials and methods\nBioBERT basically has the same structure as BERT. We briefly dis-\ncuss the recently proposed BERT, and then we describe in detail the\npre-training and fine-tuning process of BioBERT.\n3.1 BERT: bidirectional encoder representations from\ntransformers\nLearning word representations from a large amount of unannotated\ntext is a long-established method. While previous models (e.g.\nWord2Vec ( Mikolov et al. , 2013 ), GloVe ( Pennington et al. , 2014 ))\nfocused on learning context independent word representations, re-cent works have focused on learning context dependent word repre-\nsentations. For instance, ELMo ( Peters et al. , 2018 ) uses a\nbidirectional language model, while CoVe ( McCann et al. , 2017 )\nuses machine translation to embed context information into word\nrepresentations.\nBERT ( Devlin et al. , 2019 ) is a contextualized word representa-\ntion model that is based on a masked language model and pre-trained using bidirectional transformers ( Vaswani et al. , 2017 ). Due\nto the nature of language modeling where future words cannot be\nseen, previous language models were limited to a combination of\ntwo unidirectional language models (i.e. left-to-right and right-to-\nleft). BERT uses a masked language model that predicts randomly\nmasked words in a sequence, and hence can be used for learning bi-\ndirectional representations. Also, it obtains state-of-the-art perform-\nance on most NLP tasks, while requiring minimal task-specific\narchitectural modification. According to the authors of BERT,incorporating information from bidirectional representations, rather\nthan unidirectional representations, is crucial for representing words\nin natural language. We hypothesize that such", " Introduction\nThe discovery of new molecules for drugs and materials can bring enormous societal and technological\nprogress, potentially curing rare diseases and providing a pathway for personalized precision medicine\n[1]. However, complete exploration of the huge space of potential chemicals is computationally\nintractable; it has been estimated that the number of pharmacologically-sensible molecules is in\nthe order of 1023to1080compounds [ 2,3]. Often, this search is constrained based on already\ndiscovered structures and desired qualities such as solubility or toxicity. There have been many\napproaches to exploring the chemical space in silico andin vitro , including high throughput screening,\ncombinatorial libraries, and evolutionary algorithms [ 4\u20137]. Recent works demonstrated that machine\nlearning methods mostly utilize molecular descriptors extracted from such graphs.\nDeep learning models, however, can learn from graphs directly with models such as Graph Con-\nvolutional Networks [ 51], Weave Networks [ 26], and Message Passing Networks [ 52]. Molecular\ngraph can also be represented as adjacency matrix and node feature matrix; this approach has been\nsuccessfully employed in the MolGAN model [ 33] for the QM9 dataset [ 53]. Other approaches such\nas Junction Tree V AE [54] process molecules in terms of their subgraphs.\n4 Metrics\nIn this section, we propose a set of metrics to assess the quality of generative models. The proposed\nmetrics detect common issues in generative models such as over\ufb01tting, imbalance of frequent\nstructures or mode collapse. Each metric depends on a generated set Gand a test (reference) set R.\nWe compute all metrics (except for validity) only for valid molecules from the generated set. We\nsuggest generating 30;000molecules and obtaining Gas valid molecules from this set.\n3Fraction of valid (Valid) and unique (Unique@k) molecules report validity and uniqueness of\nthe generated SMILES strings. We de\ufb01ne validity using RDKit\u2019s molecular structure parser that\nchecks atoms\u2019 valency and consistency of bonds in aromatic rings. In the experiments, we report\nIntDiv 1(G)and IntDiv 2(G). Limits of this metric are [0;1].\nFr\u00e9chet ChemNet Distance (FCD) [60] is calculated using activations of the penultimate layer\nof a deep neural network ChemNet trained to predict biological activities of drugs. We compute\nactivations for canonical SMILES representations of molecules. These activations capture both\nchemical and biological properties of the compounds. For two sets of molecules GandR, FCD is\nde\ufb01ned as\nFCD(G;R) =k\u0016G\u0000\u0016Rk2+ Tr\u0010\n\u0006G+ \u0006R\u00002(\u0006G\u0006R)1=2\u0011\n(5)\nwhere\u0016G,\u0016Rare mean vectors and \u0006G,\u0006Rare full covariance matrices of activations for molecules\nfrom setsGandRrespectively. FCD correlates with other metrics. For example, if the gener-\nated structures are not diverse enough (low IntDiv p) or the model produces too many duplicates\n(low uniqueness), FCD will decrease, since the variance is smaller. We suggest using FCD for\nhyperparameter tuning and \ufb01nal model selection. Values of this metric are non-negative, lower is\nbetter.\nProperties distribution is a useful tool for visually assessing the generated structures. To quanti-\ntatively compare the distributions in the generated and test sets, we compute a 1D Wasserstein-1\ndistance between property distributions of generated and test sets. We also visualize a kernel density\nestimation of these distributions in the Experiments section. We use the following four properties:\n\u2022Molecular weight (MW) : the sum of atomic weights in a molecule. By plotting histograms\nof molecular weight for the generated and test sets, one can judge if a generated set is biased\ntowards lighter or heavier molecules.\n\u2022LogP : the octanol-water partition", " Introduction\nto methodology and encoding rules. Journal of chemical information and computer\nsciences 1988,28, 31\u201336.\n(33) Weininger, D.; Weininger, A.; Weininger, J. L. SMILES. 2. Algorithm for generation\nof unique SMILES notation. Journal of chemical information and computer sciences\n1989,29, 97\u2013101.\n(34) IBM RXN for Chemistry. https://rxn.res.ibm.com .\n(35) Lowe, D. M. Extraction of chemical structures and reactions from the literature. Ph.D.\nthesis, University of Cambridge, 2012.\n(36) Nextmove Software Pistachio. http://www.nextmovesoftware.com/pistachio.html .\n(37) Schneider, N.; Lowe, D. M.; Sayle, R. A.; Tarselli, M. A.; Landrum, G. A. Big data\nfrom pharmaceutical patents: a computational analysis of medicinal chemists\u2019 bread\nand butter. J. Med. Chem. 2016,59, 4385\u20134402.\n(38) Schneider, N.; Stie\ufb02, N.; Landrum, G. A. What\u2019s what: The (nearly) de\ufb01nitive guide\nto reaction role assignment. Journal of chemical information and modeling 2016,56,\n2336\u20132346.\n21(39) Landrum, G. et al. Rdkit/Rdkit: 2017_09_1 (Q3 2017) Release. 2017; https:\n//zenodo.org/record/1004356#.Wd3LDY6l2EI .\n(40) Gehring, J.; Auli, M.; Grangier, D.; Yarats, D.; Dauphin, Y. N. Convolutional sequence\nto sequence learning. arXiv preprint arXiv:1705.03122 2017,\n(41) Klein, G.; Kim, Y.; Deng, Y.; Senellart, J.; Rush, A. M. OpenNMT: Open-Source\nToolkit for Neural Machine Translation. Proc. ACL. 2017.\n(42) Annotated Transformer. http://nlp.seas.harvard.edu/2018/04/03/attention.\nhtml.\n(43) Szegedy, C.; Vanhoucke, V.; Io\ufb00e, S.; Shlens, J.; Wojna, Z. Rethinking the inception\narchitecture for computer vision. Proceedings of the IEEE conference on computer\nvision and pattern recognition. 2016; pp 2818\u20132826.\n(44) Kingma, D. P.; Ba, J. Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980 2014,\n(45) Molecular Transformer. https://github.com/pschwllr/MolecularTransformer .\n(46) Bjerrum, E. J. SMILES enumeration as data augmentation for neural network modeling\nof molecules. arXiv preprint arXiv:1703.07076 2017,\n(47) Liu, Y.; Zhou, L.; Wang, Y.; Zhao, Y.; Zhang, J.; Zong, C. A Comparable Study on\nModel Averaging, Ensembling and Reranking in NMT. CCF International Conference\non Natural Language Processing and Chinese Computing. 2018; pp 299\u2013308.\n(48) Papineni, K.; Roukos, S.; Ward, T.; Zhu, W.-J. BLEU: a method for automatic eval-\nuation of machine translation. Proceedings of the 40th annual meeting on association\nfor computational linguistics. 2002; pp 311\u2013318.\n22(49) Satoh, H.; Funatsu, K. SOPHIA, a knowledge base-guided reaction prediction system-\nutilization of a knowledge base derived from a reaction database. Journal of chemical\ninformation and computer sciences 1995,35, 34\u201344.\n(50) Segler, M. H.; Preuss, M.; Waller, M. P. Planning chemical syntheses with deep neural\nnetworks and symbolic AI. Nature 2018,555, 604.\n23", " Introduction\nIn 2015 alone, about 100 manuscripts describ-\ning randomized controlled trials (RCTs) for med-\nical interventions were published every day . It is\nthus practically impossible for physicians to know\nwhich is the best medical intervention for a given\npatient group and condition (Borah et al., 2017;\nFraser and Dunstan, 2010; Bastian et al., 2010).\nThis inability to easily search and organize the\npublished literature impedes the aims of evidence\nbased medicine (EBM), which aspires to inform\npatient care using the totality of relevant evidence.\n\u0003* now at Google Inc.Computational methods ,\n8(3):366\u2013386.An T Nguyen, Byron C Wallace, Junyi Jessy Li, Ani\nNenkova, and Matthew Lease. 2017. Aggregating\nand predicting sequence labels from crowd anno-\ntations. In Proceedings of the conference. Associ-\nation for Computational Linguistics. Meeting , vol-\nume 2017, page 299. NIH Public Access.\nScott Novotney and Chris Callison-Burch. 2010.\nCheap, fast and good enough: Automatic speech\nrecognition with non-expert transcription. In Hu-\nman Language Technologies: The 2010 Annual\nConference of the North American Chapter of the\nAssociation for Computational Linguistics , pages\n207\u2013215. Association for Computational Linguis-\ntics.\nMarta Sabou, Kalina Bontcheva, and Arno Scharl.\n2012. Crowdsourcing research opportunities:\nlessons from natural language processing. In Pro-\nceedings of the 12th International Conference on\nKnowledge Management and Knowledge Technolo-\ngies, page 17. ACM.\nHarrisen Scells, Guido Zuccon, Bevan Koopman, An-\nthony Deacon, Leif Azzopardi, and Shlomo Geva.\n2017. A test collection for evaluating retrieval of\nstudies for inclusion in systematic reviews. In Pro-\nceedings of the 40th International ACM SIGIR Con-\nference on Research and Development in Informa-\ntion Retrieval , pages 1237\u20131240. ACM.\nPontus Stenetorp, Sampo Pyysalo, Goran Topi \u00b4c,\nTomoko Ohta, Sophia Ananiadou, and Jun\u2019ichi Tsu-\njii. 2012. Brat: a web-based tool for nlp-assisted\ntext annotation. In Proceedings of the Demonstra-\ntions at the 13th Conference of the European Chap-\nter of the Association for Computational Linguistics ,\npages 102\u2013107. Association for Computational Lin-\nguistics.\nRodney L Summerscales, Shlomo Argamon, Shangda\nBai, Jordan Hupert, and Alan Schwartz. 2011. Au-\ntomatic summarization of results from clinical trials.\nInBioinformatics and Biomedicine (BIBM), 2011\nIEEE International Conference on , pages 372\u2013377.\nIEEE.\nJames Thomas, Anna Noel-Storr, Iain Marshall, By-\nron Wallace, Steven McDonald, Chris Mavergames,\nPaul Glasziou, Ian Shemilt, Anneliese Synnot, Tari\nTurner, et al. 2017. Living systematic reviews: 2.\ncombining human and machine effort. Journal of\nclinical epidemiology , 91:31\u201337.\nGuy Tsafnat, Adam Dunn, Paul Glasziou, Enrico\nCoiera, et al. 2013. The automation of systematic\nreviews. BMJ , 346(f139):1\u20132.\nMathias Verbeke, Vincent Van Asch, Roser Morante,\nPaolo Frasconi, Walter Daelemans, and Luc\nDe Raedt. 2012. A statistical relational learning ap-\nproach to identifying evidence based medicine cate-\ngories. In Proceedings of the Joint Conference on\nEmpirical Related Work\nWe brie\ufb02y review two lines of research relevant to\nthe current effort: work on NLP to facilitate EBM,\nand research in crowdsourcing for NLP.\n2.1 NLP for EBM\nPrior work on NLP for EBM has been limited\nby the availability of only small corpora, which\nhave typically provided on the order of a cou-\nple hundred annotated abstracts or articles for\nvery complex information extraction tasks. For\nexample, the ExaCT system (Kiritchenko et al.,\n2010) applies rules to extract 21 aspects of the\nreported trial. It was developed and validated on\na dataset of 182 marked full-text articles. The\nACRES system (Summerscales et al., 2011) pro-\nduces summaries of several trial characteristic,\nand was trained on 263 annotated abstracts. Hint-\ning at more challenging tasks that can build upon\nfoundational information extraction, Alamri and\nStevenson (2015) developed abstract, and assignPrecision Recall F-1\nParticipants 0.39 0.52 0.44\nInterventions 0.41 0.50", " Introduction\nRecurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht\u22121and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [ 21] and conditional\ncomputation [ 32], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3 Model Architecture\nMost competitive neural sequence transduction", " Introduction\nOverlap between chemistry and statistical learning has had a long history. The \feld of chem-\ninformatics has been utilizing machine learning introduction of the ImageNet benchmark in 2009 has triggered a series of\nbreakthroughs in computer vision, and in particular has facilitated the rapid development of\ndeep convolutional networks. The ILSVRC, an annual contest held by the ImageNet team,26\ndraws considerable attention from the community, and greatly stimulates collaborations and\ncompetitions across the \feld. The contest has given rise to a series of prominent machine\nlearning models such as AlexNet,27GoogLeNet,28ResNet29which have had broad impact on\nthe academic and industrial computer science communities. We hope that MoleculeNet will\ntrigger similar breakthroughs by serving as a platform for the wider community to develop\nand improve models for learning molecular properties.\n3In particular, MoleculeNet contains data on the properties of over 700,000 compounds.\nAll datasets have been curated and integrated into the open source DeepChem package.30\nUsers of DeepChem can easily load all MoleculeNet benchmark data through provided library\ncalls. MoleculeNet also contributes high quality implementations of well known (bio)chemical\nfeaturization results.\nNote that the original paper trained a single model for each task in the qm9 dataset.\nHere we only picked one representative task to compare.\nMAE in eV:\n\u000fOriginal result: 0 :0544\n\u000fReimplementation: 0 :0997 for valid subset, 0 :101 for test subset\n57In\ruence Relevance Voting\nWe evaluate the model on the HIV dataset, using 80/10/10 random train, valid, test split-\nting. The original paper reported performance under 10-fold cross validation.75\nROC-AUC:\n\u000fOriginal result: 0 :845\n\u000fReimplementation: 0 :840 for valid subset, 0 :852 for test subset related work section will review prior work in the chemistry community on gather-\ning curated datasets and discuss how MoleculeNet di\u000bers from these previous e\u000borts. The conclusions about the algorithms and datasets considered. Related Work\nMoleculeNet draws upon a broader movement within the chemical community to gather large\nsources of curated data. PubChem34and PubChem BioAssasy35gather together thousands\nof bioassay experiments focusing on how variable size of training set a\u000bect model\nperformances.(Tox21, FreeSolv and QM7) Details will be presented in the following texts.\n28Figure 7: Benchmark performances for biophysics tasks: PCBA , 4 models are evaluated by\nAUC-PRC on random split; MUV , 8 models are evaluated by AUC-PRC on random split;\nHIV , 8 models are evaluated by AUC-ROC on sca\u000bold split; BACE , 9 models are evaluated\nby AUC-ROC on sca\u000bold split. For AUC-ROC and AUC-PRC, higher value indicates better\nperformance(to the right).\n29Figure 8: Benchmark performances for physiology tasks: ToxCast , 8 models are evaluated\nby AUC-ROC on random split; Tox21 , 9 models are evaluated by AUC-ROC on random\nsplit; BBBP , 9 models are evaluated by AUC-ROC on sca\u000bold split; SIDER , 9 models\nare evaluated by AUC-ROC on random split. For AUC-ROC, higher value indicates better\nperformance(to the right).\n30Figure 9: Benchmark performances for physiology tasks: ClinTox , 9 models are evaluated\nby AUC-ROC on random split.\nPhysiology and Biophysics Tasks\nTables 5, 6 and Figures 7, 8, 9 report AUC-ROC or AUC-PRC Appendix.\nWe measured model running time of Tox21, MUV, QM8 and Lipophicility on a single\nnode in Stanford's GPU clusters(CPU: Intel Xeon E5-2640 v3 @2.60 GHz, GPU: NVIDIA\nTesla K80), abstract information of the graph, then the readout\nphase is responsible for mapping the graph to its properties.\nHere we reimplemented the best-performing model in the", " Introduction to\nmethodology and encoding rules. J. Chem. Inf. Model. 1988,28, 31\u201336.\n(27)Heller, S.; McNaught, A.; Stein, S.; Tchekhovskoi, D.; Pletnev, I. InChI - the worldwide\nchemical structure identi\ufb01er standard. J. Cheminf. 2013,5, 7.\n17(28)RDKit: Open-source cheminformatics. http://www.rdkit.org , [Online; accessed 11-\nApril-2017].\n(29) Kingma, D. P.; Welling, M. Auto-encoding variational bayes. 2013,\n(30)Ramakrishnan, R.; Dral, P. O.; Rupp, M.; Von Lilienfeld, O. A. Quantum chemistry\nstructures and properties of 134 kilo molecules. Scienti\ufb01c data 2014,1, 140022.\n(31)Irwin, J. J.; Sterling, T.; Mysinger, M. M.; Bolstad, E. S.; Coleman, R. G. ZINC: A Free\nTool to Discover Chemistry for Biology. J. Chem. Inf. Model. 2012,52, 1757\u20131768.\n(32)Aggarwal, C. C.; Hinneburg, A.; Keim, D. A. Database Theory \u2014 ICDT 2001: 8th\nInternational Conference London, UK, January 4\u20136, 2001 Proceedings ; Springer, Berlin,\nHeidelberg, 2001; pp 420\u2013434.\n(33)Domingos, P.; Pedro, A few useful things to know about machine learning. Communica-\ntions of the ACM 2012,55, 78.\n(34) White, T. Sampling Generative Networks. 2016,\n(35)Wildman, S. A.; Crippen, G. M. Prediction of Physicochemical Parameters by Atomic\nContributions. J. Chem. Inf. Comput. Sci. 1999,39, 868\u2013873.\n(36)Ertl, P.; Schu\ufb00enhauer, A. Estimation of synthetic accessibility score of drug-like\nmolecules based on molecular complexity and fragment contributions. J. Cheminf. 2009,\n1, 1\u201311.\n(37)Bickerton, G. R.; Paolini, G. V.; Besnard, J.; Muresan, S.; Hopkins, A. L. Quantifying\nthe chemical beauty of drugs. Nat. Chem. 2012,4, 90\u201398.\n(38)E-molecules. https://www.emolecules.com/info/plus/download-database , [On-\nline; accessed 22-July-2017].\n18(39)Wu, Z.; Ramsundar, B.; Feinberg, E. N.; Gomes, J.; Geniesse, C.; Pappu, A. S.;\nLeswing, K.; Pande, V. MoleculeNet: A Benchmark for Molecular Machine Learning.\narXiv:1703.00564 2017,\n(40)Rasmussen, C. E.; Williams, C. K. Gaussian processes for machine learning ; MIT press\nCambridge, 2006; Vol. 1.\n(41)Kusner, M. J.; Paige, B.; Hern\u00e1ndez-Lobato, J. M. Grammar Variational Autoencoder.\narXiv:1703.01925 2017,\n(42)Janz, D.; van der Westhuizen, J.; Hern\u00e1ndez-Lobato, J. M. Actively Learning what\nmakes a Discrete Sequence Valid. 2017,\n(43)Guimaraes, G. L.; Sanchez-Lengeling, B.; Farias, P. L. C.; Aspuru-Guzik, A. Objective-\nReinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models.\narXiv:1705.10843 2017,\n(44)Sanchez-Lengeling, B.; Outeiral, C.; Guimaraes, G. L.; Aspuru-Guzik, A. Optimizing\ndistributions over molecular space. An Objective-Reinforced Generative Adversarial\nNetwork for Inverse-design Chemistry (ORGANIC). 2017,\n(45)Sutskever, I.; Vinyals, O.; Le, Q. V. Sequence to sequence learning with neural networks.\nAdvances in neural information processing systems. 2014; pp 3104\u20133112.\n(46)Kalchbrenner, N.; Grefenstette, E.; Blunsom, P. A Convolutional Neural Network for\nModelling Sentences. Proceedings of the 52nd Annual Meeting of the Association for\nComputational Linguistics 2014,\n(47)Chung, J.; G\u00fcl\u00e7ehre, \u00c7.; Cho, K.; Bengio, Y. Empirical Evaluation of Gated Recurrent\nNeural Networks on Sequence Modeling. CoRR 2014,abs/1412.3555 .\n(48)Williams, R. J.; Zipser, D. A Learning Algorithm for Continually Running Fully Recur-\nrent Neural Networks. Neural Comput. 1989,1, 270\u2013280.\n19(49) Chollet, F. keras. https://github.com/fchollet/keras , 2015.\n(50)Abadi, M. et al. TensorFlow: A system for large-scale machine learning. 12th USENIX\nSymposium on Operating Systems Design and Implementation (OSDI 16). 2016; pp\n265\u2013283.\n20Supplementary Materials\nThe code and full training data sets will be made available at https://github.com/\naspuru-guzik-group/chemical_vae\nTable 3: Percentage of successfully decoding of latent representation after 1000 attempts for\n1000 molecules from the traning set, 1000 validation molecules randomly chosen from ZINC\nand a 1000 validation molecules randomly chosen from eMolecules. Both VAEs perform\nvery well for training data, and they are well transferable within molecules of the same class\noutside the training data, as evidence by the good validation performance of the ZINC VAE\nand the underperformance of the QM9 VAE against", " Introduction to the conll-2003 shared task:\nLanguage-independent named entity recognition. In\nCoNLL .\nJoseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.\nWord representations: A simple and general method\nfor semi-supervised learning. In Proceedings of the\n48th Annual Meeting of the Association for Compu-\ntational Linguistics , ACL \u201910, pages 384\u2013394.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , pages 6000\u20136010.\nPascal Vincent, Hugo Larochelle, Yoshua Bengio, and\nPierre-Antoine Manzagol. 2008. Extracting and\ncomposing robust features with denoising autoen-\ncoders. In Proceedings of the 25th international\nconference on Machine learning , pages 1096\u20131103.\nACM.\nAlex Wang, Amanpreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel Bowman. 2018a.\nGlue: A multi-task benchmark and analysis platformfor natural language understanding. In Proceedings\nof the 2018 EMNLP Workshop BlackboxNLP: An-\nalyzing and Interpreting Neural Networks for NLP ,\npages 353\u2013355.\nWei Wang, Ming Yan, and Chen Wu. 2018b. Multi-\ngranularity hierarchical attention fusion networks\nfor reading comprehension and question answering.\nInProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) . Association for Computational Lin-\nguistics.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-\nman. 2018. Neural network acceptability judg-\nments. arXiv preprint arXiv:1805.12471 .\nAdina Williams, Nikita Nangia, and Samuel R Bow-\nman. 2018. A broad-coverage challenge corpus\nfor sentence understanding through inference. In\nNAACL .\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\nLe, Mohammad Norouzi, Wolfgang Macherey,\nMaxim Krikun, Yuan Cao, Qin Gao, Klaus\nMacherey, et al. 2016. Google\u2019s neural ma-\nchine translation system: Bridging the gap between\nhuman and machine translation. arXiv preprint\narXiv:1609.08144 .\nJason Yosinski, Jeff Clune, Yoshua Bengio, and Hod\nLipson. 2014. How transferable are features in deep\nneural networks? In Advances in neural information\nprocessing systems , pages 3320\u20133328.\nAdams Wei Yu, David Dohan, Minh-Thang Luong, Rui\nZhao, Kai Chen, Mohammad Norouzi, and Quoc V\nLe. 2018. QANet: Combining local convolution\nwith global self-attention for reading comprehen-\nsion. In ICLR .\nRowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin\nChoi. 2018. Swag: A large-scale adversarial dataset\nfor grounded commonsense inference. In Proceed-\nings of the 2018 Conference on Empirical Related Work\nThere is a long history of pre-training general lan-\nguage representations, and we brie\ufb02y review the\nmost widely-used approaches in this section.\n2.1 Unsupervised Feature-based Approaches\nLearning widely applicable representations of\nwords has been an active area of research for\ndecades, including non-neural (Brown et al., 1992;\nAndo and Zhang, 2005; Blitzer et al., 2006) and\nneural (Mikolov et al., 2013; Pennington et al.,\n2014) methods could be\nminimally compared. The core argument of this\nwork is that the bi-directionality and the two pre-\ntraining tasks presented in Section 3.1 account for\nthe majority of the empirical improvements, but\nwe do note that there are several other differences\nbetween how BERT and GPT were trained:\n\u2022 GPT is trained on the BooksCorpus (800M\nwords); BERT is trained on the BooksCor-\npus (800M words) and Wikipedia (2,500M\nwords).\n\u2022 GPT uses a sentence separator ( [SEP] ) and\nclassi\ufb01er token ( [CLS] ) which are only in-\ntroduced at \ufb01ne-tuning time; BERT learns\n[SEP] ,[CLS] and sentence A/Bembed-\ndings during pre-training.\n\u2022 GPT was trained for 1M steps with a batch\nsize of 32,000 words; BERT was trained for\n1M steps with a batch size of 128,000 words.\n\u2022 GPT used the same learning rate of 5e-5 for\nall \ufb01ne-tuning results. For the feature-based approach,\nwe concatenate the last 4 layers of BERT"], "bleu": 0.15874522913807182, "rouge_l": 0.31965442764578833, "gpt_metric_score": 0.5, "bert_score": 0.20827479660511017}
{"paper_key": "Chemist-X: Large Language Model-empowered Agent for Reaction Condition Recommendation in Chemical Synthesis", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively utilize large language models (LLMs) to automate the search, analysis, and recommendation of optimal reaction conditions for unfamiliar chemical reactions?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem has significant implications for the research community as it can streamline the process of chemical reaction optimization, reducing the time and labor required for experimental chemistry. By automating the search and analysis phases, researchers can focus on more complex problems, leading to faster discoveries and innovations in chemical synthesis. This advancement could also enhance collaboration between AI and chemists, fostering interdisciplinary research and potentially leading to practical applications in pharmaceuticals, materials science, and beyond.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in addressing this problem include the vast and complex chemical space that must be navigated to identify relevant reaction conditions. Naive approaches may fail due to the high dimensionality of chemical data and the need for contextual understanding of chemical reactions, which requires sophisticated reasoning capabilities. Additionally, integrating diverse data sources, such as molecular databases and literature, poses technical obstacles in terms of data retrieval, analysis, and synthesis of information into actionable recommendations.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on isolated aspects of chemical reaction optimization, such as reaction classification or yield prediction, without a comprehensive framework that integrates information retrieval, analysis, and recommendation. Barriers include the lack of advanced AI models capable of understanding and synthesizing complex chemical information and the absence of systematic methodologies that mimic human expert reasoning. Our approach differs by employing a three-phase solution that combines LLMs with CAD technology, providing a more holistic and practical framework for addressing the reaction condition recommendation challenge.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology consists of three phases: (1) Information retrieval using a molecule database to identify similar molecules and potential reaction conditions; (2) Information analysis through web crawling and literature review to refine the chemical space; and (3) Final recommendations using CAD tools to suggest optimal reaction conditions. We will utilize a dataset of chemical reactions and their conditions, and metrics such as prediction accuracy and computational efficiency will be employed to evaluate our approach. The expected outcomes include a robust system that significantly enhances the efficiency and accuracy of reaction condition recommendations, ultimately advancing the field of automated chemistry.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can we develop an adaptive investment advisor framework that effectively integrates large language models with decentralized IoT systems to analyze real-time social media sentiment and economic indicators for optimized investment decision-making?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem has significant implications for the research community as it merges the fields of financial technology, natural language processing, and decentralized systems. By creating a framework that leverages real-time sentiment analysis and economic indicators, we can facilitate more informed investment decisions, ultimately leading to improved market efficiency. This research could pave the way for future studies on adaptive systems in finance, enhancing our understanding of how collective intelligence can influence investment strategies. Moreover, the practical applications of such a framework can empower individual investors and institutions alike, democratizing access to advanced financial analytics and promoting more effective resource allocation.\n\n[Question 3]: Why is it hard?  \nThe challenges in solving this problem are manifold. First, integrating large language models with decentralized IoT systems requires overcoming significant technical hurdles related to data interoperability, real-time processing, and ensuring low-latency communication in resource-constrained environments. Naive approaches may fail due to inadequate handling of the vast and noisy data generated by social media, leading to inaccurate sentiment analysis. Moreover, there are theoretical complexities in dynamically adjusting communication protocols and resource allocation based on fluctuating market conditions, which necessitates advanced algorithms and robust data models. The integration of adaptive semantic compression techniques adds another layer of complexity, as it involves ensuring that vital information is preserved while reducing data transmission overhead.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on either sentiment analysis or investment strategies in isolation, with limited exploration of their integration in real-time decentralized environments. Existing solutions may have overlooked the need for adaptive frameworks that can respond to rapid market changes, often relying on static models that do not account for dynamic data inputs. Barriers such as technological limitations in IoT communication and a lack of comprehensive approaches to include LLMs in investment decision-making have hindered progress. My approach differs by combining advanced communication technologies with adaptive frameworks, utilizing LLMs not just for analysis but also for decision-making processes, which enhances both the responsiveness and effectiveness of investment strategies.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves developing an adaptive investment advisor framework that integrates LLMs with decentralized IoT systems. I will employ a combination of real-time data sources, including social media sentiment and economic indicators, using advanced semantic compression techniques to optimize data transmission. The dataset will comprise social media feeds, economic reports, and historical market data. The primary metric for success will be the accuracy of investment decisions based on sentiment analysis compared to traditional methods. Expected outcomes include a significant improvement in investment strategy effectiveness, evidenced by enhanced returns and reduced risks, along with a demonstration of the framework's scalability and adaptability in varying market conditions.", "referenced_intros": ["Abstract \u2014Task-oriented communications are an important\nelement in future intelligent IoT systems. Existing IoT systems,\nhowever, are limited in their capacity to handle complex tasks,\nparticularly in their interactions with humans to accomplish these\ntasks. In this paper, we present LLMind, an LLM-based task-\noriented AI agent framework that enables effective collaboration\namong IoT devices, with humans communicating high-level\nverbal instructions, to perform complex tasks. Inspired by the\nfunctional specialization theory of the brain, our framework\nintegrates an LLM with domain-specific AI modules, enhancing\nits capabilities. Complex tasks, which may involve collaborations\nof multiple domain-specific AI modules and IoT devices, are\nexecuted through a control script generated by the LLM using a\nLanguage-Code transformation approach, which first converts\nlanguage descriptions to an intermediate finite-state machine\n(FSM) before final precise transformation to code. Furthermore,\nthe framework incorporates a novel experience accumulation\nmechanism to enhance response speed and effectiveness, allowing\nthe framework to evolve and become progressively sophisticated\nthrough continuing user and machine interactions.\nIndex Terms \u2014Large Language Models, IoT Device Control,\nIntelligent Agents, AI Modules, Finite-State Machine.\nI. I NTRODUCTION\nTask-oriented communications and execution framework are\nan important trend to exploit artificial intelligence to allow IoT\nsystems to interact with humans to execute complex tasks [1],\n[2]. They enable human users to control multiple IoT devices\nsimultaneously through various media, including text, voice,\nvideo, and virtual reality. Communications between humans\nand IoT devices, and among IoT devices, are indispensable in\nsuch systems. Traditional communications systems emphasize\non throughput, latency, and reliability. For intelligent IoT\nsystems, beyond these requirements, a shift is needed to also\nemphasize \u201cintention\u201d at the high level [3]. Hence, the entrance\nof Large Language Model (LLM).\nThe paper proposes and demonstrates the efficacy of a\nframework, LLMind, that incorporates LLM to allow humans\nto interact with IoT devices, and for IoT devices to commu-\nnicate and collaborate with each other, to perform complex\ntasks. LLMind not only reaffirms LLM\u2019s impressive linguistic\nproficiency and exceptional logical reasoning [4], but also\nshowcases its ability to transform conventional IoT devices\nH. Cui, Y . Du, Q. Yang, and S. C. Liew are with the Department of\nInformation Engineering, The Chinese University of Hong Kong, Hong Kong\nSAR (e-mails: {ch021, dy020, yq020, soung }@ie.cuhk.edu.hk).\nY . Shao is with the State Key Laboratory of Internet of Things for Smart\nCity, University of Macau, S.A.R. He is also with the Department of Electrical\nand Electronic Engineering, Imperial College London, London SW7 2AZ,\nU.K. (e-mail: ylshao@um.edu.mo).\n\u2217Authors contributed equally to this work. Corresponding author: Soung\nChang Liew.into an overall IoT system that can accomplish complex\ntasks through collaborations with high-level instructions from\nhumans. In particular, in LLMind, LLM serves as an orches-\ntrator to facilitate seamless intention-oriented communications\namong human and IoT entities to execute complex tasks.\nThe LLM orchestrator in LLMind goes beyond rigid\nscripted intelligence in traditional IoT device controlmethods, including AI modules and connected IoT devices.\nFollowing that, the AI agent generates an executable script and\nresponds to the user\u2019s request based on the execution outcome.\nWe deployed the coordinator and AI modules of the system\non an edge server. The edge server is connected to the same\nlocal network as the IoT devices via WiFi and can interact\nwith ChatGPT using OpenAI\u2019s APIs.\nThe available IoT devices in the system are as follows:\n1) Security cameras: The cameras are positioned within the\nroom to capture images of the surrounding environment.\nThese images are transmitted to the edge server", " Introduction\nA long-term aspiration in AI research is to develop principles of computational intelligence and to\nharness these to build learning and reasoning systems that can perform general problem solving\nacross a diversity of tasks [21, 22]. In line with this goal, large language models, also referred to as\nfoundation models, such as GPT-3 [3] and GPT-4 [24], have demonstrated surprising competencies\non a broad swath of tasks without requiring heavy specialized training [4]. These models build on the\ntext-to-text paradigm [31] with investments in compute and data to learn at scale from indiscriminate\nconsumption of large amounts of public web data. Some of these models are tuned via a learning\nobjective to perform general instruction-following via prompts.\n   PubMedBERT\n       (38.1)BioLinkBERT\n(45.1)DRAGON\n  (47.5)BioMedLM\n   (50.3)Med-PaLM\n   (67.2) Med-PaLM 2\n     (86.5)\nGPT-3.5\n(60.2)GPT-4 base\n(86.1)GPT-4\n(Medprompt)\n(90.2)\nGPT-4\n(Simple Prompt)\n(81.7)\nSep 21 Mar 22 Oct 22 Dec 22 Dec 22 Mar 23 May 23 Sep 23405060708090No fine-tuning\nIntensive fine-tuningMedQA (USMLE-style) T est Accuracy (%)\n(a)\nMedQA US\n(4-option)\nMedMCQA Dev\nPubMedQA\nReasoning\nRequired\nMMLU Clinical\nKnowledge\nMMLU Medical\nGeneticsMMLU AnatomyMMLU\nProfessional\nMedicineMMLU College\nBiologyMMLU College\nMedicine\n84.288.3\n73.777.3\n75.080.0\n86.7\n93.393.3\n96.784.2\n88.386.3\n92.793.396.777.885.7\nGPT-4 (Medprompt) Med-PaLM 2 (Best) GPT-4 (Simple Prompt) (b)\nFigure 1: (a) Comparison of performance on MedQA. (b) GPT-4 with Medprompt achieves SoTA\non a wide range of medical challenge questions.\nA core metric for characterizing the performance of foundation models is the accuracy of next\nword prediction. Accuracy with next word prediction is found to increase with scale in training\ndata, model parameters, and compute, in accordance with empirically derived \u201cneural model scaling\nlaws\u201d [3, 12]). However, beyond predictions of scaling laws on basic measures such as next word\nprediction, foundation models show the sudden emergence of numerous problem-solving capabilities\nat different thresholds of scale [33, 27, 24].\nDespite the observed emergence of sets of general capabilities, questions remain about whether\ntruly exceptional performance can be achieved on challenges within specialty areas like medicine in\nthe absence of extensive specialized training or fine-tuning of the general models. Most explorations\nof foundation model capability on biomedical applications rely heavily on domain- and task-specific\nfine-tuning. With first-generation foundation models, the community found an unambiguous ad-\nvantage with domain-specific pretraining, as exemplified by popular models in biomedicine such as\n2PubMedBERT [10] and BioGPT [19]. But it is unclear whether this is still the case with modern\nfoundation models pretrained at much larger scale.\nWe focus in this paper on steering foundation models via prompt engineering to excel on a\nset of medical challenge benchmarks. Med-PaLM 2 attains competitive Background\n2.1 Foundation Models on Medical Challenge Problems\nIn the era of first-generation foundation models, limited model size and computational resources made\ndomain-specific pretraining advantageous. Models such as PubMedBERT [10], BioLinkBERT [37],\nDRAGON [36], BioGPT [19], and BioMedLM [2] were pretrained with self-supervised objectives us-\ning domain-specific data sources, such as the PubMed corpus and UMLS knowledge graph. Despite\ntheir small size and limited computational power, these models demonstrate strong performance in\nbiomedical NLP tasks. More powerful, general-domain foundation models have demonstrated signif-\nicantly elevated performance in medical challenges without requiring domain-specific pretraining.\nSeveral studies have explored the performance of generalist foundation models on medical chal-\nlenge problems. In [17], ChatGPT-3.5 was evaluated on questions drawn from United States Medical\nLicensing Exam (USMLE), and performed at or near the passing threshold without any specialized\ntraining. In [23], GPT-4 was shown", " Introduction\nIn these years, 3D vision has gained significant atten-\ntion and development, driven by the rising popularity of au-\ntonomous driving [11, 69, 71], navigation [72, 76, 98], 3D\nscene understanding [2, 43, 46, 74], and robotics [31, 67].\nTo extend its application scenarios, numerous efforts [1,23,\n92,95] have been made to incorporate 3D point clouds with\ndata from other modalities, allowing for improved 3D un-\nderstanding [1, 23], text-to-3D generation [35, 49, 52], and\n3D question answering [3, 28].\nFor 3D geometry understanding, previous works either\nleverage 2D-language embeddings to guide 3D open-world\nrecognition [90, 100], or harness visual and textual seman-\nImagePoint Cloud\nPoint-LLM for 3D Q&A\n3D Embedding Arithmetic\n3D Zero-shot LearningAny-to-3D Generation\nLanguage\u201cA3D modelof an airplane.\u201d\nPOINT-BIND\nAudio[ Airplane Engine ] \nFigure 1. Characteristics of Point-Bind. We propose to align\n3D with multi-modalities and develop a unified framework, Point-\nBind, which extends various 3D multi-modal applications. Based\non Point-Bind, we further introduce Point-LLM, a 3D large lan-\nguage model with bilingual 3D instruction-following capacity.\ntics to assist 3D representation learning [39, 56, 84]. How-\never, their perception capabilities are mostly constrained by\nlimited modalities provided in the training phase. Inspired\nby 2D generative models [60, 63, 64], a collection of meth-\nods [35,49,52] has achieved text-to-3D synthesis with high\nquality and efficiency. Despite this, they lack the ability to\ngenerate 3D shapes conditioned on multi-modal input, i.e.,\nany-to-3D generation. Another series of works connects de-\nscriptive natural language with 3D data, which is applied\nto 3D captioning [12, 87], question answering [3, 78], and\nvisual grounding [24, 79]. Yet, they fail to utilize the pre-arXiv:2309.00615v1  [cs.CV]  1 Sep 20233D Embedding Arithmetic\nAny-to-3D Generation\nPoint-LLM for 3D Q&A\nDescribe the 3D object in detail.\nThe3Dobjectisasmallairplane,specificallyaprivatejet.andblackcolorscheme,anditappearstobeasmall-sizedaircraft.Itis\u2026...\n[ Audio ofPouring Water ]\nWhat\u2019s happening?\n3D Zero-shot Understanding\nText-referred:Point-Bindairplane, piano, guitar\nairplaneCLASSA  model  of  a\npianoguitar\nThesceneshowsapersonpouringaclearliquid,likelywater,intoaglass.Theglassisplacedonatable,filledtothebrim,indicatingthatasignificantamountofliquidhasbeenpouredintoit.\nText-to-3D:Audio-to-3D:Image-to-3D:Point-to-3D:\n[ Audio ofSea Wave ]+Cross-modal Retrieval3D Point Cloud\u201cA Car\u201d\n[ Car Horn ]\n\ud83d\udd0a [ AirplaneEngine ]\n\ud83c\udfb6 [ PianoMusic ]\n\ud83c\udfb6 [ GuitarSound ]Audio-referred:\nPoint-Bindairplanepianoguitar\n\u00d8No Need for 3D Instruction Data\u00d83D and Multi-modal ReasoningFigure 2. 3D Multi-modal Applications of Point-Bind. With a joint 3D multi-modal embedding space, Point-Bind enables many promis-\ning application scenarios, e.g., Point-LLM for 3D instruction following, 3D generation conditioned on any modalities, embedding-space\narithmetic with 3D, and multi-modal 3D zero-shot understanding.\ntrained linguistic knowledge within large language models\n(LLMs) to better capture 3D geometrics.\nTherefore, how to develop a unified 3D framework align-\ning with multi-modality for general 3D learning still re-\nmains an open question. Very recently, ImageBind [22] was\nproposed to learn a shared representation space across six\ndifferent modalities, i.e., images, text, audio, depth, ther-\nmal, and IMU data. Motivated by this, we ask the following\nquestion: can we construct a joint embedding space be-\ntween 3D and multi-modality for unified 3D understand-\ning, generation, and insturction following?\nTo this end, we introduce Point-Bind , a 3D multi-\nmodality framework that aligns point clouds with multiple\nmodalities for general 3D analysis, as shown in Figure 1.\nSpecifically, we collect 3D-image-text-audio pairs as the\ntraining data, and construct a joint embedding space guided\nby ImageBind. We adopt a contrastive loss between the\nextracted features from a trainable 3D encoder, e.g., I2P-\nMAE [92], and the frozen multi-modal encoders of Image-\nBind. Such a simple strategy can efficiently integrate dif-\nferent modalities into a unified representation space, and al-\nlows for various 3D-centric multi-modal tasks in Figure 2.The main contributions of Point-Bind are as follows:\n\u2022Aligning 3D with ImageBind.", " introduction\nto REFERENCES\n[1] B. Brik, H. Chergui, L. Zanzi, F. Devoti, A. Ksentini, M. S. Siddiqui,\nX. Costa-P \u00b4erez, and C. Verikoukis, \u201cA survey on explainable AI for 6G\nO-RAN: Architecture, use cases, challenges and research directions,\u201d\narXiv preprint arXiv:2307.00319 , 2023.\n[2] I. F. Akyildiz, H. Guo, R. Dai, and W. Gerstacker, \u201cMulsemedia com-\nmunication research challenges for metaverse in 6G wireless systems,\u201d\narXiv preprint arXiv:2306.16359 , 2023.\n[3] L. Bariah, Q. Zhao, H. Zou, Y . Tian, F. Bader, and M. Debbah, \u201cLarge\nlanguage models for telecom: The next big thing?\u201d arXiv preprint\narXiv:2306.10249 , 2023.\n[4] X. Jiao, W. Liu, M. Mehari, M. Aslam, and I. Moerman, \u201cOpenwifi:\na free and open-source IEEE802. 11 SDR implementation on SoC,\u201d in\nVTC2020-Spring . IEEE, 2020, pp. 1\u20132.\n[5] M. Aslam, W. Liu, X. Jiao, J. Haxhibeqiri, G. Miranda, J. Hoebeke,\nJ. Marquez-Barja, and I. Moerman, \u201cHardware efficient clock synchro-\nnization across Wi-Fi and ethernet-based network using PTP,\u201d IEEE\nTrans. Industr. Inform. , vol. 18, no. 6, pp. 3808\u20133819, 2022.\n[6] L. Zhang, S. C. Liew, and H. Chen, \u201cA just-in-time networking frame-\nwork for minimizing request-response latency of wireless time-sensitive\napplications,\u201d IEEE Internet Things J. , vol. 10, no. 8, pp. 7126\u20137142,\n2023.\n[7] G. Miranda, J. Haxhibeqiri, N. Slamnik-krije \u02c7storac, X. Jiao, J. Hoebeke,\nI. Moerman, D. F. Macedo, and J. M. Marquez-Barja, \u201cThe quality-aware\nand vertical-tailored management of wireless time-sensitive networks,\u201d\nIEEE Internet Things J. , vol. 5, no. 4, pp. 142\u2013148, 2022.\n[8] P. Avila-Campos, J. Haxhibeqiri, I. Moerman, and J. Hoebeke, \u201cBeacon-\nbased wireless TSN association,\u201d in IEEE INFOCOM 2022 , 2022, pp.\n1\u20132.\n[9] H. Pearce, B. Ahmad, B. Tan, B. Dolan-Gavitt, and R. Karri, \u201cAsleep at\nthe keyboard? Assessing the security of Github copilot\u2019s code contribu-\ntions,\u201d in 2022 IEEE Symposium on Security and Privacy (SP) . IEEE,\n2022, pp. 754\u2013768.\n[10] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt, \u201cExam-\nining zero-shot vulnerability repair with large language models,\u201d arXiv\npreprint arXiv:2112.02125 , 2021.\n[11] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, \u201cFixing\nhardware security bugs with large language models,\u201d arXiv preprint\narXiv:2302.01215 , 2023.\n[12] RapidSilicon, \u201cRapidgpt,\u201d 2023, [Online]. Available: https://rapidsilicon.\ncom/rapidgpt/.[13] H. Pearce, B. Tan, and R. Karri, \u201cDave: Deriving automatically Verilog\nfrom English,\u201d in Proceedings of the 2020 ACM/IEEE Workshop on\nMachine Learning for CAD , 2020, pp. 27\u201332.\n[14] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-\nGavitt, and S. Garg, \u201cBenchmarking large language models for auto-\nmated verilog RTL code generation,\u201d in 2023 Design, Automation &\nTest in Europe Conference & Exhibition . IEEE, 2023, pp. 1\u20136.\n[15] J. Blocklove, S. Garg, R. Karri, and H. Pearce, \u201cChip-Chat: Challenges\nand opportunities in conversational hardware design,\u201d arXiv preprint\narXiv:2305.13243 , 2023.\n[16] K. Chang, Y . Wang, H. Ren, M. Wang, S. Liang, Y . Han, H. Li, and\nX. Li, \u201cChipGPT: How far are we from natural language hardware\ndesign,\u201d arXiv preprint arXiv:2305.14019 , 2023.\n[17] Y . Du, S. C. Liew, and Y . Shao, \u201cEfficient FFT computation in IFDMA\ntransceivers,\u201d IEEE Trans. Wirel. Commun. , 2023.\n[18] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V . Le,\nD. Zhou et al. , \u201cChain-of-thought prompting elicits reasoning in large\nlanguage models,\u201d Advances in Neural Information Processing Systems ,\nvol. 35, pp. 24 824\u201324 837, 2022.\n[19] X. Wang,", "ABSTRACT\nLarge language models (LLMs) have shown exceptional performance on a va-\nriety of natural language tasks. Yet, their capabilities for HTML understanding\n\u2013 i.e., parsing the raw HTML of a webpage, with applications to automation of\nweb-based tasks, crawling, and browser-assisted retrieval \u2013 have not been fully\nexplored. We contribute HTML understanding models (\ufb01ne-tuned LLMs) and an\nin-depth analysis of their capabilities under three tasks: (i) Semantic Classi\ufb01ca-\ntionof HTML elements, (ii) Description Generation for HTML inputs, and (iii)\nAutonomous Web Navigation of HTML pages. While previous work has devel-\noped dedicated architectures and training procedures for HTML understanding,\nwe show that LLMs pretrained on standard natural language corpora transfer re-\nmarkably well to HTML understanding tasks. For instance, \ufb01ne-tuned LLMs are\n12% more accurate at semantic classi\ufb01cation compared to models trained exclu-\nsively on the task dataset. Moreover, when \ufb01ne-tuned on data from the MiniWoB\nbenchmark, LLMs successfully complete 50% more tasks using 192x less data\ncompared to the previous best supervised model. Out of the LLMs we evalu-\nate, we show evidence that T5-based models are ideal due to their bidirectional\nencoder-decoder architecture. To promote further research on LLMs for HTML\nunderstanding, we create and open-source a large-scale HTML dataset distilled\nand auto-labeled from CommonCrawl.1\n1 I NTRODUCTION\nWeb crawling (Olston et al., 2010), form-\ufb01lling (Diaz et al., 2013; Gur et al., 2021), or information\nretrieving web agents (Nogueira & Cho, 2016) are important for both automating and assisting\nusers in web-based tasks. These and similar applications rely on models that can search for speci\ufb01c\ncontent or controls on a web page as well as navigate a website autonomously. Since a web page in\nits raw form is represented as an HTML-based text sequence, the success of models for web-based\ntasks relies on their ability to understand HTML semantics, structure, and embedded interactions.\nThe predominant approach to web automation and HTML understanding is to train specialized mod-\nels, i.e., gathering application-speci\ufb01c datasets and designing neural network (NN) architectures to\nleverage inductive biases of the HTML\u2019s structure; see, e.g., Liu et al. (2018); Toyama et al. (2021);\nGur et al. (2021); Humphreys et al. (2022). However, both dataset collection and neural architecture\ndesign are expensive, time-consuming, and require highly-specialized, domain-speci\ufb01c knowledge.\nMeanwhile, in the natural language processing (NLP) literature, large language models (LLMs) have\nemerged as a solution to the dif\ufb01culties of dataset collection and specialized NN design (Kaplan\net al., 2020; Bommasani et al., 2021). A popular paradigm in NLP is to take an off-the-shelf LLM\n\u2013 pretrained on a large text corpus via an unsupervised and task-agnostic learning objective \u2013 and\neither \ufb01ne-tune or prompt the LLM on a small task-speci\ufb01c dataset. This paradigm has shown\nexceptional performance on a variety of NLP tasks (Xue et al., 2020; Brown et al., 2020; Austin\net al., 2021). Whether LLMs can be applied to HTML understanding \u2013 especially given the much\nlarger context and sequence lengths \u2013 remains an under-explored question.\n1See visualizations of theresults are borrowed from\n(Humphreys et al., 2022). Note that these are normalized between 0 and 1.\nTASK Human CC-Net CC-Net World Work\ufb02ow Learning DOM-Q-Net Work\ufb02ow Learning Aggregated Aggregated\nWebN-T5-3B WebN-T5-3B (SL & RL) (SL) of guided to (RL) guided to SOTA SOTA\n(no history) bits exploration navigate exploration navigate (SL & RL) (Augmented)\n(SL & RL) (SL & RL) the", " Introduction\nOpen Domain Question Answering (ODQA) (Lee\net al., 2019; Lewis et al., 2020c) is an important\n1This paper is awaiting publication at TACL and this is a\npre-MIT Press publication versiontask in natural language understanding. ODQA methods of putting in an appropriate way, what was at issue there. There was \na disagreement about the content of the allegations. <end> MS. ROBIN-VERGEER (RESPONDENT): I don't think it's important, \nfor, maybe, purposes of this, to iron this out, but I -- respectfully, I don't agree with that characterization, because, even in the \nresolution of the grievance internally, the -- what they found in the grievance was that they took no adverse action against him \nbecause of what he said -- <end> JUSTICE BREYER: That doesn't -- <end> MS. ROBIN-VERGEER (RESPONDENT): -- in \nconnection with this case. <end> JUSTICE BREYER: That isn't in an appropriate way, what was at issue there. There was a \ndisagreement about the content of the allegations. <end> MS. ROBIN-VERGEER (RESPONDENT): I don't think it's important, \nfor, maybe, purposes of this, to iron this out, but I -- respectfully, I don't agree with that characterization, because, even in the \nresolution of the grievance internally, the -- what they found in the grievance was that they took no adverse action against him \nbecause of what he said -- <end> JUSTICE BREYER: That doesn't -- <end> MS. ROBIN-VERGEER (RESPONDENT): -- in \nconnection with this case. <end> JUSTICE BREYER: That isn't in an appropriate way, what was at issue there. There was a \ndisagreement about the content of the allegations. <end> MS. ROBIN-VERGEER (RESPONDENT): I don't think it's important, \nfor, maybe, purposes of this, to iron this out, but I -- respectfully, I don't agree with that characterization, because, even in the \nresolution of the grievance internally, the -- what they found in the grievance was that they took no adverse action against him \nbecause of what he said -- <end> JUSTICE BREYER: That doesn't -- <end> MS. ROBIN-VERGEER (RESPONDENT): -- in \nconnection with this case. <end> JUSTICE BREYER: That isn'tKimbery I looked at the source code for Racket\u00e2\u20ac\u2122s require and provide and I examined %require and %provide a little end \nKimbery Here\u00e2\u20ac\u2122s what I learned require transformers and provide pretransformers are implemented in Racket Provide \ntransformers are implemented in C end Kimbery I think provide transformers are pretty restricted because they have access to the \nbindings exported by allfromout and things like that but in order to know that the module needs to know which bindings are \nshadowed by the module body So provide transformers are essentially the very last step of macro transformation in a module\u00e2\u20ac\u2122s \nexpansion end Kimbery I looked at the source code for Racket\u00e2\u20ac\u2122s require and provide and I examined %require and %provide a \nlittle end Kimbery Here\u00e2\u20ac\u2122s what I learned require transformers and provide pretransformers are implemented in Racket Provide \ntransformers are implemented in C end Kimbery I think provide transformers are pretty restricted because they have access to the \nbindings exported by allfromout and things like that but in order to know that the module needs to know which", " introduction. We study the importance\nof the retriever module, the ef\ufb01cacy of the source pointer work\ufb02ow, the tradeoff between ef\ufb01ciency\nand effectiveness using a controlled baseline, and \ufb01nally we compare our FiD-LightSPto related Appendix C.\nEven our T5-Base con\ufb01guration in row 8 already outperforms previous SOTA conclusion we observe clear and statistically signi\ufb01cant improvements between FiDSPand FiD-\nLightSP\u2013 both in terms of effectiveness and ef\ufb01ciency \u2013 across a variety of KILT tasks. FiD-LightSP\n8Table 3: Comparing our models with discussion with the open domain QA tasks in Figure 5 (a, b, & c) as they provide\na similar picture: Comparing our FiD-LightSPmodel with the baseline we do observe a drop in\neffectiveness from the strongest baseline (gray dotted vertical line) when using the same T5-Base\nmodel. However, due to the more ef\ufb01cient architecture we are able to swap backbones and earn\nthe bene\ufb01ts of those larger models in terms of effectiveness. At the same time we outperform the\nlatency of the baseline as well, shifting the Pareto optimum. Interestingly, the FiD-LightSPmodel\nwith T5-XL and only a single encoded vector per passage shows a larger drop in effectiveness than\nthe counterparts for smaller T5\u2019s. The only 2-label classi\ufb01cation task, FEVER, shown in Figure 5\n(d), exhibits the lowest reduction in effectiveness, when constraining the number of encoded vectors\nin FiD-LightSP. This is likely due to the fact, that only little generation is necessary to solve the task.\nTherefore, our FiD-LightSPcon\ufb01gurations improve the Pareto optimum again. The slot-\ufb01lling tasks\nin Figure 5 (e & f) show less impact of the T5 size, with little improvement for Large and XL over\nthe Base con\ufb01gurations. Fortunately, we also observe a similarly small reduction in effectiveness\nfor reducing the number of encoded FiD-LightSPvectors, leading to our \ufb01nal Pareto gains.\nIn conclusions or recommendations\nexpressed in this material are those of the authors and do not necessarily re\ufb02ect those of the sponsors. REFERENCES\nAkari Asai, Matt Gardner, and Hannaneh Hajishirzi. Evidentiality-guided generation for knowledge-\nintensive nlp tasks. arXiv preprint arXiv:2112.08688 , 2021. 4\nPayal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Ma-\njumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated\nmachine reading comprehension dataset. arXiv preprint arXiv:1611.09268 , 2016. 13, 14\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the\ndangers of stochastic parrots: Can language models be too big? In Proc. of FAccT , 2021. 8\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Wen-tau Yih, Sebastian Riedel, and Fabio\nPetroni. Autoregressive search engines: Generating substrings as document identi\ufb01ers. arXiv\npreprint arXiv:2204.10628 , 2022. 9, 15\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Mil-\nlican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego\nde Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren\nMaggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol\nVinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. Im-\nproving language models by retrieving from trillions of tokens. arXiv preprint arXiv:2112.04426 ,\n2021. 4\nJordan Boyd-Graber and Benjamin B \u00a8orschinger. What question answering can learn from trivia\nnerds. arXiv preprint arXiv:1910.14464 , 2019. 16\nJiecao Chen, Liu Yang, Karthik Raman, Michael Bendersky, Jung-Jung Yeh, Yun Zhou, Marc Na-\njork, Danyang Cai, and Ehsan Emadzadeh.", " Introduction\nDeep unsupervised learning with generative and embed-\nding models has seen dramatic success in the past few\nyears. Generative models (Peters et al., 2018; Raffel et al.,\n2019; van den Oord et al., 2016; Ramesh et al., 2021;\nBrown et al., 2020; Chen et al., 2021) are trained to max-\n*Equal contribution1OpenAI. Correspondence to: Arvind\nNeelakantan <arvind@openai.com >.\nS-300M M-1.2B L-6B XL-175B\nModel Size606264666870Performance\nAverage performance vs model sizeFigure 1. Average performance of unsupervised cpt-text\nmodels of different sizes across 22 tasks consisting of linear-probe\nclassi\ufb01cation, text search, and sentence similarity tasks.\nimize the likelihood of observed data while embedding\nmodels are trained to distinguish observed data from noise\n(Sohn, 2016; van den Oord et al., 2018; Radford et al.,\n2021; Jia et al., 2021; Gao et al., 2021; Izacard et al., 2021).\nGenerative models have been shown to produce realistic\ncontent and bene\ufb01t many downstream applications, reduc-\ning the need for labeled training datasets. In generative\nmodels, the information about the input is typically dis-\ntributed over multiple hidden states of the model. While\nsome generative models (Kingma & Welling, 2014; Kiros\net al., 2015) can learn a single representation of the in-\nput, most autoregressive Transformer (Vaswani et al., 2017)\nmodels do not (Raffel et al., 2019; Brown et al., 2020; Chen\net al., 2021; Ramesh et al., 2021). However, learning such a\nrepresentation (or embedding) is necessary for many tasks.\nSystems that search over millions or billions of items re-\nquire each entry to be embedded as a dense representation\nand build an index in advance to save computational costs\nat query time. These embeddings are useful features for\nclassi\ufb01cation tasks and can also enable data visualization\napplications via techniques such as clustering. Embedding\nmodels are explicitly optimized to learn a low dimensional\nrepresentation that captures the semantic meaning of the\ninput (Radford et al., 2021; Jia et al., 2021; Giorgi et al.,\n2020; Gao et al., 2021; Izacard et al., 2021).arXiv:2201.10005v1  [cs.CL]  24 Jan 2022Text and Code Embeddings by Contrastive Pre-Training\nIn this work, we train embedding models using a con-\ntrastive learning objective with in-batch negatives (Sohn,\n2016; Yih et al., 2011) on unlabeled data. The input is en-\ncoded with a Transformer encoder (Vaswani et al., 2017)\nand we leverage naturally occurring paired data to con-\nstruct training data with no explicit labels. Text embedding\nmodels are trained on paired text data where we consider\nneighboring pieces of text on the Internet as positive pairs.\nCode embedding models treat the top-level docstring in a\nfunction along with its implementation as a (text, code)\npair. The training signal of the contrastive objective on\nits own is not suf\ufb01cient to learn useful representations and\nwe overcome this by initializing our model with other pre-\ntrained models (Brown et al., 2020; Chen et al., 2021). Fi-\nnally, we \ufb01nd that it is critical to use a suf\ufb01ciently large\nbatch to achieve the optimal performance. We show that\nthis simple recipe combining pre-trained model initializa-\ntion, large-batch contrastive learning and training at scale,\ncan produce text and code embeddings that possess a broad\nrange of capabilities.\nWe train a series of unsupervised text embedding mod-\nels (cpt-text ) of different sizes, ranging from 300M\nto 175B parameters, and observe a consistent perfor-\nmance improvement with increasing model sizes (Figure\n1). On classi\ufb01cation accuracy averaging across 7 linear-\nprobe classi\ufb01cation tasks in SentEval (Conneau & Kiela,\n2018), our largest unsupervised model", " Introduction\nThe vast majority of text used to pretrain lan-\nguage models is extracted from web pages, while\ndiscarding any markup they contain ( Liu et al. ,\n2019 ;Brown et al. ,2020 ;Raffel et al. ,2019 ;\nLewis et al. ,2019 ). We argue that this HTML\nshould not be ignored; it enables new forms of\nhighly effective language model pretraining and\n\u2217Equal Contribution<!DOCTYPE html>\n<html>\n<title> <mask>12 </title>\n<body>\n\u02dc south korea on monday announced sweeping\ntax reforms , including income and\ncorporate tax cuts to boost growth by\nstimulating sluggish private\nconsumption and business investment .\n</body>\n</html>\n\u2193\n<!DOCTYPE html>\n<html>\n<title> \u02dc South Korea Announces Tax Reforms To\nBoost Economic Growth \u02dc </title>\n<body>\n\u02dc south korea on monday announced sweeping\ntax reforms...\n</body>\n</html>\nFigure 1: An example structured prompt for a simple\nsummarization task, where we ask a generative masked\nlanguage model to generate a mask representing the ti-\ntle with an average tokens size of 12.\nprompting with structured document-level super-\nvision.\nHyper-text, such as the HTML found in the\nCommon Crawl1, has a number of advantages for\npretraining over plain text. It often encodes high-\nlevel properties of different parts of the documents,\nwhich are dif\ufb01cult to infer from the text alone.\nFor example, <title> elements can be excellent\nsummaries of the <body> of a document, while\nelementclass andidattributes can encode cate-\ngorical properties of documents. Such supervision\nis highly diverse, depending on what the website\nauthors choose to present, and provides close prox-\nies for many NLP tasks we aim to later solve.\nModeling hyper-text allows us to introduce\nstructured prompting of language models. We de-\nsign prompts that incorporate the established se-\nmantics of HTML to better control for the de-\nsired model output. This includes, for exam-\n1https://commoncrawl.org/ple, performing zero-shot summarization by ask-\ning the model to in\ufb01ll <title> tags in a web\npage. And, the fact that we jointly model text\nand hyper-text formatting also allows for effective\nauto-prompting. If we have even a few examples\nfor a new task, we can directly ask the model to\nformat them in HTML, and templatize the result\nto de\ufb01ne the new prompt.\nOur HyperTextLanguage Model (HTLM ) is\ntrained on 23TB of simpli\ufb01ed HTML which we\nautomatically extract from common crawl dumps\n(see Section \u00a7 2.1). We use a modi\ufb01ed BART\ndenoising objective ( Lewis et al. ,2019 ) that ran-\ndomly masks spans of hyper-text and aims to re-\nconstruct the original input. We extend the origi-\nnal masking with a new size hint scheme, where\neach mask is associated with an integer that pro-\nvides a noisy hint for the size of the masked text,\nto allow for more \ufb01ne grained task-speci\ufb01c length\npriors when prompting the \ufb01nal model (see Sec-\ntion \u00a7 2.3). Figure 1shows an example mask that\nshould be reconstructed with a phrase that contains\nroughly 12 tokens.\nThrough extensive experiments on GLUE results on\nzero-shot prompting for summarization by a wide\nmargin by creating prompts that capture the un-\nderlying semantics of each summarization dataset.\nFurthermore, we show that pre-training on struc-\ntured data improved full \ufb01netuning performance\nrelative to other pre-trained models that only mod-\neled natural language.\nWe also showed additional advantages of model-\ning hyper-text, beyond improved accuracy. HTLM\ncan be used for auto-prompt by simply asking\nthe model to recover the document structure from\ntraining samples; these auto-prompts on datasets\nlike Gigaword and CNN/DM outperformed previ-\nous state-of-the-art zero-shot approaches. Lastly,\nwe provided an in-depth comparison of the train-\ning advantage, in terms of data ef\ufb01ciency, that\nHTLM had compared to other", " Introduction\nRecognizing and describing the visual world with natural\nlanguage is an essential capability for arti\ufb01cial intelligence.\nIt motivates the research of image-text matching, which\nchallenges a learning agent to establish accurate and general-\nizable alignment between visual and textual data, so that one\ncan identify images or videos by text queries or vice versa.\nVisual semantic embedding (VSE) [ 10,11,23] tackles\n*Authors contributed equallythis challenge by learning a semantic embedding space,\nwhere the distance between paired visual and textual in-\nstances in the embedding space is optimized to be small.\nThe core idea of the VSE has three steps:\nStep 1. Extract a set (or sequence) of features from data,\nusing feature extractors (e.g., ConvNets for visual data).\nStep 2. Contextualize and aggregate the extracted features\nto project them into the joint embedding space as holistic\nvectors, using feature aggregators .\nStep 3. Compute the matching score between embeddings\nwith a similarity metric ( e.g., cosine distance).\nWith the feature extractor determined, one might expect that\na complex aggregator is required to achieve good results is that: feature extractors have provided\nadequate information for multi-modal matching, so the fea-\nture aggregators do not have to further contextualize the\nfeature vectors. Too complicated models for feature contex-\ntualization might increase the risk of over-\ufb01tting and hurt\nthe performance at the end. introduction of its formal de\ufb01nition\n(\u00a7 3.2), followed by the details of GPO\u2019s concrete model\narchitecture (\u00a7 3.3). Finally, we summarize our multi-modal\nsystem (VSE1) that leverages GPO (\u00a7 3.4).\n3.1. Simple Pooling Works the Best\nAs aforementioned in \u00a7 1, complex aggregators fhave\nbeen investigated in the VSE literature [ 18,28,44,46,47],\nsuch as sequence-to-sequence encoder (Seq2Seq), graph con-\nvolution network (GCN), self-attention encoder (SelfAttn),\netc. However, we surprisingly \ufb01nd that these aggregation\nmodels with millions of parameters underperform carefully\nselected pooling functions.\nTable 1 highlights a comparison between different aggre-\ngators, across two widely used image feature extractors in\nthe literature [ 19] \u2013Grid feature is the feature maps from\nConvNets and Region feature is the ROI features from object\ndetectors [ 1] (details in \u00a7 5). The Appendix\nprovides more motivations for this augmentation strategy.\nSurprisingly, we \ufb01nd this strategy also improves the baseline\nVSE++ [ 10], potentially as a regularization method. State-of-\nthe-art video-text matching model [ 4] uses a similar strategy,\nfeature dropout, which adds a dropout layer for input fea-\ntures. The difference is that it randomly set feature values to\n0, while Size Augmentation randomly drops entire elements\nfrom the feature set.\n(3) Different choices of the sequence model in GPO We\nalso try using different sequence model to implement GPO.\nTable 8 shows that using a Transformer Encoder [ 43] to re-\nplace the simple BiGRU does not yield improvements on\ntwo different combinations of features. The sequence model\nof GPO only takes the positional information as the input\nwithout using the exact feature vectors, thus we believe it\u2019sTable 8. Different choices of the sequence model used by GPO\nData Split COCO 5-fold 1 KTest [5]\nEval Task IMG!TEXT TEXT!IMG\nFeatures Seq. Model R@1 R@5 R@1 R@5\nBUTD (Region)\n+ BiGRUTransformer 77.4 95.4 61.4 90.1\nBiGRU 78.5 96.0 61.7 90.3\nBUTD (Grid)\n+ BiGRUTransformer 76.6 95.7 62.7 90.7\nBiGRU 78.0 95.8 62.6 90.6\nnot necessary for the sequence model to have large capacity.\nA simple BiGRU will suf\ufb01ce for both capacity and compu-\ntational ef\ufb01ciency, and more complex mechanisms like the\nmulti-head attentions of Transformers could even hurt the\nperformance.\nB.2. More Results are", " Introduction\nRecent years have featured a trend towards pre-trained language representations in NLP systems, applied in increasingly\n\ufb02exible and task-agnostic ways for downstream transfer. First, single-layer representations were learned using word\nvectors [ MCCD13 ,PSM14 ] and fed to task-speci\ufb01c architectures, then RNNs with multiple layers of representations\nand contextual state were used to form stronger representations [ DL15 ,MBXS17 ,PNZtY18 ] (though still applied to\ntask-speci\ufb01c architectures), and more recently pre-trained recurrent or transformer language models [ VSP+17] have\nbeen directly \ufb01ne-tuned, entirely removing the need for task-speci\ufb01c architectures [RNSS18, DCLT18, HR18].\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension,\nquestion answering, textual entailment, and many others, and has continued to advance based on new architectures\nand algorithms [ RSR+19,LOG+19,YDY+19,LCG+19]. However, a major limitation to this approach is that while\nthe architecture is task-agnostic, there is still a need for task-speci\ufb01c datasets and task-speci\ufb01c \ufb01ne-tuning: to achieve\nstrong performance on a desired task typically requires \ufb01ne-tuning on a dataset of thousands to hundreds of thousands\nof examples speci\ufb01c to that task. Removing this limitation would be desirable, for several reasons.\nFirst, from a practical perspective, the need for a large dataset of labeled examples for every new task limits the\napplicability of language models. There exists a very wide range of possible useful language tasks, encompassing\nanything from correcting grammar, to generating examples of an Results for SAT task.\n Figure H.3: All Related Work\nSeveral lines of work have focused on increasing parameter count and/or computation in language models as a\nmeans to improve generative or task performance. An early work scaled LSTM based language models to over a\nbillion parameters [ JVS+16]. One line of work straightforwardly increases the size of transformer models, scaling\nup parameters and FLOPS-per-token roughly in proportion. Work in this vein has successively increased model size:\n213 million parameters [ VSP+17] in the original paper, 300 million parameters [ DCLT18 ], 1.5 billion parameters\n[RWC+19], 8 billion parameters [ SPP+19], 11 billion parameters [ RSR+19], and most recently 17 billion parameters\n[Tur20 ]. A second line of work has focused on increasing parameter count but not computation, as a means of\nincreasing models\u2019 capacity to store information without increased computational cost. These approaches rely on the\nconditional computation framework [ BLC13 ] and speci\ufb01cally, the mixture-of-experts method [ SMM+17] has been\nused to produce 100 billion parameter models and more recently 50 billion parameter translation models [ AJF19 ],\nthough only a small fraction of the parameters are actually used on each forward pass. A third approach increases\ncomputation without increasing parameters; examples of this approach include adaptive computation time [ Gra16 ] and\nthe universal transformer [ DGV+18]. Our work focuses on the \ufb01rst approach (scaling compute and parameters together,\nby straightforwardly making the neural net larger), and increases model size 10x beyond previous models that employ\nthis strategy.\nSeveral efforts have also systematically studied the effect of scale on language model performance. [ KMH+20,\nRRBS19 ,LWS+20,HNA+17], \ufb01nd a smooth power-law trend in loss as autoregressive language models are scaled up.\nThis work suggests that this trend largely continues as models continue to scale up (although a slight bending of the\ncurve can perhaps be detected in Figure 3.1),", " Introduction\nFigure 1: Our SupCon loss consistently outper-\nforms cross-entropy with standard data augmenta-\ntions. We show top-1 accuracy for the ImageNet\ndataset, on ResNet-50, ResNet-101 and ResNet-\n200, and compare against AutoAugment [5], Ran-\ndAugment [6] and CutMix [60].The cross-entropy loss is the most widely used loss\nfunction for supervised learning of deep classi\ufb01ca-\ntion models. A number of works have explored\nshortcomings of this loss, such as lack of robustness\nto noisy labels [64, 46] and the possibility of poor\nmargins [10, 31], leading to reduced generalization\nperformance. However, in practice, most proposed\nalternatives have not worked better for large-scale\ndatasets, such as ImageNet [7], as evidenced by the\ncontinued use of cross-entropy to achieve state of the\nart results for more optimizers and data augmentation strategies. Added SupCon loss\nhierarchy. Adjusted table reporting for clarity.\nVersion 3 (2020-10-13) Removed deprecated sentence from Related Work\nOur work draws on existing literature in self-supervised representation learning, metric learning\nand supervised learning. Here we focus on the most relevant papers. The cross-entropy loss was\nintroduced as a powerful loss function to train deep networks [40, 1, 29]. The key idea is simple\nand intuitive: each class is assigned a target (usually 1-hot) vector. However, it is unclear why\nthese target labels should be the optimal ones and some work has tried to identify better target label\nvectors, e.g. [57]. A number of papers have studied other drawbacks of the cross-entropy loss,\nsuch as sensitivity to noisy labels [64, 46], presence of adversarial examples [10, 36], and poor\nmargins [2]. Alternative losses have been proposed, but the most effective ideas in practice have\nbeen approaches that change the reference label distribution, such as label smoothing [47, 35], data\naugmentations such as Mixup [61] and CutMix [60], and knowledge distillation [21].\nPowerful self-supervised representation learning approaches based on deep learning models have\nrecently been developed in the natural language domain [8, 58, 33]. In the image domain, pixel-\npredictive approaches have also been used to learn embeddings [9, 62, 63, 37]. These methods consistently outperform cross entropy for varying strengths of augmentation.\n2215 Change Log\nVersion 1 (2020-04-23) Initial Arxiv version.\nVersion 2 (2020-10-22) Added analysis of different forms of supervised contrastive loss and its\ngradients as well as experimental experiments. Moved accuracy vs num positives to supplemen-\ntary. More heavily tuned models resulted in deterioration of ECE. Added StackedRandAugment\naugmentation. Added GitHub link for code. Added conclusion. As shown in the Supplementary,\nthe gradient for eitherLsup\nout;i orLsup\nin;iwith respect to the embedding zihas the following form.\n@Lsup\ni\n@zi=1\n\u001c8\n<\n:X\np2P(i)zp(Pip\u0000Xip) +X\nn2N(i)znPin9\n=\n;(4)\nHere,N(i)\u0011fn2A(i) :~yn6=~yigis the set of indices of all negatives in the multiviewed batch,\nandPix\u0011exp(zi\u000fzx=\u001c)=P\na2A(i)exp(zi\u000fza=\u001c). The difference between the gradients for the\ntwo losses is in Xip.\nXip=8\n<\n:exp(zi\u000fzp=\u001c)P\np02P(i)exp(zi\u000fzp0=\u001c);ifLsup\ni=Lsup\nin;i\n1\njP(i)j;ifLsup\ni=Lsup\nout;i(5)\nIf each zpis set to the (less biased) mean positive representation vector, z,Xin\nipreduces toXout\nip:\nXin\nip\f\f\nzp=z=exp(zi\u000fz=\u001c)P\np02P(i)exp(zi\u000fz=\u001c)=exp(zi\u000fz=\u001c)\njP(i)j\u0001exp(zi\u000fz=\u001c)=1\njP(i)j=Xout\nip (6)\nFrom the form of @Lsup\ni=@zi, we conclude that the stabilization due to using the mean of positives\nbene\ufb01ts training. Throughout the rest of the paper, we consider only Lsup\nout.\n3.2.3 Connection to Triplet Loss and N-pairs Loss\nSupervised contrastive learning is closely related to the triplet loss [53], one of the widely-used loss\nfunctions for supervised learning. In the Supplementary, we show that the triplet loss is a special\ncase of the contrastive loss when one positive and one negative are used. When more than one\nnegative is used, we show that the SupCon", " Introduction. MIT press .\nTai, K.S., Socher, R., Manning, C.D., 2015. Improved semantic representations from tree-\nstructured long short-term memory networks. In: Proceeding of IJCNLP,\npp. 1556 \u20131566 .\nTang, J., Zhang, J., Yao, L., Li, J., Zhang, L., Su, Z., 2008. Arnetminer: extraction and\nmining of academic social networks. In: Proceedings of KDD. ACM, pp. 990 \u2013998.J. Zhou et al. AI Open 1 (2020) 57 \u201381\n79Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J., Mei, Q., 2015. Line: large-scale\ninformation network embedding. In: Proceedings of WWW, pp. 1067 \u20131077 .\nTeney, D., Liu, L., Den Hengel, A.V., 2017. Graph-structured representations for visual\nquestion answering. In: Proceedings of CVPR, pp. 3233 \u20133241 .\nTiezzi, M., Marra, G., Melacci, S., Maggini, M., 2020. Deep Lagrangian Constraint-Based\nPropagation in Graph Neural Networks. arXiv preprint arXiv:2005.02392 .\nToivonen, H., Srinivasan, A., King, R.D., Kramer, S., Helma, C., 2003. Statistical\nevaluation of the predictive toxicology challenge 2000 \u20132001. Bioinformatics 19,\n1183 \u20131193 .\nToutanova, K., Chen, D., Pantel, P., Poon, H., Choudhury, P., Gamon, M., 2015.\nRepresenting text for joint embedding of text and knowledge bases. In: Proceedings\nof EMNLP, pp. 1499 \u20131509 .\nTsitsulin, A., Palowitch, J., Perozzi, B., M\u00fcller, E., 2020. Graph Clustering with Graph\nNeural Networks. arXiv preprint arXiv:2006.16904 .\nTu, M., Wang, G., Huang, J., Tang, Y., He, X., Zhou, B., 2019. Multi-hop reading\ncomprehension across multiple documents by reasoning over heterogeneous graphs.\nIn: Proceedings of ACL, pp. 2704 \u20132713 .\nvan den Berg, R., Kipf, T.N., Welling, M., 2017. Graph convolutional matrix completion.\narXiv preprint arXiv:1706.02263 .\nVaswani, A., Shazeer, N., Parmar, N., Jones, L., Uszkoreit, J., Gomez, A.N., Kaiser, L.,\n2017. Attention is all you need. In: Proceeding of NIPS, pp. 5998 \u20136008 .\nVelickovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., 2018. Graph\nattention networks. In: Proceedings of ICLR .\nVelickovic, P., Fedus, W., Hamilton, W.L., Li /C18o, P., Bengio, Y., Hjelm, R.D., 2019. Deep\ngraph infomax. In: Proceedings of ICLR .\nVerma, S., Zhang, Z.-L., 2019. Stability and generalization of graph convolutional neural\nnetworks. In: Proceedings of KDD, pp. 1539 \u20131548 .\nVinyals, O., Bengio, S., Kudlur, M., 2015a. Order Matters: Sequence to Sequence for Sets\narXiv preprint arXiv:1511.06391 .\nVinyals, O., Fortunato, M., Jaitly, N., 2015b. Pointer networks. In: Proceedings of NIPS,\npp. 2692 \u20132700 .\nWale, N., Watson, I.A., Karypis, G., 2008. Comparison of descriptor spaces for chemical\ncompound retrieval and classi \ufb01cation. Knowl. Inf. Syst. 14, 347 \u2013375.\nWang, H., Leskovec, J., 2020. Unifying Graph Convolutional Neural Networks and Label\nPropagation. arXiv preprint arXiv:2002.06755 .\nWang, C., Pan, S., Long, G., Zhu, X., Jiang, J., 2017. Mgae: marginalized graph\nautoencoder for graph clustering. In: Proceedings of CIKM, pp. 889 \u2013898.\nWang, X., Girshick, R., Gupta, A., He, K., 2018a. Non-local neural networks. In:\nProceedings of CVPR, pp. 7794 \u20137803 .\nWang, Z., Lv, Q., Lan, X., Zhang, Y., 2018b. Cross-lingual knowledge graph alignment via\ngraph convolutional networks. Proceedings of EMNLP 349 \u2013357.\nWang, Z., Chen, T., Ren, J.S.J., Yu, W., Cheng, H., Lin, L., 2018c. Deep reasoning with\nknowledge graph for social relationship understanding. Proceedings of IJCAI\n1021 \u20131028 .\nWang, X., Ye, Y., Gupta, A., 2018d. Zero-shot recognition via semantic embeddings and\nknowledge graphs. Proceedings of CVPR 6857 \u20136866 .\nWang, Y., Sun, Y., Liu, Z., Sarma, S.E., Bronstein, M.M., Solomon, J.M., 2018e. Dynamic\nGraph Cnn for Learning on Point", " INTRODUCTION\nMachine learning and data-driven approaches are becom-\ning very important in many areas. Smart spam classi\fers\nprotect our email by learning from massive amounts of spam\ndata and user feedback; advertising systems learn to match\nthe right ads with the right context; fraud detection systems\nprotect banks from malicious attackers; anomaly event de-\ntection systems help experimental physicists to \fnd events\nthat lead to new physics. There are two important factors\nthat drive these successful applications: usage of e\u000bective\n(statistical) models that capture the complex data depen-\ndencies and scalable learning systems that learn the model\nof interest from large datasets.\nAmong the machine learning methods on\ndi\u000berent subsets of criteo data. The missing data\npoints are due to out of disk space. We can \fnd\nthat basic algorithm can only handle 200M exam-\nples. Adding compression gives 3x speedup, and\nsharding into two disks gives another 2x speedup.\nThe system runs out of \fle cache start from 400M\nexamples. The algorithm really has to rely on disk\nafter this point. The compression+shard method\nhas a less dramatic slowdown when running out of\n\fle cache, and exhibits a linear trend afterwards.\nlearning to rank problem. We compare against pGBRT [22],\nthe best previously pubished system on this task. XGBoost\nruns exact greedy algorithm, while pGBRT only support an\napproximate algorithm. The Related work\nis discussed in Sec. 5. Detailed end-to-end evaluations are\nincluded in Sec. 6. Finally we conclude the paper in Sec. 7.\n2. TREE BOOSTING IN A NUTSHELL\nWe review gradient tree boosting algorithms in this sec-\ntion. The derivation follows from the same idea in existing\nliteratures in gradient boosting. Specicially the second order\nmethod is originated from Friedman et al. [12]. We make mi-\nnor improvements in the reguralized objective, which were\nfound helpful in practice.\n2.1 Regularized Learning Objective\nFor a given data set with nexamples and mfeatures\nD=f(xi;yi)g(jDj=n;xi2Rm;yi2R), a tree ensem-\nble model (shown in Fig. 1) uses Kadditive functions to\npredict the output.\n^yi=\u001e(xi) =KX\nk=1fk(xi); fk2F; (1)\nwhereF=ff(x) =wq(x)g(q:Rm!T;w2RT) is the\nspace of regression trees (also known as CART). Here qrep-\nresents the structure of each tree that maps an example to\nthe corresponding leaf index. Tis the number of leaves in the\ntree. Each fkcorresponds to an independent tree structure\nqand leaf weights w. Unlike decision trees, each regression\ntree contains a continuous score on each of the leaf, we use\nwito represent score on i-th leaf. For a given example, we\nwill use the decision rules in the trees (given by q) to classify\nFigure 1: Tree Ensemble Model. The \fnal predic-\ntion for a given example is the sum of predictions\nfrom each tree.\nit into the leaves and calculate the \fnal prediction by sum-\nming up the score in the corresponding leaves (given by w).\nTo learn the set of functions used in the model, we minimize\nthe following regularized objective.\nL(\u001e) =X\nil(^yi;yi) +X\nk\n(fk)\nwhere \n(f) =\rT+1\n2\u0015kwk2(2)\nHerelis a di\u000berentiable convex loss function that measures\nthe di\u000berence between the prediction ^ yiand the target yi.\nThe second term \n penalizes the complexity of the model\n(i.e., the regression tree functions). The additional regular-\nization term helps to smooth the \fnal learnt weights to avoid\nover-\ftting. Intuitively, the regularized objective will tend\nto select a model employing simple and predictive functions.\nA similar regularization technique has been used in Regu-\nlarized greedy forest (RGF) [25] model. Our objective and\nthe corresponding learning algorithm is simpler than RGF\nand easier to parallelize.", " Introduction\nTo take advantage of the sheer size of modern data sets, we now need learn-\ning algorithms that scale with the volume of information, while maintaining\nsu\u000ecient statistical e\u000eciency. Random forests, devised by L. Breiman in\nthe early 2000s (Breiman, 2001), are part of the list of the most successful methods. arXiv:1502.03836 , 2015b.\nE. Scornet, G. Biau, and J.-P. Vert. Consistency of random forests. The\nAnnals of Statistics , 43:1716{1741, 2015.\nM.R. Segal. Regression trees for censored data. Biometrics , 44:35{47, 1988.\nJ. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore,\nA. Kipman, and A. Blake. Real-time human pose recognition in parts\nfrom single depth images. In IEEE Conference on Computer Vision and\nPattern Recognition , pages 1297{1304, 2011.\nC.J. Stone. Consistent nonparametric regression. The Annals of Statistics ,\n5:595{645, 1977.\nC.J. Stone. Optimal rates of convergence for nonparametric estimators. The\nAnnals of Statistics , 8:1348{1360, 1980.\nC.J. Stone. Optimal global rates of convergence for nonparametric regression.\nThe Annals of Statistics , 10:1040{1053, 1982.\nC. Strobl, A.-L. Boulesteix, T. Kneib, T. Augustin, and A. Zeileis. Con-\nditional variable importance for random forests. BMC Bioinformatics , 9:\n307, 2008.\nV. Svetnik, A. Liaw, C. Tong, J.C. Culberson, R.P. Sheridan, and B.P.\nFeuston. Random forest: A classi\fcation and regression tool for compound\nclassi\fcation and QSAR modeling. Journal of Chemical Information and\nComputer Sciences , 43:1947{1958, 2003.\n40L. Tolo\u0018 si and T. Lengauer. Classi\fcation with correlated features: Unre-\nliability of feature ranking and solutions. Bioinformatics , 27:1986{1994,\n2011.\nA.K.Y. Truong. Fast Growing and Interpretable Oblique Trees via Logistic\nRegression Models . PhD thesis, University of Oxford, Oxford, 2009.\nH. Varian. Big data: New tricks for econometrics. Journal of Economic\nPerspectives , 28:3{28, 2014.\nS. Wager. Asymptotic theory for random forests. arXiv:1405.0352 , 2014.\nS. Wager, T. Hastie, and B. Efron. Con\fdence intervals for random forests:\nThe jackknife and the in\fnitesimal jackknife. Journal of Machine Learning\nResearch , 15:1625{1651, 2014.\nG.S. Watson. Smooth regression analysis. Sankhy \u0016aSeries A , pages 359{372,\n1964.\nJ. Welbl. Casting random forests as arti\fcial neural networks (and pro\ft-\ning from it). In X. Jiang, J. Hornegger, and R. Koch, editors, Pattern\nRecognition , pages 765{771. Springer, 2014.\nS.J. Winham, R.R. Freimuth, and J.M. Biernacka. A weighted random forests\napproach to improve predictive performance. Statistical Analysis and Data\nMining: The ASA Data Science Journal , 6:496{505, 2013.\nD. Yan, A. Chen, and M.I. Jordan. Cluster forests. Computational Statistics\n& Data Analysis , 66:178{192, 2013.\nF. Yang, J. Wang, and G. Fan. Kernel induced random survival forests.\narXiv:1008.3952 , 2010.\nZ. Yi, S. Soatto, M. Dewan, and Y. Zhan. Information forests. In 2012\nInformation Theory and Applications Workshop , pages 143{146, 2012.\nR. Zhu, D. Zeng, and M.R. Kosorok. Reinforcement learning trees. Journal\nof the American Statistical Association, accepted , 2015.\nA. Ziegler and I.R. K\u007f onig. Mining data with random forests: Current options\nfor real-world applications. Wiley Interdisciplinary Reviews: Data Mining\nand Knowledge Discovery , 4:55{63, 2014.\n41Figure 4: An example of a distribution for which greedy random forests\nare inconsistent. The distribution of Xis uniform on the union of the three\nlarge squares. White areas represent the set where m(x) = 0 and grey where\nm(x) = 1.\n42 discussion on the choice of this parameter in various\nregression problems. Another interesting and related approach is by Latinne\net al. (2001), who propose a simple procedure that determines a priori a min-\nimum number of tree estimates"], "bleu": 0.1676307423417937, "rouge_l": 0.30368763557483736, "gpt_metric_score": 0.0, "bert_score": 0.2631272077560425}
{"paper_key": "Chemist-X: Large Language Model-empowered Agent for Reaction Condition Recommendation in Chemical Synthesis", "current_5q": "**[Question 1] - What is the problem?**  \nHow can we effectively utilize large language models (LLMs) to automate the search, analysis, and recommendation of optimal reaction conditions for unfamiliar chemical reactions?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem has significant implications for the research community as it can streamline the process of chemical reaction optimization, reducing the time and labor required for experimental chemistry. By automating the identification of reaction conditions, researchers can focus on more complex problems, leading to faster advancements in chemical synthesis and discovery. This work could pave the way for practical applications in pharmaceuticals, materials science, and other fields where efficient chemical reactions are crucial, ultimately enhancing innovation and productivity.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in addressing this problem include the vast and complex chemical space that must be navigated to identify relevant reaction conditions. Naive approaches may fail due to the high dimensionality of chemical data and the need for nuanced understanding of chemical interactions that LLMs may not inherently possess. Additionally, integrating diverse data sources, such as molecular databases and literature, requires sophisticated information retrieval and analysis techniques. Overcoming these technical and theoretical obstacles is essential for developing a robust automated system.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on isolated aspects of chemical reaction optimization, such as reaction classification or yield prediction, without integrating a comprehensive approach that combines information retrieval, analysis, and recommendation. Barriers such as the lack of effective algorithms for synthesizing information from multiple sources and the complexity of chemical data have hindered progress. Our approach differs by employing a systematic \"search-analyze-recommend\" methodology that mirrors human expert processes, leveraging LLMs to enhance the automation of this workflow.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology consists of three phases: (1) information retrieval using a molecule database to identify similar molecules and potential reaction conditions; (2) information analysis through web crawling and literature review to refine these conditions; and (3) final recommendations using Computer-Aided Design (CAD) tools to suggest optimal reaction conditions. We will evaluate our approach using a dataset of chemical reactions and measure success through metrics such as accuracy of recommendations and reduction in experimental time. Expected outcomes include a validated framework for automated reaction condition optimization and improved efficiency in chemical research.", "proposal_5q": "[Question 1]: What is the problem?  \nThe specific research question I aim to address is: How can an integrated hybrid AI system that combines large-scale language models (LLMs), augmented reality (AR), and gesture recognition technologies be developed to enhance real-time chemical synthesis and laboratory operations?\n\n[Question 2]: Why is it interesting and important?  \nSolving this problem has significant implications for the research community, particularly in the fields of chemistry, artificial intelligence, and educational technology. By developing a system that integrates LLMs with AR and gesture recognition, we can create a dynamic educational interface that enhances engagement and understanding in chemical processes. This advancement could lead to improved efficiency in laboratory operations, enabling chemists to conduct experiments more effectively and make informed decisions based on real-time data. Furthermore, this research could pave the way for future applications of hybrid AI systems in other scientific disciplines, promoting interdisciplinary collaboration and innovation.\n\n[Question 3]: Why is it hard?  \nThe challenges involved in solving this problem are multifaceted. First, integrating LLMs with AR and gesture recognition requires sophisticated technical expertise and a comprehensive understanding of each technology's capabilities and limitations. Naive approaches may fail due to the complexity of chemical queries that LLMs must interpret, as well as the need for accurate and real-time visualization of chemical reactions in AR. Additionally, ensuring effective gesture recognition in a laboratory environment presents practical obstacles, such as varying lighting conditions and the need for precise tracking of user movements. Overcoming these technical, theoretical, and practical hurdles is essential for the successful implementation of the proposed system.\n\n[Question 4]: Why hasn't it been solved before?  \nPrevious research has often focused on individual components, such as LLMs for data interpretation or AR for visualization, but rarely have these elements been integrated into a cohesive system tailored for chemical synthesis. Limitations in existing solutions stem from a lack of interdisciplinary collaboration and the challenges associated with real-time data processing and user interaction. Additionally, prior studies may not have addressed the dynamic nature of chemical experimentation, where conditions can change rapidly. My approach differs by creating an adaptive interface that evolves based on user interactions, utilizing mmWave radar for gesture recognition, which has not been widely explored in laboratory settings.\n\n[Question 5]: What are the key components of my approach and results?  \nMy proposed methodology involves the development of an integrated hybrid AI system that utilizes LLMs to interpret complex chemical queries and generate adaptive control scripts for IoT-enabled laboratory equipment. I will employ a dataset comprising chemical reaction data, user interactions, and environmental variables to train the LLMs. The AR component will visualize chemical reactions in real-time, providing interactive feedback on reaction conditions, while gesture recognition will be implemented using mmWave radar technology to allow intuitive manipulation of experimental variables. Key metrics for evaluation will include user engagement, efficiency in conducting experiments, and accuracy of the generated control scripts. The expected outcomes include a fully functional prototype that enhances laboratory operations and educational experiences, demonstrating significant improvements in engagement and decision-making.", "referenced_intros": ["Abstract \u2014Task-oriented communications are an important\nelement in future intelligent IoT systems. Existing IoT systems,\nhowever, are limited in their capacity to handle complex tasks,\nparticularly in their interactions with humans to accomplish these\ntasks. In this paper, we present LLMind, an LLM-based task-\noriented AI agent framework that enables effective collaboration\namong IoT devices, with humans communicating high-level\nverbal instructions, to perform complex tasks. Inspired by the\nfunctional specialization theory of the brain, our framework\nintegrates an LLM with domain-specific AI modules, enhancing\nits capabilities. Complex tasks, which may involve collaborations\nof multiple domain-specific AI modules and IoT devices, are\nexecuted through a control script generated by the LLM using a\nLanguage-Code transformation approach, which first converts\nlanguage descriptions to an intermediate finite-state machine\n(FSM) before final precise transformation to code. Furthermore,\nthe framework incorporates a novel experience accumulation\nmechanism to enhance response speed and effectiveness, allowing\nthe framework to evolve and become progressively sophisticated\nthrough continuing user and machine interactions.\nIndex Terms \u2014Large Language Models, IoT Device Control,\nIntelligent Agents, AI Modules, Finite-State Machine.\nI. I NTRODUCTION\nTask-oriented communications and execution framework are\nan important trend to exploit artificial intelligence to allow IoT\nsystems to interact with humans to execute complex tasks [1],\n[2]. They enable human users to control multiple IoT devices\nsimultaneously through various media, including text, voice,\nvideo, and virtual reality. Communications between humans\nand IoT devices, and among IoT devices, are indispensable in\nsuch systems. Traditional communications systems emphasize\non throughput, latency, and reliability. For intelligent IoT\nsystems, beyond these requirements, a shift is needed to also\nemphasize \u201cintention\u201d at the high level [3]. Hence, the entrance\nof Large Language Model (LLM).\nThe paper proposes and demonstrates the efficacy of a\nframework, LLMind, that incorporates LLM to allow humans\nto interact with IoT devices, and for IoT devices to commu-\nnicate and collaborate with each other, to perform complex\ntasks. LLMind not only reaffirms LLM\u2019s impressive linguistic\nproficiency and exceptional logical reasoning [4], but also\nshowcases its ability to transform conventional IoT devices\nH. Cui, Y . Du, Q. Yang, and S. C. Liew are with the Department of\nInformation Engineering, The Chinese University of Hong Kong, Hong Kong\nSAR (e-mails: {ch021, dy020, yq020, soung }@ie.cuhk.edu.hk).\nY . Shao is with the State Key Laboratory of Internet of Things for Smart\nCity, University of Macau, S.A.R. He is also with the Department of Electrical\nand Electronic Engineering, Imperial College London, London SW7 2AZ,\nU.K. (e-mail: ylshao@um.edu.mo).\n\u2217Authors contributed equally to this work. Corresponding author: Soung\nChang Liew.into an overall IoT system that can accomplish complex\ntasks through collaborations with high-level instructions from\nhumans. In particular, in LLMind, LLM serves as an orches-\ntrator to facilitate seamless intention-oriented communications\namong human and IoT entities to execute complex tasks.\nThe LLM orchestrator in LLMind goes beyond rigid\nscripted intelligence in traditional IoT device controlmethods, including AI modules and connected IoT devices.\nFollowing that, the AI agent generates an executable script and\nresponds to the user\u2019s request based on the execution outcome.\nWe deployed the coordinator and AI modules of the system\non an edge server. The edge server is connected to the same\nlocal network as the IoT devices via WiFi and can interact\nwith ChatGPT using OpenAI\u2019s APIs.\nThe available IoT devices in the system are as follows:\n1) Security cameras: The cameras are positioned within the\nroom to capture images of the surrounding environment.\nThese images are transmitted to the edge server", " Introduction\nA long-term aspiration in AI research is to develop principles of computational intelligence and to\nharness these to build learning and reasoning systems that can perform general problem solving\nacross a diversity of tasks [21, 22]. In line with this goal, large language models, also referred to as\nfoundation models, such as GPT-3 [3] and GPT-4 [24], have demonstrated surprising competencies\non a broad swath of tasks without requiring heavy specialized training [4]. These models build on the\ntext-to-text paradigm [31] with investments in compute and data to learn at scale from indiscriminate\nconsumption of large amounts of public web data. Some of these models are tuned via a learning\nobjective to perform general instruction-following via prompts.\n   PubMedBERT\n       (38.1)BioLinkBERT\n(45.1)DRAGON\n  (47.5)BioMedLM\n   (50.3)Med-PaLM\n   (67.2) Med-PaLM 2\n     (86.5)\nGPT-3.5\n(60.2)GPT-4 base\n(86.1)GPT-4\n(Medprompt)\n(90.2)\nGPT-4\n(Simple Prompt)\n(81.7)\nSep 21 Mar 22 Oct 22 Dec 22 Dec 22 Mar 23 May 23 Sep 23405060708090No fine-tuning\nIntensive fine-tuningMedQA (USMLE-style) T est Accuracy (%)\n(a)\nMedQA US\n(4-option)\nMedMCQA Dev\nPubMedQA\nReasoning\nRequired\nMMLU Clinical\nKnowledge\nMMLU Medical\nGeneticsMMLU AnatomyMMLU\nProfessional\nMedicineMMLU College\nBiologyMMLU College\nMedicine\n84.288.3\n73.777.3\n75.080.0\n86.7\n93.393.3\n96.784.2\n88.386.3\n92.793.396.777.885.7\nGPT-4 (Medprompt) Med-PaLM 2 (Best) GPT-4 (Simple Prompt) (b)\nFigure 1: (a) Comparison of performance on MedQA. (b) GPT-4 with Medprompt achieves SoTA\non a wide range of medical challenge questions.\nA core metric for characterizing the performance of foundation models is the accuracy of next\nword prediction. Accuracy with next word prediction is found to increase with scale in training\ndata, model parameters, and compute, in accordance with empirically derived \u201cneural model scaling\nlaws\u201d [3, 12]). However, beyond predictions of scaling laws on basic measures such as next word\nprediction, foundation models show the sudden emergence of numerous problem-solving capabilities\nat different thresholds of scale [33, 27, 24].\nDespite the observed emergence of sets of general capabilities, questions remain about whether\ntruly exceptional performance can be achieved on challenges within specialty areas like medicine in\nthe absence of extensive specialized training or fine-tuning of the general models. Most explorations\nof foundation model capability on biomedical applications rely heavily on domain- and task-specific\nfine-tuning. With first-generation foundation models, the community found an unambiguous ad-\nvantage with domain-specific pretraining, as exemplified by popular models in biomedicine such as\n2PubMedBERT [10] and BioGPT [19]. But it is unclear whether this is still the case with modern\nfoundation models pretrained at much larger scale.\nWe focus in this paper on steering foundation models via prompt engineering to excel on a\nset of medical challenge benchmarks. Med-PaLM 2 attains competitive Background\n2.1 Foundation Models on Medical Challenge Problems\nIn the era of first-generation foundation models, limited model size and computational resources made\ndomain-specific pretraining advantageous. Models such as PubMedBERT [10], BioLinkBERT [37],\nDRAGON [36], BioGPT [19], and BioMedLM [2] were pretrained with self-supervised objectives us-\ning domain-specific data sources, such as the PubMed corpus and UMLS knowledge graph. Despite\ntheir small size and limited computational power, these models demonstrate strong performance in\nbiomedical NLP tasks. More powerful, general-domain foundation models have demonstrated signif-\nicantly elevated performance in medical challenges without requiring domain-specific pretraining.\nSeveral studies have explored the performance of generalist foundation models on medical chal-\nlenge problems. In [17], ChatGPT-3.5 was evaluated on questions drawn from United States Medical\nLicensing Exam (USMLE), and performed at or near the passing threshold without any specialized\ntraining. In [23], GPT-4 was shown", " Introduction\nIn these years, 3D vision has gained significant atten-\ntion and development, driven by the rising popularity of au-\ntonomous driving [11, 69, 71], navigation [72, 76, 98], 3D\nscene understanding [2, 43, 46, 74], and robotics [31, 67].\nTo extend its application scenarios, numerous efforts [1,23,\n92,95] have been made to incorporate 3D point clouds with\ndata from other modalities, allowing for improved 3D un-\nderstanding [1, 23], text-to-3D generation [35, 49, 52], and\n3D question answering [3, 28].\nFor 3D geometry understanding, previous works either\nleverage 2D-language embeddings to guide 3D open-world\nrecognition [90, 100], or harness visual and textual seman-\nImagePoint Cloud\nPoint-LLM for 3D Q&A\n3D Embedding Arithmetic\n3D Zero-shot LearningAny-to-3D Generation\nLanguage\u201cA3D modelof an airplane.\u201d\nPOINT-BIND\nAudio[ Airplane Engine ] \nFigure 1. Characteristics of Point-Bind. We propose to align\n3D with multi-modalities and develop a unified framework, Point-\nBind, which extends various 3D multi-modal applications. Based\non Point-Bind, we further introduce Point-LLM, a 3D large lan-\nguage model with bilingual 3D instruction-following capacity.\ntics to assist 3D representation learning [39, 56, 84]. How-\never, their perception capabilities are mostly constrained by\nlimited modalities provided in the training phase. Inspired\nby 2D generative models [60, 63, 64], a collection of meth-\nods [35,49,52] has achieved text-to-3D synthesis with high\nquality and efficiency. Despite this, they lack the ability to\ngenerate 3D shapes conditioned on multi-modal input, i.e.,\nany-to-3D generation. Another series of works connects de-\nscriptive natural language with 3D data, which is applied\nto 3D captioning [12, 87], question answering [3, 78], and\nvisual grounding [24, 79]. Yet, they fail to utilize the pre-arXiv:2309.00615v1  [cs.CV]  1 Sep 20233D Embedding Arithmetic\nAny-to-3D Generation\nPoint-LLM for 3D Q&A\nDescribe the 3D object in detail.\nThe3Dobjectisasmallairplane,specificallyaprivatejet.andblackcolorscheme,anditappearstobeasmall-sizedaircraft.Itis\u2026...\n[ Audio ofPouring Water ]\nWhat\u2019s happening?\n3D Zero-shot Understanding\nText-referred:Point-Bindairplane, piano, guitar\nairplaneCLASSA  model  of  a\npianoguitar\nThesceneshowsapersonpouringaclearliquid,likelywater,intoaglass.Theglassisplacedonatable,filledtothebrim,indicatingthatasignificantamountofliquidhasbeenpouredintoit.\nText-to-3D:Audio-to-3D:Image-to-3D:Point-to-3D:\n[ Audio ofSea Wave ]+Cross-modal Retrieval3D Point Cloud\u201cA Car\u201d\n[ Car Horn ]\n\ud83d\udd0a [ AirplaneEngine ]\n\ud83c\udfb6 [ PianoMusic ]\n\ud83c\udfb6 [ GuitarSound ]Audio-referred:\nPoint-Bindairplanepianoguitar\n\u00d8No Need for 3D Instruction Data\u00d83D and Multi-modal ReasoningFigure 2. 3D Multi-modal Applications of Point-Bind. With a joint 3D multi-modal embedding space, Point-Bind enables many promis-\ning application scenarios, e.g., Point-LLM for 3D instruction following, 3D generation conditioned on any modalities, embedding-space\narithmetic with 3D, and multi-modal 3D zero-shot understanding.\ntrained linguistic knowledge within large language models\n(LLMs) to better capture 3D geometrics.\nTherefore, how to develop a unified 3D framework align-\ning with multi-modality for general 3D learning still re-\nmains an open question. Very recently, ImageBind [22] was\nproposed to learn a shared representation space across six\ndifferent modalities, i.e., images, text, audio, depth, ther-\nmal, and IMU data. Motivated by this, we ask the following\nquestion: can we construct a joint embedding space be-\ntween 3D and multi-modality for unified 3D understand-\ning, generation, and insturction following?\nTo this end, we introduce Point-Bind , a 3D multi-\nmodality framework that aligns point clouds with multiple\nmodalities for general 3D analysis, as shown in Figure 1.\nSpecifically, we collect 3D-image-text-audio pairs as the\ntraining data, and construct a joint embedding space guided\nby ImageBind. We adopt a contrastive loss between the\nextracted features from a trainable 3D encoder, e.g., I2P-\nMAE [92], and the frozen multi-modal encoders of Image-\nBind. Such a simple strategy can efficiently integrate dif-\nferent modalities into a unified representation space, and al-\nlows for various 3D-centric multi-modal tasks in Figure 2.The main contributions of Point-Bind are as follows:\n\u2022Aligning 3D with ImageBind.", " introduction\nto REFERENCES\n[1] B. Brik, H. Chergui, L. Zanzi, F. Devoti, A. Ksentini, M. S. Siddiqui,\nX. Costa-P \u00b4erez, and C. Verikoukis, \u201cA survey on explainable AI for 6G\nO-RAN: Architecture, use cases, challenges and research directions,\u201d\narXiv preprint arXiv:2307.00319 , 2023.\n[2] I. F. Akyildiz, H. Guo, R. Dai, and W. Gerstacker, \u201cMulsemedia com-\nmunication research challenges for metaverse in 6G wireless systems,\u201d\narXiv preprint arXiv:2306.16359 , 2023.\n[3] L. Bariah, Q. Zhao, H. Zou, Y . Tian, F. Bader, and M. Debbah, \u201cLarge\nlanguage models for telecom: The next big thing?\u201d arXiv preprint\narXiv:2306.10249 , 2023.\n[4] X. Jiao, W. Liu, M. Mehari, M. Aslam, and I. Moerman, \u201cOpenwifi:\na free and open-source IEEE802. 11 SDR implementation on SoC,\u201d in\nVTC2020-Spring . IEEE, 2020, pp. 1\u20132.\n[5] M. Aslam, W. Liu, X. Jiao, J. Haxhibeqiri, G. Miranda, J. Hoebeke,\nJ. Marquez-Barja, and I. Moerman, \u201cHardware efficient clock synchro-\nnization across Wi-Fi and ethernet-based network using PTP,\u201d IEEE\nTrans. Industr. Inform. , vol. 18, no. 6, pp. 3808\u20133819, 2022.\n[6] L. Zhang, S. C. Liew, and H. Chen, \u201cA just-in-time networking frame-\nwork for minimizing request-response latency of wireless time-sensitive\napplications,\u201d IEEE Internet Things J. , vol. 10, no. 8, pp. 7126\u20137142,\n2023.\n[7] G. Miranda, J. Haxhibeqiri, N. Slamnik-krije \u02c7storac, X. Jiao, J. Hoebeke,\nI. Moerman, D. F. Macedo, and J. M. Marquez-Barja, \u201cThe quality-aware\nand vertical-tailored management of wireless time-sensitive networks,\u201d\nIEEE Internet Things J. , vol. 5, no. 4, pp. 142\u2013148, 2022.\n[8] P. Avila-Campos, J. Haxhibeqiri, I. Moerman, and J. Hoebeke, \u201cBeacon-\nbased wireless TSN association,\u201d in IEEE INFOCOM 2022 , 2022, pp.\n1\u20132.\n[9] H. Pearce, B. Ahmad, B. Tan, B. Dolan-Gavitt, and R. Karri, \u201cAsleep at\nthe keyboard? Assessing the security of Github copilot\u2019s code contribu-\ntions,\u201d in 2022 IEEE Symposium on Security and Privacy (SP) . IEEE,\n2022, pp. 754\u2013768.\n[10] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt, \u201cExam-\nining zero-shot vulnerability repair with large language models,\u201d arXiv\npreprint arXiv:2112.02125 , 2021.\n[11] B. Ahmad, S. Thakur, B. Tan, R. Karri, and H. Pearce, \u201cFixing\nhardware security bugs with large language models,\u201d arXiv preprint\narXiv:2302.01215 , 2023.\n[12] RapidSilicon, \u201cRapidgpt,\u201d 2023, [Online]. Available: https://rapidsilicon.\ncom/rapidgpt/.[13] H. Pearce, B. Tan, and R. Karri, \u201cDave: Deriving automatically Verilog\nfrom English,\u201d in Proceedings of the 2020 ACM/IEEE Workshop on\nMachine Learning for CAD , 2020, pp. 27\u201332.\n[14] S. Thakur, B. Ahmad, Z. Fan, H. Pearce, B. Tan, R. Karri, B. Dolan-\nGavitt, and S. Garg, \u201cBenchmarking large language models for auto-\nmated verilog RTL code generation,\u201d in 2023 Design, Automation &\nTest in Europe Conference & Exhibition . IEEE, 2023, pp. 1\u20136.\n[15] J. Blocklove, S. Garg, R. Karri, and H. Pearce, \u201cChip-Chat: Challenges\nand opportunities in conversational hardware design,\u201d arXiv preprint\narXiv:2305.13243 , 2023.\n[16] K. Chang, Y . Wang, H. Ren, M. Wang, S. Liang, Y . Han, H. Li, and\nX. Li, \u201cChipGPT: How far are we from natural language hardware\ndesign,\u201d arXiv preprint arXiv:2305.14019 , 2023.\n[17] Y . Du, S. C. Liew, and Y . Shao, \u201cEfficient FFT computation in IFDMA\ntransceivers,\u201d IEEE Trans. Wirel. Commun. , 2023.\n[18] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V . Le,\nD. Zhou et al. , \u201cChain-of-thought prompting elicits reasoning in large\nlanguage models,\u201d Advances in Neural Information Processing Systems ,\nvol. 35, pp. 24 824\u201324 837, 2022.\n[19] X. Wang,", "ABSTRACT\nLarge language models (LLMs) have shown exceptional performance on a va-\nriety of natural language tasks. Yet, their capabilities for HTML understanding\n\u2013 i.e., parsing the raw HTML of a webpage, with applications to automation of\nweb-based tasks, crawling, and browser-assisted retrieval \u2013 have not been fully\nexplored. We contribute HTML understanding models (\ufb01ne-tuned LLMs) and an\nin-depth analysis of their capabilities under three tasks: (i) Semantic Classi\ufb01ca-\ntionof HTML elements, (ii) Description Generation for HTML inputs, and (iii)\nAutonomous Web Navigation of HTML pages. While previous work has devel-\noped dedicated architectures and training procedures for HTML understanding,\nwe show that LLMs pretrained on standard natural language corpora transfer re-\nmarkably well to HTML understanding tasks. For instance, \ufb01ne-tuned LLMs are\n12% more accurate at semantic classi\ufb01cation compared to models trained exclu-\nsively on the task dataset. Moreover, when \ufb01ne-tuned on data from the MiniWoB\nbenchmark, LLMs successfully complete 50% more tasks using 192x less data\ncompared to the previous best supervised model. Out of the LLMs we evalu-\nate, we show evidence that T5-based models are ideal due to their bidirectional\nencoder-decoder architecture. To promote further research on LLMs for HTML\nunderstanding, we create and open-source a large-scale HTML dataset distilled\nand auto-labeled from CommonCrawl.1\n1 I NTRODUCTION\nWeb crawling (Olston et al., 2010), form-\ufb01lling (Diaz et al., 2013; Gur et al., 2021), or information\nretrieving web agents (Nogueira & Cho, 2016) are important for both automating and assisting\nusers in web-based tasks. These and similar applications rely on models that can search for speci\ufb01c\ncontent or controls on a web page as well as navigate a website autonomously. Since a web page in\nits raw form is represented as an HTML-based text sequence, the success of models for web-based\ntasks relies on their ability to understand HTML semantics, structure, and embedded interactions.\nThe predominant approach to web automation and HTML understanding is to train specialized mod-\nels, i.e., gathering application-speci\ufb01c datasets and designing neural network (NN) architectures to\nleverage inductive biases of the HTML\u2019s structure; see, e.g., Liu et al. (2018); Toyama et al. (2021);\nGur et al. (2021); Humphreys et al. (2022). However, both dataset collection and neural architecture\ndesign are expensive, time-consuming, and require highly-specialized, domain-speci\ufb01c knowledge.\nMeanwhile, in the natural language processing (NLP) literature, large language models (LLMs) have\nemerged as a solution to the dif\ufb01culties of dataset collection and specialized NN design (Kaplan\net al., 2020; Bommasani et al., 2021). A popular paradigm in NLP is to take an off-the-shelf LLM\n\u2013 pretrained on a large text corpus via an unsupervised and task-agnostic learning objective \u2013 and\neither \ufb01ne-tune or prompt the LLM on a small task-speci\ufb01c dataset. This paradigm has shown\nexceptional performance on a variety of NLP tasks (Xue et al., 2020; Brown et al., 2020; Austin\net al., 2021). Whether LLMs can be applied to HTML understanding \u2013 especially given the much\nlarger context and sequence lengths \u2013 remains an under-explored question.\n1See visualizations of theresults are borrowed from\n(Humphreys et al., 2022). Note that these are normalized between 0 and 1.\nTASK Human CC-Net CC-Net World Work\ufb02ow Learning DOM-Q-Net Work\ufb02ow Learning Aggregated Aggregated\nWebN-T5-3B WebN-T5-3B (SL & RL) (SL) of guided to (RL) guided to SOTA SOTA\n(no history) bits exploration navigate exploration navigate (SL & RL) (Augmented)\n(SL & RL) (SL & RL) the", " Introduction\nOpen Domain Question Answering (ODQA) (Lee\net al., 2019; Lewis et al., 2020c) is an important\n1This paper is awaiting publication at TACL and this is a\npre-MIT Press publication versiontask in natural language understanding. ODQA methods of putting in an appropriate way, what was at issue there. There was \na disagreement about the content of the allegations. <end> MS. ROBIN-VERGEER (RESPONDENT): I don't think it's important, \nfor, maybe, purposes of this, to iron this out, but I -- respectfully, I don't agree with that characterization, because, even in the \nresolution of the grievance internally, the -- what they found in the grievance was that they took no adverse action against him \nbecause of what he said -- <end> JUSTICE BREYER: That doesn't -- <end> MS. ROBIN-VERGEER (RESPONDENT): -- in \nconnection with this case. <end> JUSTICE BREYER: That isn't in an appropriate way, what was at issue there. There was a \ndisagreement about the content of the allegations. <end> MS. ROBIN-VERGEER (RESPONDENT): I don't think it's important, \nfor, maybe, purposes of this, to iron this out, but I -- respectfully, I don't agree with that characterization, because, even in the \nresolution of the grievance internally, the -- what they found in the grievance was that they took no adverse action against him \nbecause of what he said -- <end> JUSTICE BREYER: That doesn't -- <end> MS. ROBIN-VERGEER (RESPONDENT): -- in \nconnection with this case. <end> JUSTICE BREYER: That isn't in an appropriate way, what was at issue there. There was a \ndisagreement about the content of the allegations. <end> MS. ROBIN-VERGEER (RESPONDENT): I don't think it's important, \nfor, maybe, purposes of this, to iron this out, but I -- respectfully, I don't agree with that characterization, because, even in the \nresolution of the grievance internally, the -- what they found in the grievance was that they took no adverse action against him \nbecause of what he said -- <end> JUSTICE BREYER: That doesn't -- <end> MS. ROBIN-VERGEER (RESPONDENT): -- in \nconnection with this case. <end> JUSTICE BREYER: That isn'tKimbery I looked at the source code for Racket\u00e2\u20ac\u2122s require and provide and I examined %require and %provide a little end \nKimbery Here\u00e2\u20ac\u2122s what I learned require transformers and provide pretransformers are implemented in Racket Provide \ntransformers are implemented in C end Kimbery I think provide transformers are pretty restricted because they have access to the \nbindings exported by allfromout and things like that but in order to know that the module needs to know which bindings are \nshadowed by the module body So provide transformers are essentially the very last step of macro transformation in a module\u00e2\u20ac\u2122s \nexpansion end Kimbery I looked at the source code for Racket\u00e2\u20ac\u2122s require and provide and I examined %require and %provide a \nlittle end Kimbery Here\u00e2\u20ac\u2122s what I learned require transformers and provide pretransformers are implemented in Racket Provide \ntransformers are implemented in C end Kimbery I think provide transformers are pretty restricted because they have access to the \nbindings exported by allfromout and things like that but in order to know that the module needs to know which", " introduction. We study the importance\nof the retriever module, the ef\ufb01cacy of the source pointer work\ufb02ow, the tradeoff between ef\ufb01ciency\nand effectiveness using a controlled baseline, and \ufb01nally we compare our FiD-LightSPto related Appendix C.\nEven our T5-Base con\ufb01guration in row 8 already outperforms previous SOTA conclusion we observe clear and statistically signi\ufb01cant improvements between FiDSPand FiD-\nLightSP\u2013 both in terms of effectiveness and ef\ufb01ciency \u2013 across a variety of KILT tasks. FiD-LightSP\n8Table 3: Comparing our models with discussion with the open domain QA tasks in Figure 5 (a, b, & c) as they provide\na similar picture: Comparing our FiD-LightSPmodel with the baseline we do observe a drop in\neffectiveness from the strongest baseline (gray dotted vertical line) when using the same T5-Base\nmodel. However, due to the more ef\ufb01cient architecture we are able to swap backbones and earn\nthe bene\ufb01ts of those larger models in terms of effectiveness. At the same time we outperform the\nlatency of the baseline as well, shifting the Pareto optimum. Interestingly, the FiD-LightSPmodel\nwith T5-XL and only a single encoded vector per passage shows a larger drop in effectiveness than\nthe counterparts for smaller T5\u2019s. The only 2-label classi\ufb01cation task, FEVER, shown in Figure 5\n(d), exhibits the lowest reduction in effectiveness, when constraining the number of encoded vectors\nin FiD-LightSP. This is likely due to the fact, that only little generation is necessary to solve the task.\nTherefore, our FiD-LightSPcon\ufb01gurations improve the Pareto optimum again. The slot-\ufb01lling tasks\nin Figure 5 (e & f) show less impact of the T5 size, with little improvement for Large and XL over\nthe Base con\ufb01gurations. Fortunately, we also observe a similarly small reduction in effectiveness\nfor reducing the number of encoded FiD-LightSPvectors, leading to our \ufb01nal Pareto gains.\nIn conclusions or recommendations\nexpressed in this material are those of the authors and do not necessarily re\ufb02ect those of the sponsors. REFERENCES\nAkari Asai, Matt Gardner, and Hannaneh Hajishirzi. Evidentiality-guided generation for knowledge-\nintensive nlp tasks. arXiv preprint arXiv:2112.08688 , 2021. 4\nPayal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Ma-\njumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated\nmachine reading comprehension dataset. arXiv preprint arXiv:1611.09268 , 2016. 13, 14\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the\ndangers of stochastic parrots: Can language models be too big? In Proc. of FAccT , 2021. 8\nMichele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Wen-tau Yih, Sebastian Riedel, and Fabio\nPetroni. Autoregressive search engines: Generating substrings as document identi\ufb01ers. arXiv\npreprint arXiv:2204.10628 , 2022. 9, 15\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Mil-\nlican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego\nde Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren\nMaggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol\nVinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. Im-\nproving language models by retrieving from trillions of tokens. arXiv preprint arXiv:2112.04426 ,\n2021. 4\nJordan Boyd-Graber and Benjamin B \u00a8orschinger. What question answering can learn from trivia\nnerds. arXiv preprint arXiv:1910.14464 , 2019. 16\nJiecao Chen, Liu Yang, Karthik Raman, Michael Bendersky, Jung-Jung Yeh, Yun Zhou, Marc Na-\njork, Danyang Cai, and Ehsan Emadzadeh.", " Introduction\nDeep unsupervised learning with generative and embed-\nding models has seen dramatic success in the past few\nyears. Generative models (Peters et al., 2018; Raffel et al.,\n2019; van den Oord et al., 2016; Ramesh et al., 2021;\nBrown et al., 2020; Chen et al., 2021) are trained to max-\n*Equal contribution1OpenAI. Correspondence to: Arvind\nNeelakantan <arvind@openai.com >.\nS-300M M-1.2B L-6B XL-175B\nModel Size606264666870Performance\nAverage performance vs model sizeFigure 1. Average performance of unsupervised cpt-text\nmodels of different sizes across 22 tasks consisting of linear-probe\nclassi\ufb01cation, text search, and sentence similarity tasks.\nimize the likelihood of observed data while embedding\nmodels are trained to distinguish observed data from noise\n(Sohn, 2016; van den Oord et al., 2018; Radford et al.,\n2021; Jia et al., 2021; Gao et al., 2021; Izacard et al., 2021).\nGenerative models have been shown to produce realistic\ncontent and bene\ufb01t many downstream applications, reduc-\ning the need for labeled training datasets. In generative\nmodels, the information about the input is typically dis-\ntributed over multiple hidden states of the model. While\nsome generative models (Kingma & Welling, 2014; Kiros\net al., 2015) can learn a single representation of the in-\nput, most autoregressive Transformer (Vaswani et al., 2017)\nmodels do not (Raffel et al., 2019; Brown et al., 2020; Chen\net al., 2021; Ramesh et al., 2021). However, learning such a\nrepresentation (or embedding) is necessary for many tasks.\nSystems that search over millions or billions of items re-\nquire each entry to be embedded as a dense representation\nand build an index in advance to save computational costs\nat query time. These embeddings are useful features for\nclassi\ufb01cation tasks and can also enable data visualization\napplications via techniques such as clustering. Embedding\nmodels are explicitly optimized to learn a low dimensional\nrepresentation that captures the semantic meaning of the\ninput (Radford et al., 2021; Jia et al., 2021; Giorgi et al.,\n2020; Gao et al., 2021; Izacard et al., 2021).arXiv:2201.10005v1  [cs.CL]  24 Jan 2022Text and Code Embeddings by Contrastive Pre-Training\nIn this work, we train embedding models using a con-\ntrastive learning objective with in-batch negatives (Sohn,\n2016; Yih et al., 2011) on unlabeled data. The input is en-\ncoded with a Transformer encoder (Vaswani et al., 2017)\nand we leverage naturally occurring paired data to con-\nstruct training data with no explicit labels. Text embedding\nmodels are trained on paired text data where we consider\nneighboring pieces of text on the Internet as positive pairs.\nCode embedding models treat the top-level docstring in a\nfunction along with its implementation as a (text, code)\npair. The training signal of the contrastive objective on\nits own is not suf\ufb01cient to learn useful representations and\nwe overcome this by initializing our model with other pre-\ntrained models (Brown et al., 2020; Chen et al., 2021). Fi-\nnally, we \ufb01nd that it is critical to use a suf\ufb01ciently large\nbatch to achieve the optimal performance. We show that\nthis simple recipe combining pre-trained model initializa-\ntion, large-batch contrastive learning and training at scale,\ncan produce text and code embeddings that possess a broad\nrange of capabilities.\nWe train a series of unsupervised text embedding mod-\nels (cpt-text ) of different sizes, ranging from 300M\nto 175B parameters, and observe a consistent perfor-\nmance improvement with increasing model sizes (Figure\n1). On classi\ufb01cation accuracy averaging across 7 linear-\nprobe classi\ufb01cation tasks in SentEval (Conneau & Kiela,\n2018), our largest unsupervised model", " Introduction\nThe vast majority of text used to pretrain lan-\nguage models is extracted from web pages, while\ndiscarding any markup they contain ( Liu et al. ,\n2019 ;Brown et al. ,2020 ;Raffel et al. ,2019 ;\nLewis et al. ,2019 ). We argue that this HTML\nshould not be ignored; it enables new forms of\nhighly effective language model pretraining and\n\u2217Equal Contribution<!DOCTYPE html>\n<html>\n<title> <mask>12 </title>\n<body>\n\u02dc south korea on monday announced sweeping\ntax reforms , including income and\ncorporate tax cuts to boost growth by\nstimulating sluggish private\nconsumption and business investment .\n</body>\n</html>\n\u2193\n<!DOCTYPE html>\n<html>\n<title> \u02dc South Korea Announces Tax Reforms To\nBoost Economic Growth \u02dc </title>\n<body>\n\u02dc south korea on monday announced sweeping\ntax reforms...\n</body>\n</html>\nFigure 1: An example structured prompt for a simple\nsummarization task, where we ask a generative masked\nlanguage model to generate a mask representing the ti-\ntle with an average tokens size of 12.\nprompting with structured document-level super-\nvision.\nHyper-text, such as the HTML found in the\nCommon Crawl1, has a number of advantages for\npretraining over plain text. It often encodes high-\nlevel properties of different parts of the documents,\nwhich are dif\ufb01cult to infer from the text alone.\nFor example, <title> elements can be excellent\nsummaries of the <body> of a document, while\nelementclass andidattributes can encode cate-\ngorical properties of documents. Such supervision\nis highly diverse, depending on what the website\nauthors choose to present, and provides close prox-\nies for many NLP tasks we aim to later solve.\nModeling hyper-text allows us to introduce\nstructured prompting of language models. We de-\nsign prompts that incorporate the established se-\nmantics of HTML to better control for the de-\nsired model output. This includes, for exam-\n1https://commoncrawl.org/ple, performing zero-shot summarization by ask-\ning the model to in\ufb01ll <title> tags in a web\npage. And, the fact that we jointly model text\nand hyper-text formatting also allows for effective\nauto-prompting. If we have even a few examples\nfor a new task, we can directly ask the model to\nformat them in HTML, and templatize the result\nto de\ufb01ne the new prompt.\nOur HyperTextLanguage Model (HTLM ) is\ntrained on 23TB of simpli\ufb01ed HTML which we\nautomatically extract from common crawl dumps\n(see Section \u00a7 2.1). We use a modi\ufb01ed BART\ndenoising objective ( Lewis et al. ,2019 ) that ran-\ndomly masks spans of hyper-text and aims to re-\nconstruct the original input. We extend the origi-\nnal masking with a new size hint scheme, where\neach mask is associated with an integer that pro-\nvides a noisy hint for the size of the masked text,\nto allow for more \ufb01ne grained task-speci\ufb01c length\npriors when prompting the \ufb01nal model (see Sec-\ntion \u00a7 2.3). Figure 1shows an example mask that\nshould be reconstructed with a phrase that contains\nroughly 12 tokens.\nThrough extensive experiments on GLUE results on\nzero-shot prompting for summarization by a wide\nmargin by creating prompts that capture the un-\nderlying semantics of each summarization dataset.\nFurthermore, we show that pre-training on struc-\ntured data improved full \ufb01netuning performance\nrelative to other pre-trained models that only mod-\neled natural language.\nWe also showed additional advantages of model-\ning hyper-text, beyond improved accuracy. HTLM\ncan be used for auto-prompt by simply asking\nthe model to recover the document structure from\ntraining samples; these auto-prompts on datasets\nlike Gigaword and CNN/DM outperformed previ-\nous state-of-the-art zero-shot approaches. Lastly,\nwe provided an in-depth comparison of the train-\ning advantage, in terms of data ef\ufb01ciency, that\nHTLM had compared to other", " Introduction\nRecognizing and describing the visual world with natural\nlanguage is an essential capability for arti\ufb01cial intelligence.\nIt motivates the research of image-text matching, which\nchallenges a learning agent to establish accurate and general-\nizable alignment between visual and textual data, so that one\ncan identify images or videos by text queries or vice versa.\nVisual semantic embedding (VSE) [ 10,11,23] tackles\n*Authors contributed equallythis challenge by learning a semantic embedding space,\nwhere the distance between paired visual and textual in-\nstances in the embedding space is optimized to be small.\nThe core idea of the VSE has three steps:\nStep 1. Extract a set (or sequence) of features from data,\nusing feature extractors (e.g., ConvNets for visual data).\nStep 2. Contextualize and aggregate the extracted features\nto project them into the joint embedding space as holistic\nvectors, using feature aggregators .\nStep 3. Compute the matching score between embeddings\nwith a similarity metric ( e.g., cosine distance).\nWith the feature extractor determined, one might expect that\na complex aggregator is required to achieve good results is that: feature extractors have provided\nadequate information for multi-modal matching, so the fea-\nture aggregators do not have to further contextualize the\nfeature vectors. Too complicated models for feature contex-\ntualization might increase the risk of over-\ufb01tting and hurt\nthe performance at the end. introduction of its formal de\ufb01nition\n(\u00a7 3.2), followed by the details of GPO\u2019s concrete model\narchitecture (\u00a7 3.3). Finally, we summarize our multi-modal\nsystem (VSE1) that leverages GPO (\u00a7 3.4).\n3.1. Simple Pooling Works the Best\nAs aforementioned in \u00a7 1, complex aggregators fhave\nbeen investigated in the VSE literature [ 18,28,44,46,47],\nsuch as sequence-to-sequence encoder (Seq2Seq), graph con-\nvolution network (GCN), self-attention encoder (SelfAttn),\netc. However, we surprisingly \ufb01nd that these aggregation\nmodels with millions of parameters underperform carefully\nselected pooling functions.\nTable 1 highlights a comparison between different aggre-\ngators, across two widely used image feature extractors in\nthe literature [ 19] \u2013Grid feature is the feature maps from\nConvNets and Region feature is the ROI features from object\ndetectors [ 1] (details in \u00a7 5). The Appendix\nprovides more motivations for this augmentation strategy.\nSurprisingly, we \ufb01nd this strategy also improves the baseline\nVSE++ [ 10], potentially as a regularization method. State-of-\nthe-art video-text matching model [ 4] uses a similar strategy,\nfeature dropout, which adds a dropout layer for input fea-\ntures. The difference is that it randomly set feature values to\n0, while Size Augmentation randomly drops entire elements\nfrom the feature set.\n(3) Different choices of the sequence model in GPO We\nalso try using different sequence model to implement GPO.\nTable 8 shows that using a Transformer Encoder [ 43] to re-\nplace the simple BiGRU does not yield improvements on\ntwo different combinations of features. The sequence model\nof GPO only takes the positional information as the input\nwithout using the exact feature vectors, thus we believe it\u2019sTable 8. Different choices of the sequence model used by GPO\nData Split COCO 5-fold 1 KTest [5]\nEval Task IMG!TEXT TEXT!IMG\nFeatures Seq. Model R@1 R@5 R@1 R@5\nBUTD (Region)\n+ BiGRUTransformer 77.4 95.4 61.4 90.1\nBiGRU 78.5 96.0 61.7 90.3\nBUTD (Grid)\n+ BiGRUTransformer 76.6 95.7 62.7 90.7\nBiGRU 78.0 95.8 62.6 90.6\nnot necessary for the sequence model to have large capacity.\nA simple BiGRU will suf\ufb01ce for both capacity and compu-\ntational ef\ufb01ciency, and more complex mechanisms like the\nmulti-head attentions of Transformers could even hurt the\nperformance.\nB.2. More Results are", " Introduction\nRecent years have featured a trend towards pre-trained language representations in NLP systems, applied in increasingly\n\ufb02exible and task-agnostic ways for downstream transfer. First, single-layer representations were learned using word\nvectors [ MCCD13 ,PSM14 ] and fed to task-speci\ufb01c architectures, then RNNs with multiple layers of representations\nand contextual state were used to form stronger representations [ DL15 ,MBXS17 ,PNZtY18 ] (though still applied to\ntask-speci\ufb01c architectures), and more recently pre-trained recurrent or transformer language models [ VSP+17] have\nbeen directly \ufb01ne-tuned, entirely removing the need for task-speci\ufb01c architectures [RNSS18, DCLT18, HR18].\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension,\nquestion answering, textual entailment, and many others, and has continued to advance based on new architectures\nand algorithms [ RSR+19,LOG+19,YDY+19,LCG+19]. However, a major limitation to this approach is that while\nthe architecture is task-agnostic, there is still a need for task-speci\ufb01c datasets and task-speci\ufb01c \ufb01ne-tuning: to achieve\nstrong performance on a desired task typically requires \ufb01ne-tuning on a dataset of thousands to hundreds of thousands\nof examples speci\ufb01c to that task. Removing this limitation would be desirable, for several reasons.\nFirst, from a practical perspective, the need for a large dataset of labeled examples for every new task limits the\napplicability of language models. There exists a very wide range of possible useful language tasks, encompassing\nanything from correcting grammar, to generating examples of an Results for SAT task.\n Figure H.3: All Related Work\nSeveral lines of work have focused on increasing parameter count and/or computation in language models as a\nmeans to improve generative or task performance. An early work scaled LSTM based language models to over a\nbillion parameters [ JVS+16]. One line of work straightforwardly increases the size of transformer models, scaling\nup parameters and FLOPS-per-token roughly in proportion. Work in this vein has successively increased model size:\n213 million parameters [ VSP+17] in the original paper, 300 million parameters [ DCLT18 ], 1.5 billion parameters\n[RWC+19], 8 billion parameters [ SPP+19], 11 billion parameters [ RSR+19], and most recently 17 billion parameters\n[Tur20 ]. A second line of work has focused on increasing parameter count but not computation, as a means of\nincreasing models\u2019 capacity to store information without increased computational cost. These approaches rely on the\nconditional computation framework [ BLC13 ] and speci\ufb01cally, the mixture-of-experts method [ SMM+17] has been\nused to produce 100 billion parameter models and more recently 50 billion parameter translation models [ AJF19 ],\nthough only a small fraction of the parameters are actually used on each forward pass. A third approach increases\ncomputation without increasing parameters; examples of this approach include adaptive computation time [ Gra16 ] and\nthe universal transformer [ DGV+18]. Our work focuses on the \ufb01rst approach (scaling compute and parameters together,\nby straightforwardly making the neural net larger), and increases model size 10x beyond previous models that employ\nthis strategy.\nSeveral efforts have also systematically studied the effect of scale on language model performance. [ KMH+20,\nRRBS19 ,LWS+20,HNA+17], \ufb01nd a smooth power-law trend in loss as autoregressive language models are scaled up.\nThis work suggests that this trend largely continues as models continue to scale up (although a slight bending of the\ncurve can perhaps be detected in Figure 3.1),", " Introduction\nFigure 1: Our SupCon loss consistently outper-\nforms cross-entropy with standard data augmenta-\ntions. We show top-1 accuracy for the ImageNet\ndataset, on ResNet-50, ResNet-101 and ResNet-\n200, and compare against AutoAugment [5], Ran-\ndAugment [6] and CutMix [60].The cross-entropy loss is the most widely used loss\nfunction for supervised learning of deep classi\ufb01ca-\ntion models. A number of works have explored\nshortcomings of this loss, such as lack of robustness\nto noisy labels [64, 46] and the possibility of poor\nmargins [10, 31], leading to reduced generalization\nperformance. However, in practice, most proposed\nalternatives have not worked better for large-scale\ndatasets, such as ImageNet [7], as evidenced by the\ncontinued use of cross-entropy to achieve state of the\nart results for more optimizers and data augmentation strategies. Added SupCon loss\nhierarchy. Adjusted table reporting for clarity.\nVersion 3 (2020-10-13) Removed deprecated sentence from Related Work\nOur work draws on existing literature in self-supervised representation learning, metric learning\nand supervised learning. Here we focus on the most relevant papers. The cross-entropy loss was\nintroduced as a powerful loss function to train deep networks [40, 1, 29]. The key idea is simple\nand intuitive: each class is assigned a target (usually 1-hot) vector. However, it is unclear why\nthese target labels should be the optimal ones and some work has tried to identify better target label\nvectors, e.g. [57]. A number of papers have studied other drawbacks of the cross-entropy loss,\nsuch as sensitivity to noisy labels [64, 46], presence of adversarial examples [10, 36], and poor\nmargins [2]. Alternative losses have been proposed, but the most effective ideas in practice have\nbeen approaches that change the reference label distribution, such as label smoothing [47, 35], data\naugmentations such as Mixup [61] and CutMix [60], and knowledge distillation [21].\nPowerful self-supervised representation learning approaches based on deep learning models have\nrecently been developed in the natural language domain [8, 58, 33]. In the image domain, pixel-\npredictive approaches have also been used to learn embeddings [9, 62, 63, 37]. These methods consistently outperform cross entropy for varying strengths of augmentation.\n2215 Change Log\nVersion 1 (2020-04-23) Initial Arxiv version.\nVersion 2 (2020-10-22) Added analysis of different forms of supervised contrastive loss and its\ngradients as well as experimental experiments. Moved accuracy vs num positives to supplemen-\ntary. More heavily tuned models resulted in deterioration of ECE. Added StackedRandAugment\naugmentation. Added GitHub link for code. Added conclusion. As shown in the Supplementary,\nthe gradient for eitherLsup\nout;i orLsup\nin;iwith respect to the embedding zihas the following form.\n@Lsup\ni\n@zi=1\n\u001c8\n<\n:X\np2P(i)zp(Pip\u0000Xip) +X\nn2N(i)znPin9\n=\n;(4)\nHere,N(i)\u0011fn2A(i) :~yn6=~yigis the set of indices of all negatives in the multiviewed batch,\nandPix\u0011exp(zi\u000fzx=\u001c)=P\na2A(i)exp(zi\u000fza=\u001c). The difference between the gradients for the\ntwo losses is in Xip.\nXip=8\n<\n:exp(zi\u000fzp=\u001c)P\np02P(i)exp(zi\u000fzp0=\u001c);ifLsup\ni=Lsup\nin;i\n1\njP(i)j;ifLsup\ni=Lsup\nout;i(5)\nIf each zpis set to the (less biased) mean positive representation vector, z,Xin\nipreduces toXout\nip:\nXin\nip\f\f\nzp=z=exp(zi\u000fz=\u001c)P\np02P(i)exp(zi\u000fz=\u001c)=exp(zi\u000fz=\u001c)\njP(i)j\u0001exp(zi\u000fz=\u001c)=1\njP(i)j=Xout\nip (6)\nFrom the form of @Lsup\ni=@zi, we conclude that the stabilization due to using the mean of positives\nbene\ufb01ts training. Throughout the rest of the paper, we consider only Lsup\nout.\n3.2.3 Connection to Triplet Loss and N-pairs Loss\nSupervised contrastive learning is closely related to the triplet loss [53], one of the widely-used loss\nfunctions for supervised learning. In the Supplementary, we show that the triplet loss is a special\ncase of the contrastive loss when one positive and one negative are used. When more than one\nnegative is used, we show that the SupCon", " Introduction. MIT press .\nTai, K.S., Socher, R., Manning, C.D., 2015. Improved semantic representations from tree-\nstructured long short-term memory networks. In: Proceeding of IJCNLP,\npp. 1556 \u20131566 .\nTang, J., Zhang, J., Yao, L., Li, J., Zhang, L., Su, Z., 2008. Arnetminer: extraction and\nmining of academic social networks. In: Proceedings of KDD. ACM, pp. 990 \u2013998.J. Zhou et al. AI Open 1 (2020) 57 \u201381\n79Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J., Mei, Q., 2015. Line: large-scale\ninformation network embedding. In: Proceedings of WWW, pp. 1067 \u20131077 .\nTeney, D., Liu, L., Den Hengel, A.V., 2017. Graph-structured representations for visual\nquestion answering. In: Proceedings of CVPR, pp. 3233 \u20133241 .\nTiezzi, M., Marra, G., Melacci, S., Maggini, M., 2020. Deep Lagrangian Constraint-Based\nPropagation in Graph Neural Networks. arXiv preprint arXiv:2005.02392 .\nToivonen, H., Srinivasan, A., King, R.D., Kramer, S., Helma, C., 2003. Statistical\nevaluation of the predictive toxicology challenge 2000 \u20132001. Bioinformatics 19,\n1183 \u20131193 .\nToutanova, K., Chen, D., Pantel, P., Poon, H., Choudhury, P., Gamon, M., 2015.\nRepresenting text for joint embedding of text and knowledge bases. In: Proceedings\nof EMNLP, pp. 1499 \u20131509 .\nTsitsulin, A., Palowitch, J., Perozzi, B., M\u00fcller, E., 2020. Graph Clustering with Graph\nNeural Networks. arXiv preprint arXiv:2006.16904 .\nTu, M., Wang, G., Huang, J., Tang, Y., He, X., Zhou, B., 2019. Multi-hop reading\ncomprehension across multiple documents by reasoning over heterogeneous graphs.\nIn: Proceedings of ACL, pp. 2704 \u20132713 .\nvan den Berg, R., Kipf, T.N., Welling, M., 2017. Graph convolutional matrix completion.\narXiv preprint arXiv:1706.02263 .\nVaswani, A., Shazeer, N., Parmar, N., Jones, L., Uszkoreit, J., Gomez, A.N., Kaiser, L.,\n2017. Attention is all you need. In: Proceeding of NIPS, pp. 5998 \u20136008 .\nVelickovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., 2018. Graph\nattention networks. In: Proceedings of ICLR .\nVelickovic, P., Fedus, W., Hamilton, W.L., Li /C18o, P., Bengio, Y., Hjelm, R.D., 2019. Deep\ngraph infomax. In: Proceedings of ICLR .\nVerma, S., Zhang, Z.-L., 2019. Stability and generalization of graph convolutional neural\nnetworks. In: Proceedings of KDD, pp. 1539 \u20131548 .\nVinyals, O., Bengio, S., Kudlur, M., 2015a. Order Matters: Sequence to Sequence for Sets\narXiv preprint arXiv:1511.06391 .\nVinyals, O., Fortunato, M., Jaitly, N., 2015b. Pointer networks. In: Proceedings of NIPS,\npp. 2692 \u20132700 .\nWale, N., Watson, I.A., Karypis, G., 2008. Comparison of descriptor spaces for chemical\ncompound retrieval and classi \ufb01cation. Knowl. Inf. Syst. 14, 347 \u2013375.\nWang, H., Leskovec, J., 2020. Unifying Graph Convolutional Neural Networks and Label\nPropagation. arXiv preprint arXiv:2002.06755 .\nWang, C., Pan, S., Long, G., Zhu, X., Jiang, J., 2017. Mgae: marginalized graph\nautoencoder for graph clustering. In: Proceedings of CIKM, pp. 889 \u2013898.\nWang, X., Girshick, R., Gupta, A., He, K., 2018a. Non-local neural networks. In:\nProceedings of CVPR, pp. 7794 \u20137803 .\nWang, Z., Lv, Q., Lan, X., Zhang, Y., 2018b. Cross-lingual knowledge graph alignment via\ngraph convolutional networks. Proceedings of EMNLP 349 \u2013357.\nWang, Z., Chen, T., Ren, J.S.J., Yu, W., Cheng, H., Lin, L., 2018c. Deep reasoning with\nknowledge graph for social relationship understanding. Proceedings of IJCAI\n1021 \u20131028 .\nWang, X., Ye, Y., Gupta, A., 2018d. Zero-shot recognition via semantic embeddings and\nknowledge graphs. Proceedings of CVPR 6857 \u20136866 .\nWang, Y., Sun, Y., Liu, Z., Sarma, S.E., Bronstein, M.M., Solomon, J.M., 2018e. Dynamic\nGraph Cnn for Learning on Point", " INTRODUCTION\nMachine learning and data-driven approaches are becom-\ning very important in many areas. Smart spam classi\fers\nprotect our email by learning from massive amounts of spam\ndata and user feedback; advertising systems learn to match\nthe right ads with the right context; fraud detection systems\nprotect banks from malicious attackers; anomaly event de-\ntection systems help experimental physicists to \fnd events\nthat lead to new physics. There are two important factors\nthat drive these successful applications: usage of e\u000bective\n(statistical) models that capture the complex data depen-\ndencies and scalable learning systems that learn the model\nof interest from large datasets.\nAmong the machine learning methods on\ndi\u000berent subsets of criteo data. The missing data\npoints are due to out of disk space. We can \fnd\nthat basic algorithm can only handle 200M exam-\nples. Adding compression gives 3x speedup, and\nsharding into two disks gives another 2x speedup.\nThe system runs out of \fle cache start from 400M\nexamples. The algorithm really has to rely on disk\nafter this point. The compression+shard method\nhas a less dramatic slowdown when running out of\n\fle cache, and exhibits a linear trend afterwards.\nlearning to rank problem. We compare against pGBRT [22],\nthe best previously pubished system on this task. XGBoost\nruns exact greedy algorithm, while pGBRT only support an\napproximate algorithm. The Related work\nis discussed in Sec. 5. Detailed end-to-end evaluations are\nincluded in Sec. 6. Finally we conclude the paper in Sec. 7.\n2. TREE BOOSTING IN A NUTSHELL\nWe review gradient tree boosting algorithms in this sec-\ntion. The derivation follows from the same idea in existing\nliteratures in gradient boosting. Specicially the second order\nmethod is originated from Friedman et al. [12]. We make mi-\nnor improvements in the reguralized objective, which were\nfound helpful in practice.\n2.1 Regularized Learning Objective\nFor a given data set with nexamples and mfeatures\nD=f(xi;yi)g(jDj=n;xi2Rm;yi2R), a tree ensem-\nble model (shown in Fig. 1) uses Kadditive functions to\npredict the output.\n^yi=\u001e(xi) =KX\nk=1fk(xi); fk2F; (1)\nwhereF=ff(x) =wq(x)g(q:Rm!T;w2RT) is the\nspace of regression trees (also known as CART). Here qrep-\nresents the structure of each tree that maps an example to\nthe corresponding leaf index. Tis the number of leaves in the\ntree. Each fkcorresponds to an independent tree structure\nqand leaf weights w. Unlike decision trees, each regression\ntree contains a continuous score on each of the leaf, we use\nwito represent score on i-th leaf. For a given example, we\nwill use the decision rules in the trees (given by q) to classify\nFigure 1: Tree Ensemble Model. The \fnal predic-\ntion for a given example is the sum of predictions\nfrom each tree.\nit into the leaves and calculate the \fnal prediction by sum-\nming up the score in the corresponding leaves (given by w).\nTo learn the set of functions used in the model, we minimize\nthe following regularized objective.\nL(\u001e) =X\nil(^yi;yi) +X\nk\n(fk)\nwhere \n(f) =\rT+1\n2\u0015kwk2(2)\nHerelis a di\u000berentiable convex loss function that measures\nthe di\u000berence between the prediction ^ yiand the target yi.\nThe second term \n penalizes the complexity of the model\n(i.e., the regression tree functions). The additional regular-\nization term helps to smooth the \fnal learnt weights to avoid\nover-\ftting. Intuitively, the regularized objective will tend\nto select a model employing simple and predictive functions.\nA similar regularization technique has been used in Regu-\nlarized greedy forest (RGF) [25] model. Our objective and\nthe corresponding learning algorithm is simpler than RGF\nand easier to parallelize.", " Introduction\nTo take advantage of the sheer size of modern data sets, we now need learn-\ning algorithms that scale with the volume of information, while maintaining\nsu\u000ecient statistical e\u000eciency. Random forests, devised by L. Breiman in\nthe early 2000s (Breiman, 2001), are part of the list of the most successful methods. arXiv:1502.03836 , 2015b.\nE. Scornet, G. Biau, and J.-P. Vert. Consistency of random forests. The\nAnnals of Statistics , 43:1716{1741, 2015.\nM.R. Segal. Regression trees for censored data. Biometrics , 44:35{47, 1988.\nJ. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore,\nA. Kipman, and A. Blake. Real-time human pose recognition in parts\nfrom single depth images. In IEEE Conference on Computer Vision and\nPattern Recognition , pages 1297{1304, 2011.\nC.J. Stone. Consistent nonparametric regression. The Annals of Statistics ,\n5:595{645, 1977.\nC.J. Stone. Optimal rates of convergence for nonparametric estimators. The\nAnnals of Statistics , 8:1348{1360, 1980.\nC.J. Stone. Optimal global rates of convergence for nonparametric regression.\nThe Annals of Statistics , 10:1040{1053, 1982.\nC. Strobl, A.-L. Boulesteix, T. Kneib, T. Augustin, and A. Zeileis. Con-\nditional variable importance for random forests. BMC Bioinformatics , 9:\n307, 2008.\nV. Svetnik, A. Liaw, C. Tong, J.C. Culberson, R.P. Sheridan, and B.P.\nFeuston. Random forest: A classi\fcation and regression tool for compound\nclassi\fcation and QSAR modeling. Journal of Chemical Information and\nComputer Sciences , 43:1947{1958, 2003.\n40L. Tolo\u0018 si and T. Lengauer. Classi\fcation with correlated features: Unre-\nliability of feature ranking and solutions. Bioinformatics , 27:1986{1994,\n2011.\nA.K.Y. Truong. Fast Growing and Interpretable Oblique Trees via Logistic\nRegression Models . PhD thesis, University of Oxford, Oxford, 2009.\nH. Varian. Big data: New tricks for econometrics. Journal of Economic\nPerspectives , 28:3{28, 2014.\nS. Wager. Asymptotic theory for random forests. arXiv:1405.0352 , 2014.\nS. Wager, T. Hastie, and B. Efron. Con\fdence intervals for random forests:\nThe jackknife and the in\fnitesimal jackknife. Journal of Machine Learning\nResearch , 15:1625{1651, 2014.\nG.S. Watson. Smooth regression analysis. Sankhy \u0016aSeries A , pages 359{372,\n1964.\nJ. Welbl. Casting random forests as arti\fcial neural networks (and pro\ft-\ning from it). In X. Jiang, J. Hornegger, and R. Koch, editors, Pattern\nRecognition , pages 765{771. Springer, 2014.\nS.J. Winham, R.R. Freimuth, and J.M. Biernacka. A weighted random forests\napproach to improve predictive performance. Statistical Analysis and Data\nMining: The ASA Data Science Journal , 6:496{505, 2013.\nD. Yan, A. Chen, and M.I. Jordan. Cluster forests. Computational Statistics\n& Data Analysis , 66:178{192, 2013.\nF. Yang, J. Wang, and G. Fan. Kernel induced random survival forests.\narXiv:1008.3952 , 2010.\nZ. Yi, S. Soatto, M. Dewan, and Y. Zhan. Information forests. In 2012\nInformation Theory and Applications Workshop , pages 143{146, 2012.\nR. Zhu, D. Zeng, and M.R. Kosorok. Reinforcement learning trees. Journal\nof the American Statistical Association, accepted , 2015.\nA. Ziegler and I.R. K\u007f onig. Mining data with random forests: Current options\nfor real-world applications. Wiley Interdisciplinary Reviews: Data Mining\nand Knowledge Discovery , 4:55{63, 2014.\n41Figure 4: An example of a distribution for which greedy random forests\nare inconsistent. The distribution of Xis uniform on the union of the three\nlarge squares. White areas represent the set where m(x) = 0 and grey where\nm(x) = 1.\n42 discussion on the choice of this parameter in various\nregression problems. Another interesting and related approach is by Latinne\net al. (2001), who propose a simple procedure that determines a priori a min-\nimum number of tree estimates"], "bleu": 0.1922303895084158, "rouge_l": 0.33920704845814975, "gpt_metric_score": 0.5, "bert_score": 0.2990667223930359}

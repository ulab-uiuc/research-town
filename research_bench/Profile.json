{
  "6f34668a-8c53-4a5d-8317-66dd8b3ce24f": {
    "pk": "6f34668a-8c53-4a5d-8317-66dd8b3ce24f",
    "name": "Andrew Lizarraga",
    "bio": "I am a researcher dedicated to advancing the fields of generative modeling and reinforcement learning, with a particular focus on planning and decision-making. My recent work has led to the development of the Latent Plan Transformer (LPT), a novel model that effectively connects trajectory generation with long-term returns through latent variable inference. This approach allows for nuanced credit assignments and improved decision-making from sub-optimal trajectories, demonstrating the potential of planning as inference.\n\nIn addition to LPT, I have explored the integration of world models with decision transformers, creating a framework that enhances contextual decision-making through anticipatory trajectory generation. This bidirectional enhancement loop not only accelerates learning but also improves sample efficiency and robustness across diverse benchmarks.\n\nMy research also extends to the realm of text-to-image diffusion models, where I have proposed a Bayesian approach to refine attention mechanisms. By designing custom priors, I aim to improve attribute-object alignment and enhance the interpretability of generative models. My work has consistently achieved state-of-the-art results, addressing long-standing challenges in the field and paving the way for more reliable and interpretable generative systems.\n\nThrough my research, I strive to bridge the gap between complex decision-making tasks and generative modeling, contributing to the development of more sophisticated and effective AI systems.",
    "collaborators": [
      "Ying Nian Wu",
      "Deqian Kong",
      "E. H. Jiang",
      "Zhi Zhang",
      "Yasi Zhang",
      "Dehong Xu",
      "Minglu Zhao",
      "Bo Pang",
      "Jianwen Xie",
      "Yuhao Huang",
      "Sirui Xie",
      "Dinghuai Zhang",
      "Chenheng Xu",
      "Siyan Zhao",
      "Zhengjie Xu",
      "Peiyu Yu",
      "Yuer Tang",
      "Shufan Li"
    ],
    "pub_titles": [
      "Latent Plan Transformer for Trajectory Abstraction: Planning as Latent Space Inference",
      "DODT: Enhanced Online Decision Transformer Learning through Dreamer's Actor-Critic Trajectory Forecasting",
      "Unlocking the Potential of Text-to-Image Diffusion with PAC-Bayesian Theory"
    ],
    "pub_abstracts": [
      "In tasks aiming for long-term returns, planning becomes essential. We study generative modeling for planning with datasets repurposed from offline reinforcement learning. Specifically, we identify temporal consistency in the absence of step-wise rewards as one key technical challenge. We introduce the Latent Plan Transformer (LPT), a novel model that leverages a latent variable to connect a Transformer-based trajectory generator and the final return. LPT can be learned with maximum likelihood estimation on trajectory-return pairs. In learning, posterior sampling of the latent variable naturally integrates sub-trajectories to form a consistent abstraction despite the finite context. At test time, the latent variable is inferred from an expected return before policy execution, realizing the idea of planning as inference. Our experiments demonstrate that LPT can discover improved decisions from sub-optimal trajectories, achieving competitive performance across several benchmarks, including Gym-Mujoco, Franka Kitchen, Maze2D, and Connect Four. It exhibits capabilities in nuanced credit assignments, trajectory stitching, and adaptation to environmental contingencies. These results validate that latent variable inference can be a strong alternative to step-wise reward prompting.",
      "Advancements in reinforcement learning have led to the development of sophisticated models capable of learning complex decision-making tasks. However, efficiently integrating world models with decision transformers remains a challenge. In this paper, we introduce a novel approach that combines the Dreamer algorithm's ability to generate anticipatory trajectories with the adaptive learning strengths of the Online Decision Transformer. Our methodology enables parallel training where Dreamer-produced trajectories enhance the contextual decision-making of the transformer, creating a bidirectional enhancement loop. We empirically demonstrate the efficacy of our approach on a suite of challenging benchmarks, achieving notable improvements in sample efficiency and reward maximization over existing methods. Our results indicate that the proposed integrated framework not only accelerates learning but also showcases robustness in diverse and dynamic scenarios, marking a significant step forward in model-based reinforcement learning.",
      "Text-to-image (T2I) diffusion models have revolutionized generative modeling by producing high-fidelity, diverse, and visually realistic images from textual prompts. Despite these advances, existing models struggle with complex prompts involving multiple objects and attributes, often misaligning modifiers with their corresponding nouns or neglecting certain elements. Recent attention-based methods have improved object inclusion and linguistic binding, but still face challenges such as attribute misbinding and a lack of robust generalization guarantees. Leveraging the PAC-Bayes framework, we propose a Bayesian approach that designs custom priors over attention distributions to enforce desirable properties, including divergence between objects, alignment between modifiers and their corresponding nouns, minimal attention to irrelevant tokens, and regularization for better generalization. Our approach treats the attention mechanism as an interpretable component, enabling fine-grained control and improved attribute-object alignment. We demonstrate the effectiveness of our method on standard benchmarks, achieving state-of-the-art results across multiple metrics. By integrating custom priors into the denoising process, our method enhances image quality and addresses long-standing challenges in T2I diffusion models, paving the way for more reliable and interpretable generative models."
    ],
    "domain": [
      "Reinforcement Learning",
      "Generative Modeling",
      "Text-to-Image",
      "Machine Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "5420a687-e30b-4b3a-b8a8-4e30555f0989": {
    "pk": "5420a687-e30b-4b3a-b8a8-4e30555f0989",
    "name": "Eric Hanchen Jiang",
    "bio": "I am a researcher dedicated to advancing the field of reinforcement learning (RL), particularly in the context of lifelong learning and generative modeling. My recent work has focused on developing innovative algorithms that enhance the adaptability and efficiency of RL agents in dynamic environments. One of my key contributions is EPIC (Empirical PAC-Bayes that Improves Continuously), which leverages PAC-Bayes theory to create a shared policy distribution, enabling agents to rapidly adapt to new tasks while retaining valuable knowledge from previous experiences. \n\nIn addition, I have explored the integration of world models with decision transformers, proposing a novel approach that combines the strengths of the Dreamer algorithm with the adaptive learning capabilities of Online Decision Transformers. This work has demonstrated significant improvements in sample efficiency and reward maximization across challenging benchmarks.\n\nMy research also extends to generative modeling, where I have tackled the complexities of text-to-image diffusion models. By employing a Bayesian approach to design custom priors over attention distributions, I have enhanced attribute-object alignment and improved the overall quality of generated images.\n\nFurthermore, I introduced the Skill-Driven Skill Recombination Algorithm (SDSRA), which enhances the efficiency of achieving maximum entropy in RL tasks, outperforming traditional methods like Soft Actor-Critic. Through these contributions, I aim to push the boundaries of RL and generative modeling, making them more robust, interpretable, and applicable to real-world challenges.",
    "collaborators": [
      "Zhi Zhang",
      "Yasi Zhang",
      "Andrew Lizarraga",
      "Ying Nian Wu",
      "Chris Chow",
      "Yanchao Sun",
      "Haochen Zhang",
      "Han Liu",
      "Furong Huang",
      "Yuchen Cui",
      "Oscar Hernan Madrid Padilla",
      "Dinghuai Zhang",
      "Chenheng Xu",
      "Siyan Zhao",
      "Zhengjie Xu",
      "Peiyu Yu",
      "Yuer Tang",
      "Deqian Kong",
      "Shufan Li"
    ],
    "pub_titles": [
      "Statistical Guarantees for Lifelong Reinforcement Learning using PAC-Bayesian Theory",
      "DODT: Enhanced Online Decision Transformer Learning through Dreamer's Actor-Critic Trajectory Forecasting",
      "Unlocking the Potential of Text-to-Image Diffusion with PAC-Bayesian Theory",
      "SDSRA: A Skill-Driven Skill-Recombination Algorithm for Efficient Policy Learning"
    ],
    "pub_abstracts": [
      "Lifelong reinforcement learning (RL) has been developed as a paradigm for extending single-task RL to more realistic, dynamic settings. In lifelong RL, the\"life\"of an RL agent is modeled as a stream of tasks drawn from a task distribution. We propose EPIC (\\underline{E}mpirical \\underline{P}AC-Bayes that \\underline{I}mproves \\underline{C}ontinuously), a novel algorithm designed for lifelong RL using PAC-Bayes theory. EPIC learns a shared policy distribution, referred to as the \\textit{world policy}, which enables rapid adaptation to new tasks while retaining valuable knowledge from previous experiences. Our theoretical analysis establishes a relationship between the algorithm's generalization performance and the number of prior tasks preserved in memory. We also derive the sample complexity of EPIC in terms of RL regret. Extensive experiments on a variety of environments demonstrate that EPIC significantly outperforms existing methods in lifelong RL, offering both theoretical guarantees and practical efficacy through the use of the world policy.",
      "Advancements in reinforcement learning have led to the development of sophisticated models capable of learning complex decision-making tasks. However, efficiently integrating world models with decision transformers remains a challenge. In this paper, we introduce a novel approach that combines the Dreamer algorithm's ability to generate anticipatory trajectories with the adaptive learning strengths of the Online Decision Transformer. Our methodology enables parallel training where Dreamer-produced trajectories enhance the contextual decision-making of the transformer, creating a bidirectional enhancement loop. We empirically demonstrate the efficacy of our approach on a suite of challenging benchmarks, achieving notable improvements in sample efficiency and reward maximization over existing methods. Our results indicate that the proposed integrated framework not only accelerates learning but also showcases robustness in diverse and dynamic scenarios, marking a significant step forward in model-based reinforcement learning.",
      "Text-to-image (T2I) diffusion models have revolutionized generative modeling by producing high-fidelity, diverse, and visually realistic images from textual prompts. Despite these advances, existing models struggle with complex prompts involving multiple objects and attributes, often misaligning modifiers with their corresponding nouns or neglecting certain elements. Recent attention-based methods have improved object inclusion and linguistic binding, but still face challenges such as attribute misbinding and a lack of robust generalization guarantees. Leveraging the PAC-Bayes framework, we propose a Bayesian approach that designs custom priors over attention distributions to enforce desirable properties, including divergence between objects, alignment between modifiers and their corresponding nouns, minimal attention to irrelevant tokens, and regularization for better generalization. Our approach treats the attention mechanism as an interpretable component, enabling fine-grained control and improved attribute-object alignment. We demonstrate the effectiveness of our method on standard benchmarks, achieving state-of-the-art results across multiple metrics. By integrating custom priors into the denoising process, our method enhances image quality and addresses long-standing challenges in T2I diffusion models, paving the way for more reliable and interpretable generative models.",
      "In this paper, we introduce a novel algorithm - the Skill-Driven Skill Recombination Algorithm (SDSRA) - an innovative framework that significantly enhances the efficiency of achieving maximum entropy in reinforcement learning tasks. We find that SDSRA achieves faster convergence compared to the traditional Soft Actor-Critic (SAC) algorithm and produces improved policies. By integrating skill-based strategies within the robust Actor-Critic framework, SDSRA demonstrates remarkable adaptability and performance across a wide array of complex and diverse benchmarks."
    ],
    "domain": [
      "Reinforcement Learning",
      "Generative Modeling",
      "PAC-Bayes",
      "Decision Making"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "01dd5b8b-f5b7-4417-8c02-9c55a3827848": {
    "pk": "01dd5b8b-f5b7-4417-8c02-9c55a3827848",
    "name": "Yun Qi Li",
    "bio": "As a researcher in the field of astrophysics, I am deeply engaged in leveraging machine learning techniques to address fundamental questions about the universe, particularly in the context of large-scale extragalactic surveys. My recent work focuses on improving photometric redshift (photo-z) estimation using Bayesian convolutional neural networks (BCNNs), which allow for accurate predictions and well-constrained uncertainties. By utilizing high-quality imaging data from the Hyper Suprime-Cam survey, I have demonstrated significant improvements in photo-z accuracy, particularly when using galaxy images over traditional photometry.\n\nIn addition to photo-z estimation, I am exploring the potential of generative models to advance our understanding of galaxy evolution. My research includes developing conditional denoising diffusion probabilistic models and conditional variational autoencoders to generate realistic galaxy images based on their redshifts. This work not only tests the capabilities of these models but also incorporates physics-motivated metrics to evaluate their performance, revealing insights that traditional human evaluations may overlook.\n\nI am also committed to fostering collaboration and innovation in the field by creating and sharing comprehensive datasets, such as GalaxiesML, which includes over 286,000 galaxy images and associated properties. This dataset is designed to support machine learning applications in astrophysics and is crucial for the next generation of surveys like Euclid and LSST. Through my research, I aim to bridge the gap between machine learning and astrophysics, unlocking new discoveries and enhancing our understanding of the cosmos.",
    "collaborators": [
      "Evan Jones",
      "Tuan Do",
      "Kevin Alfaro",
      "Bernie Boscoe",
      "J. Singal",
      "Zooey Nguyen"
    ],
    "pub_titles": [
      "Redshift Prediction with Images for Cosmology Using a Bayesian Convolutional Neural Network with Conformal Predictions",
      "Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models",
      "GalaxiesML: a dataset of galaxy images, photometry, redshifts, and structural parameters for machine learning"
    ],
    "pub_abstracts": [
      "  In the emerging era of big data astrophysics, large-scale extragalactic surveys will soon provide high-quality imaging for billions of celestial objects to answer major questions in astrophysics such as the nature of dark matter and dark energy. Precision cosmology with surveys requires accurate photometric redshift (photo-z) estimation with well-constrained uncertainties as inputs for weak lensing models to measure cosmological parameters. Machine learning methods have shown promise in optimizing the information gained from galaxy images in photo-z estimation; however, many of these methods are limited in their ability to estimate accurate uncertainties. In this work, we present one of the first applications of Bayesian convolutional neural networks (BCNNs) for photo-z estimation and uncertainties. In addition, we use conformal mapping to calibrate the photo-z uncertainties to achieve good statistical coverage. We use the public GalaxiesML data set of \u223c300k galaxies from the Hyper Suprime-Cam survey containing five-band photometric images and known spectroscopic redshifts from 0 < z < 4. We find that the performance is much improved when using images compared to photometry, with the BCNN achieving 0.098 rms error, a standard outlier rate of 3.9%, a 3\u03c3 outlier rate of 4.5%, and a bias of 0.0007. The performance drops significantly beyond z > 1.5 due to the relative lack of training data beyond those redshifts. This investigation demonstrates the power of using images directly and we advocate that future photo-z analysis of large-scale surveys include galaxy images.",
      "Generative models producing images have enormous potential to advance discoveries across scientific fields and require metrics capable of quantifying the high dimensional output. We propose that astrophysics data, such as galaxy images, can test generative models with additional physics-motivated ground truths in addition to human judgment. For example, galaxies in the Universe form and change over billions of years, following physical laws and relationships that are both easy to characterize and difficult to encode in generative models. We build a conditional denoising diffusion probabilistic model (DDPM) and a conditional variational autoencoder (CVAE) and test their ability to generate realistic galaxies conditioned on their redshifts (galaxy ages). This is one of the first studies to probe these generative models using physically motivated metrics. We find that both models produce comparable realistic galaxies based on human evaluation, but our physics-based metrics are better able to discern the strengths and weaknesses of the generative models. Overall, the DDPM model performs better than the CVAE on the majority of the physics-based metrics. Ultimately, if we can show that generative models can learn the physics of galaxy evolution, they have the potential to unlock new astrophysical discoveries.",
      "We present a dataset built for machine learning applications consisting of galaxy photometry, images, spectroscopic redshifts, and structural properties. This dataset comprises 286,401 galaxy images and photometry from the Hyper-Suprime-Cam Survey PDR2 in five imaging filters ($g,r,i,z,y$) with spectroscopically confirmed redshifts as ground truth. Such a dataset is important for machine learning applications because it is uniform, consistent, and has minimal outliers but still contains a realistic range of signal-to-noise ratios. We make this dataset public to help spur development of machine learning methods for the next generation of surveys such as Euclid and LSST. The aim of GalaxiesML is to provide a robust dataset that can be used not only for astrophysics but also for machine learning, where image properties cannot be validated by the human eye and are instead governed by physical laws. We describe the challenges associated with putting together a dataset from publicly available archives, including outlier rejection, duplication, establishing ground truths, and sample selection. This is one of the largest public machine learning-ready training sets of its kind with redshifts ranging from 0.01 to 4. The redshift distribution of this sample peaks at redshift of 1.5 and falls off rapidly beyond redshift 2.5. We also include an example application of this dataset for redshift estimation, demonstrating that using images for redshift estimation produces more accurate results compared to using photometry alone. For example, the bias in redshift estimate is a factor of 10 lower when using images between redshift of 0.1 to 1.25 compared to photometry alone. Results from dataset such as this will help inform us on how to best make use of data from the next generation of galaxy surveys."
    ],
    "domain": [
      "Astrophysics",
      "Machine Learning",
      "Generative Models",
      "Bayesian Inference"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "679004cb-e0dd-42a7-bca1-313c12c74bc4": {
    "pk": "679004cb-e0dd-42a7-bca1-313c12c74bc4",
    "name": "Bernie Boscoe",
    "bio": "I am a researcher at the intersection of machine learning and astrophysics, dedicated to harnessing advanced computational techniques to tackle fundamental questions in cosmology. My recent work focuses on improving photometric redshift (photo-z) estimation, a critical task for interpreting data from large-scale extragalactic surveys. I have pioneered the application of Bayesian convolutional neural networks (BCNNs) for photo-z estimation, achieving significant improvements in accuracy and uncertainty quantification. \n\nI am particularly interested in the potential of generative models to advance our understanding of galaxy evolution. By developing conditional denoising diffusion probabilistic models and conditional variational autoencoders, I have explored how these models can generate realistic galaxy images while adhering to physical laws. My research emphasizes the importance of combining different ground truths, utilizing transfer learning to enhance model generalizability, and creating robust datasets like GalaxiesML to support machine learning applications in astrophysics.\n\nThrough my work, I aim to bridge the gap between machine learning and astrophysical data analysis, ensuring that our methodologies not only meet the scientific requirements of upcoming surveys like LSST but also contribute to the broader understanding of dark matter and dark energy. I am committed to fostering reproducible science practices and developing datasets that empower future research in this exciting field.",
    "collaborators": [
      "Tuan Do",
      "Evan Jones",
      "Kevin Alfaro",
      "J. Singal",
      "Yunqi Li",
      "Zooey Nguyen",
      "E. Jones",
      "Yujie Wan",
      "Jonathan Soriano",
      "Srinath Saikrishnan",
      "Vikram Seenivasan",
      "T. Do",
      "Yunqiang Li",
      "Christy Ma"
    ],
    "pub_titles": [
      "Redshift Prediction with Images for Cosmology Using a Bayesian Convolutional Neural Network with Conformal Predictions",
      "Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models",
      "Using different sources of ground truths and transfer learning to improve the generalization of photometric redshift estimation",
      "GalaxiesML: a dataset of galaxy images, photometry, redshifts, and structural parameters for machine learning",
      "Improving Photometric Redshift Estimation for Cosmology with LSST Using Bayesian Neural Networks",
      "Photometric Redshifts for Cosmology: Improving Accuracy and Uncertainty Estimates Using Bayesian Neural Networks",
      "Elements of effective machine learning datasets in astronomy"
    ],
    "pub_abstracts": [
      "  In the emerging era of big data astrophysics, large-scale extragalactic surveys will soon provide high-quality imaging for billions of celestial objects to answer major questions in astrophysics such as the nature of dark matter and dark energy. Precision cosmology with surveys requires accurate photometric redshift (photo-z) estimation with well-constrained uncertainties as inputs for weak lensing models to measure cosmological parameters. Machine learning methods have shown promise in optimizing the information gained from galaxy images in photo-z estimation; however, many of these methods are limited in their ability to estimate accurate uncertainties. In this work, we present one of the first applications of Bayesian convolutional neural networks (BCNNs) for photo-z estimation and uncertainties. In addition, we use conformal mapping to calibrate the photo-z uncertainties to achieve good statistical coverage. We use the public GalaxiesML data set of \u223c300k galaxies from the Hyper Suprime-Cam survey containing five-band photometric images and known spectroscopic redshifts from 0 < z < 4. We find that the performance is much improved when using images compared to photometry, with the BCNN achieving 0.098 rms error, a standard outlier rate of 3.9%, a 3\u03c3 outlier rate of 4.5%, and a bias of 0.0007. The performance drops significantly beyond z > 1.5 due to the relative lack of training data beyond those redshifts. This investigation demonstrates the power of using images directly and we advocate that future photo-z analysis of large-scale surveys include galaxy images.",
      "Generative models producing images have enormous potential to advance discoveries across scientific fields and require metrics capable of quantifying the high dimensional output. We propose that astrophysics data, such as galaxy images, can test generative models with additional physics-motivated ground truths in addition to human judgment. For example, galaxies in the Universe form and change over billions of years, following physical laws and relationships that are both easy to characterize and difficult to encode in generative models. We build a conditional denoising diffusion probabilistic model (DDPM) and a conditional variational autoencoder (CVAE) and test their ability to generate realistic galaxies conditioned on their redshifts (galaxy ages). This is one of the first studies to probe these generative models using physically motivated metrics. We find that both models produce comparable realistic galaxies based on human evaluation, but our physics-based metrics are better able to discern the strengths and weaknesses of the generative models. Overall, the DDPM model performs better than the CVAE on the majority of the physics-based metrics. Ultimately, if we can show that generative models can learn the physics of galaxy evolution, they have the potential to unlock new astrophysical discoveries.",
      "In this work, we explore methods to improve galaxy redshift predictions by combining different ground truths. Traditional machine learning models rely on training sets with known spectroscopic redshifts, which are precise but only represent a limited sample of galaxies. To make redshift models more generalizable to the broader galaxy population, we investigate transfer learning and directly combining ground truth redshifts derived from photometry and spectroscopy. We use the COSMOS2020 survey to create a dataset, TransferZ, which includes photometric redshift estimates derived from up to 35 imaging filters using template fitting. This dataset spans a wider range of galaxy types and colors compared to spectroscopic samples, though its redshift estimates are less accurate. We first train a base neural network on TransferZ and then refine it using transfer learning on a dataset of galaxies with more precise spectroscopic redshifts (GalaxiesML). In addition, we train a neural network on a combined dataset of TransferZ and GalaxiesML. Both methods reduce bias by $\\sim$ 5x, RMS error by $\\sim$ 1.5x, and catastrophic outlier rates by 1.3x on GalaxiesML, compared to a baseline trained only on TransferZ. However, we also find a reduction in performance for RMS and bias when evaluated on TransferZ data. Overall, our results demonstrate these approaches can meet cosmological requirements.",
      "We present a dataset built for machine learning applications consisting of galaxy photometry, images, spectroscopic redshifts, and structural properties. This dataset comprises 286,401 galaxy images and photometry from the Hyper-Suprime-Cam Survey PDR2 in five imaging filters ($g,r,i,z,y$) with spectroscopically confirmed redshifts as ground truth. Such a dataset is important for machine learning applications because it is uniform, consistent, and has minimal outliers but still contains a realistic range of signal-to-noise ratios. We make this dataset public to help spur development of machine learning methods for the next generation of surveys such as Euclid and LSST. The aim of GalaxiesML is to provide a robust dataset that can be used not only for astrophysics but also for machine learning, where image properties cannot be validated by the human eye and are instead governed by physical laws. We describe the challenges associated with putting together a dataset from publicly available archives, including outlier rejection, duplication, establishing ground truths, and sample selection. This is one of the largest public machine learning-ready training sets of its kind with redshifts ranging from 0.01 to 4. The redshift distribution of this sample peaks at redshift of 1.5 and falls off rapidly beyond redshift 2.5. We also include an example application of this dataset for redshift estimation, demonstrating that using images for redshift estimation produces more accurate results compared to using photometry alone. For example, the bias in redshift estimate is a factor of 10 lower when using images between redshift of 0.1 to 1.25 compared to photometry alone. Results from dataset such as this will help inform us on how to best make use of data from the next generation of galaxy surveys.",
      "We present results exploring the role that probabilistic deep learning models can play in cosmology from large-scale astronomical surveys through photometric redshift (photo-z) estimation. Photo-z uncertainty estimates are critical for the science goals of upcoming large-scale surveys such as the Legacy Survey of Space and Time (LSST); however, common machine learning methods typically provide only point estimates and lack uncertainties on predictions. We turn to Bayesian neural networks (BNNs) as a promising way to provide accurate predictions of redshift values with uncertainty estimates. We have compiled a galaxy data set from the Hyper Suprime-Cam Survey with grizy photometry, which is designed to be a smaller-scale version of large surveys like LSST. We use this data set to investigate the performance of a neural network and a probabilistic BNN for photo-z estimation and evaluate their performance with respect to LSST photo-z science requirements. We also examine the utility of photo-z uncertainties as a means to reduce catastrophic outlier estimates. The BNN outputs the estimate in the form of a Gaussian probability distribution. We use the mean and standard deviation as the redshift estimate and uncertainty. We find that the BNN can produce accurate uncertainties. Using a coverage test, we find excellent agreement with expectation\u201467.2% of galaxies between 0 < 2.5 have 1\u03c3 uncertainties that cover the spectroscopic value. We also include a comparison to alternative machine learning models using the same data. We find the BNN meets two out of three of the LSST photo-z science requirements in the range 0 < z < 2.5.",
      "We present results exploring the role that probabilistic deep learning models can play in cosmology from large scale astronomical surveys through estimating the distances to galaxies (redshifts) from photometry. Due to the massive scale of data coming from these new and upcoming sky surveys, machine learning techniques using galaxy photometry are increasingly adopted to predict galactic redshifts which are important for inferring cosmological parameters such as the nature of dark energy. Associated uncertainty estimates are also critical measurements, however, common machine learning methods typically provide only point estimates and lack uncertainty information as outputs. We turn to Bayesian neural networks (BNNs) as a promising way to provide accurate predictions of redshift values. We have compiled a new galaxy training dataset from the Hyper Suprime-Cam Survey, designed to mimic large surveys, but over a smaller portion of the sky. We evaluate the performance and accuracy of photometric redshift (photo-z) predictions from photometry using machine learning, astronomical and probabilistic metrics. We find that while the Bayesian neural network did not perform as well as non-Bayesian neural networks if evaluated solely by point estimate photo-z values, BNNs can provide uncertainty estimates that are necessary for cosmology",
      "In this work, we identify elements of effective machine learning datasets in astronomy and present suggestions for their design and creation. Machine learning has become an increasingly important tool for analyzing and understanding the large-scale flood of data in astronomy. To take advantage of these tools, datasets are required for training and testing. However, building machine learning datasets for astronomy can be challenging. Astronomical data is collected from instruments built to explore science questions in a traditional fashion rather than to conduct machine learning. Thus, it is often the case that raw data, or even downstream processed data is not in a form amenable to machine learning. We explore the construction of machine learning datasets and we ask: what elements define effective machine learning datasets? We define effective machine learning datasets in astronomy to be formed with well-defined data points, structure, and metadata. We discuss why these elements are important for astronomical applications and ways to put them in practice. We posit that these qualities not only make the data suitable for machine learning, they also help to foster usable, reusable, and replicable science practices."
    ],
    "domain": [
      "Machine Learning",
      "Astrophysics",
      "Bayesian Neural Networks",
      "Generative Models"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "46e85f58-2d76-4c46-b59c-51fd1b059560": {
    "pk": "46e85f58-2d76-4c46-b59c-51fd1b059560",
    "name": "Tuan Do",
    "bio": "I am a researcher at the intersection of machine learning and astrophysics, dedicated to enhancing our understanding of the universe through advanced data analysis techniques. My recent work focuses on the critical task of photometric redshift (photo-z) estimation, which is essential for precision cosmology and understanding phenomena like dark matter and dark energy. I have pioneered the application of Bayesian convolutional neural networks (BCNNs) for photo-z estimation, achieving significant improvements in accuracy and uncertainty quantification.\n\nIn my research, I explore innovative methods to leverage large-scale datasets, such as the GalaxiesML dataset, which I developed to facilitate machine learning applications in astrophysics. This dataset, comprising over 286,000 galaxy images and photometric data, serves as a robust foundation for training models that can predict redshifts more effectively. I am particularly interested in generative models and their potential to simulate realistic galaxy images, using physics-based metrics to evaluate their performance.\n\nMy work also delves into transfer learning techniques to enhance redshift predictions by combining data from different sources, demonstrating that integrating diverse datasets can significantly reduce bias and improve accuracy. I am passionate about making my datasets publicly available to spur further research and development in the field, particularly as we prepare for the next generation of astronomical surveys. Ultimately, my goal is to harness the power of machine learning to unlock new insights into the cosmos and contribute to our understanding of fundamental astrophysical questions.",
    "collaborators": [
      "Bernie Boscoe",
      "Evan Jones",
      "Yunqi Li",
      "Kevin Alfaro",
      "J. Singal",
      "Zooey Nguyen",
      "Jonathan Soriano",
      "Srinath Saikrishnan",
      "Vikram Seenivasan",
      "Yujie Wan"
    ],
    "pub_titles": [
      "Redshift Prediction with Images for Cosmology Using a Bayesian Convolutional Neural Network with Conformal Predictions",
      "Using Galaxy Evolution as Source of Physics-Based Ground Truth for Generative Models",
      "Using different sources of ground truths and transfer learning to improve the generalization of photometric redshift estimation",
      "GalaxiesML: a dataset of galaxy images, photometry, redshifts, and structural parameters for machine learning",
      "Photometric Redshifts for Cosmology: Improving Accuracy and Uncertainty Estimates Using Bayesian Neural Networks"
    ],
    "pub_abstracts": [
      "  In the emerging era of big data astrophysics, large-scale extragalactic surveys will soon provide high-quality imaging for billions of celestial objects to answer major questions in astrophysics such as the nature of dark matter and dark energy. Precision cosmology with surveys requires accurate photometric redshift (photo-z) estimation with well-constrained uncertainties as inputs for weak lensing models to measure cosmological parameters. Machine learning methods have shown promise in optimizing the information gained from galaxy images in photo-z estimation; however, many of these methods are limited in their ability to estimate accurate uncertainties. In this work, we present one of the first applications of Bayesian convolutional neural networks (BCNNs) for photo-z estimation and uncertainties. In addition, we use conformal mapping to calibrate the photo-z uncertainties to achieve good statistical coverage. We use the public GalaxiesML data set of \u223c300k galaxies from the Hyper Suprime-Cam survey containing five-band photometric images and known spectroscopic redshifts from 0 < z < 4. We find that the performance is much improved when using images compared to photometry, with the BCNN achieving 0.098 rms error, a standard outlier rate of 3.9%, a 3\u03c3 outlier rate of 4.5%, and a bias of 0.0007. The performance drops significantly beyond z > 1.5 due to the relative lack of training data beyond those redshifts. This investigation demonstrates the power of using images directly and we advocate that future photo-z analysis of large-scale surveys include galaxy images.",
      "Generative models producing images have enormous potential to advance discoveries across scientific fields and require metrics capable of quantifying the high dimensional output. We propose that astrophysics data, such as galaxy images, can test generative models with additional physics-motivated ground truths in addition to human judgment. For example, galaxies in the Universe form and change over billions of years, following physical laws and relationships that are both easy to characterize and difficult to encode in generative models. We build a conditional denoising diffusion probabilistic model (DDPM) and a conditional variational autoencoder (CVAE) and test their ability to generate realistic galaxies conditioned on their redshifts (galaxy ages). This is one of the first studies to probe these generative models using physically motivated metrics. We find that both models produce comparable realistic galaxies based on human evaluation, but our physics-based metrics are better able to discern the strengths and weaknesses of the generative models. Overall, the DDPM model performs better than the CVAE on the majority of the physics-based metrics. Ultimately, if we can show that generative models can learn the physics of galaxy evolution, they have the potential to unlock new astrophysical discoveries.",
      "In this work, we explore methods to improve galaxy redshift predictions by combining different ground truths. Traditional machine learning models rely on training sets with known spectroscopic redshifts, which are precise but only represent a limited sample of galaxies. To make redshift models more generalizable to the broader galaxy population, we investigate transfer learning and directly combining ground truth redshifts derived from photometry and spectroscopy. We use the COSMOS2020 survey to create a dataset, TransferZ, which includes photometric redshift estimates derived from up to 35 imaging filters using template fitting. This dataset spans a wider range of galaxy types and colors compared to spectroscopic samples, though its redshift estimates are less accurate. We first train a base neural network on TransferZ and then refine it using transfer learning on a dataset of galaxies with more precise spectroscopic redshifts (GalaxiesML). In addition, we train a neural network on a combined dataset of TransferZ and GalaxiesML. Both methods reduce bias by $\\sim$ 5x, RMS error by $\\sim$ 1.5x, and catastrophic outlier rates by 1.3x on GalaxiesML, compared to a baseline trained only on TransferZ. However, we also find a reduction in performance for RMS and bias when evaluated on TransferZ data. Overall, our results demonstrate these approaches can meet cosmological requirements.",
      "We present a dataset built for machine learning applications consisting of galaxy photometry, images, spectroscopic redshifts, and structural properties. This dataset comprises 286,401 galaxy images and photometry from the Hyper-Suprime-Cam Survey PDR2 in five imaging filters ($g,r,i,z,y$) with spectroscopically confirmed redshifts as ground truth. Such a dataset is important for machine learning applications because it is uniform, consistent, and has minimal outliers but still contains a realistic range of signal-to-noise ratios. We make this dataset public to help spur development of machine learning methods for the next generation of surveys such as Euclid and LSST. The aim of GalaxiesML is to provide a robust dataset that can be used not only for astrophysics but also for machine learning, where image properties cannot be validated by the human eye and are instead governed by physical laws. We describe the challenges associated with putting together a dataset from publicly available archives, including outlier rejection, duplication, establishing ground truths, and sample selection. This is one of the largest public machine learning-ready training sets of its kind with redshifts ranging from 0.01 to 4. The redshift distribution of this sample peaks at redshift of 1.5 and falls off rapidly beyond redshift 2.5. We also include an example application of this dataset for redshift estimation, demonstrating that using images for redshift estimation produces more accurate results compared to using photometry alone. For example, the bias in redshift estimate is a factor of 10 lower when using images between redshift of 0.1 to 1.25 compared to photometry alone. Results from dataset such as this will help inform us on how to best make use of data from the next generation of galaxy surveys.",
      "We present results exploring the role that probabilistic deep learning models can play in cosmology from large scale astronomical surveys through estimating the distances to galaxies (redshifts) from photometry. Due to the massive scale of data coming from these new and upcoming sky surveys, machine learning techniques using galaxy photometry are increasingly adopted to predict galactic redshifts which are important for inferring cosmological parameters such as the nature of dark energy. Associated uncertainty estimates are also critical measurements, however, common machine learning methods typically provide only point estimates and lack uncertainty information as outputs. We turn to Bayesian neural networks (BNNs) as a promising way to provide accurate predictions of redshift values. We have compiled a new galaxy training dataset from the Hyper Suprime-Cam Survey, designed to mimic large surveys, but over a smaller portion of the sky. We evaluate the performance and accuracy of photometric redshift (photo-z) predictions from photometry using machine learning, astronomical and probabilistic metrics. We find that while the Bayesian neural network did not perform as well as non-Bayesian neural networks if evaluated solely by point estimate photo-z values, BNNs can provide uncertainty estimates that are necessary for cosmology"
    ],
    "domain": [
      "Astrophysics",
      "Machine Learning",
      "Bayesian Neural Networks",
      "Generative Models"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "bcc19da8-9033-4a13-8467-96e87ed513ad": {
    "pk": "bcc19da8-9033-4a13-8467-96e87ed513ad",
    "name": "Paxson Swierc",
    "bio": "I am a researcher dedicated to the intersection of deep learning and astrophysics, particularly in the analysis of galaxy-scale gravitational lensing. My recent work addresses a critical challenge in this field: the scarcity of real lensing data for training deep learning algorithms. To tackle this, I have explored the potential of domain adaptation techniques to bridge the gap between simulated and real datasets. \n\nIn my latest study, I applied Domain Adversarial Neural Networks (DANN) and Maximum Mean Discrepancy (MMD) to estimate the Einstein radius in simulated gravitational lensing images. By training on a source domain of simulated lenses and testing on a target domain that mimics the noise conditions of the Dark Energy Survey, I demonstrated significant improvements in model performance. This work marks a pioneering application of domain adaptation for regression tasks in strong lensing imaging analysis, showcasing the promise of these techniques for analyzing future survey data.\n\nI am passionate about leveraging advanced machine learning methods to enhance our understanding of the universe, and I am excited about the potential of my research to contribute to the discovery of new astronomical phenomena.",
    "collaborators": [
      "Megan Zhao",
      "A. 'Ciprijanovi'c",
      "Brian Nord"
    ],
    "pub_titles": [
      "Domain Adaptation for Measurements of Strong Gravitational Lenses"
    ],
    "pub_abstracts": [
      "Upcoming surveys are predicted to discover galaxy-scale strong lenses on the order of $10^5$, making deep learning methods necessary in lensing data analysis. Currently, there is insufficient real lensing data to train deep learning algorithms, but the alternative of training only on simulated data results in poor performance on real data. Domain Adaptation may be able to bridge the gap between simulated and real datasets. We utilize domain adaptation for the estimation of Einstein radius ($\\Theta_E$) in simulated galaxy-scale gravitational lensing images with different levels of observational realism. We evaluate two domain adaptation techniques - Domain Adversarial Neural Networks (DANN) and Maximum Mean Discrepancy (MMD). We train on a source domain of simulated lenses and apply it to a target domain of lenses simulated to emulate noise conditions in the Dark Energy Survey (DES). We show that both domain adaptation techniques can significantly improve the model performance on the more complex target domain dataset. This work is the first application of domain adaptation for a regression task in strong lensing imaging analysis. Our results show the potential of using domain adaptation to perform analysis of future survey data with a deep neural network trained on simulated data."
    ],
    "domain": [
      "Deep Learning",
      "Domain Adaptation",
      "Gravitational Lensing",
      "Computer Vision"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "9921c57b-f223-4d36-a98f-ed54b287d496": {
    "pk": "9921c57b-f223-4d36-a98f-ed54b287d496",
    "name": "Marcos Tamargo-Arizmendi",
    "bio": "I am an astrophysicist specializing in strong gravitational lensing and the study of quasar host galaxies. My recent work has focused on the analysis of cluster-scale strong gravitational lenses, particularly through the COOL-LAMPS collaboration. I have developed parametric measurements of the Einstein-radius-enclosed total mass for 177 strong gravitational lenses, revealing significant correlations between the enclosed total mass, luminosity, and stellar mass. These findings provide a framework for validating strong lensing candidates in future imaging surveys, such as the Rubin/Legacy Survey of Space and Time (LSST).\n\nAdditionally, I have explored the intriguing realm of wide-separation lensed quasars (WSLQs), where I derived constraints on the properties of their host galaxies. My research indicates a mixture of star-forming and quiescent galaxies among these hosts, and I have investigated the co-evolution of active galactic nuclei (AGNs) and their host galaxies, finding minimal evolution in the black hole mass-stellar mass relation.\n\nOne of my notable discoveries is COOL J0335\u22121927, the highest redshift wide-separation lensed quasar known to date. This work involved constructing a parametric strong gravitational lens model and predicting time delays between the quasar images, which will ultimately allow for further studies of AGN variability and time delay measurements. My research aims to deepen our understanding of the interplay between massive galaxies and their central black holes, contributing to the broader field of cosmology and galaxy formation.",
    "collaborators": [
      "Simon Mork",
      "M. Gladders",
      "K. Sharon",
      "Aidan P. Cloonan",
      "H. Dahle",
      "Grace Wagner",
      "Yunchong Zhang",
      "K. Napier",
      "Riley Rosener",
      "Jamar L. Sullivan",
      "Isaiah Escapa",
      "Josh Garza",
      "Natalie Malagon",
      "Kunwanhui Niu",
      "Raul Teixeira",
      "Kabelo Tsiane",
      "Megan Zhao",
      "G. Khullar",
      "N. Chicoine",
      "Diego Garza",
      "Rowen Glusman",
      "K. Gozman",
      "Gabriela Horwath",
      "Benjamin C. Levine",
      "Olina Liang",
      "Michael N. Martinez",
      "A. Masegian",
      "Owen S. Matthews Acuna",
      "Yue Pan",
      "Isaac Sierra",
      "Ezra O. Sukay",
      "K. Tavangar",
      "G. Mahler",
      "Andrew Kisare",
      "Marie Tagliavia",
      "Daniel Mahronic",
      "V. Manwadkar",
      "Kaiya Merz",
      "Jorge A. Sanchez",
      "Daniel J. Kavin Stein",
      "Ruoyang Tu",
      "E. Zaborowski",
      "M. Bayliss",
      "Andi Kisare",
      "M. Riley Owens",
      "J. Rigby",
      "Antony Stark",
      "Erik Zaborowski"
    ],
    "pub_titles": [
      "COOL-LAMPS. VII. Quantifying Strong-lens Scaling Relations with 177 Cluster-scale Gravitational Lenses in DECaLS",
      "COOL-LAMPS VIII: Known wide-separation lensed quasars and their host galaxies reveal a lack of evolution in $M_{\\rm{BH}}/M_\\star$ since $z\\sim 3$",
      "COOL-LAMPS. Discovery of COOL J0335\u22121927, a Gravitationally Lensed Quasar at z = 3.27 with an Image Separation of 23.\u20333",
      "COOL-LAMPS. V. Discovery of COOL J0335 \u2212 1927, a Gravitationally Lensed Quasar at z =3.27 with an Image Separation of 23 . \u2032\u2032 3"
    ],
    "pub_abstracts": [
      "We compute parametric measurements of the Einstein-radius-enclosed total mass for 177 cluster-scale strong gravitational lenses identified by the ChicagO Optically-selected Lenses Located At the Margins of Public Surveys (COOL-LAMPS) collaboration with lens redshifts ranging from $0.2 \\lessapprox z \\lessapprox 1.0$ using only two measured parameters in each lensing system: the Einstein radius, and the brightest-cluster-galaxy (BCG) redshift. We then constrain the Einstein-radius-enclosed luminosity and stellar mass by fitting parametric spectral energy distributions (SEDs) with aperture photometry from the Dark Energy Camera Legacy Survey (DECaLS) in the $g$, $r$, and $z$-band Dark Energy Camera (DECam) filters. We find that the BCG redshift, enclosed total mass, and enclosed luminosity are strongly correlated and well described by a planar relationship in 3D space. We also find that the enclosed total mass and stellar mass are correlated with a logarithmic slope of $0.443\\pm0.035$, and the enclosed total mass and stellar-to-total mass fraction are correlated with a logarithmic slope of $-0.563\\pm0.035$. The correlations described here can be used to validate strong lensing candidates in upcoming imaging surveys -- such as Rubin/Legacy Survey of Space and Time (LSST) -- in which an algorithmic treatment of lensing systems will be needed due to the sheer volume of data these surveys will produce.",
      "Wide-separation lensed quasars (WSLQs) are a rare class of strongly lensed quasars, magnified by foreground massive galaxy clusters, with typically large magnifications of the multiple quasar images. They are a relatively unexplored opportunity for detailed study of quasar host galaxies. The current small sample of known WSLQs has a median redshift of $z\\approx 2.1$, larger than most other samples of quasar host galaxies studied to date. Here, we derive precise constraints on the properties of six WSLQs and their host galaxies, using parametric surface brightness fitting, measurements of quasar emission lines, and stellar population synthesis of host galaxies in six WSLQ systems. Our results, with significant uncertainty, indicate that these six hosts are a mixture of star-forming and quiescent galaxies. To probe for co-evolution between AGNs and host galaxies, we model the offset from the `local' ($z=0$) $M_{\\rm{BH}}\\unicode{x2013}M_\\star$ relation as a simple power-law in redshift. Accounting for selection effects, a WSLQ-based model for evolution in the $M_{\\rm{BH}}\\unicode{x2013}M_\\star$ relation has a power-law index of $\\gamma_M=-0.42\\pm0.31$, consistent with no evolution. Compared to several literature samples, which mostly probe unlensed quasars at $z<2$, the WSLQ sample shows less evolution from the local relation, at $\\sim 4\\sigma$. We find that selection affects and choices of $M_{\\rm{BH}}$ calibration are the most important systematics in these comparisons. Given that we resolve host galaxy flux confidently even from the ground in some instances, our work demonstrates that WSLQs and highly magnified AGNs are exceptional systems for future AGN$\\unicode{x2013}$host co-evolution studies.",
      "We report the discovery of COOL J0335\u22121927, a quasar at z = 3.27 lensed into three images with a maximum separation of 23.\u20333 by a galaxy cluster at z = 0.4178. To date, this is the highest redshift wide-separation lensed quasar known. In addition, COOL J0335\u22121927 shows several strong intervening absorbers visible in the spectra of all three quasar images with varying equivalent widths. The quasar also shows mini-broad line absorption. We construct a parametric strong gravitational lens model using ground-based imaging, constrained by the redshift and positions of the quasar images as well as the positions of three other multiply imaged background galaxies. Using our best-fit lens model, we calculate the predicted time delays between the three quasar images to be \u0394t AB = 499\u2212146+141 (stat) and \u0394t AC = \u2212127\u221217+83 (stat) days. Folding in systematic uncertainties, the model-predicted time delays are within the ranges 240 < \u0394t AB < 700 and \u2212300 < \u0394t AC < \u221230. We also present g-band photometry from archival Dark Energy Camera Legacy Survey and Pan-STARRS imaging, and new multi-epoch observations obtained between 2022 September 18 UT and 2023 February 22 UT, which demonstrate significant variability in the quasar and will eventually enable the measurement of the time delay between the three quasar images. The currently available light curves are consistent with the model-predicted time delays. This is the fifth paper from the COOL-LAMPS collaboration.",
      "We report the discovery of COOL J0335-1927, a quasar at z = 3.27 lensed into three images with a maximum separation of 23 . \u2032\u2032 3 by a galaxy cluster at z = 0.4178. We construct a parametric strong gravitational lens model using ground-based imaging, constrained by the redshift and positions of the quasar images as well as the positions of three other multiply-imaged background galaxies. Using our best-fit lens model, we calculate the predicted time delays between the three quasar images to be"
    ],
    "domain": [
      "Gravitational Lensing",
      "Quasar Host Galaxies",
      "Astrophysics",
      "Cosmology"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "4d0a1a93-1dfb-4df8-a5ef-c0f799b10f58": {
    "pk": "4d0a1a93-1dfb-4df8-a5ef-c0f799b10f58",
    "name": "Brian D. Nord",
    "bio": "I am a researcher dedicated to the intersection of deep learning and uncertainty quantification (UQ), particularly in scientific applications where understanding uncertainty is crucial. My recent work has focused on assessing the quality of aleatoric uncertainty estimates produced by various UQ methods, such as Deep Ensembles (DE) and Deep Evidential Regression (DER). I systematically investigate how these methods perform across different data dimensionalities, revealing critical insights into their calibration and accuracy, especially under high-noise conditions.\n\nAdditionally, I have explored the application of deep learning in modeling strong gravitational lenses, a task that is computationally intensive due to the complexity of data from modern cosmic surveys. My research demonstrates the effectiveness of combining Mean-Variance Estimators (MVEs) with unsupervised domain adaptation (UDA) to enhance the accuracy of predictions on real observational data. This work not only improves the performance of UQ methods but also paves the way for their application in future astronomical studies.\n\nThrough my research, I aim to bridge the gap between theoretical uncertainty quantification and practical applications, ensuring that the models we develop are robust, reliable, and capable of handling the complexities of real-world data.",
    "collaborators": [
      "Aleksandra 'Ciprijanovi'c",
      "Rebecca Nevin",
      "Shrihan Agarwal"
    ],
    "pub_titles": [
      "DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods",
      "Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification"
    ],
    "pub_abstracts": [
      "Assessing the quality of aleatoric uncertainty estimates from uncertainty quantification (UQ) deep learning methods is important in scientific contexts, where uncertainty is physically meaningful and important to characterize and interpret exactly. We systematically compare aleatoric uncertainty measured by two UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER). Our method focuses on both zero-dimensional (0D) and two-dimensional (2D) data, to explore how the UQ methods function for different data dimensionalities. We investigate uncertainty injected on the input and output variables and include a method to propagate uncertainty in the case of input uncertainty so that we can compare the predicted aleatoric uncertainty to the known values. We experiment with three levels of noise. The aleatoric uncertainty predicted across all models and experiments scales with the injected noise level. However, the predicted uncertainty is miscalibrated to $\\rm{std}(\\sigma_{\\rm al})$ with the true uncertainty for half of the DE experiments and almost all of the DER experiments. The predicted uncertainty is the least accurate for both UQ methods for the 2D input uncertainty experiment and the high-noise level. While these results do not apply to more complex data, they highlight that further research on post-facto calibration for these methods would be beneficial, particularly for high-noise and high-dimensional settings.",
      "Modeling strong gravitational lenses is computationally expensive for the complex data from modern and next-generation cosmic surveys. Deep learning has emerged as a promising approach for finding lenses and predicting lensing parameters, such as the Einstein radius. Mean-variance Estimators (MVEs) are a common approach for obtaining aleatoric (data) uncertainties from a neural network prediction. However, neural networks have not been demonstrated to perform well on out-of-domain target data successfully - e.g., when trained on simulated data and applied to real, observational data. In this work, we perform the first study of the efficacy of MVEs in combination with unsupervised domain adaptation (UDA) on strong lensing data. The source domain data is noiseless, and the target domain data has noise mimicking modern cosmology surveys. We find that adding UDA to MVE increases the accuracy on the target data by a factor of about two over an MVE model without UDA. Including UDA also permits much more well-calibrated aleatoric uncertainty predictions. Advancements in this approach may enable future applications of MVE models to real observational data."
    ],
    "domain": [
      "Uncertainty Quantification",
      "Deep Learning",
      "Domain Adaptation",
      "Gravitational Lensing"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "3e8319e2-43d5-47ca-ad98-e68463a67415": {
    "pk": "3e8319e2-43d5-47ca-ad98-e68463a67415",
    "name": "Felix Richards",
    "bio": "I am a researcher dedicated to advancing the field of astronomical image analysis through innovative machine learning techniques. My work primarily focuses on the segmentation and classification of low surface brightness (LSB) structures in large astronomical images, where I have developed novel methodologies to enhance the efficiency and accuracy of these processes.\n\nIn my recent publications, I introduced a gridded attention mechanism that significantly improves the efficiency of capturing global context in images while maintaining sensitivity to textural patterns. This approach has been validated on a new dataset of astronomical images, specifically targeting the segmentation of large contaminating dust clouds. Additionally, I created an online annotation tool that has facilitated the delineation of LSB structures around hundreds of galaxies, resulting in a comprehensive database that supports both quantitative analysis and machine learning training.\n\nI have also explored the integration of learned Gabor filters into convolutional neural networks to achieve orientation robustness, leading to the development of Learnable Convolutional Gabor Networks (LCGNs). This work demonstrates my commitment to addressing the unique challenges posed by astronomical imaging, particularly in handling the complexities of orientation and low surface brightness.\n\nMy overarching goal is to automate the cataloguing of astronomical objects, leveraging deep learning to tackle the increasing volume of data generated by modern imaging surveys. By synthesizing datasets and proposing efficient neural network architectures, I aim to push the boundaries of what is possible in astronomical image analysis, ultimately contributing to our understanding of the universe.",
    "collaborators": [
      "A. Paiement",
      "P. Duc",
      "Xianghua Xie",
      "Elisabeth Sola",
      "Mathias Urbano",
      "J. Klehammer",
      "M. B'ilek",
      "J. Cuillandre",
      "S. Gwyn",
      "A. McConnachie"
    ],
    "pub_titles": [
      "Multi-scale gridded Gabor attention for cirrus segmentation",
      "Characterization of low surface brightness structures in annotated deep images",
      "Learnable Gabor modulated complex-valued networks for orientation robustness",
      "Classification and Segmentation of Galactic Structuresin Large Multi-spectral Images"
    ],
    "pub_abstracts": [
      "In this paper, we address the challenge of segmenting global contaminants in large images. The precise delineation of such structures requires ample global context alongside understanding of textural patterns. CNNs specialise in the latter, though their ability to generate global features is limited. Attention measures long range dependencies in images, capturing global context, though at a large computational cost. We propose a gridded attention mechanism to address this limitation, greatly increasing efficiency by processing multi-scale features into smaller tiles. We also enhance the attention mechanism for increased sensitivity to texture orientation, by measuring correlations across features dependent on different orientations, in addition to channel and positional attention. We present results on a new dataset of astronomical images, where the task is segmenting large contaminating dust clouds.",
      "The characterization of Low Surface Brightness (LSB) stellar structures around galaxies such as tidal debris of on-going or past collisions is essential to constrain models of galactic evolution. Our goal is to obtain quantitative measurements of LSB structures identified in deep images of samples consisting of hundreds of galaxies. We developed an online annotation tool that enables contributors to delineate the shapes of diffuse extended stellar structures, as well as artefacts or foreground structures. All parameters are automatically stored in a database which may be queried to retrieve quantitative measurements. We annotated LSB structures around 352 nearby massive galaxies with deep images obtained with the CFHT as part of two large programs: MATLAS and UNIONS/CFIS. Each LSB structure was delineated and labeled according to its likely nature: stellar shells, streams associated to a disrupted satellite, tails formed in major mergers, ghost reflections or cirrus. From our database containing 8441 annotations, the area, size, median surface brightness and distance to the host of 228 structures were computed. The results confirm the fact that tidal structures defined as streams are thinner than tails, as expected by numerical simulations. In addition, tidal tails appear to exhibit a higher surface brightness than streams (by about 1 mag), which may be related to different survival times for the two types of collisional debris. We did not detect any tidal feature fainter than 27.5 mag.arcsec$^{-2}$, while the nominal surface brightness limits of our surveys range between 28.3 and 29 mag.arcsec$^{-2}$, a difference that needs to be taken into account when estimating the sensitivity of future surveys to identify LSB structures. Our annotation database of observed LSB structures may be used for quantitative analysis and as a training set for machine learning algorithms (abbreviated).",
      "Robustness to transformation is desirable in many computer vision tasks, given that input data often exhibits pose variance within classes. While translation invariance and equivariance is a documented phenomenon of CNNs, sensitivity to other transformations is typically encouraged through data augmentation. We investigate the modulation of complex valued convolutional weights with learned Gabor filters to enable orientation robustness. With Gabor modulation, the designed network is able to generate orientation dependent features free of interpolation with a single set of rotation-governing parameters. Moreover, by learning rotation parameters alongside traditional convolutional weights, the representation space is not constrained and may adapt to the exact input transformation. We present Learnable Convolutional Gabor Networks (LCGNs), that are parameter-efficient and offer increased model complexity while keeping backpropagation simple. We demonstrate that learned Gabor modulation utilising an end-to-end complex architecture enables rotation invariance and equivariance on MNIST and a new dataset of simulated images of galactic cirri.",
      "Extensive and exhaustive cataloguing of astronomical objects is imperative for studies seeking to understand mechanisms which drive the universe. Such cataloguing tasks can be tedious, time consuming and demand a high level of domain specific knowledge. Past astronomical imaging surveys have been catalogued through mostly manual effort. Immi-nent imaging surveys, however, will produce a magnitude of data that cannot be feasibly processed through manual cataloguing. Furthermore, these surveys will capture objects fainter than the night sky, termed low surface brightness objects, and at unprecedented spatial resolution owing to advancements in astronomical imaging. In this thesis, we in-vestigate the use of deep learning to automate cataloguing processes, such as detection, classification and segmentation of objects. A common theme throughout this work is the adaptation of machine learning methods to challenges specific to the domain of low surface brightness imaging.We begin with creating an annotated dataset of structures in low surface brightness images. To facilitate supervised learning in neural networks, a dataset comprised of input and corresponding ground truth target labels is required. An online tool is presented, allowing astronomers to classify and draw over objects in large multi-spectral images. A dataset produced using the tool is then detailed, containing 227 low surface brightness images from the MATLAS survey and labels made by four annotators. We then present a method for synthesising images of galactic cirrus which appear similar to MATLAS images, allowing pretraining of neural networks.A method for integrating sensitivity to orientation in convolutional neural networks is then presented. Objects in astronomical images can present in any given orientation, and thus the ability for neural networks to handle rotations is desirable. We modify con-volutional filters with sets of Gabor filters with different orientations. These orientations are learned alongside network parameters during backpropagation, allowing exact optimal orientations to be captured. The method is validated extensively on multiple datasets and use cases.We propose an attention based neural network architecture to process global contami-nants in large images. Performing analysis of low surface brightness images requires plenty of contextual information and local textual patterns. As a result, a network for processing low surface brightness images should ideally be able to accommodate large high resolu-tion images without compromising on either local or global features. We utilise attention to capture long range dependencies, and propose an efficient attention operator which significantly reduces computational cost, allowing the input of large images. We also use Gabor filters to build an attention mechanism to better capture long range orientational patterns. These techniques are validated on the task of cirrus segmentation in MAT-LAS images, and cloud segmentation on the SWIMSEG database, where state of the art performance is achieved.Following, cirrus segmentation in MATLAS images is further investigated, and a com-prehensive study is performed on the task. We discuss challenges associated with cirrus segmentation and low surface brightness images in general, and present several tech-niques to accommodate them. A novel loss function is proposed to facilitate training of the segmentation model on probabilistic targets. Results are presented on the annotated MATLAS images, with extensive ablation studies and a final benchmark to test the limits of the detailed segmentation pipeline.Finally, we develop a pipeline for multi-class segmentation of galactic structures and surrounding contaminants. Techniques of previous chapters are combined with a popu-lar instance segmentation architecture to create a neural network capable of segmenting localised objects and extended amorphous regions. The process of data preparation for training instance segmentation models is thoroughly detailed. The method is tested on segmentation of five object classes in MATLAS images. We find that unifying the tasks of galactic structure segmentation and contaminant segmentation improves model perfor-mance in comparison to isolating each task."
    ],
    "domain": [
      "Computer Vision",
      "Deep Learning",
      "Image Segmentation",
      "Astronomy"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "68f73e5d-ef54-4934-960a-a91770fa967a": {
    "pk": "68f73e5d-ef54-4934-960a-a91770fa967a",
    "name": "Adeline Paiement",
    "bio": "I am a researcher dedicated to advancing the fields of computer vision, deep learning, and their applications in health and environmental sciences. My recent work has focused on developing innovative methodologies that leverage attention mechanisms and graph neural networks to enhance image analysis and prediction tasks. For instance, I introduced a gridded attention mechanism to efficiently segment global contaminants in large images, addressing the limitations of traditional CNNs in capturing global context.\n\nIn the realm of medical imaging, I designed AttentNet, an automated lung nodule detection framework that utilizes fully convolutional attention blocks to improve detection accuracy in 3D pulmonary CT scans. My research also extends to solar imaging, where I developed a U-Net based method for removing cloud shadows from solar images, enhancing the quality of solar structure detection.\n\nI am particularly interested in integrating domain knowledge into graph neural networks, as demonstrated in my work on estimating the potential energy of chemical systems. By incorporating knowledge of chemical bonds and physical quantities, I have shown how GNNs can achieve higher accuracy and generalization.\n\nAdditionally, I have explored the intersection of health and technology, proposing a symbolic behavior recognition approach to monitor kitchen activities and assess eating behaviors, which could provide valuable insights for clinicians. My work is driven by a commitment to not only push the boundaries of machine learning but also to apply these advancements to real-world challenges, from healthcare to environmental monitoring.",
    "collaborators": [
      "Xianghua Xie",
      "Majedaldein Almahasneh",
      "Jay Morgan",
      "J. Aboudarham",
      "M. Mirmehdi",
      "Felix Richards",
      "P. Duc",
      "Elisabeth Sola",
      "C. Klinke",
      "J. Jenkins",
      "Faegheh Sardari",
      "S. Hannuna",
      "Kristina Yordanova",
      "I. Craddock",
      "Amal Chaoui",
      "Jean Aboudarham",
      "Xiang-Wen Xie",
      "Mathias Urbano",
      "J. Klehammer",
      "M. B'ilek",
      "J. Cuillandre",
      "S. Gwyn",
      "A. McConnachie",
      "Y. Ourmi\u00e8res",
      "J. Sommer",
      "J. Verron",
      "C. Ubelmann",
      "H. Glotin",
      "A. Pauly",
      "M. Seisenberger",
      "X. Bonnin",
      "S. L\u00fcdtke",
      "Samuel Whitehouse",
      "Frank Kr\u00fcger",
      "T. Kirste",
      "Paul Stroe",
      "Max Schr\u00f6der",
      "E. Tonkin",
      "Przemyslaw Woznowski",
      "C. Olsson",
      "Joseph Rafferty",
      "T. Sztyler",
      "L. Tao",
      "T. Burghardt",
      "D. Damen",
      "A. Cooper",
      "M. Camplani"
    ],
    "pub_titles": [
      "Multi-scale gridded Gabor attention for cirrus segmentation",
      "AttentNet: Fully Convolutional 3D Attention for Lung Nodule Detection",
      "Removing cloud shadows from ground-based solar imagery",
      "Domain-informed graph neural networks: a quantum chemistry case study",
      "Characterization of low surface brightness structures in annotated deep images",
      "Adaptive Neighbourhoods for the Discovery of Adversarial Examples",
      "Active Region Detection in Multi-spectral Solar Images",
      "Physics-informed detection and segmentation of type II solar radio bursts",
      "Learnable Gabor modulated complex-valued networks for orientation robustness",
      "VI-Net: View-Invariant Quality of Human Movement Assessment",
      "Analysing Cooking Behaviour in Home Settings: Towards Health Monitoring \u2020",
      "VIMPNN: A physics informed neural network for estimating potential energies of out-of-equilibrium systems",
      "Challenges in Annotation of useR Data for UbiquitOUs Systems: Results from the 1st ARDUOUS Workshop",
      "Energy expenditure estimation using visual and inertial sensors"
    ],
    "pub_abstracts": [
      "In this paper, we address the challenge of segmenting global contaminants in large images. The precise delineation of such structures requires ample global context alongside understanding of textural patterns. CNNs specialise in the latter, though their ability to generate global features is limited. Attention measures long range dependencies in images, capturing global context, though at a large computational cost. We propose a gridded attention mechanism to address this limitation, greatly increasing efficiency by processing multi-scale features into smaller tiles. We also enhance the attention mechanism for increased sensitivity to texture orientation, by measuring correlations across features dependent on different orientations, in addition to channel and positional attention. We present results on a new dataset of astronomical images, where the task is segmenting large contaminating dust clouds.",
      "Motivated by the increasing popularity of attention mechanisms, we observe that popular convolutional (conv.) attention models like Squeeze-and-Excite (SE) and Convolutional Block Attention Module (CBAM) rely on expensive multi-layer perception (MLP) layers. These MLP layers significantly increase computational complexity, making such models less applicable to 3D image contexts, where data dimensionality and computational costs are higher. In 3D medical imaging, such as 3D pulmonary CT scans, efficient processing is crucial due to the large data volume. Traditional 2D attention generalized to 3D increases the computational load, creating demand for more efficient attention mechanisms for 3D tasks. We investigate the possibility of incorporating fully convolutional (conv.) attention in 3D context. We present two 3D fully conv. attention blocks, demonstrating their effectiveness in 3D context. Using pulmonary CT scans for 3D lung nodule detection, we present AttentNet, an automated lung nodule detection framework from CT images, performing detection as an ensemble of two stages, candidate proposal and false positive (FP) reduction. We compare the proposed 3D attention blocks to popular 2D conv. attention methods generalized to 3D modules and to self-attention units. For the FP reduction stage, we also use a joint analysis approach to aggregate spatial information from different contextual levels. We use LUNA-16 lung nodule detection dataset to demonstrate the benefits of the proposed fully conv. attention blocks compared to baseline popular lung nodule detection methods when no attention is used. Our work does not aim at achieving state-of-the-art results in the lung nodule detection task, rather to demonstrate the benefits of incorporating fully conv. attention within a 3D context.",
      "The study and prediction of space weather entails the analysis of solar images showing structures of the Sun\u2019s atmosphere. When imaged from the Earth\u2019s ground, images may be polluted by terrestrial clouds which hinder the detection of solar structures. We propose a new method to remove cloud shadows, based on a U-Net architecture, and compare classical supervision with conditional GAN. We evaluate our method on two different imaging modalities, using both real images and a new dataset of synthetic clouds. Quantitative assessments are obtained through image quality indices (RMSE, PSNR, SSIM, and FID). We demonstrate improved results with regards to the traditional cloud removal technique and a sparse coding baseline, on different cloud types and textures.",
      "We explore different strategies to integrate prior domain knowledge into the design of graph neural networks (GNN). Our study is supported by a use-case of estimating the potential energy of chemical systems (molecules and crystals) represented as graphs. We integrate two elements of domain knowledge into the design of the GNN to constrain and regularise its learning, towards higher accuracy and generalisation. First, knowledge on the existence of different types of relations/graph edges (e.g. chemical bonds in our case study) between nodes of the graph is used to modulate their interactions. We formulate and compare two strategies, namely specialised message production and specialised update of internal states. Second, knowledge of the relevance of some physical quantities is used to constrain the learnt features towards a higher physical relevance using a simple multi-task learning (MTL) paradigm. We explore the potential of MTL to better capture the underlying mechanisms behind the studied phenomenon. We demonstrate the general applicability of our two knowledge integrations by applying them to three architectures that rely on different mechanisms to propagate information between nodes and to update node states. Our implementations are made publicly available. To support these experiments, we release three new datasets of out-of-equilibrium molecules and crystals of various complexities.",
      "The characterization of Low Surface Brightness (LSB) stellar structures around galaxies such as tidal debris of on-going or past collisions is essential to constrain models of galactic evolution. Our goal is to obtain quantitative measurements of LSB structures identified in deep images of samples consisting of hundreds of galaxies. We developed an online annotation tool that enables contributors to delineate the shapes of diffuse extended stellar structures, as well as artefacts or foreground structures. All parameters are automatically stored in a database which may be queried to retrieve quantitative measurements. We annotated LSB structures around 352 nearby massive galaxies with deep images obtained with the CFHT as part of two large programs: MATLAS and UNIONS/CFIS. Each LSB structure was delineated and labeled according to its likely nature: stellar shells, streams associated to a disrupted satellite, tails formed in major mergers, ghost reflections or cirrus. From our database containing 8441 annotations, the area, size, median surface brightness and distance to the host of 228 structures were computed. The results confirm the fact that tidal structures defined as streams are thinner than tails, as expected by numerical simulations. In addition, tidal tails appear to exhibit a higher surface brightness than streams (by about 1 mag), which may be related to different survival times for the two types of collisional debris. We did not detect any tidal feature fainter than 27.5 mag.arcsec$^{-2}$, while the nominal surface brightness limits of our surveys range between 28.3 and 29 mag.arcsec$^{-2}$, a difference that needs to be taken into account when estimating the sensitivity of future surveys to identify LSB structures. Our annotation database of observed LSB structures may be used for quantitative analysis and as a training set for machine learning algorithms (abbreviated).",
      "Deep Neural Networks (DNNs) have often supplied state-of-the-art results in pattern recognition tasks. Despite their advances, however, the existence of adversarial examples have caught the attention of the community. Many existing works have proposed methods for searching for adversarial examples within fixed-sized regions around training points. Our work complements and improves these existing approaches by adapting the size of these regions based on the problem complexity and data sampling density. This makes such approaches more appropriate for other types of data and may further improve adversarial training methods by increasing the region sizes without creating incorrect labels.",
      "Precisely detecting solar Active Regions (AR) from multi-spectral images is a challenging task yet important in understanding solar activity and its influence on space weather. A main challenge comes from each modality capturing a different location of these 3D objects, as opposed to more traditional multi-spectral imaging scenarios where all image bands observe the same scene. We present a multi-task deep learning framework that exploits the dependencies between image bands to produce 3D AR detection where different image bands (and physical locations) each have their own set of results. We compare our detection method against baseline approaches for solar image analysis (multi-channel coronal hole detection, SPOCA for ARs (Verbeeck et al., 2013)) and a state-of-the-art deep learning method (Faster RCNN) and show enhanced performances in detecting ARs jointly from multiple bands.",
      "Type II solar radio bursts have proven to be a useful tool for gaining insights into the behaviour of complex solar events and for forecasting and mitigating their damages on Earth. In this work, we detect and segment the occurrence of type II bursts in solar radio spectrograms, thereby facilitating the extraction of parameters needed to gain insight into solar events. We utilise prior knowledge of how type II bursts drift through frequencies over time to assist with these tasks of detection and segmentation. A new adaptive Region of Interest (ROI) is proposed, to constrain the search to regions that follow the burst curvature at a given frequency. It comes with an implicit data normalisation that reduces the variance of burst appearance in the data, hence simplifying the learning process from small datasets. We demonstrate the effectiveness of our methodology using a simple and popular HOG and logistic regression detector and basic segmentation based on voting and background subtraction. On a custom dataset representative of different levels of solar activity, at a wavelength range where no other detection algorithm currently operates, our adaptive ROI significantly improves over traditional sliding windows. In future work, it may be applied to other, state-of-the-art, machine learning algorithms.",
      "Robustness to transformation is desirable in many computer vision tasks, given that input data often exhibits pose variance within classes. While translation invariance and equivariance is a documented phenomenon of CNNs, sensitivity to other transformations is typically encouraged through data augmentation. We investigate the modulation of complex valued convolutional weights with learned Gabor filters to enable orientation robustness. With Gabor modulation, the designed network is able to generate orientation dependent features free of interpolation with a single set of rotation-governing parameters. Moreover, by learning rotation parameters alongside traditional convolutional weights, the representation space is not constrained and may adapt to the exact input transformation. We present Learnable Convolutional Gabor Networks (LCGNs), that are parameter-efficient and offer increased model complexity while keeping backpropagation simple. We demonstrate that learned Gabor modulation utilising an end-to-end complex architecture enables rotation invariance and equivariance on MNIST and a new dataset of simulated images of galactic cirri.",
      "We propose a view-invariant method towards the assessment of the quality of human movements which does not rely on skeleton data. Our end-to-end convolutional neural network consists of two stages, where at first a view-invariant trajectory descriptor for each body joint is generated from RGB images, and then the collection of trajectories for all joints are processed by an adapted, pre-trained 2D CNN (e.g. VGG-19 or ResNeXt-50) to learn the relationship amongst the different body parts and deliver a score for the movement quality. We release the only publicly-available, multi-view, non-skeleton, non-mocap, rehabilitation movement dataset (QMAR), and provide results for both cross-subject and cross-view scenarios on this dataset. We show that VI-Net achieves average rank correlation of 0.66 on cross-subject and 0.65 on unseen views when trained on only two views. We also evaluate the proposed method on the single-view rehabilitation dataset KIMORE and obtain 0.66 rank correlation against a baseline of 0.62.",
      "Wellbeing is often affected by health-related conditions. Among them are nutrition-related health conditions, which can significantly decrease the quality of life. We envision a system that monitors the kitchen activities of patients and that based on the detected eating behaviour could provide clinicians with indicators for improving a patient\u2019s health. To be successful, such system has to reason about the person\u2019s actions and goals. To address this problem, we introduce a symbolic behaviour recognition approach, called Computational Causal Behaviour Models (CCBM). CCBM combines symbolic representation of person\u2019s behaviour with probabilistic inference to reason about one\u2019s actions, the type of meal being prepared, and its potential health impact. To evaluate the approach, we use a cooking dataset of unscripted kitchen activities, which contains data from various sensors in a real kitchen. The results show that the approach is able to reason about the person\u2019s cooking actions. It is also able to recognise the goal in terms of type of prepared meal and whether it is healthy. Furthermore, we compare CCBM to state-of-the-art approaches such as Hidden Markov Models (HMM) and decision trees (DT). The results show that our approach performs comparable to the HMM and DT when used for activity recognition. It outperformed the HMM for goal recognition of the type of meal with median accuracy of 1 compared to median accuracy of 0.12 when applying the HMM. Our approach also outperformed the HMM for recognising whether a meal is healthy with a median accuracy of 1 compared to median accuracy of 0.5 with the HMM.",
      "Simulation of molecular and crystal systems enables insight into interesting chemical properties that benefit processes ranging from drug discovery to material synthesis. However these simulations can be computationally expensive and time consuming despite the approximations through Density Functional Theory (DFT). We propose the Valence Interaction Message Passing Neural Network (VIMPNN) to approximate DFT\u2019s ground-state energy calculations. VIMPNN integrates physics prior knowledge such as the existence of different interatomic bounds to estimate more accurate energies. Furthermore, while many previous machine learning methods consider only stable systems, our proposed method is demonstrated on unstable systems at different atomic distances. VIMPNN predictions can be used to determine the stable configurations of systems, i.e. stable distance for atoms \u2013 a necessary step for the future simulation of crystal growth for example. Our method is extensively evaluated on a augmented version of the QM9 dataset that includes unstable molecules, as well as a new dataset of infiniteand finite-size crystals, and is compared with the Message Passing Neural Network (MPNN). VIMPNN has comparable accuracy with DFT, while allowing for 5 orders of magnitude in computational speed up compared to DFT simulations, and produces more accurate and informative potential energy curves than MPNN for estimating stable configurations.",
      "Labelling user data is a central part of the design and evaluation of pervasive systems that aim to support the user through situation-aware reasoning. It is essential both in designing and trainin ...",
      "Deriving a person's energy expenditure accurately forms the foundation for tracking physical activity levels across many health and lifestyle monitoring tasks. In this study, the authors present a method for estimating calorific expenditure from combined visual and accelerometer sensors by way of an RGB-Depth camera and a wearable inertial sensor. The proposed individual-independent framework fuses information from both modalities which leads to improved estimates beyond the accuracy of single modality and manual metabolic equivalents of task (MET) lookup table based methods. For evaluation, the authors introduce a new dataset called SPHERE_RGBD\u2009 +\u2009 Inertial_calorie, for which visual and inertial data are simultaneously obtained with indirect calorimetry ground truth measurements based on gas exchange. Experiments show that the fusion of visual and inertial data reduces the estimation error by 8 and 18% compared with the use of visual only and inertial sensor only, respectively, and by 33% compared with a MET-based approach. The authors conclude from their results that the proposed approach is suitable for home monitoring in a controlled environment."
    ],
    "domain": [
      "Computer Vision",
      "Deep Learning",
      "Graph Neural Network",
      "Image Processing"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "b043edd2-fc56-4e1a-8062-0da3548c8ec9": {
    "pk": "b043edd2-fc56-4e1a-8062-0da3548c8ec9",
    "name": "Xianghua Xie",
    "bio": "I am a researcher dedicated to advancing machine learning techniques with a strong focus on privacy, efficiency, and real-world applications. My recent work in Federated Learning (FL) addresses critical privacy concerns, proposing a novel gradient leakage defense technique that secures model architectures while maintaining performance. I have also explored the intersection of machine learning and manufacturing, developing models to enhance the accuracy of surface texture predictions in steel production and improve vehicle detection using LiDAR data.\n\nMy research extends to the medical domain, where I have applied deep learning to nuclei detection in histopathology images, demonstrating the effectiveness of graph convolutional networks over traditional methods. Additionally, I have contributed to the development of interpretable models for predicting hospitalizations related to COVID-19, collaborating with medical experts to enhance the usability of recurrent neural networks.\n\nI am passionate about tackling complex challenges, such as defect detection in steel manufacturing and 3D geometry segmentation, by leveraging innovative machine learning approaches. My work emphasizes the importance of model efficiency and robustness, as evidenced by my contributions to model compression and acceleration techniques. Overall, I strive to bridge the gap between theoretical advancements and practical applications, ensuring that my research has a meaningful impact across various domains.",
    "collaborators": [
      "Jingjing Deng",
      "Lin Wu",
      "Xiaoke Ma",
      "Chen Hu",
      "Deyin Liu",
      "Bo Li",
      "Hanchi Ren",
      "A. Milne",
      "Michael Edwards",
      "F. Boussaid",
      "Bennamoun",
      "Chengwu Liang",
      "J. Ma",
      "Hongyang Chen",
      "Y. Ye",
      "Kayalvizhi Lakshmanan",
      "Matt Roach",
      "C. Giannetti",
      "Shubham Bhoite",
      "D. George",
      "Tim Mortensen",
      "Manduhu Manduhu",
      "B. Heravi",
      "S. Kariyawasam",
      "Connor Clarkson",
      "Sachin Bahade",
      "Zengfa Dou",
      "Hui Liu",
      "Chubing Guo",
      "L. Wu",
      "Shiyin Tan",
      "Xiaoxiong Zhong",
      "Hassan Eshkiki",
      "Benjamin Mora",
      "Suraj Ramchand",
      "Gavin Tsang",
      "Duncan Cole",
      "Ali Alqahtani",
      "Mark W. Jones",
      "Majedaldein Almahasneh",
      "A. Paiement",
      "J. Aboudarham"
    ],
    "pub_titles": [
      "Gradient Leakage Defense with Key-Lock Module for Federated Learning",
      "Predicting Surface Texture in Steel Manufacturing at Speed",
      "Image Template Matching via Dense and Consistent Contrastive Learning",
      "Steel Surface Roughness Parameter Calculations Using Lasers and Machine Learning Models",
      "A Robust Vehicle Detection Model for LiDAR Sensor Using Simulation Data and Transfer Learning Methods",
      "Active Anchors",
      "Cascaded Graph Convolution Approach for Nuclei Detection in Histopathology Images",
      "Fully Connected Networks on a Diet With the Mediterranean Matrix Multiplication",
      "RetainEXT: Enhancing Rare Event Detection and Improving Interpretability of Health Records using Temporal Neural Networks",
      "GRNN: Generative Regression Neural Network\u2014A Data Leakage Attack for Federated Learning",
      "Literature Review of Deep Network Compression",
      "3D Interactive Segmentation With Semi-Implicit Representation and Active Learning"
    ],
    "pub_abstracts": [
      "Federated Learning (FL) is a widely adopted privacy-preserving machine learning approach where private data remains local, enabling secure computations and the exchange of local model gradients between local clients and third-party parameter servers. However, recent findings reveal that privacy may be compromised and sensitive information potentially recovered from shared gradients. In this study, we offer detailed analysis and a novel perspective on understanding the gradient leakage problem. These theoretical works lead to a new gradient leakage defense technique that secures arbitrary model architectures using a private key-lock module. Only the locked gradient is transmitted to the parameter server for global model aggregation. Our proposed learning method is resistant to gradient leakage attacks, and the key-lock module is designed and trained to ensure that, without the private information of the key-lock module: a) reconstructing private training data from the shared gradient is infeasible; and b) the global model's inference performance is significantly compromised. We discuss the theoretical underpinnings of why gradients can leak private information and provide theoretical proof of our method's effectiveness. We conducted extensive empirical evaluations with a total of forty-four models on several popular benchmarks, demonstrating the robustness of our proposed approach in both maintaining model performance and defending against gradient leakage attacks.",
      "Control of the surface texture of steel strip during the galvanizing and temper rolling processes is essential to satisfy customer requirements and is conventionally measured post-production using a stylus. In-production laser reflection measurement is less consistent than physical measurement but enables real time adjustment of processing parameters to optimize product surface characteristics. We propose the use of machine learning to improve accuracy of the transformation from inline laser reflection measurements to a prediction of surface properties. In addition to accuracy, model evaluation speed is important for fast feedback control. The ROCKET model is one of the fastest state of the art models, however it can be sped up by utilizing a GPU. Our contribution is to implement the model in PyTorch for fast GPU kernel transforms and provide a soft version of the Proportion of Positive Values (PPV) nonlinear pooling function, allowing gradient flow. We perform timing and performance experiments comparing the implementations.",
      "Image template matching refers to localizing a small query image as opposed to a large reference image map. The query image a.k.a template has to be screened across every equal-sized region in the reference map to perform inner-product at pixel-level and the resulting similarity indicates the template location. Due to the domain heterogeneity between template and reference images, the matching performance degrades under dramatic appearance changes. More severely, the asymmetric matching easily leads to over-fitting by suggesting excessively false positive regions. To these ends, we propose an effective template matching method based on contrastive learning to perform a dense and consistent InfoNCEloss during matching. This can increase the matching at finer details, and thus effectively regularizes network training to prevent over-fitting. Extensive experiments on the synthetic aperture radar (SAR) and optical datasets, i.e., SEN1-2 and OS datasets demonstrate that our proposed method outperforms state-of-the-art methods by a large margin.",
      "Control of surface texture in strip steel is essential to meet customer requirements during galvanizing and temper rolling processes. Traditional methods rely on post-production stylus measurements, while on-line techniques offer non-contact and real-time measurements of the entire strip. However, ensuring accurate measurement is imperative for their effective utilization in the manufacturing pipeline. Moreover, accurate on-line measurements enable real-time adjustments of manufacturing processing parameters during production, ensuring consistent quality and the possibility of closed-loop control of the temper mill. In this study, we leverage state-of-the-art machine learning models to enhance the transformation of on-line measurements into significantly a more accurate Ra surface roughness metric. By comparing a selection of data-driven approaches, including both deep learning and non-deep learning methods, to the close-form transformation, we evaluate their potential for improving surface texture control in temper strip steel manufacturing.",
      "Vehicle detection in parking areas provides the spatial and temporal utilisation of parking spaces. Parking observations are typically performed manually, limiting the temporal resolution due to the high labour cost. This paper uses simulated data and transfer learning to build a robust real-world model for vehicle detection and classification from single-beam LiDAR of a roadside parking scenario. The paper presents a synthetically augmented transfer learning approach for LiDAR-based vehicle detection and the implementation of synthetic LiDAR data. A synthetic augmented transfer learning method was used to supplement the small real-world data set and allow the development of data-handling techniques. In addition, adding the synthetically augmented transfer learning method increases the robustness and overall accuracy of the model. Experiments show that the method can be used for fast deployment of the model for vehicle detection using a LIDAR sensor.",
      "Defect detection in steel manufacturing has achieved state-of-the-art results in both localisation and classification of various types of defects, however, this assumes very high-quality datasets that have been verified by domain experts. Labelling such data has become a time-consuming and interaction-heavy task with a great amount of user effort, this is due to variability in the defect characteristics and composite nature. We propose a new acquisition function based on the similarity of defects for refining labels over time by showing the user only the most required to be labelled. We also explore different ways in which to feed these new refinements back into the model to utilize the new knowledge in an effortful way. We achieve this with a graphical interface that provides additional information to the domain expert as the data gets refined, allowing for decision-making with uncertain areas of the steel.",
      "Nuclei detection in histopathology images of cancerous tissue stained with conventional hematoxylin and eosin stain is a challenging task due to the complexity and diversity of cell data. Deep learning techniques have produced encouraging results in the field of nuclei detection, where the main emphasis is on classification and regressionbased methods. Recent research has demonstrated that regression-based techniques outperform classification. In this paper, we propose a classification model based on graph convolutions to classify nuclei, and similar models to detect nuclei using cascaded architecture. With nearly 29,000 annotated nuclei in a large dataset of cancer histology images, we evaluated the Convolutional Neural Network (CNN) and Graph Convolutional Networks (GCN) based approaches. Our findings demonstrate that graph convolutions perform better with a cascaded GCN architecture and are more stable than centre-of-pixel approach. We have compared our twofold evaluation quantitative results with CNN-based models such as Spatial Constrained Convolutional Neural Network (SC-CNN) and Centre-of-Pixel Convolutional Neural Network (CP-CNN). We used two different loss functions, binary cross-entropy and focal loss function, and also investigated the behaviour of CP-CNN and GCN models to observe the effectiveness of CNN and GCN operators. The compared quantitative F1 score of cascaded-GCN shows an improvement of 6% compared to state-of-the-art methods.",
      "This article proposes the Mediterranean matrix multiplication, a new, simple and practical randomized algorithm that samples angles between the rows and columns of two matrices with sizes <inline-formula> <tex-math notation=\"LaTeX\">$m, n, $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> to approximate matrix multiplication in <inline-formula> <tex-math notation=\"LaTeX\">$O(k(mn+np+mp))$ </tex-math></inline-formula> steps, where <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula> is a constant only related to the precision desired. The number of instructions carried out is mainly bounded by bitwise operators, amenable to a simplified processing architecture and compressed matrix weights. Results show that the method is superior in size and number of operations to the standard approximation with signed matrices. Equally important, this article demonstrates a first application to machine learning inference by showing that weights of fully connected layers can be compressed between <inline-formula> <tex-math notation=\"LaTeX\">$30\\times $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$100\\times $ </tex-math></inline-formula> with little to no loss in inference accuracy. The requirements for pure floating-point operations are also down as our algorithm relies mainly on simpler bitwise operators.",
      "A recurring theme during the pandemic was the shortage of hospital beds. Despite all efforts, the healthcare system still faces 25 % of resource strain felt during the first peak of coronavirus. Digitisation of Electronic Healthcare Records (EHRs) and the pandemic have brought about many successful applications of Recurrent Neural Networks (RNNs) to predict patients' current and future states. Despite their strong per-formance, it remains a challenge for users to delve into the black box which has heavily influenced researchers to utilise more interpretable techniques such as ID-Convolutional neural networks. Others focus on using more interpretable machine learning techniques but only achieve high performance on a select subset of patients. By collaborating with medical experts and artificial intelligence scientists, our study improves on the REverse Time AttentIoN EX model, a feature and visit level attention network, for increased interpretability and usability of RNNs in predicting COVID-19-related hospitalisations. We achieved 82.40 % area under the receiver operating characteristic curve and showcased effective use of the REverse Time AttentIoN EXTension model and EHRs in understanding how individual medical codes contribute to hospitalisation risk prediction. This study provides a guideline for researchers aiming to design interpretable temporal neural networks using the power of RNNs and data mining techniques.",
      "Data privacy has become an increasingly important issue in Machine Learning (ML), where many approaches have been developed to tackle this challenge, e.g., cryptography (Homomorphic Encryption (HE), Differential Privacy (DP)) and collaborative training (Secure Multi-Party Computation (MPC), Distributed Learning, and Federated Learning (FL)). These techniques have a particular focus on data encryption or secure local computation. They transfer the intermediate information to the third party to compute the final result. Gradient exchanging is commonly considered to be a secure way of training a robust model collaboratively in Deep Learning (DL). However, recent researches have demonstrated that sensitive information can be recovered from the shared gradient. Generative Adversarial Network (GAN), in particular, has shown to be effective in recovering such information. However, GAN based techniques require additional information, such as class labels that are generally unavailable for privacy-preserved learning. In this article, we show that, in the FL system, image-based privacy data can be easily recovered in full from the shared gradient only via our proposed Generative Regression Neural Network (GRNN). We formulate the attack to be a regression problem and optimize two branches of the generative model by minimizing the distance between gradients. We evaluate our method on several image classification tasks. The results illustrate that our proposed GRNN outperforms state-of-the-art methods with better stability, stronger robustness, and higher accuracy. It also has no convergence requirement to the global FL model. Moreover, we demonstrate information leakage using face re-identification. Some defense strategies are also discussed in this work.",
      "Deep networks often possess a vast number of parameters, and their significant redundancy in parameterization has become a widely-recognized property. This presents significant challenges and restricts many deep learning applications, making the focus on reducing the complexity of models while maintaining their powerful performance. In this paper, we present an overview of popular methods and review recent works on compressing and accelerating deep neural networks. We consider not only pruning methods but also quantization methods, and low-rank factorization methods. This review also intends to clarify these major concepts, and highlights their characteristics, advantages, and shortcomings.",
      "Segmenting complex 3D geometry is a challenging task due to rich structural details and complex appearance variations of target object. Shape representation and foreground-background delineation are two of the core components of segmentation. Explicit shape models, such as mesh based representations, suffer from poor handling of topological changes. On the other hand, implicit shape models, such as level-set based representations, have limited capacity for interactive manipulation. Fully automatic segmentation for separating foreground objects from background generally utilizes non-interoperable machine learning methods, which heavily rely on the off-line training dataset and are limited to the discrimination power of the chosen model. To address these issues, we propose a novel semi-implicit representation method, namely Non-Uniform Implicit B-spline Surface (NU-IBS), which adaptively distributes parametrically blended patches according to geometrical complexity. Then, a two-stage cascade classifier is introduced to carry out efficient foreground and background delineation, where a simplistic Na\u00efve-Bayesian model is trained for fast background elimination, followed by a stronger pseudo-3D Convolutional Neural Network (CNN) multi-scale classifier to precisely identify the foreground objects. A localized interactive and adaptive segmentation scheme is incorporated to boost the delineation accuracy by utilizing the information iteratively gained from user intervention. The segmentation result is obtained via deforming an NU-IBS according to the probabilistic interpretation of delineated regions, which also imposes a homogeneity constrain for individual segments. The proposed method is evaluated on a 3D cardiovascular Computed Tomography Angiography (CTA) image dataset and Brain Tumor Image Segmentation Benchmark 2015 (BraTS2015) 3D Magnetic Resonance Imaging (MRI) dataset."
    ],
    "domain": [
      "Federated Learning",
      "Machine Learning",
      "Computer Vision",
      "Data Privacy"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "7554771d-3558-45b1-bca3-a5ad1d763759": {
    "pk": "7554771d-3558-45b1-bca3-a5ad1d763759",
    "name": "Elisabeth Sola",
    "bio": "I am an astrophysicist with a keen interest in the structural dynamics of early-type galaxies (ETGs) and their globular cluster (GC) systems. My recent work has focused on understanding the intricate relationships between galaxy morphology, rotational support, and the effects of mergers. Through observational studies utilizing data from the MATLAS and NGVS surveys, I have explored how different merger types influence the characteristics of ETGs, revealing significant correlations between tidal features, kinematic structures, and metallicity.\n\nOne of my notable contributions is the development of a gridded attention mechanism for segmenting global contaminants in large astronomical images, which enhances the efficiency of capturing both local textural patterns and global context. This innovative approach has been applied to a new dataset of astronomical images, demonstrating its effectiveness in delineating complex structures like dust clouds.\n\nAdditionally, I have conducted extensive analyses of GC systems across various early-type galaxies, uncovering relationships between effective radii and galaxy properties. My research has also delved into the plane-of-satellite problem, where I employed spectroscopic follow-up observations to confirm dwarf galaxy candidates and investigate their stellar populations.\n\nI am passionate about leveraging advanced techniques and collaborative tools to enhance our understanding of galaxy evolution and the underlying physical processes that shape the universe. My work not only contributes to the field of astrophysics but also aims to inspire future research through the development of comprehensive databases and methodologies for analyzing low surface brightness structures.",
    "collaborators": [
      "P. Duc",
      "Sungsoon Lim",
      "J. Cuillandre",
      "P. Durrell",
      "E. Emsellem",
      "S. Gwyn",
      "F. Marleau",
      "M. B'ilek",
      "Felix Richards",
      "A. Paiement",
      "E. Peng",
      "P. Cot'e",
      "L. Ferrarese",
      "J. Roediger",
      "Chengze Liu",
      "C. Spengler",
      "Laura V. Sales",
      "J. Blakeslee",
      "J. C. Mihos",
      "T. Puzia",
      "R. S'anchez-Janssen",
      "Mathias Urbano",
      "Xianghua Xie",
      "A. Lanccon",
      "Oliver Muller",
      "Michal Bilek",
      "O. Muller",
      "N. Heesters",
      "M. Pawlowski",
      "M. Poulain",
      "R. Habas",
      "Rory Smith",
      "S. Paudel",
      "A. Lan\u00e7on",
      "O. M\u00fcller",
      "R\u00faben S\u00e1nchez-Janssen",
      "J. Klehammer",
      "A. McConnachie"
    ],
    "pub_titles": [
      "Multi-scale gridded Gabor attention for cirrus segmentation",
      "The Spatial Distribution of Globular Cluster Systems in Early Type Galaxies: Estimation Procedure and Catalog of Properties for Globular Cluster Systems Observed with Deep Imaging Surveys",
      "Why do different early-type-galaxies have different amounts of rotational support?",
      "Dwarf galaxies in the MATLAS survey: The satellite system of NGC 474 under scrutiny with MUSE",
      "The Next Generation Virgo Cluster Survey (NGVS). XXVII. The Size and Structure of Globular Cluster Systems and Their Connection to Dark Matter Halos",
      "When and how did early-type galaxies outside of galaxy clusters lose their rotational support?",
      "Characterization of low surface brightness structures in annotated deep images",
      "Origin of the differences in rotational support among early-type galaxies: The case of galaxies outside clusters"
    ],
    "pub_abstracts": [
      "In this paper, we address the challenge of segmenting global contaminants in large images. The precise delineation of such structures requires ample global context alongside understanding of textural patterns. CNNs specialise in the latter, though their ability to generate global features is limited. Attention measures long range dependencies in images, capturing global context, though at a large computational cost. We propose a gridded attention mechanism to address this limitation, greatly increasing efficiency by processing multi-scale features into smaller tiles. We also enhance the attention mechanism for increased sensitivity to texture orientation, by measuring correlations across features dependent on different orientations, in addition to channel and positional attention. We present results on a new dataset of astronomical images, where the task is segmenting large contaminating dust clouds.",
      "We present an analysis of the spatial distribution of globular cluster (GC) systems of 118 nearby early-type galaxies in the Next Generation Virgo Cluster Survey (NGVS) and Mass Assembly of early-Type GaLAxies with their fine Structures (MATLAS) survey programs, which both used MegaCam on the Canada-France-Hawaii Telescope. We describe the procedure used to select GC candidates and fit the spatial distributions of GCs to a two-dimensional S\\'ersic function, which provides effective radii (half number radii) and S\\'ersic indices, and estimate background contamination by adding a constant term to the S'ersic function. In cases where a neighboring galaxy affects the estimation of the GC spatial distribution in the target galaxy, we fit two 2D S\\'ersic functions, simultaneously. We also investigate the color distributions of GCs in our sample by using Gaussian Mixture Modeling. For GC systems with bimodal color distributions, we divide the GCs into blue and red subgroups and fit their respective spatial distributions with S\\'ersic functions. Finally, we measure the total number of GCs based on our fitted S\\'ersic function, and calculate the GC specific frequency.",
      "Early-type galaxies (ETGs, i.e. elliptical and lenticular galaxies) differ in their amount of rotational support -- some are purely supported by velocity dispersion, while others show pronounced ordered rotation. Cosmological hydrodynamical simulations show that the progenitors of all ETGs were first rotating quickly, but then mergers decreased their rotational support. In the presented work, we studied this process using an observational archaeological approach. Namely, we inspected the correlations of 23 merger-sensitive characteristics of local ETGs with a parameter quantifying the rotational support. We used a volume-limited sample of local ETGs, that are not in galaxy clusters, from the MATLAS survey. We found, for example, that slowly rotating galaxies have tidal features and kinematically distinct components more often and have lower metallicities. We sought for mutual interpretation of the correlations among all 23 quantities, together with literature results on high-redshift massive galaxies. There seems to be only one interpretation possible: on average, ETGs lose their rotational support through multiple minor wet mergers happening at the redshifts above about two.",
      "A recent study of the distribution of dwarf galaxies in the MATLAS sample in galaxy groups revealed an excess of flattened satellite structures, reminiscent of the co-rotating planes of dwarf galaxies discovered in the local Universe. If confirmed, this lends credence to the plane-of-satellite problem and further challenges the standard model of hierarchical structure formation. However, with only photometric data and no confirmation of the satellite membership the study could not address the plane-of-satellite problem in full detail . Here we present spectroscopic follow-up observations of one of the most promising planes-of-satellite candidates in the MATLAS survey, the satellite system of NGC\\,474. Employing MUSE at the VLT and full spectrum fitting we studied 13 dwarf galaxy candidates and confirmed nine to be members of the field around NGC\\,474. Measuring the stellar populations of all observed galaxies, we find that the MATLAS dwarfs have lower metallicities than the Local Group dwarfs at a given luminosity. Two dwarf galaxies may form a pair of satellites based on their close projection and common velocity. Within the virial radius, we do not find a significant plane-of-satellites, however, there is a sub-population of six dwarf galaxies which seem to be anti-correlated in phase-space. Due to the low number of dwarf galaxies, this signal may arise by chance. With over 2000 dwarf galaxy candidates found in the MATLAS survey this remains an intriguing data set to study the plane-of-satellites problem in a statistical fashion once more follow-up observations have been conducted.",
      "We study the size and structure of globular cluster (GC) systems of 118 early-type galaxies from the NGVS, MATLAS, and ACSVCS surveys. Fitting S\u00e9rsic profiles, we investigate the relationship between effective radii of GC systems (R e,gc) and galaxy properties. GC systems are 2\u20134 times more extended than host galaxies across the entire stellar mass range of our sample (108.3 M \u2299 < M * < 1011.6 M \u2299). The relationship between R e,gc and galaxy stellar mass exhibits a characteristic \u201cknee\u201d at a stellar mass of M p \u2243 1010.8, similar to the galaxy R e \u2013stellar mass relationship. We present a new characterization of the traditional blue and red GC color subpopulations, describing them with respect to host galaxy (g\u2032\u2212i\u2032) color (\u0394gi): GCs with similar colors to their hosts have a \u201cred\u201d \u0394gi, and those significantly bluer GCs have a \u201cblue\u201d \u0394gi. The GC populations with red \u0394gi, even in dwarf galaxies, are twice as extended as the stars, suggesting that formation or survival mechanisms favor the outer regions. We find a tight correlation between R e,gc and the total number of GCs, with intrinsic scatter \u22720.1 dex spanning two and three orders of magnitude in size and number, respectively. This holds for both red and blue subpopulations, albeit with different slopes. Assuming that N GC,Total correlates with M 200, we find that the red GC systems have effective radii of roughly 1%\u20135% R 200, while the blue GC systems in massive galaxies can have sizes as large as \u223c10% R 200. Environmental dependence on R e,gc is also found, with lower-density environments exhibiting more extended GC systems at fixed mass.",
      "Context. Early-type galaxies (ETGs) are divided into slow and fast rotators (FRs and SRs) according to the degree of ordered rotation of their stellar populations. Cosmological hydrodynamical simulations indicate that galaxies are formed as FRs before their rotational support decreases, usually because of mergers. Aims. We aimed to investigate this process observationally for galaxies outside of clusters. Methods. We made use of the fact that di \ufb00 erent merger types leave di \ufb00 erent traces that have di \ufb00 erent lifetimes. We statistically analyzed multiple characteristics of galaxies that are expected to be in\ufb02uenced by mergers: tidal features, kinematically distinct cores, stellar age, etc. They were taken from the MATLAS and ATLAS 3D databases. We identi\ufb01ed through multilinear regression the quantities that, at a \ufb01xed mass and environmental density of the galaxy, signi\ufb01cantly correlate with a measure of the ordered rotation of the galaxy, \u03bb N R e . Results. We found a negative correlation of the rotational support with the occurrence of tidal disturbances and kinematic substructures and a positive correlation with metallicity and metallicity gradients. For massive galaxies, the rotational support correlates negatively with the abundance of alpha elements, and for the galaxies in low-density environments, it correlates negatively with the central photometric cuspiness. These and additional literature observational constraints are explained the easiest if the mergers that decreased the rotational support of ETGs were typically minor, wet and happening at z \u2248 2. They did not form the currently observed tidal features. The observed frequency of tidal features implies a merging rate of 0.07-0.2 per Gyr. This is insu \ufb03 cient for explaining the observed growth of radii of ETGs with redshift by",
      "The characterization of Low Surface Brightness (LSB) stellar structures around galaxies such as tidal debris of on-going or past collisions is essential to constrain models of galactic evolution. Our goal is to obtain quantitative measurements of LSB structures identified in deep images of samples consisting of hundreds of galaxies. We developed an online annotation tool that enables contributors to delineate the shapes of diffuse extended stellar structures, as well as artefacts or foreground structures. All parameters are automatically stored in a database which may be queried to retrieve quantitative measurements. We annotated LSB structures around 352 nearby massive galaxies with deep images obtained with the CFHT as part of two large programs: MATLAS and UNIONS/CFIS. Each LSB structure was delineated and labeled according to its likely nature: stellar shells, streams associated to a disrupted satellite, tails formed in major mergers, ghost reflections or cirrus. From our database containing 8441 annotations, the area, size, median surface brightness and distance to the host of 228 structures were computed. The results confirm the fact that tidal structures defined as streams are thinner than tails, as expected by numerical simulations. In addition, tidal tails appear to exhibit a higher surface brightness than streams (by about 1 mag), which may be related to different survival times for the two types of collisional debris. We did not detect any tidal feature fainter than 27.5 mag.arcsec$^{-2}$, while the nominal surface brightness limits of our surveys range between 28.3 and 29 mag.arcsec$^{-2}$, a difference that needs to be taken into account when estimating the sensitivity of future surveys to identify LSB structures. Our annotation database of observed LSB structures may be used for quantitative analysis and as a training set for machine learning algorithms (abbreviated).",
      "Context: Early-type galaxies (ETGs) are divided into slow and fast rotators (FRs and SRs) according to the degree of ordered rotation of their stellar populations. Cosmological hydrodynamical simulations indicate that galaxies form as FRs before their rotational support decreases, usually because of mergers. Aims: We aimed to investigate this process observationally for galaxies outside of clusters. Methods: We made use of the fact that different merger types leave different traces that have different lifetimes. We statistically analyzed multiple characteristics of galaxies that are expected to be influenced by mergers, such as tidal features, kinematically distinct cores, and stellar ages. They were taken from the MATLAS and ATLAS$^\\mathrm{3D}$ databases. Through multilinear regression we identified the quantities that, at a fixed mass and environmental density of the galaxy, significantly correlate with a measure of the ordered rotation of the galaxy, $\\lambda_{R_e}^N$. Results: We found a negative correlation of the rotational support with the occurrence of tidal disturbances and kinematic substructures, and a positive correlation with metallicity and metallicity gradients. For massive galaxies, the rotational support correlates negatively with the abundance of alpha elements, and for the galaxies in low-density environments, it correlates negatively with the central photometric cuspiness. These and additional literature observational constraints are explained the easiest if the mergers that decreased the rotational support of ETGs were typically minor, wet, and happening at $z\\approx 2$. They did not form the currently observed tidal features. The observed frequency of tidal features implies a merging rate of 0.07-0.2 per Gyr. This is insufficient to explain the observed growth of the radii of ETGs with redshift by mergers."
    ],
    "domain": [
      "Astronomy",
      "Image Segmentation",
      "Machine Learning",
      "Galaxy Dynamics"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "2ed0796e-b45f-48a8-ba58-22096e303231": {
    "pk": "2ed0796e-b45f-48a8-ba58-22096e303231",
    "name": "Pierre-Alain Duc",
    "bio": "I am an astrophysicist specializing in the study of galaxy interactions, star formation, and the complex dynamics of the intergalactic medium. My recent research has focused on the intricate processes occurring in environments like Stephan's Quintet and tidal dwarf galaxies, where I combine advanced imaging from the James Webb Space Telescope and Hubble Space Telescope with spectroscopy from the Atacama Large Millimeter Array. \n\nThrough my work, I have explored the turbulent multiphase intergalactic medium, revealing how massive clouds of gas interact and evolve under extreme conditions. I have also investigated the star formation rates and gas dynamics in tidal dwarf galaxies, demonstrating their unique behaviors compared to regular galaxies. My studies extend to dwarf galaxies beyond the Local Volume, where I analyze their stellar populations and metallicity relations, contributing to our understanding of galaxy formation and evolution across different environments.\n\nI am particularly interested in the role of tidal features and ram pressure stripping in shaping galaxy morphology and star formation activity. My findings highlight the diverse mechanisms driving these processes, from minor mergers to the effects of environmental density. I aim to bridge observational data with theoretical models, providing insights into the complex histories of galaxies and their interactions. As I continue my research, I look forward to leveraging new observational technologies to deepen our understanding of the universe's structure and evolution.",
    "collaborators": [
      "Sungsoon Lim",
      "J. Cuillandre",
      "J. Fensch",
      "F. Marleau",
      "M. Poulain",
      "R. Habas",
      "P. Durrell",
      "S. Gwyn",
      "M. B'ilek",
      "Rub'en S'anchez-Janssen",
      "S. Paudel",
      "R. S\u00e1nchez-Janssen",
      "Elisabeth Sola",
      "A. McConnachie",
      "P. Appleton",
      "K. Voggel",
      "U. Lisenfeld",
      "N. Heesters",
      "F. Renaud",
      "S. Brough",
      "J. Carlin",
      "N. E. Chisari",
      "R. Gavazzi",
      "R. Ibata",
      "C. Laigle",
      "M. Montes",
      "J. Rom'an",
      "A. Watkins",
      "A. Wright",
      "I. Yoon",
      "J. Klehammer",
      "R. Carlberg",
      "O. Mueller",
      "P. Guillard",
      "B. Emonts",
      "F. Boulanger",
      "A. Togi",
      "W. Reach",
      "K. Alatalo",
      "M. Cluver",
      "T. Diaz Santos",
      "S. Gallagher",
      "P. Ogle",
      "E. O\u2019Sullivan",
      "C. Xu",
      "Navyasree Kovakkuni",
      "F. Lelli",
      "M. Boquien",
      "J. Braine",
      "E. Brinks",
      "V. Charmandaris",
      "Francoise Combes",
      "S. McGaugh",
      "J. Mihos",
      "M. Pawlowski",
      "Y. Revaz",
      "P. Weilbacher",
      "O. Muller",
      "Oliver M\u00fcller",
      "D. N. Chhatkuli",
      "Suk-Jin Yoon",
      "R. Rakhi",
      "Geethika Santhosh",
      "Prajwel Joseph",
      "K. George",
      "S. Subramanian",
      "Indulekha Kavila",
      "J. Postma",
      "P. C\u00f4t\u00e9",
      "L. Cortese",
      "S. Ghosh",
      "A. Subramaniam",
      "S. Tandon",
      "J. Hutchings",
      "P Samuel Wesley",
      "Aditya Bharadwaj",
      "Neeran Niroula",
      "Cheng Cheng",
      "Cong K. Xu",
      "N. Tang",
      "Y. Dai",
      "J.-S. Huang",
      "Chuan He",
      "H. Feng",
      "L. Guy",
      "E. Bachelet",
      "M. Banerji",
      "F. Bauer",
      "T. Collett",
      "C. Conselice",
      "S. Eggl",
      "A. Ferguson",
      "A. Fontana",
      "C. Heymans",
      "I. Hook",
      "'Eric Aubourg",
      "H. Aussel",
      "J. Bosch",
      "B. Carry",
      "H. Hoekstra"
    ],
    "pub_titles": [
      "Multiphase Gas Interactions on Subarcsec Scales in the Shocked Intergalactic Medium of Stephan\u2019s Quintet with JWST and ALMA",
      "Molecular and Ionized Gas in Tidal Dwarf Galaxies: The Spatially Resolved Star-Formation Relation",
      "Radial velocities and stellar population properties of 56 MATLAS dwarf galaxies observed with MUSE",
      "The creation of a massive UCD by tidal threshing from NGC\u00a0936",
      "UVIT view of NGC 5291: Ongoing star formation in tidal dwarf galaxies at \u223c 0.35\u00a0kpc resolution",
      "Deep H i Mapping of Stephan\u2019s Quintet and Its Neighborhood",
      "Rubin-Euclid Derived Data Products: Initial Recommendations",
      "Preparing for low surface brightness science with the Vera C. Rubin Observatory: characterisation of tidal features from mock images",
      "From starburst to quenching: merger-driven evolution of the star formation regimes in a shell galaxy",
      "The interacting pair of galaxies Arp 82: Integral field spectroscopy and numerical simulations",
      "The Next Generation Virgo Cluster Survey. XXXIII. Stellar Population Gradients in the Virgo Cluster Core Globular Cluster System",
      "When and how did early-type galaxies outside of galaxy clusters lose their rotational support?",
      "Constraints on galaxy formation from the cosmic-far-infrared-background\u00a0\u2212\u00a0optical-imaging cross-correlation using Herschel and UNIONS",
      "Characterization of low surface brightness structures in annotated deep images",
      "Origin of the differences in rotational support among early-type galaxies: The case of galaxies outside clusters",
      "Origin of the spectacular tidal shells of galaxy NGC474",
      "HI observations of the MATLAS dwarf and ultra-diffuse galaxies",
      "Structure and morphology of the MATLAS dwarf galaxies and their central nuclei",
      "Ram Pressure Candidates in UNIONS"
    ],
    "pub_abstracts": [
      "We combine James Webb Space Telescope (JWST) and Hubble Space Telescope imaging with Atacama Large Millimeter Array CO(2\u20131) spectroscopy to study the highly turbulent multiphase intergalactic medium (IGM) in Stephan\u2019s Quintet on 25\u2013150 pc scales. Previous Spitzer observations revealed luminous H2 line cooling across a 45 kpc-long filament, created by a giant shock wave, following the collision with an intruder galaxy, NGC 7318b. We demonstrate that the Mid-Infrared Instrument/F1000W/F770W filters are dominated by 0\u20130 S(3) H2 and a combination of polycyclic aromatic hydrocarbon and 0\u20130 S(5) H2 emission. These observations reveal the dissipation of kinetic energy as massive clouds experience collisions, interactions, and likely destruction/recycling within different phases of the IGM. In 1 kpc-scaled structure, warm H2 was seen to form a triangular-shaped head and tail of compressed and stripped gas behind a narrow shell of cold H2. In another region, two cold molecular clumps with very different velocities are connected by an arrow-shaped stream of warm, probably shocked, H2 suggesting a cloud\u2013cloud collision is occurring. In both regions, a high warm-to-cold molecular gas fraction indicates that the cold clouds are being disrupted and converted into warm gas. We also map gas associated with an apparently forming dwarf galaxy. We suggest that the primary mechanism for exciting strong mid-IR H2 lines throughout Stephan\u2019s Quintet is through a fog of warm gas created by the shattering of denser cold molecular clouds and mixing/recycling in the post-shocked gas. A full picture of the diverse kinematics and excitation of the warm H2 will require future JWST mid-IR spectroscopy. The current observations reveal the rich variety of ways that different gas phases can interact with one another.",
      "Tidal dwarf galaxies (TDGs) are low-mass objects that form within tidal and/or collisional debris ejected from more massive interacting galaxies. We use CO($1-0$) observations from ALMA and integral-field spectroscopy from MUSE to study molecular and ionized gas in three TDGs: two around the collisional galaxy NGC 5291 and one in the late-stage merger NGC 7252. The CO and H$\\alpha$ emission is more compact than the HI emission and displaced from the HI dynamical center, so these gas phases cannot be used to study the internal dynamics of TDGs. We use CO, HI, and H$\\alpha$ data to measure the surface densities of molecular gas ($\\Sigma_{\\rm mol}$), atomic gas ($\\Sigma_{\\rm atom}$) and star-formation rate ($\\Sigma_{\\rm SFR}$), respectively. We confirm that TDGs follow the same spatially integrated $\\Sigma_{\\rm SFR}-\\Sigma_{\\rm gas}$ relation of regular galaxies, where $\\Sigma_{\\rm gas} = \\Sigma_{\\rm mol} + \\Sigma_{\\rm atom}$, even though they are HI dominated. We find a more complex behaviour in terms of the spatially resolved $\\Sigma_{\\rm SFR}-\\Sigma_{\\rm mol}$ relation on sub-kpc scales. The majority ($\\sim$60$\\%$) of SF regions in TDGs lie on the same $\\Sigma_{\\rm SFR}-\\Sigma_{\\rm mol}$ relation of normal spiral galaxies but show a higher dispersion around the mean. The remaining fraction of SF regions ($\\sim$40$\\%$) lie in the starburst region and are associated with the formation of massive super star clusters, as shown by Hubble Space Telescope images. We conclude that the local SF activity in TDGs proceeds in a hybrid fashion, with some regions comparable to normal spiral galaxies and others to extreme starbursts.",
      "Dwarf galaxies have been extensively studied in the Local Group, in nearby groups, and selected clusters, giving us a robust picture of their global stellar and dynamical properties in particular locations in the Universe. Intense study of these properties has revealed correlations between them, including the well known universal stellar mass-metallicity relation. However, since dwarfs play a role in a vast range of different environments, much can be learned about galaxy formation and evolution through extending the study of these objects to various locations. We present MUSE spectroscopy of a sample of 56 dwarf galaxies as a follow-up to the MATLAS survey in low-to-moderate density environments beyond the Local Volume. The dwarfs have stellar masses in the range of $M_{*}/M_{\\odot}$ = 10$^{6.1}$-10$^{9.4}$ and show a distance range of D = 14-148 Mpc, the majority (75%) of which are located in the range targeted by the MATLAS survey (10-45 Mpc). We thus report a 75% (79% for dwarf ellipticals) success rate for the semi-automatic identification of dwarf galaxies in the MATLAS survey on the here presented subsample. Using pPXF full spectrum fitting, we determine their line-of-sight velocity and can match the majority of them with their massive host galaxy. Close inspection of their spectra reveals that ~30% show clear emission lines and thus star formation activity. We estimate their stellar population properties (age and metallicity) and compare our results with other works investigating Local Volume and cluster dwarf galaxies. We find that the dwarf galaxies presented in this work show a systematic offset from the stellar mass-metallicity relation towards lower metallicities at the same stellar mass. A similar deviation is present in other works in the stellar mass range probed in this work and might be attributed to the use of different methodologies for deriving the metallicity.",
      "  We study a compact nucleus embedded in an early-type dwarf galaxy, MATLAS-167, which is in the process of disruption by the tidal force of the neighboring giant S0 galaxy, NGC\u00a0936, in a group environment. Using the imaging data of the MATLAS survey, we analyze the stellar tidal tail of MATLAS-167 and its central compact nucleus, designated as NGC\u00a0936_UCD. We find that NGC\u00a0936_UCD has a luminosity of Mg = \u221211.43 \u00b10.01 mag and a size of 66.5\u00b117\u00a0pc, sharing the global properties of Ultra Compact Dwarf galaxies (UCDs) but significantly larger and brighter compared to the typical UCD populations observed in the Virgo cluster. By integrating the total luminosity of both the tidal stream and MATLAS-167, we estimate that the disrupted dwarf progenitor possesses a luminosity of Mg = \u221215.92 \u00b10.06 mag, a typical bright dE luminosity. With the help of the optical spectrum observed by the SDSS survey, we derive the simple stellar population properties of NGC\u00a0936_UCD: a light-weighted age of 5.6\u00b10.7\u00a0Gyr and metallicity of [Z/H] = \u22120.83 \u00b10.3 dex. Our findings suggest that tidal threshing is a possible formation mechanism of bright UCD populations in close proximity to giant galaxies.",
      "  NGC 5291, an early-type galaxy surrounded by a giant H\u00a0i ring, is believed to be formed from collision with another galaxy. Several star forming complexes and tidal dwarf galaxies are distributed along the collisional ring which are sites of star formation in environments where extreme dynamical effects are involved. Dynamical effects can affect the star formation properties and the spatial distribution of star forming complexes along the tidal features. To study and quantify the star formation activity in the main body and in the ring structure of the NGC 5291 system, we use high spatial resolution FUV and NUV imaging observations from the Ultraviolet Imaging Telescope onboard AstroSat. A total of 57 star-forming knots are identified to be part of this interacting system out of which 12 are new detections (star forming complexes that lie inside the H\u00a0i contour) compared to the previous measurements from lower resolution UV imaging. We estimate the attenuation in UV for each of the resolved star-forming knots using the UV spectral slope \u03b2, derived from the FUV \u2212 NUV colour. Using the extinction corrected UV fluxes, we derive the star formation rate of the resolved star forming complexes. The extinction corrected total star formation rate of this system is estimated as 1.75 \u00b1 0.04\u00a0M\u2299\u2009yr\u22121. The comparison with dwarf galaxy populations (BCD, Sm and dIm galaxies) in the nearby Universe shows that many of the knots in the NGC 5291 system have SFR values comparable to the SFR of BCD galaxies.",
      "We carried out deep mapping observations of the atomic hydrogen (H i) 21 cm line emission in a field centered on the famous galaxy group Stephan's Quintet (SQ), using the Five-hundred-meter Aperture Spherical Telescope (FAST) equipped with a 19-beam receiver. The final data cube reaches an H i column density sensitivity of 5\u03c3 = 2.1 \u00d7 1017 cm\u22122 per 20 km s\u22121 channel with an angular resolution of 4.\u20320. The discovery of a large diffuse feature of the H i emission in the outskirts of the intragroup medium of SQ was reported in a previous paper (Xu et al.). Here we present a new study of the total H i emission of SQ and the detection of several neighboring galaxies, exploiting the high sensitivity and the large sky coverage of the FAST observations. A total H i mass of M H I = 3.48 \u00b1 0.35 \u00d7 1010 M \u2609 is found for SQ, which is significantly higher than previous measurements in the literature. This indicates that, contrary to earlier claims, SQ is not H i deficient. The excessive H i gas is mainly found in the velocity ranges of 6200\u20136400 km s\u22121 and 6800\u20137000 km s\u22121, which were undetected in previous observations that are less sensitive than ours. Our results suggest that the \u201cmissing H i\u201d in compact groups may be hidden in the low-density diffuse neutral gas instead of in the ionized gas.",
      "This report is the result of a joint discussion between the Rubin and Euclid scientific communities. The work presented in this report was focused on designing and recommending an initial set of Derived Data products (DDPs) that could realize the science goals enabled by joint processing. All interested Rubin and Euclid data rights holders were invited to contribute via an online discussion forum and a series of virtual meetings. Strong interest in enhancing science with joint DDPs emerged from across a wide range of astrophysical domains: Solar System, the Galaxy, the Local Volume, from the nearby to the primaeval Universe, and cosmology.",
      "  Tidal features in the outskirts of galaxies yield unique information about their past interactions and are a key prediction of the hierarchical structure formation paradigm. The Vera C. Rubin Observatory is poised to deliver deep observations for potentially of millions of objects with visible tidal features, but the inference of galaxy interaction histories from such features is not straightforward. Utilising automated techniques and human visual classification in conjunction with realistic mock images produced using the NewHorizon cosmological simulation, we investigate the nature, frequency and visibility of tidal features and debris across a range of environments and stellar masses. In our simulated sample, around 80 per cent of the flux in the tidal features around Milky Way or greater mass galaxies is detected at the 10-year depth of the Legacy Survey of Space and Time (30 \u2212 31 mag arcsec\u22122), falling to 60 per cent assuming a shallower final depth of 29.5 mag arcsec\u22122. The fraction of total flux found in tidal features increases towards higher masses, rising to 10 per cent for the most massive objects in our sample (M\u22c6 \u223c 1011.5\u00a0M\u2299). When observed at sufficient depth, such objects frequently exhibit many distinct tidal features with complex shapes. The interpretation and characterisation of such features varies significantly with image depth and object orientation, introducing significant biases in their classification. Assuming the data reduction pipeline is properly optimised, we expect the Rubin Observatory to be capable of recovering much of the flux found in the outskirts of Milky Way mass galaxies, even at intermediate redshifts (z < 0.2).",
      "  Shell galaxies make a class of tidally distorted galaxies, characterised by wide concentric arc(s), extending out to large galactocentric distances with sharp outer edges. Recent observations of young massive star clusters in the prominent outer shell of NGC 474 suggest that such systems host extreme conditions of star formation. In this paper, we present a hydrodynamic simulation of a galaxy merger and its transformation into a shell galaxy. We analyse how the star formation activity evolves with time, location-wise within the system, and what are the physical conditions for star formation. During the interaction, an excess of dense gas appears, triggering a starburst, i.e. an enhanced star formation rate and a reduced depletion time. Star formation coincides with regions of high molecular gas fraction, such as the galactic nucleus, spiral arms, and occasionally the tidal debris during the early stages of the merger. Tidal interactions scatter stars into a stellar spheroid, while the gas cools down and reforms a disc. The morphological transformation after coalescence stabilises the gas and thus quenches star formation, without the need for feedback from an active galactic nucleus. This evolution shows similarities with a compaction scenario for compact quenched spheroids at high-redshift, yet without a long red nugget phase. Shells appear after coalescence, during the quenched phase, implying that they do not host the conditions necessary for in\u00a0situ star formation. The results suggest that shell-forming mergers might be part of the process of turning blue late-type galaxies into red and dead early-types.",
      "  Spectral data cubes of the interacting pair of galaxies NGC 2535 and NGC 2536 (the Arp 82 system) targeting bright emission lines in the visible band, obtained with the imaging Fourier transform spectrometer (iFTS) SITELLE attached to the Canada-France-Hawaii Telescope (CFHT), are presented. Analysis of H\u03b1 velocity maps reveals a bar in $\\rm NGC\\, 2536$. In $\\rm NGC\\, 2535$, we find strong non-circular motions outside the ocular ring, in the elliptical arc and tidal tails of $\\rm NGC\\, 2535$ and a misalignment between the kinematic and photometric position angles. We detect 155 HII region complexes in the interacting pair of galaxies and determine oxygen abundances for 66 of them using different calibrators. We find, regardless of the indicator used, that the oxygen abundance distribution in $\\rm NGC\\, 2536$ is shallow whereas, in $\\rm NGC\\, 2535$, it is best fitted by two slopes, the break occurring beyond the ocular ring. The inner slope is comparable to the one observed in isolated normal star-forming galaxies but the outer slope is shallow. We present a numerical simulation of the interaction that reproduces the observed tidal features, kinematics, and metallicity distribution, to investigate the effect of the interaction on the galaxies. The model indicates that the galaxies have undergone a close encounter, strongly prograde for the primary, and are half way in their course to a second close encounter.",
      "We present a study of the stellar populations of globular clusters (GCs) in the Virgo Cluster core with a homogeneous spectroscopic catalog of 692 GCs within a major-axis distance R maj = 840 kpc from M87. We investigate radial and azimuthal variations in the mean age, total metallicity, [Fe/H], and \u03b1-element abundance of blue (metal-poor) and red (metal-rich) GCs using their co-added spectra. We find that the blue GCs have a steep radial gradient in [Z/H] within R maj = 165 kpc, with roughly equal contributions from [Fe/H] and [\u03b1/Fe], and flat gradients beyond. By contrast, the red GCs show a much shallower gradient in [Z/H], which is entirely driven by [Fe/H]. We use GC-tagged Illustris simulations to demonstrate an accretion scenario where more massive satellites (with more metal- and \u03b1-rich GCs) sink further into the central galaxy than less massive ones, and where the gradient flattening occurs because of the low GC occupation fraction of low-mass dwarfs disrupted at larger distances. The dense environment around M87 may also cause the steep [\u03b1/Fe] gradient of the blue GCs, mirroring what is seen in the dwarf galaxy population. The progenitors of red GCs have a narrower mass range than those of blue GCs, which makes their gradients shallower. We also explore spatial inhomogeneity in GC abundances, finding that the red GCs to the northwest of M87 are slightly more metal-rich. Future observations of GC stellar population gradients will be useful diagnostics of halo merger histories.",
      "Context. Early-type galaxies (ETGs) are divided into slow and fast rotators (FRs and SRs) according to the degree of ordered rotation of their stellar populations. Cosmological hydrodynamical simulations indicate that galaxies are formed as FRs before their rotational support decreases, usually because of mergers. Aims. We aimed to investigate this process observationally for galaxies outside of clusters. Methods. We made use of the fact that di \ufb00 erent merger types leave di \ufb00 erent traces that have di \ufb00 erent lifetimes. We statistically analyzed multiple characteristics of galaxies that are expected to be in\ufb02uenced by mergers: tidal features, kinematically distinct cores, stellar age, etc. They were taken from the MATLAS and ATLAS 3D databases. We identi\ufb01ed through multilinear regression the quantities that, at a \ufb01xed mass and environmental density of the galaxy, signi\ufb01cantly correlate with a measure of the ordered rotation of the galaxy, \u03bb N R e . Results. We found a negative correlation of the rotational support with the occurrence of tidal disturbances and kinematic substructures and a positive correlation with metallicity and metallicity gradients. For massive galaxies, the rotational support correlates negatively with the abundance of alpha elements, and for the galaxies in low-density environments, it correlates negatively with the central photometric cuspiness. These and additional literature observational constraints are explained the easiest if the mergers that decreased the rotational support of ETGs were typically minor, wet and happening at z \u2248 2. They did not form the currently observed tidal features. The observed frequency of tidal features implies a merging rate of 0.07-0.2 per Gyr. This is insu \ufb03 cient for explaining the observed growth of radii of ETGs with redshift by",
      "  Using Herschel-SPIRE imaging and the Canada-France Imaging Survey (CFIS) Low Surface Brightness data products from the Ultraviolet Near-Infrared Optical Northern Survey (UNIONS), we present a cross-correlation between the cosmic far-infrared background and cosmic optical background fluctuations. The cross-spectrum is measured for two cases: all galaxies are kept in the images; or all individually-detected galaxies are masked to produce \u2018background\u2019 maps. We report the detection of the cross-correlation signal at \u2273 18\u2009\u03c3 (\u2273 14\u2009\u03c3 for the background map). The part of the optical brightness variations that are correlated with the submm emission translates to an rms brightness of \u2243 32.5\u2009mag\u2009arcsec\u22122 in the r band, a level normally unreachable for individual sources. A critical issue is determining what fraction of the cross-power spectrum might be caused by emission from Galactic cirrus. For one of the fields, the Galactic contamination is 10\u00a0times higher than the extragalactic signal; however, for the other fields, the contamination is around 20\u00a0per cent. An additional discriminant is that the cross-power spectrum is of the approximate form P(k)\u221d1/k, much shallower than that of Galactic cirrus. We interpret the results in a halo-model framework, which shows good agreement with independent measurements for the scalings of star-formation rates in galaxies. The approach presented in this study holds great promise for future surveys such as FYST/CCAT-prime combined with Euclid or the Vera Rubin Observatory (LSST), which will enable a detailed exploration of the evolution of star formation in galaxies.",
      "The characterization of Low Surface Brightness (LSB) stellar structures around galaxies such as tidal debris of on-going or past collisions is essential to constrain models of galactic evolution. Our goal is to obtain quantitative measurements of LSB structures identified in deep images of samples consisting of hundreds of galaxies. We developed an online annotation tool that enables contributors to delineate the shapes of diffuse extended stellar structures, as well as artefacts or foreground structures. All parameters are automatically stored in a database which may be queried to retrieve quantitative measurements. We annotated LSB structures around 352 nearby massive galaxies with deep images obtained with the CFHT as part of two large programs: MATLAS and UNIONS/CFIS. Each LSB structure was delineated and labeled according to its likely nature: stellar shells, streams associated to a disrupted satellite, tails formed in major mergers, ghost reflections or cirrus. From our database containing 8441 annotations, the area, size, median surface brightness and distance to the host of 228 structures were computed. The results confirm the fact that tidal structures defined as streams are thinner than tails, as expected by numerical simulations. In addition, tidal tails appear to exhibit a higher surface brightness than streams (by about 1 mag), which may be related to different survival times for the two types of collisional debris. We did not detect any tidal feature fainter than 27.5 mag.arcsec$^{-2}$, while the nominal surface brightness limits of our surveys range between 28.3 and 29 mag.arcsec$^{-2}$, a difference that needs to be taken into account when estimating the sensitivity of future surveys to identify LSB structures. Our annotation database of observed LSB structures may be used for quantitative analysis and as a training set for machine learning algorithms (abbreviated).",
      "Context: Early-type galaxies (ETGs) are divided into slow and fast rotators (FRs and SRs) according to the degree of ordered rotation of their stellar populations. Cosmological hydrodynamical simulations indicate that galaxies form as FRs before their rotational support decreases, usually because of mergers. Aims: We aimed to investigate this process observationally for galaxies outside of clusters. Methods: We made use of the fact that different merger types leave different traces that have different lifetimes. We statistically analyzed multiple characteristics of galaxies that are expected to be influenced by mergers, such as tidal features, kinematically distinct cores, and stellar ages. They were taken from the MATLAS and ATLAS$^\\mathrm{3D}$ databases. Through multilinear regression we identified the quantities that, at a fixed mass and environmental density of the galaxy, significantly correlate with a measure of the ordered rotation of the galaxy, $\\lambda_{R_e}^N$. Results: We found a negative correlation of the rotational support with the occurrence of tidal disturbances and kinematic substructures, and a positive correlation with metallicity and metallicity gradients. For massive galaxies, the rotational support correlates negatively with the abundance of alpha elements, and for the galaxies in low-density environments, it correlates negatively with the central photometric cuspiness. These and additional literature observational constraints are explained the easiest if the mergers that decreased the rotational support of ETGs were typically minor, wet, and happening at $z\\approx 2$. They did not form the currently observed tidal features. The observed frequency of tidal features implies a merging rate of 0.07-0.2 per Gyr. This is insufficient to explain the observed growth of the radii of ETGs with redshift by mergers.",
      "Context. The lenticular galaxy NGC474 hosts a rich system of tidal shells and streams, some of which are exceptionally bright. Two teams recently presented spectroscopic observations of the brightest shells. These were the \ufb01rst shell spectra ever observed in integrated starlight. The authors studied the stellar populations of the shell, of the center of the galaxy, and of its globular clusters. The precise formation scenario for the tidal features of this prominent galaxy still remained unclear, however. Aims. Here, we add further clues on their formation from the radii of the shells, and we present a scenario for the formation of the tidal features that seems to be unique and can explain all available data. Methods. Shell radii were analyzed with the shell identi\ufb01cation method, and we ran self-consistent simulations of the formation of the tidal features. We considered Newtonian as well as MOND gravity. Results. Observations suggest that the tidal features originate from the accretion of a spiral galaxy. According to the shell identi\ufb01cation method, the merging galaxies \ufb01rst collided 1.3Gyr ago and then again 0.9Gyr ago, thereby forming the shells in two generations. This would also explain the young ages of stellar populations in the center of the galaxy and the young age of the globular clusters. The analytic models of shell propagation that underlie the shell identi\ufb01cation method are veri\ufb01ed by a simulation. The simulations reproduce the observed morphology of the tidal features well. The accreted spiral likely reached NGC474 on the plane of the sky nearly radially from the south, its rotation axis pointing toward us. It probably had a stellar mass of about one-sixth of NGC474, that is, 10 9 . 8 M (cid:12) . Apparently, all tidal features in the galaxy originate from one merger.",
      "The presence of HI gas in galaxies is inextricably linked to their morphology and evolution. This paper aims to understand the HI content of the already identi\ufb01ed 2210 dwarfs located in the low-to-moderate density environments of the Mass Assembly of early-Type GaLAxies with their \ufb01ne Structures (MATLAS) deep imaging survey. We combined the HI observations from the ATLAS 3D survey, with the extragalactic HI sources from the Arecibo Legacy Fast ALFA survey, to extract the HI line width, velocity, and mass of the MATLAS dwarfs. From the 1773 dwarfs in our sample with available HI observations, 8% (145) have an HI line detection. The majority of the dwarfs show an irregular morphology, while 29% (42) are ellipticals, which is the largest sample of HI-bearing dwarf ellipticals (dEs) to date. Of the HI dwarf sample, 2% (three) are ultra-di \ufb00 use galaxies (UDGs), 12% have a transition-type morphology, 5% are tidal dwarf candidates, and 10% appear to be disrupted objects. In our optically selected sample, 9.5% of the dEs, 7% of the UDGs, and 10% of the classical dwarfs are HI-bearing. The HI-bearing dwarfs have, on average, bluer colors than the dwarfs without detected HI. We \ufb01nd relations between the stellar and HI masses, gas fraction, color, and absolute magnitude to be consistent with previous studies of dwarfs probing similar masses and environments. For 79% of the dwarfs identi\ufb01ed as satellites of massive early-type galaxies, we \ufb01nd that the HI mass increases with the projected distance to the host. Using the HI line width, we estimate dynamical masses and \ufb01nd that 5% (seven) of the dwarfs are dark matter de\ufb01cient.",
      "  We present a photometric study of the dwarf galaxy population in the low to moderate density environments of the MATLAS (Mass Assembly of early-Type gaLAxies with their fine Structures) deep imaging survey. The sample consists of 2210 dwarfs, including 508 nucleated. We define a nucleus as a compact source that is close to the galaxy photocentre (within 0.5 $R_\\mathrm{ e}$) which is also the brightest such source within the galaxy\u2019s effective radius. The morphological analysis is performed using a 2D surface brightness profile modelling on the g-band images of both the galaxies and nuclei. Our study reveals that, for similar luminosities, the MATLAS dwarfs show ranges in the distribution of structural properties comparable to cluster (Virgo and Fornax) dwarfs and a range of sizes comparable to the Local Group and Local Volume dwarfs. Colour measurements using the r- and i-band images indicate that the dwarfs in low and moderate density environments are as red as cluster dwarfs on average. The observed similarities between dwarf ellipticals in vastly different environments imply that dEs are not uniquely the product of morphological transformation due to ram-pressure stripping and galaxy harassment in high density environments. We measure that the dwarf nuclei are located predominantly in massive, bright and round dwarfs and observe fewer nuclei in dwarfs with a faint centre and a small size. The colour of the galaxy nucleus shows no clear relation to the colour of the dwarf, in agreement with the migration and wet migration nucleus formation scenarios. The catalogues of the MATLAS dwarfs photometric and structural properties are provided.",
      "We present a search for disturbed, candidate ram pressure stripping galaxies across more than 50 spectroscopically selected SDSS groups and clusters. Forty-eight ram pressure candidates are visually identified in these systems using high quality UNIONS imaging from the Canada-France Hawaii Telescope, covering \u223c6200 deg2 and \u223c2800 deg2 in the uand r-bands respectively. Ram pressure candidates are found in groups and clusters spanning a wide range in halo mass and include \u223c30 ram pressure candidates in the group regime (Mh < 1014). The observed frequency of ram pressure candidates shows substantial scatter with group/cluster mass, but on average is larger in clusters (Mh \u2265 1014M ) than groups (Mh < 1014M ) by a factor of \u223c2. We find that ram pressure candidates are most commonly low-mass galaxies and have enhanced star formation rates relative to star-forming field galaxies. The enhancement in star formation is largely independent of galaxy mass and strongest for galaxies in clusters. As a result of the large survey footprint and excellent image quality from UNIONS, we are able to identify disturbed galaxies, potentially affected by ram pressure stripping, across a wide range of host environment."
    ],
    "domain": [
      "Astrophysics",
      "Galaxy Formation",
      "Intergalactic Medium",
      "Dwarf Galaxies"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "601d7dd2-5e26-460f-a329-a9fd23ea1d42": {
    "pk": "601d7dd2-5e26-460f-a329-a9fd23ea1d42",
    "name": "Albert Gu",
    "bio": "I am a researcher deeply engaged in the intersection of large-scale sequence modeling and biological applications, particularly in genomics. My recent work has led to the development of innovative architectures like Caduceus, which addresses the unique challenges of modeling genomic sequences, such as long-range interactions and reverse complementarity. Caduceus stands out as the first family of RC equivariant bi-directional long-range DNA language models, achieving remarkable performance on downstream tasks, even surpassing much larger models.\n\nIn addition to my work in genomics, I have explored the potential of state-space models (SSMs) as alternatives to traditional Transformer architectures. My research has revealed the close relationship between SSMs and Transformers, leading to the creation of Mamba-2, a refined architecture that is both faster and competitive in language modeling tasks. Through extensive comparisons, I have demonstrated that while SSMs excel in many areas, hybrid models combining SSMs and attention mechanisms can outperform Transformers, particularly in long-context reasoning tasks.\n\nI am passionate about advancing our understanding of sequence models through a unifying matrix mixer framework, which has allowed me to develop new sub-quadratic sequence models like Hydra. This model not only enhances performance on non-causal tasks but also serves as a drop-in replacement for attention layers, showcasing the potential of structured matrix approaches in sequence modeling. My work aims to push the boundaries of what is possible in both natural language processing and biological sequence analysis, contributing to the broader field of machine learning.",
    "collaborators": [
      "Tri Dao",
      "Yair Schiff",
      "Chia-Hsiang Kao",
      "Aaron Gokaslan",
      "Volodymyr Kuleshov",
      "Aviv Bick",
      "Kevin Y. Li",
      "Eric P. Xing",
      "J. Z. Kolter",
      "R. Waleffe",
      "Wonmin Byeon",
      "Duncan Riach",
      "Brandon Norick",
      "V. Korthikanti",
      "Ali Hatamizadeh",
      "Sudhakar Singh",
      "Deepak Narayanan",
      "Garvit Kulshreshtha",
      "Vartika Singh",
      "Jared Casper",
      "Jan Kautz",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Sukjun Hwang",
      "Aakash Lahoti"
    ],
    "pub_titles": [
      "Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling",
      "Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models",
      "Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality",
      "An Empirical Study of Mamba-based Language Models",
      "Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers"
    ],
    "pub_abstracts": [
      "Large-scale sequence modeling has sparked rapid advances that now extend into biology and genomics. However, modeling genomic sequences introduces challenges such as the need to model long-range token interactions, the effects of upstream and downstream regions of the genome, and the reverse complementarity (RC) of DNA. Here, we propose an architecture motivated by these challenges that builds off the long-range Mamba block, and extends it to a BiMamba component that supports bi-directionality, and to a MambaDNA block that additionally supports RC equivariance. We use MambaDNA as the basis of Caduceus, the first family of RC equivariant bi-directional long-range DNA language models, and we introduce pre-training and fine-tuning strategies that yield Caduceus DNA foundation models. Caduceus outperforms previous long-range models on downstream benchmarks; on a challenging long-range variant effect prediction task, Caduceus exceeds the performance of 10x larger models that do not leverage bi-directionality or equivariance.",
      "Transformer architectures have become a dominant paradigm for domains like language modeling but suffer in many inference settings due to their quadratic-time self-attention. Recently proposed subquadratic architectures, such as Mamba, have shown promise, but have been pretrained with substantially less computational resources than the strongest Transformer models. In this work, we present a method that is able to distill a pretrained Transformer architecture into alternative architectures such as state space models (SSMs). The key idea to our approach is that we can view both Transformers and SSMs as applying different forms of mixing matrices over the token sequences. We can thus progressively distill the Transformer architecture by matching different degrees of granularity in the SSM: first matching the mixing matrices themselves, then the hidden units at each block, and finally the end-to-end predictions. Our method, called MOHAWK, is able to distill a Mamba-2 variant based on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid version (Hybrid Phi-Mamba) using 5B tokens. Despite using less than 1% of the training data typically used to train models from scratch, Phi-Mamba boasts substantially stronger performance compared to all past open-source non-Transformer models. MOHAWK allows models like SSMs to leverage computational resources invested in training Transformer-based architectures, highlighting a new avenue for building such models.",
      "While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.",
      "Selective state-space models (SSMs) like Mamba overcome some of the shortcomings of Transformers, such as quadratic computational complexity with sequence length and large inference-time memory requirements from the key-value cache. Moreover, recent studies have shown that SSMs can match or exceed the language modeling capabilities of Transformers, making them an attractive alternative. In a controlled setting (e.g., same data), however, studies so far have only presented small scale experiments comparing SSMs to Transformers. To understand the strengths and weaknesses of these architectures at larger scales, we present a direct comparison between 8B-parameter Mamba, Mamba-2, and Transformer models trained on the same datasets of up to 3.5T tokens. We also compare these models to a hybrid architecture consisting of 43% Mamba-2, 7% attention, and 50% MLP layers (Mamba-2-Hybrid). Using a diverse set of tasks, we answer the question of whether Mamba models can match Transformers at larger training budgets. Our results show that while pure SSMs match or exceed Transformers on many tasks, they lag behind Transformers on tasks which require strong copying or in-context learning abilities (e.g., 5-shot MMLU, Phonebook) or long-context reasoning. In contrast, we find that the 8B Mamba-2-Hybrid exceeds the 8B Transformer on all 12 standard tasks we evaluated (+2.65 points on average) and is predicted to be up to 8x faster when generating tokens at inference time. To validate long-context capabilities, we provide additional experiments evaluating variants of the Mamba-2-Hybrid and Transformer extended to support 16K, 32K, and 128K sequences. On an additional 23 long-context tasks, the hybrid model continues to closely match or exceed the Transformer on average. To enable further study, we release the checkpoints as well as the code used to train our models as part of NVIDIA's Megatron-LM project.",
      "A wide array of sequence models are built on a framework modeled after Transformers, comprising alternating sequence mixer and channel mixer layers. This paper studies a unifying matrix mixer view of sequence mixers that can be conceptualized as a linear map on the input sequence. This framework encompasses a broad range of well-known sequence models, including the self-attention of Transformers as well as recent strong alternatives such as structured state space models (SSMs), and allows understanding downstream characteristics such as efficiency and expressivity through properties of their structured matrix class. We identify a key axis of matrix parameterizations termed sequence alignment, which increases the flexibility and performance of matrix mixers, providing insights into the strong performance of Transformers and recent SSMs such as Mamba. Furthermore, the matrix mixer framework offers a systematic approach to developing sequence mixers with desired properties, allowing us to develop several new sub-quadratic sequence models. In particular, we propose a natural bidirectional extension of the Mamba model (Hydra), parameterized as a quasiseparable matrix mixer, which demonstrates superior performance over other sequence models including Transformers on non-causal tasks. As a drop-in replacement for attention layers, Hydra outperforms BERT by 0.8 points on the GLUE benchmark and ViT by 2% Top-1 accuracy on ImageNet."
    ],
    "domain": [
      "Machine Learning",
      "Sequence Modeling",
      "State-Space Models",
      "Genomics"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "9dfb4734-a216-4c45-bd80-5596c8e0eb97": {
    "pk": "9dfb4734-a216-4c45-bd80-5596c8e0eb97",
    "name": "Tri Dao",
    "bio": "I am a researcher deeply engaged in the intersection of deep learning and genomics, with a particular focus on sequence modeling. My recent work has led to the development of Caduceus, a pioneering family of DNA language models that leverage bi-directionality and reverse complementarity (RC) to enhance long-range genomic sequence predictions. This innovative architecture not only outperforms larger models but also sets a new standard for DNA language modeling.\n\nI have also explored the theoretical underpinnings of state-space models (SSMs) and their relationship to Transformers, culminating in the creation of the Mamba-2 architecture. This model is designed to be significantly faster while maintaining competitive performance in language tasks. My research emphasizes the practical implications of these models, demonstrating their strengths and weaknesses across various scales and tasks, particularly in long-context reasoning.\n\nAdditionally, I have contributed to a unifying framework for sequence models, which has allowed me to develop new architectures like Hydra, a bidirectional extension of Mamba that excels in non-causal tasks. My work aims to push the boundaries of what is possible in sequence modeling, providing insights that not only advance theoretical understanding but also yield practical tools for real-world applications. I am committed to sharing my findings with the community, releasing model checkpoints and code to facilitate further research and innovation in this exciting field.",
    "collaborators": [
      "Albert Gu",
      "Yair Schiff",
      "Chia-Hsiang Kao",
      "Aaron Gokaslan",
      "Volodymyr Kuleshov",
      "R. Waleffe",
      "Wonmin Byeon",
      "Duncan Riach",
      "Brandon Norick",
      "V. Korthikanti",
      "Ali Hatamizadeh",
      "Sudhakar Singh",
      "Deepak Narayanan",
      "Garvit Kulshreshtha",
      "Vartika Singh",
      "Jared Casper",
      "Jan Kautz",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Sukjun Hwang",
      "Aakash Lahoti"
    ],
    "pub_titles": [
      "Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling",
      "Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality",
      "An Empirical Study of Mamba-based Language Models",
      "Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers"
    ],
    "pub_abstracts": [
      "Large-scale sequence modeling has sparked rapid advances that now extend into biology and genomics. However, modeling genomic sequences introduces challenges such as the need to model long-range token interactions, the effects of upstream and downstream regions of the genome, and the reverse complementarity (RC) of DNA. Here, we propose an architecture motivated by these challenges that builds off the long-range Mamba block, and extends it to a BiMamba component that supports bi-directionality, and to a MambaDNA block that additionally supports RC equivariance. We use MambaDNA as the basis of Caduceus, the first family of RC equivariant bi-directional long-range DNA language models, and we introduce pre-training and fine-tuning strategies that yield Caduceus DNA foundation models. Caduceus outperforms previous long-range models on downstream benchmarks; on a challenging long-range variant effect prediction task, Caduceus exceeds the performance of 10x larger models that do not leverage bi-directionality or equivariance.",
      "While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.",
      "Selective state-space models (SSMs) like Mamba overcome some of the shortcomings of Transformers, such as quadratic computational complexity with sequence length and large inference-time memory requirements from the key-value cache. Moreover, recent studies have shown that SSMs can match or exceed the language modeling capabilities of Transformers, making them an attractive alternative. In a controlled setting (e.g., same data), however, studies so far have only presented small scale experiments comparing SSMs to Transformers. To understand the strengths and weaknesses of these architectures at larger scales, we present a direct comparison between 8B-parameter Mamba, Mamba-2, and Transformer models trained on the same datasets of up to 3.5T tokens. We also compare these models to a hybrid architecture consisting of 43% Mamba-2, 7% attention, and 50% MLP layers (Mamba-2-Hybrid). Using a diverse set of tasks, we answer the question of whether Mamba models can match Transformers at larger training budgets. Our results show that while pure SSMs match or exceed Transformers on many tasks, they lag behind Transformers on tasks which require strong copying or in-context learning abilities (e.g., 5-shot MMLU, Phonebook) or long-context reasoning. In contrast, we find that the 8B Mamba-2-Hybrid exceeds the 8B Transformer on all 12 standard tasks we evaluated (+2.65 points on average) and is predicted to be up to 8x faster when generating tokens at inference time. To validate long-context capabilities, we provide additional experiments evaluating variants of the Mamba-2-Hybrid and Transformer extended to support 16K, 32K, and 128K sequences. On an additional 23 long-context tasks, the hybrid model continues to closely match or exceed the Transformer on average. To enable further study, we release the checkpoints as well as the code used to train our models as part of NVIDIA's Megatron-LM project.",
      "A wide array of sequence models are built on a framework modeled after Transformers, comprising alternating sequence mixer and channel mixer layers. This paper studies a unifying matrix mixer view of sequence mixers that can be conceptualized as a linear map on the input sequence. This framework encompasses a broad range of well-known sequence models, including the self-attention of Transformers as well as recent strong alternatives such as structured state space models (SSMs), and allows understanding downstream characteristics such as efficiency and expressivity through properties of their structured matrix class. We identify a key axis of matrix parameterizations termed sequence alignment, which increases the flexibility and performance of matrix mixers, providing insights into the strong performance of Transformers and recent SSMs such as Mamba. Furthermore, the matrix mixer framework offers a systematic approach to developing sequence mixers with desired properties, allowing us to develop several new sub-quadratic sequence models. In particular, we propose a natural bidirectional extension of the Mamba model (Hydra), parameterized as a quasiseparable matrix mixer, which demonstrates superior performance over other sequence models including Transformers on non-causal tasks. As a drop-in replacement for attention layers, Hydra outperforms BERT by 0.8 points on the GLUE benchmark and ViT by 2% Top-1 accuracy on ImageNet."
    ],
    "domain": [
      "Machine Learning",
      "Sequence Modeling",
      "State-Space Models",
      "Genomics"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "add5f70c-b273-449d-846c-2405a5788b3f": {
    "pk": "add5f70c-b273-449d-846c-2405a5788b3f",
    "name": "Ian J. Goodfellow",
    "bio": "I am a researcher deeply engaged in the field of machine learning, particularly focusing on neural networks and their optimization. My work has explored various aspects of training neural networks, including the challenges posed by local minima and the effectiveness of stochastic gradient descent in overcoming these obstacles. I have developed frameworks such as the generative adversarial network (GAN) model, which innovatively combines generative and discriminative processes to enhance data distribution learning.\n\nMy research also delves into the intricacies of adversarial examples, where I argue that the linear nature of neural networks contributes significantly to their vulnerability. I have investigated catastrophic forgetting in neural networks, revealing that dropout training consistently yields the best performance in adapting to new tasks while retaining knowledge of previous ones.\n\nAdditionally, I have contributed to the development of advanced models like the multi-prediction deep Boltzmann machine (MP-DBM) and the partially directed deep Boltzmann machine (PD-DBM), which improve classification tasks without the need for greedy layerwise pretraining. My work on dropout and maxout models has led to state-of-the-art results across various benchmark datasets, demonstrating the power of these techniques in enhancing neural network performance.\n\nThrough my research, I aim to bridge the gap between theoretical insights and practical applications, ultimately advancing the capabilities of machine learning systems in real-world scenarios.",
    "collaborators": [
      "Yoshua Bengio",
      "Aaron C. Courville",
      "Mehdi Mirza",
      "David Warde-Farley",
      "J. Bergstra",
      "Bing Xu",
      "Christian Szegedy",
      "Vincent Dumoulin",
      "Pascal Lamblin",
      "Razvan Pascanu",
      "Fr\u00e9d\u00e9ric Bastien",
      "D. Erhan",
      "O. Vinyals",
      "Jean Pouget-Abadie",
      "Sherjil Ozair",
      "Jonathon Shlens",
      "Xia Da",
      "Yaroslav Bulatov",
      "Julian Ibarz",
      "Sacha Arnoud",
      "Vinay D. Shet",
      "Wojciech Zaremba",
      "I. Sutskever",
      "Joan Bruna",
      "R. Fergus",
      "P. Carrier",
      "Benjamin Hamner",
      "William J. Cukierski",
      "Yichuan Tang",
      "David Thaler",
      "Dong-Hyun Lee",
      "Yingbo Zhou",
      "Chetan Ramaiah",
      "Fangxiang Feng",
      "Ruifan Li",
      "Xiaojie Wang",
      "Dimitris Athanasakis",
      "J. Shawe-Taylor",
      "Maxim Milakov",
      "John Park",
      "Radu Tudor Ionescu",
      "M. Popescu",
      "C. Grozea",
      "Jingjing Xie",
      "Lukasz Romaszko",
      "Chuang Zhang",
      "Olivier Breuleux",
      "Olivier Delalleau",
      "Guillaume Desjardins",
      "Arnaud Bergeron"
    ],
    "pub_titles": [
      "Qualitatively characterizing neural network optimization problems",
      "Generative Adversarial Nets",
      "On distinguishability criteria for estimating generative models",
      "Explaining and Harnessing Adversarial Examples",
      "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
      "On the Challenges of Physical Implementations of RBMs",
      "Pylearn2: a machine learning research library",
      "Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning",
      "Multi-Prediction Deep Boltzmann Machines",
      "Piecewise Linear Multilayer Perceptrons and Dropout",
      "An empirical analysis of dropout in piecewise linear networks",
      "Joint Training Deep Boltzmann Machines for Classification",
      "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks",
      "Maxout Networks",
      "Intriguing properties of neural networks",
      "Large-Scale Feature Learning With Spike-and-Slab Sparse Coding",
      "Theano: Deep Learning on GPUs with Python",
      "Joint Training of Partially-Directed Deep Boltzmann Machines"
    ],
    "pub_abstracts": [
      "Training neural networks involves solving large-scale non-convex optimization problems. This task has long been believed to be extremely difficult, with fear of local minima and other obstacles motivating a variety of schemes to improve optimization, such as unsupervised pretraining. However, modern neural networks are able to achieve negligible training error on complex tasks, using only direct training with stochastic gradient descent. We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima. We find that, in fact, on a straight path from initialization to solution, a variety of state of the art neural networks never encounter any significant obstacles.",
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
      "Two recently introduced criteria for estimation of generative models are both based on a reduction to binary classification. Noise-contrastive estimation (NCE) is an estimation procedure in which a generative model is trained to be able to distinguish data samples from noise samples. Generative adversarial networks (GANs) are pairs of generator and discriminator networks, with the generator network learning to generate samples by attempting to fool the discriminator network into believing its samples are real data. Both estimation procedures use the same function to drive learning, which naturally raises questions about how they are related to each other, as well as whether this function is related to maximum likelihood estimation (MLE). NCE corresponds to training an internal data model belonging to the {\\em discriminator} network but using a fixed generator network. We show that a variant of NCE, with a dynamic generator network, is equivalent to maximum likelihood estimation. Since pairing a learned discriminator with an appropriate dynamically selected generator recovers MLE, one might expect the reverse to hold for pairing a learned generator with a certain discriminator. However, we show that recovering MLE for a learned generator requires departing from the distinguishability game. Specifically:  (i) The expected gradient of the NCE discriminator can be made to match the expected gradient of  MLE, if one is allowed to use a non-stationary noise distribution for NCE,  (ii) No choice of discriminator network can make the expected gradient for the GAN generator match that of MLE, and  (iii) The existing theory does not guarantee that GANs will converge in the non-convex case.  This suggests that the key next step in GAN research is to determine whether GANs converge, and if not, to modify their training algorithm to force convergence.",
      "Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.",
      "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
      "    Restricted Boltzmann machines (RBMs) are powerful machine learning models, but learning and some kinds of inference in the model require sampling-based approximations, which, in classical digital computers, are implemented using expensive MCMC. Physical computation offers the opportunity to reduce the costof sampling by building physical systems whose natural dynamics correspond to drawing samples from the desired RBM distribution. Such a system avoids the burn-in and mixing cost of a Markov chain. However, hardware implementations of this variety usually entail limitations such as low-precision and limited range of the parameters and restrictions on the size and topology of the RBM. We conduct software simulations to determine how harmful each of these restrictions is. Our simulations are based on the D-Wave Two computer, but the issues we investigate arise in most forms of physical computation.Our findings suggest that designers of new physical computing hardware and algorithms for physical computers should focus their efforts on overcoming the limitations imposed by the topology restrictions of currently existing physical computers.   ",
      "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
      "We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.",
      "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
      "We propose a new type of hidden layer for a multilayer perceptron, and demonstrate that it obtains the best reported performance for an MLP on the MNIST dataset.",
      "The recently introduced dropout training criterion for neural networks has been the subject of much attention due to its simplicity and remarkable effectiveness as a regularizer, as well as its interpretation as a training procedure for an exponentially large ensemble of networks that share parameters. In this work we empirically investigate several questions related to the efficacy of dropout, specifically as it concerns networks employing the popular rectified linear activation function. We investigate the quality of the test time weight-scaling inference procedure by evaluating the geometric average exactly in small models, as well as compare the performance of the geometric mean to the arithmetic mean more commonly employed by ensemble techniques. We explore the effect of tied weights on the ensemble interpretation by training ensembles of masked networks without tied weights. Finally, we investigate an alternative criterion based on a biased estimator of the maximum likelihood ensemble gradient.",
      "We introduce a new method for training deep Boltzmann machines jointly. Prior methods of training DBMs require an initial learning pass that trains the model greedily, one layer at a time, or do not perform well on classification tasks. In our approach, we train all layers of the DBM simultaneously, using a novel training procedure called multi-prediction training. The resulting model can either be interpreted as a single generative model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent networks that share parameters and may be approximately averaged together using a novel technique we call the multi-inference trick. We show that our approach performs competitively for classification and outperforms previous methods in terms of accuracy of approximate inference and classification with missing inputs.",
      "Abstract: Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over $96\\%$ accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art, achieving $97.84\\%$ accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over $90\\%$ accuracy. To further explore the applicability of the proposed system to broader text recognition tasks, we apply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the most secure reverse turing tests that uses distorted text to distinguish humans from bots. We report a $99.8\\%$ accuracy on the hardest category of reCAPTCHA. Our evaluations on both tasks indicate that at specific operating thresholds, the performance of the proposed system is comparable to, and in some cases exceeds, that of human operators.",
      "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.",
      "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.  First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.  Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
      "We consider the problem of object recognition with a large number of classes. In order to overcome the low amount of labeled examples available in this setting, we introduce a new feature learning and extraction procedure based on a factor model we call spike-and-slab sparse coding (S3C). Prior work on S3C has not prioritized the ability to exploit parallel architectures and scale S3C to the enormous problem sizes needed for object recognition. We present a novel inference procedure for appropriate for use with GPUs which allows us to dramatically increase both the training set size and the amount of latent factors that S3C may be trained with. We demonstrate that this approach improves upon the supervised learning capabilities of both sparse coding and the spike-and-slab Restricted Boltzmann Machine (ssRBM) on the CIFAR-10 dataset. We use the CIFAR-100 dataset to demonstrate that our method scales to large numbers of classes better than previous methods. Finally, we use our method to win the NIPS 2011 Workshop on Challenges In Learning Hierarchical Models' Transfer Learning Challenge.",
      "In this paper, we present Theano 1 , a framework in the Python programming language for defining, optimizing and evaluating expressions involving high-level operations on tensors. Theano offers most of NumPy\u2019s functionality, but adds automatic symbolic differentiation, GPU support, and faster expression evaluation. Theano is a general mathematical tool, but it was developed with the goal of facilitating research in deep learning. The Deep Learning Tutorials 2 introduce recent advances in deep learning, and showcase how Theano",
      "We introduce a deep probabilistic model which we call the partially directed deep Boltzmann machine (PD-DBM). The PD-DBM is a model of real-valued data based on the deep Boltzmann machine (DBM) and the spike-and-slab sparse coding (S3C) model. We offer a hypothesis for why DBMs may not be trained succesfully without greedy layerwise training, and motivate the PD-DBM as a modified DBM that can be trained jointly."
    ],
    "domain": [
      "Deep Learning",
      "Generative Models",
      "Adversarial Learning",
      "Neural Networks"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "61cbcc25-a70d-42c4-b7dd-4431afaaccad": {
    "pk": "61cbcc25-a70d-42c4-b7dd-4431afaaccad",
    "name": "Jean Pouget-Abadie",
    "bio": "I am a researcher deeply engaged in the field of natural language processing and generative models. My work primarily focuses on enhancing the capabilities of neural machine translation systems, particularly in addressing the challenges posed by long sentences. In my early research, I developed an innovative approach to automatically segment input sentences into manageable phrases, significantly improving translation quality. This work highlighted the limitations of existing neural translation models compared to traditional phrase-based systems.\n\nAdditionally, I have explored the realm of generative models through an adversarial framework, where I simultaneously train generative and discriminative models in a minimax game setup. This approach not only simplifies the training process by eliminating the need for complex Markov chains but also ensures that the generative model accurately captures the underlying data distribution. My experiments have demonstrated the effectiveness of this framework, showcasing its potential through both qualitative and quantitative evaluations of generated samples.\n\nOverall, my research aims to push the boundaries of what is possible in machine translation and generative modeling, striving for more robust and efficient systems that can handle the complexities of human language.",
    "collaborators": [
      "Yoshua Bengio",
      "M\u00f3nica Mendes Sousa",
      "Dzmitry Bahdanau",
      "B. V. Merrienboer",
      "Kyunghyun Cho",
      "I. Goodfellow",
      "Mehdi Mirza",
      "Bing Xu",
      "David Warde-Farley",
      "Sherjil Ozair",
      "Aaron C. Courville",
      "Claude Vital",
      "Dominique Ostler",
      "R. Fernandes",
      "Dominique Carles",
      "M. J. Saraiva"
    ],
    "pub_titles": [
      "Overcoming the Curse of Sentence Length for Neural Machine Translation using Automatic Segmentation",
      "Generative Adversarial Nets"
    ],
    "pub_abstracts": [
      "The authors of (Cho et al., 2014a) have shown that the recently introduced neural network translation systems suffer from a significant drop in translation quality when translating long sentences, unlike existing phrase-based translation systems. In this paper, we propose a way to address this issue by automatically segmenting an input sentence into phrases that can be easily translated by the neural network translation model. Once each segment has been independently translated by the neural machine translation model, the translated clauses are concatenated to form a final translation. Empirical results show a significant improvement in translation quality for long sentences.",
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."
    ],
    "domain": [
      "Natural Language Processing",
      "Generative Models",
      "Neural Networks"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "91dfef3e-0566-45f7-b111-302f034c4597": {
    "pk": "91dfef3e-0566-45f7-b111-302f034c4597",
    "name": "Mehdi Mirza",
    "bio": "I am a researcher deeply engaged in the field of generative models and neural networks, with a particular focus on advancing techniques that enhance model performance and adaptability. My work began with the introduction of Conditional Generative Adversarial Nets (cGANs), where I explored how conditioning on specific data can lead to more meaningful and diverse outputs, such as generating MNIST digits based on class labels. This foundational work laid the groundwork for my ongoing exploration of adversarial processes in generative modeling.\n\nI have also investigated the challenges of catastrophic forgetting in neural networks, revealing how different training algorithms and activation functions impact a model's ability to retain knowledge across tasks. My findings emphasize the importance of dropout as a robust strategy for balancing the retention of old tasks while adapting to new ones.\n\nIn addition to theoretical advancements, I have contributed to practical applications, such as emotion recognition in video clips, where I combined multiple deep learning architectures to analyze various data modalities effectively. My work on the multi-prediction deep Boltzmann machine (MP-DBM) further demonstrates my commitment to improving classification tasks without the need for complex pretraining.\n\nThrough my research, I aim to push the boundaries of machine learning, developing flexible frameworks and innovative models that not only perform well but also adapt to the evolving landscape of data and tasks. I am passionate about fostering collaboration within the machine learning community, as exemplified by my contributions to the Pylearn2 library, which emphasizes extensibility and usability for researchers.",
    "collaborators": [
      "Yoshua Bengio",
      "Aaron C. Courville",
      "I. Goodfellow",
      "David Warde-Farley",
      "Bing Xu",
      "Pascal Lamblin",
      "Razvan Pascanu",
      "J. Bergstra",
      "Pascal Vincent",
      "P. Carrier",
      "Simon Osindero",
      "Jean Pouget-Abadie",
      "Sherjil Ozair",
      "Xia Da",
      "Vincent Dumoulin",
      "Fr\u00e9d\u00e9ric Bastien",
      "Samira Ebrahimi Kahou",
      "C. Pal",
      "Xavier Bouthillier",
      "Pierre Froumenty",
      "\u00c7aglar G\u00fcl\u00e7ehre",
      "R. Memisevic",
      "Raul Chandias Ferrari",
      "S\u00e9bastien Jean",
      "Yann Dauphin",
      "Nicolas Boulanger-Lewandowski",
      "Abhishek Aggarwal",
      "Jeremie Zumer",
      "Jean-Philippe Raymond",
      "Guillaume Desjardins",
      "Atousa Torabi",
      "Arjun Sharma",
      "Emmanuel Bengio",
      "K. Konda",
      "Zhenzhou Wu",
      "D. Erhan",
      "Benjamin Hamner",
      "William J. Cukierski",
      "Yichuan Tang",
      "David Thaler",
      "Dong-Hyun Lee",
      "Yingbo Zhou",
      "Chetan Ramaiah",
      "Fangxiang Feng",
      "Ruifan Li",
      "Xiaojie Wang",
      "Dimitris Athanasakis",
      "J. Shawe-Taylor",
      "Maxim Milakov",
      "John Park",
      "Radu Tudor Ionescu",
      "M. Popescu",
      "C. Grozea",
      "Jingjing Xie",
      "Lukasz Romaszko",
      "Chuang Zhang",
      "Salah Rifai"
    ],
    "pub_titles": [
      "Conditional Generative Adversarial Nets",
      "Generative Adversarial Nets",
      "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
      "Pylearn2: a machine learning research library",
      "Combining modality specific deep neural networks for emotion recognition in video",
      "Multi-Prediction Deep Boltzmann Machines",
      "Maxout Networks"
    ],
    "pub_abstracts": [
      "Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.",
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
      "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
      "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
      "In this paper we present the techniques used for the University of Montr\u00e9al's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds, including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities, including: (1) a deep convolutional neural network for the analysis of facial expressions within video frames; (2) a deep belief net to capture audio information; (3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the mouth of the primary human subject in the scene. We discuss each of these techniques, their performance characteristics and different strategies to aggregate their predictions. Our best single model was a convolutional neural network trained to predict emotions from static frames using two large data sets, the Toronto Face Database and our own set of faces images harvested from Google image search, followed by a per frame aggregation strategy that used the challenge training data. This yielded a test set accuracy of 35.58%. Using our best strategy for aggregating our top performing models into a single predictor we were able to produce an accuracy of 41.03% on the challenge test set. These compare favorably to the challenge baseline test set accuracy of 27.56%.",
      "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
      "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN."
    ],
    "domain": [
      "Generative Models",
      "Deep Learning",
      "Neural Networks",
      "Emotion Recognition"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "d38b14c2-4cc2-4c12-9861-f087536cad63": {
    "pk": "d38b14c2-4cc2-4c12-9861-f087536cad63",
    "name": "Bing Xu",
    "bio": "I am a researcher dedicated to the exploration and development of generative models through innovative frameworks. My recent work introduces a novel adversarial process that simultaneously trains a generative model (G) and a discriminative model (D). This approach is grounded in a minimax two-player game, where G aims to capture the true data distribution while D assesses the authenticity of samples. \n\nWhat excites me about this framework is its elegance and efficiency; it allows for the training of both models using backpropagation without the complexities of Markov chains or unrolled approximate inference networks. Through rigorous qualitative and quantitative evaluations, I have demonstrated the framework's potential in generating high-quality samples. My research not only contributes to the theoretical understanding of generative models but also paves the way for practical applications in various domains. I am passionate about pushing the boundaries of machine learning and uncovering new possibilities in generative modeling.",
    "collaborators": [
      "I. Goodfellow",
      "Mehdi Mirza",
      "Aaron C. Courville",
      "Yoshua Bengio",
      "Jean Pouget-Abadie",
      "David Warde-Farley",
      "Sherjil Ozair",
      "D. Erhan",
      "P. Carrier",
      "Benjamin Hamner",
      "William J. Cukierski",
      "Yichuan Tang",
      "David Thaler",
      "Dong-Hyun Lee",
      "Yingbo Zhou",
      "Chetan Ramaiah",
      "Fangxiang Feng",
      "Ruifan Li",
      "Xiaojie Wang",
      "Dimitris Athanasakis",
      "J. Shawe-Taylor",
      "Maxim Milakov",
      "John Park",
      "Radu Tudor Ionescu",
      "M. Popescu",
      "C. Grozea",
      "J. Bergstra",
      "Jingjing Xie",
      "Lukasz Romaszko",
      "Chuang Zhang"
    ],
    "pub_titles": [
      "Generative Adversarial Nets"
    ],
    "pub_abstracts": [
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."
    ],
    "domain": [
      "Generative Models",
      "Adversarial Learning",
      "Deep Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "d67b8a7e-d46c-47b8-a2c1-bfe526d90369": {
    "pk": "d67b8a7e-d46c-47b8-a2c1-bfe526d90369",
    "name": "Ian J. Goodfellow",
    "bio": "I am a researcher deeply engaged in the exploration of machine learning, particularly in the realms of neural networks and probabilistic models. My work has primarily focused on addressing critical challenges such as catastrophic forgetting in neural networks, where models struggle to retain knowledge from previous tasks when learning new ones. Through my investigations, I have demonstrated that dropout training consistently outperforms other methods in balancing the retention of old task performance while adapting to new tasks.\n\nI have also contributed to the development of advanced models like the partially directed deep Boltzmann machine (PD-DBM) and the multi-prediction deep Boltzmann machine (MP-DBM), which enhance classification capabilities without the need for greedy layer-wise training. My research on spike-and-slab sparse coding (S3C) has led to significant improvements in object recognition tasks, particularly in scenarios with limited labeled data.\n\nIn addition to theoretical advancements, I have been involved in practical applications, such as recognizing multi-digit numbers from Street View imagery, achieving state-of-the-art accuracy through a unified deep learning approach. My work with Theano has also facilitated research in deep learning by providing a robust framework for tensor operations and automatic differentiation.\n\nOverall, my research aims to push the boundaries of machine learning by developing models that are not only effective but also interpretable, addressing the complexities of real-world data and tasks. I am passionate about leveraging these advancements to create more intelligent systems that can learn and adapt in dynamic environments.",
    "collaborators": [
      "Yoshua Bengio",
      "Aaron C. Courville",
      "David Warde-Farley",
      "Mehdi Mirza",
      "J. Bergstra",
      "Pascal Lamblin",
      "Razvan Pascanu",
      "Fr\u00e9d\u00e9ric Bastien",
      "Vincent Dumoulin",
      "D. Erhan",
      "Guillaume Desjardins",
      "Arnaud Bergeron",
      "Xia Da",
      "Yaroslav Bulatov",
      "Julian Ibarz",
      "Sacha Arnoud",
      "Vinay D. Shet",
      "Christian Szegedy",
      "Wojciech Zaremba",
      "I. Sutskever",
      "Joan Bruna",
      "R. Fergus",
      "P. Carrier",
      "Benjamin Hamner",
      "William J. Cukierski",
      "Yichuan Tang",
      "David Thaler",
      "Dong-Hyun Lee",
      "Yingbo Zhou",
      "Chetan Ramaiah",
      "Fangxiang Feng",
      "Ruifan Li",
      "Xiaojie Wang",
      "Dimitris Athanasakis",
      "J. Shawe-Taylor",
      "Maxim Milakov",
      "John Park",
      "Radu Tudor Ionescu",
      "M. Popescu",
      "C. Grozea",
      "Jingjing Xie",
      "Lukasz Romaszko",
      "Bing Xu",
      "Chuang Zhang",
      "Olivier Breuleux",
      "Olivier Delalleau",
      "Nicolas Bouchard",
      "Daftar Pustaka",
      "Februari",
      "Boshra Bahrami",
      "Mirsaeid Hosseini",
      "Januari",
      "Gr\u00e9goire Mesnil",
      "Yann Dauphin",
      "Xavier Glorot",
      "Salah Rifai",
      "Y. Bengio",
      "Erick Lavoie",
      "X. Muller",
      "Pascal Vincent"
    ],
    "pub_titles": [
      "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
      "On the Challenges of Physical Implementations of RBMs",
      "Pylearn2: a machine learning research library",
      "Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning",
      "Multi-Prediction Deep Boltzmann Machines",
      "Piecewise Linear Multilayer Perceptrons and Dropout",
      "An empirical analysis of dropout in piecewise linear networks",
      "Joint Training Deep Boltzmann Machines for Classification",
      "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks",
      "Maxout Networks",
      "Intriguing properties of neural networks",
      "Large-Scale Feature Learning With Spike-and-Slab Sparse Coding",
      "Theano: Deep Learning on GPUs with Python",
      "Joint Training of Partially-Directed Deep Boltzmann Machines",
      "Theano: new features and speed improvements",
      "Spike-and-Slab Sparse Coding for Unsupervised Feature Discovery",
      "Joint Training of Deep Boltzmann Machines",
      "Mining",
      "Unsupervised and Transfer Learning Challenge: a Deep Learning Approach"
    ],
    "pub_abstracts": [
      "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
      "    Restricted Boltzmann machines (RBMs) are powerful machine learning models, but learning and some kinds of inference in the model require sampling-based approximations, which, in classical digital computers, are implemented using expensive MCMC. Physical computation offers the opportunity to reduce the costof sampling by building physical systems whose natural dynamics correspond to drawing samples from the desired RBM distribution. Such a system avoids the burn-in and mixing cost of a Markov chain. However, hardware implementations of this variety usually entail limitations such as low-precision and limited range of the parameters and restrictions on the size and topology of the RBM. We conduct software simulations to determine how harmful each of these restrictions is. Our simulations are based on the D-Wave Two computer, but the issues we investigate arise in most forms of physical computation.Our findings suggest that designers of new physical computing hardware and algorithms for physical computers should focus their efforts on overcoming the limitations imposed by the topology restrictions of currently existing physical computers.   ",
      "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
      "We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.",
      "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
      "We propose a new type of hidden layer for a multilayer perceptron, and demonstrate that it obtains the best reported performance for an MLP on the MNIST dataset.",
      "The recently introduced dropout training criterion for neural networks has been the subject of much attention due to its simplicity and remarkable effectiveness as a regularizer, as well as its interpretation as a training procedure for an exponentially large ensemble of networks that share parameters. In this work we empirically investigate several questions related to the efficacy of dropout, specifically as it concerns networks employing the popular rectified linear activation function. We investigate the quality of the test time weight-scaling inference procedure by evaluating the geometric average exactly in small models, as well as compare the performance of the geometric mean to the arithmetic mean more commonly employed by ensemble techniques. We explore the effect of tied weights on the ensemble interpretation by training ensembles of masked networks without tied weights. Finally, we investigate an alternative criterion based on a biased estimator of the maximum likelihood ensemble gradient.",
      "We introduce a new method for training deep Boltzmann machines jointly. Prior methods of training DBMs require an initial learning pass that trains the model greedily, one layer at a time, or do not perform well on classification tasks. In our approach, we train all layers of the DBM simultaneously, using a novel training procedure called multi-prediction training. The resulting model can either be interpreted as a single generative model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent networks that share parameters and may be approximately averaged together using a novel technique we call the multi-inference trick. We show that our approach performs competitively for classification and outperforms previous methods in terms of accuracy of approximate inference and classification with missing inputs.",
      "Abstract: Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over $96\\%$ accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art, achieving $97.84\\%$ accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over $90\\%$ accuracy. To further explore the applicability of the proposed system to broader text recognition tasks, we apply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the most secure reverse turing tests that uses distorted text to distinguish humans from bots. We report a $99.8\\%$ accuracy on the hardest category of reCAPTCHA. Our evaluations on both tasks indicate that at specific operating thresholds, the performance of the proposed system is comparable to, and in some cases exceeds, that of human operators.",
      "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.",
      "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.  First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.  Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
      "We consider the problem of object recognition with a large number of classes. In order to overcome the low amount of labeled examples available in this setting, we introduce a new feature learning and extraction procedure based on a factor model we call spike-and-slab sparse coding (S3C). Prior work on S3C has not prioritized the ability to exploit parallel architectures and scale S3C to the enormous problem sizes needed for object recognition. We present a novel inference procedure for appropriate for use with GPUs which allows us to dramatically increase both the training set size and the amount of latent factors that S3C may be trained with. We demonstrate that this approach improves upon the supervised learning capabilities of both sparse coding and the spike-and-slab Restricted Boltzmann Machine (ssRBM) on the CIFAR-10 dataset. We use the CIFAR-100 dataset to demonstrate that our method scales to large numbers of classes better than previous methods. Finally, we use our method to win the NIPS 2011 Workshop on Challenges In Learning Hierarchical Models' Transfer Learning Challenge.",
      "In this paper, we present Theano 1 , a framework in the Python programming language for defining, optimizing and evaluating expressions involving high-level operations on tensors. Theano offers most of NumPy\u2019s functionality, but adds automatic symbolic differentiation, GPU support, and faster expression evaluation. Theano is a general mathematical tool, but it was developed with the goal of facilitating research in deep learning. The Deep Learning Tutorials 2 introduce recent advances in deep learning, and showcase how Theano",
      "We introduce a deep probabilistic model which we call the partially directed deep Boltzmann machine (PD-DBM). The PD-DBM is a model of real-valued data based on the deep Boltzmann machine (DBM) and the spike-and-slab sparse coding (S3C) model. We offer a hypothesis for why DBMs may not be trained succesfully without greedy layerwise training, and motivate the PD-DBM as a modified DBM that can be trained jointly.",
      "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.",
      "We consider the problem of using a factor model we call {\\em spike-and-slab sparse coding} (S3C) to learn features for a classification task. The S3C model resembles both the spike-and-slab RBM and sparse coding. Since exact inference in this model is intractable, we derive a structured variational inference procedure and employ a variational EM training algorithm. Prior work on approximate inference for this model has not prioritized the ability to exploit parallel architectures and scale to enormous problem sizes. We present an inference procedure appropriate for use with GPUs which allows us to dramatically increase both the training set size and the amount of latent factors.  We demonstrate that this approach improves upon the supervised learning capabilities of both sparse coding and the ssRBM on the CIFAR-10 dataset. We evaluate our approach's potential for semi-supervised learning on subsets of CIFAR-10. We demonstrate state-of-the art self-taught learning performance on the STL-10 dataset and use our method to win the NIPS 2011 Workshop on Challenges In Learning Hierarchical Models' Transfer Learning Challenge.",
      "We introduce a new method for training deep Boltzmann machines jointly. Prior methods require an initial learning pass that trains the deep Boltzmann machine greedily, one layer at a time, or do not perform well on classifi- cation tasks.",
      "Purpose. To establish the feasibility of refining deep open\u00adpit mines below the boundary of the use of combined motor\u00adcon\u00ad veyor transport with an increased slope angles of the pit walls using the developed transport unit for reloading rocks to overlying horizons during the reactivation of pillars under transport berms. Methodology. Preparation of a digital block model of the deposit, the elaboration of 3D geomechanical models for the dynam\u00ad ics of mining, 2D and 3D numerical simulation of the rock stress\u00adstrain state of the outcrops of opencast workings, mathematical modeling of stepwise ore reserves and mining schedule, patent research and feasibility study. Findings. It is advisable to carry out mining in terms of the marginal rock state with an increase in the slope of the pit sides below the limit of application of the cyclic and continuous method in ultra\u00addeep open pits. Such design of pit sides is achieved when benches are mined from top to bottom within the boundaries of steeply inclined layers with the use of inter\u00adbench loaders of the developed designed in the completion zone. Provisions for the selection and feasibility of using the loader in the deep zone are formulated based on demarcation of application zones of cyclic (road transport) and cyclic\u00adflow (combined road\u00adconveyor trans\u00ad port) technologies. Originality. Schematization of the mining operation was performed based on the calculated values of safety factor of sides, which allows increasing the slope angles of the pit walls of even ultra\u00addeep open pits in the completion zone. It was found that with deepening of mining, the zones of potential sliding move away from the loose overburden to lower ore benches closer to the final depth of the Kacharsky open pit (760 m), but the safety factor corresponds to the required value according to the design standards. Practical value. An increase in the slope of the pit walls in the completion zone can be achieved using the developed loading installation, the main difference of which is that it can be moved without dismantling under conditions of reactivation of transport pillars (with an increase in lifting height by 1.5\u20134.5 times compared to the known equipment).",
      "Learning good representations from a large set of unlabeled data is a particularly challenging task. Recent work (see Bengio (2009) for a review) shows that training deep architectures is a good way to extract such representations, by extracting and disentangling gradually higher-level factors of variation characterizing the input distribution. In this paper, we describe different kinds of layers we trained for learning representations in the setting of the Unsupervised and Transfer Learning Challenge. The strategy of our team won the final phase of the challenge. It combined and stacked different one-layer unsupervised learning algorithms, adapted to each of the five datasets of the competition. This paper describes that strategy and the particular one-layer learning algorithms feeding a simple linear classifier with a tiny number of labeled training samples (1 to 64 per class)."
    ],
    "domain": [
      "Deep Learning",
      "Neural Networks",
      "Representation Learning",
      "Object Recognition"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "84e178e3-b34c-4bde-b676-4b145a51feab": {
    "pk": "84e178e3-b34c-4bde-b676-4b145a51feab",
    "name": "Mehdi Mirza",
    "bio": "I am a researcher deeply engaged in the exploration of neural networks and their capabilities, particularly in addressing challenges like catastrophic forgetting. My work has focused on understanding how different training algorithms and activation functions impact a model's ability to retain knowledge across tasks. Through my investigations, I have found that the dropout algorithm consistently outperforms others in balancing the retention of old tasks while adapting to new ones.\n\nIn addition to my work on catastrophic forgetting, I have contributed to the development of Pylearn2, a flexible machine learning research library designed to support innovative research projects. My involvement in the Emotion Recognition in the Wild Challenge showcased my ability to integrate multiple deep learning techniques, including convolutional neural networks and deep belief networks, to analyze complex data modalities like video and audio.\n\nI also introduced the multi-prediction deep Boltzmann machine (MP-DBM), which enhances classification tasks without the need for greedy layerwise pretraining, demonstrating improved performance over traditional models. My research on maxout, a model designed to work synergistically with dropout, has led to state-of-the-art results across several benchmark datasets.\n\nOverall, my work aims to push the boundaries of what neural networks can achieve, focusing on both theoretical advancements and practical applications in machine learning.",
    "collaborators": [
      "Yoshua Bengio",
      "Aaron C. Courville",
      "I. Goodfellow",
      "David Warde-Farley",
      "Pascal Lamblin",
      "Razvan Pascanu",
      "J. Bergstra",
      "Pascal Vincent",
      "P. Carrier",
      "Xia Da",
      "Vincent Dumoulin",
      "Fr\u00e9d\u00e9ric Bastien",
      "Samira Ebrahimi Kahou",
      "C. Pal",
      "Xavier Bouthillier",
      "Pierre Froumenty",
      "\u00c7aglar G\u00fcl\u00e7ehre",
      "R. Memisevic",
      "Raul Chandias Ferrari",
      "S\u00e9bastien Jean",
      "Yann Dauphin",
      "Nicolas Boulanger-Lewandowski",
      "Abhishek Aggarwal",
      "Jeremie Zumer",
      "Jean-Philippe Raymond",
      "Guillaume Desjardins",
      "Atousa Torabi",
      "Arjun Sharma",
      "Emmanuel Bengio",
      "K. Konda",
      "Zhenzhou Wu",
      "D. Erhan",
      "Benjamin Hamner",
      "William J. Cukierski",
      "Yichuan Tang",
      "David Thaler",
      "Dong-Hyun Lee",
      "Yingbo Zhou",
      "Chetan Ramaiah",
      "Fangxiang Feng",
      "Ruifan Li",
      "Xiaojie Wang",
      "Dimitris Athanasakis",
      "J. Shawe-Taylor",
      "Maxim Milakov",
      "John Park",
      "Radu Tudor Ionescu",
      "M. Popescu",
      "C. Grozea",
      "Jingjing Xie",
      "Lukasz Romaszko",
      "Bing Xu",
      "Chuang Zhang",
      "Salah Rifai"
    ],
    "pub_titles": [
      "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
      "Pylearn2: a machine learning research library",
      "Combining modality specific deep neural networks for emotion recognition in video",
      "Multi-Prediction Deep Boltzmann Machines",
      "Maxout Networks"
    ],
    "pub_abstracts": [
      "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
      "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
      "In this paper we present the techniques used for the University of Montr\u00e9al's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds, including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities, including: (1) a deep convolutional neural network for the analysis of facial expressions within video frames; (2) a deep belief net to capture audio information; (3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the mouth of the primary human subject in the scene. We discuss each of these techniques, their performance characteristics and different strategies to aggregate their predictions. Our best single model was a convolutional neural network trained to predict emotions from static frames using two large data sets, the Toronto Face Database and our own set of faces images harvested from Google image search, followed by a per frame aggregation strategy that used the challenge training data. This yielded a test set accuracy of 35.58%. Using our best strategy for aggregating our top performing models into a single predictor we were able to produce an accuracy of 41.03% on the challenge test set. These compare favorably to the challenge baseline test set accuracy of 27.56%.",
      "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
      "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN."
    ],
    "domain": [
      "Deep Learning",
      "Neural Networks",
      "Emotion Recognition",
      "Model Optimization"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "2b3f501a-7776-4f00-be4a-55aa19473b68": {
    "pk": "2b3f501a-7776-4f00-be4a-55aa19473b68",
    "name": "David Warde-Farley",
    "bio": "I am a researcher deeply engaged in the intersection of machine learning and environmental science, particularly focusing on atmospheric data and reinforcement learning. My recent work has centered on developing innovative methods for compressing high-dimensional atmospheric states, enabling broader access to critical weather and climate data. By leveraging neural network architectures and advanced projection techniques, I have achieved impressive compression ratios while preserving essential features, such as extreme weather events.\n\nIn addition to atmospheric modeling, I have explored biases in machine learning models through the introduction of SkewSize, a novel metric that characterizes model mistakes across subgroups, enhancing our understanding of model performance. My research also extends to algorithm design, where I developed RbmSAT, an incomplete algorithm for Maximum Satisfiability tailored for neural network accelerators, demonstrating superior performance in competitive settings.\n\nMy interests also encompass unsupervised skill learning in reinforcement learning, where I have proposed methods like DISDAIN and RVIC to enhance exploration and skill diversity. These contributions aim to empower agents to learn effectively in complex environments without relying on external rewards.\n\nOverall, my work strives to bridge theoretical advancements with practical applications, ensuring that machine learning techniques can be effectively utilized in real-world scenarios, from climate science to autonomous agents. I am passionate about pushing the boundaries of what is possible in these fields and contributing to a deeper understanding of both machine learning and the earth system.",
    "collaborators": [
      "S. Hansen",
      "Volodymyr Mnih",
      "Yoshua Bengio",
      "Simon Osindero",
      "Kate Baumli",
      "T. Wiele",
      "Dzmitry Bahdanau",
      "J. Chorowski",
      "Aaron C. Courville",
      "Mehdi Mirza",
      "C. Pal",
      "Mihaela Rosca",
      "Guillaume Desjardins",
      "I. Goodfellow",
      "Sherjil Ozair",
      "Nicolas Boulanger-Lewandowski",
      "Xavier Bouthillier",
      "A. D. Br\u00e9bisson",
      "Yann Dauphin",
      "Laurent Dinh",
      "Vincent Dumoulin",
      "Samira Ebrahimi Kahou",
      "Orhan Firat",
      "\u00c7aglar G\u00fcl\u00e7ehre",
      "S\u00e9bastien Jean",
      "Pascal Lamblin",
      "C\u00e9sar Laurent",
      "R. Memisevic",
      "B. V. Merrienboer",
      "Vincent Michalski",
      "M. Pezeshki",
      "Dmitriy Serdyuk",
      "Pascal Vincent",
      "Ying Zhang",
      "Piotr Mirowski",
      "Matthew Koichi Grimes",
      "Yana Hasson",
      "Hyunjik Kim",
      "M'elanie Rey",
      "Suman V. Ravuri",
      "Shakir Mohamed",
      "Isabela Albuquerque",
      "Jessica Schrouff",
      "Ali Taylan Cemgil",
      "Sven Gowal",
      "Olivia Wiles",
      "Vinod Nair",
      "Yujia Li",
      "Ivan Lobov",
      "Felix Gimeno",
      "N. Heess",
      "D. Strouse",
      "Vlad Mnih",
      "A. Mnih",
      "Will Dabney",
      "Andr\u00e9 Barreto",
      "Tejas D. Kulkarni",
      "Catalin Ionescu",
      "Jean Pouget-Abadie",
      "Bing Xu",
      "Balaji Lakshminarayanan",
      "S. Mohamed",
      "Rami Al-Rfou",
      "Guillaume Alain",
      "Amjad Almahairi",
      "Christof Angerm\u00fcller",
      "Nicolas Ballas",
      "Fr\u00e9d\u00e9ric Bastien",
      "Justin Bayer",
      "A. Belikov",
      "A. Belopolsky",
      "Arnaud Bergeron",
      "J. Bergstra",
      "Valentin Bisson",
      "Josh Bleecher Snyder",
      "Nicolas Bouchard",
      "Olivier Breuleux",
      "P. Carrier",
      "Kyunghyun Cho",
      "P. Christiano",
      "Tim Cooijmans",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Myriam C\u00f4t\u00e9",
      "Olivier Delalleau",
      "Julien Demouth",
      "S. Dieleman",
      "M\u00e9lanie Ducoffe",
      "D. Erhan",
      "Ziye Fan",
      "M. Germain",
      "Xavier Glorot",
      "M. Graham",
      "P. Hamel",
      "Iban Harlouchet",
      "J. Heng",
      "Bal\u00e1zs Hidasi",
      "S. Honari",
      "Arjun Jain",
      "Kai Jia",
      "Mikhail Korobov"
    ],
    "pub_titles": [
      "Neural Compression of Atmospheric States",
      "Evaluating Model Bias Requires Characterizing its Mistakes",
      "Solving MaxSAT with Matrix Multiplication",
      "Entropic Desired Dynamics for Intrinsic Control",
      "Learning more skills through optimistic exploration",
      "Relative Variational Intrinsic Control",
      "Q-Learning in enormous action spaces via amortized approximate maximization",
      "Fast Task Inference with Variational Intrinsic Successor Features",
      "Unsupervised Control Through Non-Parametric Discriminative Rewards",
      "Generative Adversarial Networks for Image Steganography",
      "Variational Approaches for Auto-Encoding Generative Adversarial Networks",
      "Theano: A Python framework for fast computation of mathematical expressions",
      "Improving Generative Adversarial Networks with Denoising Feature Matching",
      "Blocks and Fuel: Frameworks for deep learning"
    ],
    "pub_abstracts": [
      "Atmospheric states derived from reanalysis comprise a substantial portion of weather and climate simulation outputs. Many stakeholders -- such as researchers, policy makers, and insurers -- use this data to better understand the earth system and guide policy decisions. Atmospheric states have also received increased interest as machine learning approaches to weather prediction have shown promising results. A key issue for all audiences is that dense time series of these high-dimensional states comprise an enormous amount of data, precluding all but the most well resourced groups from accessing and using historical data and future projections. To address this problem, we propose a method for compressing atmospheric states using methods from the neural network literature, adapting spherical data to processing by conventional neural architectures through the use of the area-preserving HEALPix projection. We investigate two model classes for building neural compressors: the hyperprior model from the neural image compression literature and recent vector-quantised models. We show that both families of models satisfy the desiderata of small average error, a small number of high-error reconstructed pixels, faithful reproduction of extreme events such as hurricanes and heatwaves, preservation of the spectral power distribution across spatial scales. We demonstrate compression ratios in excess of 1000x, with compression and decompression at a rate of approximately one second per global atmospheric state.",
      "The ability to properly benchmark model performance in the face of spurious correlations is important to both build better predictors and increase confidence that models are operating as intended. We demonstrate that characterizing (as opposed to simply quantifying) model mistakes across subgroups is pivotal to properly reflect model biases, which are ignored by standard metrics such as worst-group accuracy or accuracy gap. Inspired by the hypothesis testing framework, we introduce SkewSize, a principled and flexible metric that captures bias from mistakes in a model's predictions. It can be used in multi-class settings or generalised to the open vocabulary setting of generative models. SkewSize is an aggregation of the effect size of the interaction between two categorical variables: the spurious variable representing the bias attribute and the model's prediction. We demonstrate the utility of SkewSize in multiple settings including: standard vision models trained on synthetic data, vision models trained on ImageNet, and large scale vision-and-language models from the BLIP-2 family. In each case, the proposed SkewSize is able to highlight biases not captured by other metrics, while also providing insights on the impact of recently proposed techniques, such as instruction tuning.",
      "We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT) specifically designed to run on neural network accelerators such as GPUs and TPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure constructs a Restricted Boltzmann Machine (RBM) with an equilibrium distribution wherein the probability of a Boolean assignment is exponential in the number of clauses it satisfies. Block Gibbs sampling is used to stochastically search the space of assignments with parallel Markov chains. Since matrix multiplication is the main computational primitive for block Gibbs sampling in an RBM, our approach leads to an elegantly simple algorithm (40 lines of JAX) well-suited for neural network accelerators. Theoretical results about RBMs guarantee that the required number of visible and hidden units of the RBM scale only linearly with the number of variables and constant-sized clauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs step scales reasonably with the instance size. Search throughput can be increased by batching parallel chains within a single accelerator as well as by distributing them across multiple accelerators. As a further enhancement, a heuristic based on unit propagation running on CPU is periodically applied to the sampled assignments. Our approach, which we term RbmSAT, is a new design point in the algorithm-hardware co-design space for MaxSAT. We present timed results on a subset of problem instances from the annual MaxSAT Evaluation's Incomplete Unweighted Track for the years 2018 to 2021. When allotted the same running time and CPU compute budget (but no TPUs), RbmSAT outperforms other participating solvers on problems drawn from three out of the four years' competitions. Given the same running time on a TPU cluster for which RbmSAT is uniquely designed, it outperforms all solvers on problems drawn from all four years.",
      "An agent might be said, informally, to have mastery of its environment when it has maximised the effective number of states it can reliably reach. In practice, this often means maximizing the number of latent codes that can be discriminated from future states under some short time horizon (e.g. [15]). By situating these latent codes in a globally consistent coordinate system, we show that agents can reliably reach more states in the long term while still optimizing a local objective. A simple instantiation of this idea, E ntropic D esired D ynamics for I ntrinsic C on T rol (EDDICT), assumes \ufb01xed additive latent dynamics, which results in tractable learning and an interpretable latent space. Compared to prior methods, EDDICT\u2019s globally consistent codes allow it to be far more exploratory, as demonstrated by improved state coverage and increased unsupervised performance on hard exploration games such as Montezuma\u2019s Revenge.",
      "Unsupervised skill learning objectives (Gregor et al., 2016, Eysenbach et al., 2018) allow agents to learn rich repertoires of behavior in the absence of extrinsic rewards. They work by simultaneously training a policy to produce distinguishable latent-conditioned trajectories, and a discriminator to evaluate distinguishability by trying to infer latents from trajectories. The hope is for the agent to explore and master the environment by encouraging each skill (latent) to reliably reach different states. However, an inherent exploration problem lingers: when a novel state is actually encountered, the discriminator will necessarily not have seen enough training data to produce accurate and confident skill classifications, leading to low intrinsic reward for the agent and effective penalization of the sort of exploration needed to actually maximize the objective. To combat this inherent pessimism towards exploration, we derive an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. Our objective directly estimates the epistemic uncertainty that comes from the discriminator not having seen enough training examples, thus providing an intrinsic reward more tailored to the true objective compared to pseudocount-based methods (Burda et al., 2019). We call this exploration bonus discriminator disagreement intrinsic reward, or DISDAIN. We demonstrate empirically that DISDAIN improves skill learning both in a tabular grid world (Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we encourage researchers to treat pessimism with DISDAIN.",
      "In the absence of external rewards, agents can still learn useful behaviors by identifying and mastering a set of diverse skills within their environment. Existing skill learning methods use mutual information objectives to incentivize each skill to be diverse and distinguishable from the rest. However, if care is not taken to constrain the ways in which the skills are diverse, trivially diverse skill sets can arise. To ensure useful skill diversity, we propose a novel skill learning objective, Relative Variational Intrinsic Control (RVIC), which incentivizes learning skills that are distinguishable in how they change the agent's relationship to its environment. The resulting set of skills tiles the space of affordances available to the agent. We qualitatively analyze skill behaviors on multiple environments and show how RVIC skills are more useful than skills discovered by existing methods in hierarchical reinforcement learning.",
      "Applying Q-learning to high-dimensional or continuous action spaces can be difficult due to the required maximization over the set of possible actions. Motivated by techniques from amortized inference, we replace the expensive maximization over all actions with a maximization over a small subset of possible actions sampled from a learned proposal distribution. The resulting approach, which we dub Amortized Q-learning (AQL), is able to handle discrete, continuous, or hybrid action spaces while maintaining the benefits of Q-learning. Our experiments on continuous control tasks with up to 21 dimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018) and QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action spaces demonstrate that AQL can efficiently learn good policies in spaces with thousands of discrete actions.",
      "It has been established that diverse behaviors spanning the controllable subspace of an Markov decision process can be trained by rewarding a policy for being distinguishable from other policies \\citep{gregor2016variational, eysenbach2018diversity, warde2018unsupervised}. However, one limitation of this formulation is generalizing behaviors beyond the finite set being explicitly learned, as is needed for use on subsequent tasks. Successor features \\citep{dayan93improving, barreto2017successor} provide an appealing solution to this generalization problem, but require defining the reward function as linear in some grounded feature space. In this paper, we show that these two techniques can be combined, and that each method solves the other's primary limitation. To do so we introduce Variational Intrinsic Successor FeatuRes (VISR), a novel algorithm which learns controllable features that can be leveraged to provide enhanced generalization and fast task inference through the successor feature framework. We empirically validate VISR on the full Atari suite, in a novel setup wherein the rewards are only exposed briefly after a long unsupervised phase. Achieving human-level performance on 14 games and beating all baselines, we believe VISR represents a step towards agents that rapidly learn from limited feedback.",
      "Learning to control an environment without hand-crafted rewards or expert data remains challenging and is at the frontier of reinforcement learning research. We present an unsupervised learning algorithm to train agents to achieve perceptually-specified goals using only a stream of observations and actions. Our agent simultaneously learns a goal-conditioned policy and a goal achievement reward function that measures how similar a state is to the goal state. This dual optimization leads to a co-operative game, giving rise to a learned reward function that reflects similarity in controllable aspects of the environment instead of distance in the space of observations. We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -- Atari, the DeepMind Control Suite and DeepMind Lab.",
      "Steganography is collection of methods to hide secret information (\"payload\") within non-secret information (\"container\"). Its counterpart, Steganalysis, is the practice of determining if a message contains a hidden payload, and recovering it if possible. Presence of hidden payloads is typically detected by a binary classifier. In the present study, we propose a new model for generating image-like containers based on Deep Convolutional Generative Adversarial Networks (DCGAN). This approach allows to generate more setganalysis-secure message embedding using standard steganography algorithms. Experiment results demonstrate that the new model successfully deceives the steganography analyzer, and for this reason, can be used in steganographic applications.",
      "Auto-encoding generative adversarial networks (GANs) combine the standard GAN algorithm, which discriminates between real and model-generated data, with a reconstruction loss given by an auto-encoder. Such models aim to prevent mode collapse in the learned generative model by ensuring that it is grounded in all the available training data. In this paper, we develop a principle upon which auto-encoders can be combined with generative adversarial networks by exploiting the hierarchical structure of the generative model. The underlying principle shows that variational inference can be used a basic tool for learning, but with the in- tractable likelihood replaced by a synthetic likelihood, and the unknown posterior distribution replaced by an implicit distribution; both synthetic likelihoods and implicit posterior distributions can be learned using discriminators. This allows us to develop a natural fusion of variational auto-encoders and generative adversarial networks, combining the best of both these methods. We describe a unified objective for optimization, discuss the constraints needed to guide learning, connect to the wide range of existing work, and use a battery of tests to systematically and quantitatively assess the performance of our method.",
      "Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models.  The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.",
      "We propose an augmented training procedure for generative adversarial networks designed to address shortcomings of the original by directing the generator towards probable configurations of abstract discriminator features. We estimate and track the distribution of these features, as computed from data, with a denoising auto-encoder, and use it to propose high-level targets for the generator. We combine this new loss with the original and evaluate the hybrid criterion on the task of unsupervised image synthesis from datasets comprising a diverse set of visual categories, noting a qualitative and quantitative improvement in the \u201cobjectness\u201d of the resulting samples.",
      "We introduce two Python frameworks to train neural networks on large datasets: Blocks and Fuel. Blocks is based on Theano, a linear algebra compiler with CUDA-support (Bastien et al., 2012; Bergstra et al., 2010). It facilitates the training of complex neural network models by providing parametrized Theano operations, attaching metadata to Theano\u2019s symbolic computational graph, and providing an extensive set of utilities to assist training the networks, e.g. training algorithms, logging, monitoring, visualization, and serialization. Fuel provides a standard format for machine learning datasets. It allows the user to easily iterate over large datasets, performing many types of pre-processing on the fly."
    ],
    "domain": [
      "Machine Learning",
      "Reinforcement Learning",
      "Neural Networks",
      "Generative Models"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "e72df3d5-fc04-440f-88f0-974acb1929a2": {
    "pk": "e72df3d5-fc04-440f-88f0-974acb1929a2",
    "name": "Sherjil Ozair",
    "bio": "I am a researcher dedicated to advancing the fields of generative models, reinforcement learning, and representation learning. My recent work includes the development of Genie, an innovative generative interactive environment that leverages unlabelled Internet videos to create dynamic virtual worlds. This foundation model, with its 11 billion parameters, allows users to engage with generated environments in unprecedented ways.\n\nI have also focused on enhancing low-resource language models, particularly for Thai, by creating a synthetic data framework that emphasizes fluency, diversity, and cultural context. This work demonstrates that effective instruction-tuning can be achieved with minimal data, significantly improving performance compared to traditional methods.\n\nIn the realm of reinforcement learning, I have contributed to the establishment of benchmarks like AlphaStar Unplugged, which challenges offline RL algorithms in complex environments such as StarCraft II. My research extends to model-based approaches, where I introduced Stochastic MuZero, a method that incorporates stochastic models for improved planning in uncertain environments.\n\nAdditionally, I have explored the intricacies of mutual information in representation learning, proposing novel methods to enhance generalization and data efficiency. My work on DeepNash has pushed the boundaries of AI in imperfect information games, achieving human expert-level performance in Stratego.\n\nOverall, my research aims to bridge the gap between theoretical advancements and practical applications, fostering the development of intelligent agents capable of navigating complex, real-world scenarios.",
    "collaborators": [
      "A\u00e4ron van den Oord",
      "Yoshua Bengio",
      "Ioannis Antonoglou",
      "Julian Schrittwieser",
      "David Silver",
      "Yazhe Li",
      "Alex Lamb",
      "R. Devon Hjelm",
      "Konrad Zolna",
      "Nando de Freitas",
      "Satinder Singh",
      "Erica Moreira",
      "L. Sifre",
      "Petko Georgiev",
      "O. Vinyals",
      "Ali Razavi",
      "Mina Khan",
      "Ankesh Anand",
      "Vikas Verma",
      "David Ha",
      "Ben Poole",
      "Alexander A. Alemi",
      "G. Tucker",
      "Aaron C. Courville",
      "Jake Bruce",
      "Michael D. Dennis",
      "Ashley Edwards",
      "Jack Parker-Holder",
      "Yuge Shi",
      "Edward Hughes",
      "Matthew Lai",
      "Aditi Mavalankar",
      "Richie Steigerwald",
      "Chris Apps",
      "Y. Aytar",
      "Sarah Bechtle",
      "Feryal M. P. Behbahani",
      "Stephanie Chan",
      "N. Heess",
      "Lucy Gonzalez",
      "Simon Osindero",
      "Scott Reed",
      "Jingwei Zhang",
      "Jeff Clune",
      "Tim Rocktaschel",
      "Parinthapat Pengpun",
      "Can Udomcharoenchaikit \u2020 Weerayut Buaphet",
      "Peerat Limkonchotiwat",
      "Xuan-Phi Nguyen",
      "Wenxuan Zhang",
      "Xin Li",
      "Mahani Aljunied",
      "Qingyu Tan",
      "Liying Cheng",
      "Guanzheng Chen",
      "Yue Deng",
      "Sen Yang",
      "Chaoqun Liu",
      "Haim-ing Bao",
      "Mo Bavarian",
      "J. Belgum",
      "Ir-wan Bello",
      "Jake Berdine",
      "Gabriel Bernadett-Shapiro",
      "Christopher Berner",
      "Lenny Bogdonoff",
      "Oleg Boiko",
      "Made-laine Boyd",
      "Anna-Luisa Brakman",
      "Greg Brock-man",
      "Tim Brooks",
      "M. Brundage",
      "Kevin Button",
      "Trevor Cai",
      "Rosie Campbell",
      "Andrew Cann",
      "Brittany Carey",
      "Chelsea Carlson",
      "Rory Carmichael",
      "Brooke Chan",
      "Che Chang",
      "Fotis Chantzis",
      "Derek Chen",
      "Sully Chen",
      "Ruby Chen",
      "Jason Chen",
      "Mark Chen",
      "B. Chess",
      "Chester Cho",
      "Hyung Casey Chu",
      "Won Chung",
      "Dave Cummings",
      "Jeremiah Currier",
      "Yunxing Dai",
      "Tarun Goel",
      "Gabriel Gogineni",
      "Rapha Goh",
      "Jonathan Gontijo-Lopes",
      "Morgan Gordon",
      "Scott Grafstein"
    ],
    "pub_titles": [
      "Genie: Generative Interactive Environments",
      "Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai",
      "AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning",
      "[Re] Explaining in Style: Training a GAN to explain a classifier in StyleSpace",
      "Model-based language-instructed reinforcement learning",
      "Planning in Stochastic Environments with a Learned Model",
      "Mastering the game of Stratego with model-free multiagent reinforcement learning",
      "Pretrained Encoders are All You Need",
      "Procedural Generalization by Planning with Self-Supervised World Models",
      "Vector Quantized Models for Planning",
      "SketchTransfer: A New Dataset for Exploring Detail-Invariance and the Abstractions Learned by Deep Networks",
      "Unsupervised State Representation Learning in Atari",
      "On Variational Bounds of Mutual Information",
      "The Journey is the Reward: Unsupervised Learning of Influential Trajectories",
      "SketchTransfer: A Challenging New Task for Exploring Detail-Invariance and the Abstractions Learned by Deep Networks",
      "Wasserstein Dependency Measure for Representation Learning",
      "Learning Generative Models with Locally Disentangled Latent Factors",
      "Mutual Information Neural Estimation",
      "On variational lower bounds of mutual information",
      "Generative Adversarial Networks for Image Steganography"
    ],
    "pub_abstracts": [
      "We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of action-controllable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.",
      "We present a synthetic data approach for instruction-tuning large language models (LLMs) for low-resource languages in a data-efficient manner, specifically focusing on Thai. We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity, and cultural context. We propose a seed-data-free framework for generating synthetic instruction-tuning data that incorporates these essential properties. Our framework employs an LLM to generate diverse topics, retrieve relevant contexts from Wikipedia, and create instructions for various tasks, such as question answering, summarization, and conversation. The experimental results show that our best-performing synthetic dataset, which incorporates all three key properties, achieves competitive performance using only 5,000 instructions when compared to state-of-the-art Thai LLMs trained on hundreds of thousands of instructions. Our code and dataset are publicly available at https://github.com/parinzee/seed-free-synthetic-instruct.",
      "StarCraft II is one of the most challenging simulated reinforcement learning environments; it is partially observable, stochastic, multi-agent, and mastering StarCraft II requires strategic planning over long time horizons with real-time low-level execution. It also has an active professional competitive scene. StarCraft II is uniquely suited for advancing offline RL algorithms, both because of its challenging nature and because Blizzard has released a massive dataset of millions of StarCraft II games played by human players. This paper leverages that and establishes a benchmark, called AlphaStar Unplugged, introducing unprecedented challenges for offline reinforcement learning. We define a dataset (a subset of Blizzard's release), tools standardizing an API for machine learning methods, and an evaluation protocol. We also present baseline agents, including behavior cloning, offline variants of actor-critic and MuZero. We improve the state of the art of agents using only offline data, and we achieve 90% win rate against previously published AlphaStar behavior cloning agent.",
      "StylEx is an approach for classifier-conditioned training of a StyleGAN2 [6], intending to capture classifier-specific 3 attributes in its disentangled StyleSpace [15]. Attributes can be adjusted to generate counterfactual explanations of 4 the classifier decisions. StylEx is domain and classifier-agnostic, while its explanations are claimed to be human5 interpretable, distinct, coherent and sufficient to produce flipped classifier decisions. We verify these claims by 6 reproducing a selection of the experiments in the paper. 7",
      "We explore how we can build accurate world 001 models which are partially specified by lan-002 guage and how we can plan with them in the 003 face of novelty and uncertainty. We propose the 004 first Model-Based Reinforcement Learning ap-005 proach to tackle the environment Read To Fight 006 Monsters (Zhong et al., 2019), a grounded 007 policy learning problem. In RTFM an agent 008 has to reason over a set of rules and a goal, 009 both described in a language manual, and the 010 observations, while taking into account the 011 uncertainty arising from the stochasticity of 012 the environment, in order to generalize suc-013 cessfully its policy to test episodes. We pro-014 vide a sample-efficient proof-of-concept of the 015 model-based approach for the basic dynamic 016 task of RTFM. Furthermore, we show that the 017 main open challenge of RTFM is learning the 018 language-dependent reward function and sug-019 gest that future research should focus primarily 020 on that task. 021",
      "Model-based reinforcement learning has proven highly successful. However, learning a model in isolation from its use during planning is problematic in complex environments. To date, the most effective techniques have instead combined value-equivalent model learning with powerful tree-search methods. This approach is exempli\ufb01ed by MuZero , which has achieved state-of-the-art performance in a wide range of domains, from board games to visually rich environments, with discrete and continuous action spaces, in online and of\ufb02ine settings. However, previous instantiations of this approach were limited to the use of deterministic models. This limits their performance in environments that are inherently stochastic, partially observed, or so large and complex that they appear stochastic to a \ufb01nite agent. In this paper we extend this approach to learn and plan with stochastic models. Specifically, we introduce a new algorithm, Stochastic MuZero , that learns a stochastic model incorporating afterstates, and uses this model to perform a stochastic tree search. Stochastic MuZero matched or exceeded the state of the art in a set of canonical single and multi-agent environments, including 2048 and backgammon, while maintaining the superhuman performance of standard MuZero in the game of Go.",
      "We introduce DeepNash, an autonomous agent that plays the imperfect information game Stratego at a human expert level. Stratego is one of the few iconic board games that artificial intelligence (AI) has not yet mastered. It is a game characterized by a twin challenge: It requires long-term strategic thinking as in chess, but it also requires dealing with imperfect information as in poker. The technique underpinning DeepNash uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego through self-play from scratch. DeepNash beat existing state-of-the-art AI methods in Stratego and achieved a year-to-date (2022) and all-time top-three ranking on the Gravon games platform, competing with human expert players. Description Machine learning to play Stratego Stratego is a popular two-player imperfect information board game. Because of its complexity stemming from its enormous game tree, decision-making under imperfect information, and a piece deployment phase at the start, Stratego poses a challenge for artificial intelligence (AI). Previous computer programs only performed at an amateur level at best. Perolat et al. introduce a model-free multiagent reinforcement learning methodology and show that it can achieve human expert\u2013level performance in Stratego. The present work not only adds to the growing list of games that AI systems can play as well or even better than humans but may also facilitate further applications of reinforcement learning methods in real-world, large-scale multiagent problems that are characterized by imperfect information and thus are currently unsolvable. \u2014YS Reinforcement learning achieves human expert\u2013level performance in the large-scale imperfect information board game Stratego.",
      "Data-efficiency and generalization are key challenges in deep learning and deep reinforcement learning as many models are trained on large-scale, domain-specific, and expensive-to-label datasets. Self-supervised models trained on large-scale uncurated datasets have shown successful transfer to diverse settings. We investigate using pretrained image representations and spatio-temporal attention for state representation learning in Atari. We also explore fine-tuning pretrained representations with self-supervised techniques, i.e., contrastive predictive coding, spatio-temporal contrastive learning, and augmentations. Our results show that pretrained representations are at par with state-of-the-art self-supervised methods trained on domain-specific data. Pretrained representations, thus, yield data and compute-efficient state representations. https://github.com/PAL-ML/PEARL_v1",
      "One of the key promises of model-based reinforcement learning is the ability to generalize using an internal model of the world to make predictions in novel environments and tasks. However, the generalization ability of model-based agents is not well understood because existing work has focused on model-free agents when benchmarking generalization. Here, we explicitly measure the generalization ability of model-based agents in comparison to their model-free counterparts. We focus our analysis on MuZero (Schrittwieser et al., 2020), a powerful model-based agent, and evaluate its performance on both procedural and task generalization. We identify three factors of procedural generalization -- planning, self-supervised representation learning, and procedural data diversity -- and show that by combining these techniques, we achieve state-of-the art generalization performance and data efficiency on Procgen (Cobbe et al., 2019). However, we find that these factors do not always provide the same benefits for the task generalization benchmarks in Meta-World (Yu et al., 2019), indicating that transfer remains a challenge and may require different approaches than procedural generalization. Overall, we suggest that building generalizable agents requires moving beyond the single-task, model-free paradigm and towards self-supervised model-based agents that are trained in rich, procedural, multi-task environments.",
      "Recent developments in the field of model-based RL have proven successful in a range of environments, especially ones where planning is essential. However, such successes have been limited to deterministic fully-observed environments. We present a new approach that handles stochastic and partially-observable environments. Our key insight is to use discrete autoencoders to capture the multiple possible effects of an action in a stochastic environment. We use a stochastic variant of Monte Carlo tree search to plan over both the agent's actions and the discrete latent variables representing the environment's response. Our approach significantly outperforms an offline version of MuZero on a stochastic interpretation of chess where the opponent is considered part of the environment. We also show that our approach scales to DeepMind Lab, a first-person 3D environment with large visual observations and partial observability.",
      "Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). This capability goes beyond visual data: humans are easily able to recognize isolated melodies from musical pieces when heard for the first time, even if the only piece they've listened to previously is from an orchestra. Thus the failure of machine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST \\xrightarrow SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today's best methods but has substantial room for improvement.",
      "State representation learning, or the ability to capture latent generative factors of an environment, is crucial for building intelligent agents that can perform a wide variety of tasks. Learning such representations without supervision from rewards is a challenging open problem. We introduce a method that learns state representations by maximizing mutual information across spatially and temporally distinct features of a neural encoder of the observations. We also introduce a new benchmark based on Atari 2600 games where we evaluate representations based on how well they capture the ground truth state variables. We believe this new framework for evaluating representation learning models will be crucial for future representation learning research. Finally, we compare our technique with other state-of-the-art generative and contrastive representation learning methods. The code associated with this work is available at this https URL",
      "Estimating and optimizing Mutual Information (MI) is core to many problems in machine learning; however, bounding MI in high dimensions is challenging. To establish tractable and scalable objectives, recent work has turned to variational bounds parameterized by neural networks, but the relationships and tradeoffs between these bounds remains unclear. In this work, we unify these recent developments in a single framework. We find that the existing variational lower bounds degrade when the MI is large, exhibiting either high bias or high variance. To address this problem, we introduce a continuum of lower bounds that encompasses previous bounds and flexibly trades off bias and variance. On high-dimensional, controlled problems, we empirically characterize the bias and variance of the bounds and their gradients and demonstrate the effectiveness of our new bounds for estimation and representation learning.",
      "Unsupervised exploration and representation learning become increasingly important when learning in diverse and sparse environments. The information-theoretic principle of empowerment formalizes an unsupervised exploration objective through an agent trying to maximize its influence on the future states of its environment. Previous approaches carry certain limitations in that they either do not employ closed-loop feedback or do not have an internal state. As a consequence, a privileged final state is taken as an influence measure, rather than the full trajectory. We provide a model-free method which takes into account the whole trajectory while still offering the benefits of option-based approaches. We successfully apply our approach to settings with large action spaces, where discovery of meaningful action sequences is particularly difficult.",
      "Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). The failure of ma- chine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST \u2192 SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today\u2019s best methods but has substantial room for improvement.",
      "Mutual information maximization has emerged as a powerful learning objective for unsupervised representation learning obtaining state-of-the-art performance in applications such as object recognition, speech recognition, and reinforcement learning. However, such approaches are fundamentally limited since a tight lower bound of mutual information requires sample size exponential in the mutual information. This limits the applicability of these approaches for prediction tasks with high mutual information, such as in video understanding or reinforcement learning. In these settings, such techniques are prone to overfit, both in theory and in practice, and capture only a few of the relevant factors of variation. This leads to incomplete representations that are not optimal for downstream tasks. In this work, we empirically demonstrate that mutual information-based representation learning approaches do fail to learn complete representations on a number of designed and real-world tasks. To mitigate these problems we introduce the Wasserstein dependency measure, which learns more complete representations by using the Wasserstein distance instead of the KL divergence in the mutual information estimator. We show that a practical approximation to this theoretically motivated solution, constructed using Lipschitz constraint techniques from the GAN literature, achieves substantially improved results on tasks where incomplete representations are a major challenge.",
      "One of the most successful techniques in generative models has been decomposing a complicated generation task into a series of simpler generation tasks. For example, generating an image at a low resolution and then learning to refine that into a high resolution image often improves results substantially. Here we explore a novel strategy for decomposing generation for complicated objects in which we first generate latent variables which describe a subset of the observed variables, and then map from these latent variables to the observed space. We show that this allows us to achieve decoupled training of complicated generative models and present both theoretical and experimental results supporting the benefit of such an approach.",
      "We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.",
      "Estimating and maximizing mutual information (MI) is core to many objectives in machine learning, but tractably lower bounding MI in high dimensions is challenging. Recent work has introduced variational lower bounds with neural networks to attack this problem, but the tradeoffs and relationships between these techniques remains unclear. Here, we present several results that begin to demys-tify these techniques: we show that the bias-corrected gradient in MINE (Belghazi et al., 2018) can be derived as an unbiased gradient of a new lower bound on MI, present a stabler Jensen-Shannon-based training algorithm for the critic, provide a new interpretation of contrastive predictive coding (CPC, van den Oord et al. (2018)) and prove this variant is a lower bound on MI, and demonstrate the batch-size dependence of CPC. Empirically, we show that the effectiveness of these bounds depends on properties of the data being modeled and the structure of the critic, with no one bound uniformly dominating.",
      "Steganography is collection of methods to hide secret information (\"payload\") within non-secret information (\"container\"). Its counterpart, Steganalysis, is the practice of determining if a message contains a hidden payload, and recovering it if possible. Presence of hidden payloads is typically detected by a binary classifier. In the present study, we propose a new model for generating image-like containers based on Deep Convolutional Generative Adversarial Networks (DCGAN). This approach allows to generate more setganalysis-secure message embedding using standard steganography algorithms. Experiment results demonstrate that the new model successfully deceives the steganography analyzer, and for this reason, can be used in steganographic applications."
    ],
    "domain": [
      "Generative Models",
      "Reinforcement Learning",
      "Representation Learning",
      "Machine Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "889412ee-3cc2-4643-8f4b-270de4eee311": {
    "pk": "889412ee-3cc2-4643-8f4b-270de4eee311",
    "name": "Yoshua Bengio",
    "bio": "I am a researcher deeply engaged in the exploration of neural networks and their applications across various domains, particularly focusing on the challenges of catastrophic forgetting, generative models, and deep learning methodologies. My work has investigated the nuances of how neural networks retain knowledge when transitioning between tasks, revealing that dropout algorithms consistently outperform others in balancing the retention of old tasks while adapting to new ones.\n\nI have also contributed to advancements in scene classification by leveraging object detection features, demonstrating significant improvements in accuracy while reducing dimensionality. My research extends to the realm of recommendation systems, where I developed calibration techniques to mitigate biases in off-policy evaluations, particularly in video game matchmaking.\n\nIn the generative modeling space, I introduced multimodal transition distributions for Generative Stochastic Networks (GSNs), enhancing their ability to capture complex data distributions. My work on deep recurrent neural networks (RNNs) has led to novel architectures that improve performance in tasks like polyphonic music prediction and language modeling.\n\nAdditionally, I have explored the intersection of deep learning and affective computing, aiming to model emotions through advanced AI techniques. My commitment to making deep learning accessible is reflected in my tutorials, which demystify complex algorithms for natural language processing.\n\nOverall, my research is driven by a passion for understanding and improving the capabilities of machine learning models, with a focus on practical applications and theoretical advancements that push the boundaries of what is possible in AI.",
    "collaborators": [
      "Aaron C. Courville",
      "I. Goodfellow",
      "Mehdi Mirza",
      "\u00c7aglar G\u00fcl\u00e7ehre",
      "Razvan Pascanu",
      "Pascal Vincent",
      "Eric Thibodeau-Laufer",
      "Raul Chandias Ferrari",
      "Kyunghyun Cho",
      "Vincent Dumoulin",
      "L. Yao",
      "David Warde-Farley",
      "Pascal Lamblin",
      "Yann Dauphin",
      "Xia Da",
      "Gr\u00e9goire Mesnil",
      "Salah Rifai",
      "Antoine Bordes",
      "Xavier Glorot",
      "Li Yao",
      "Olivier Delalleau",
      "Sherjil Ozair",
      "J. Bergstra",
      "Fr\u00e9d\u00e9ric Bastien",
      "H. P. Mart\u00ednez",
      "Georgios N. Yannakakis",
      "Samira Ebrahimi Kahou",
      "C. Pal",
      "Xavier Bouthillier",
      "Pierre Froumenty",
      "R. Memisevic",
      "S\u00e9bastien Jean",
      "P. Carrier",
      "Nicolas Boulanger-Lewandowski",
      "Abhishek Aggarwal",
      "Jeremie Zumer",
      "Jean-Philippe Raymond",
      "Guillaume Desjardins",
      "Atousa Torabi",
      "Arjun Sharma",
      "Emmanuel Bengio",
      "K. Konda",
      "Zhenzhou Wu",
      "R. Socher",
      "Christopher D. Manning",
      "Guillaume Alain",
      "J. Yosinski",
      "Nicholas L\u00e9onard"
    ],
    "pub_titles": [
      "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
      "Unsupervised and Transfer Learning under Uncertainty - From Object Detections to Scene Categorization",
      "Stacked calibration of off-policy policy evaluation for video game matchmaking",
      "On the Challenges of Physical Implementations of RBMs",
      "Multimodal Transitions for Generative Stochastic Networks",
      "Pylearn2: a machine learning research library",
      "Big Neural Networks Waste Capacity",
      "Estimating or Propagating Gradients Through Stochastic Neurons",
      "Learning deep physiological models of affect",
      "Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning",
      "Combining modality specific deep neural networks for emotion recognition in video",
      "Knowledge Matters: Importance of Prior Information for Optimization",
      "How to Construct Deep Recurrent Neural Networks",
      "Multi-Prediction Deep Boltzmann Machines",
      "Deep Learning for NLP (without Magic)",
      "Bounding the Test Log-Likelihood of Generative Models",
      "Deep Generative Stochastic Networks Trainable by Backprop",
      "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"
    ],
    "pub_abstracts": [
      "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
      "Classifying scenes (e.g. into \u201cstreet\u201d, \u201chome\u201d or \u201cleisure\u201d) is an important but complicated task nowadays, because images come with variability, ambiguity, and a wide range of illumination or scale conditions. Standard approaches build an intermediate representation of the global image and learn classifiers on it. Recently, it has been proposed to depict an image as an aggregation of its contained objects:the representation on which classifiers are trained is composed of many heterogeneous feature vectors derived from various object detectors. In this paper, we propose to study different approaches to efficiently combine the data extracted by these detectors. We use the features provided by Object-Bank (Li-Jia Li and Fei-Fei, 2010a) (177 different object detectors producing 252 attributes each), and show on several benchmarks for scene categorization that careful combinations, taking into account the structure of the data, allows to greatly improve over original results (from +5% to +11%) while drastically reducing the dimensionality of the representation by 97% (from",
      "We consider an industrial strength application of recommendation systems for video-game matchmaking in which off-policy policy evaluation is important but where standard approaches can hardly be applied. The objective of the policy is to sequentially form teams of players from those waiting to be matched, in such a way as to produce well-balanced matches. Unfortunately, the available training data comes from a policy that is not known perfectly and that is not stochastic, making it impossible to use methods based on importance weights. Furthermore, we observe that when the estimated reward function and the policy are obtained by training from the same off-policy dataset, the policy evaluation using the estimated reward function is biased. We present a simple calibration procedure that is similar to stacked regression and that removes most of the bias, in the experiments we performed. Data collected during beta tests of Ghost Recon Online, a first person shooter from Ubisoft, were used for the experiments.",
      "    Restricted Boltzmann machines (RBMs) are powerful machine learning models, but learning and some kinds of inference in the model require sampling-based approximations, which, in classical digital computers, are implemented using expensive MCMC. Physical computation offers the opportunity to reduce the costof sampling by building physical systems whose natural dynamics correspond to drawing samples from the desired RBM distribution. Such a system avoids the burn-in and mixing cost of a Markov chain. However, hardware implementations of this variety usually entail limitations such as low-precision and limited range of the parameters and restrictions on the size and topology of the RBM. We conduct software simulations to determine how harmful each of these restrictions is. Our simulations are based on the D-Wave Two computer, but the issues we investigate arise in most forms of physical computation.Our findings suggest that designers of new physical computing hardware and algorithms for physical computers should focus their efforts on overcoming the limitations imposed by the topology restrictions of currently existing physical computers.   ",
      "Generative Stochastic Networks (GSNs) have been recently introduced as an alternative to traditional probabilistic modeling: instead of parametrizing the data distribution directly, one parametrizes a transition operator for a Markov chain whose stationary distribution is an estimator of the data generating distribution. The result of training is therefore a machine that generates samples through this Markov chain. However, the previously introduced GSN consistency theorems suggest that in order to capture a wide class of distributions, the transition operator in general should be multimodal, something that has not been done before this paper. We introduce for the first time multimodal transition distributions for GSNs, in particular using models in the NADE family (Neural Autoregressive Density Estimator) as output distributions of the transition operator. A NADE model is related to an RBM (and can thus model multimodal distributions) but its likelihood (and likelihood gradient) can be computed easily. The parameters of the NADE are obtained as a learned function of the previous state of the learned Markov chain. Experiments clearly illustrate the advantage of such multimodal transition distributions over unimodal GSNs.",
      "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
      "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact there are highly diminishing returns for capacity in terms of training error, leading to underfitting. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.",
      "Stochastic neurons can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such s tochastic neurons, i.e., can we \u201cback-propagate\u201d through these stochastic neurons? We examine this question, existing approaches, and present two novel families of solutions, applicable in different settings. In particular, it is demonstrate d that a simple biologically plausible formula gives rise to an an unbiased (but noisy) estimator of the gradient with respect to a binary stochastic neuron firing proba bility. Unlike other estimators which view the noise as a small perturbation in order to estimate gradients by finite differences, this estimator is unbiased even w ithout assuming that the stochastic perturbation is small. This estimator is also in teresting because it can be applied in very general settings which do not allow gradient back-propagation, including the estimation of the gradient with respect to futur e rewards, as required in reinforcement learning setups. We also propose an approach to approximating this unbiased but high-variance estimator by learning to predict it using a biased estimator. The second approach we propose assumes that an estimator of the gradient can be back-propagated and it provides an unbiased estimator of the gradient, but can only work with non-linearities unlike the hard threshold, but like the rectifier, that are not flat for all of their range. This is similar to trad itional sigmoidal units but has the advantage that for many inputs, a hard decision (e.g., a 0 output) can be produced, which would be convenient for conditional computation and achieving sparse representations and sparse gradients.",
      "More than 15 years after the early studies in Affective Computing (AC), [1] the problem of detecting and modeling emotions in the context of human-computer interaction (HCI) remains complex and largely unexplored. The detection and modeling of emotion is, primarily, the study and use of artificial intelligence (AI) techniques for the construction of computational models of emotion. The key challenges one faces when attempting to model emotion [2] are inherent in the vague definitions and fuzzy boundaries of emotion, and in the modeling methodology followed. In this context, open research questions are still present in all key components of the modeling process. These include, first, the appropriateness of the modeling tool employed to map emotional manifestations and responses to annotated affective states; second, the processing of signals that express these manifestations (i.e., model input); and third, the way affective annotation (i.e., model output) is handled. This paper touches upon all three key components of an affective model (i.e., input, model, output) and introduces the use of deep learning (DL) [3], [4], [5] methodologies for affective modeling from multiple physiological signals.",
      "We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.",
      "In this paper we present the techniques used for the University of Montr\u00e9al's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds, including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities, including: (1) a deep convolutional neural network for the analysis of facial expressions within video frames; (2) a deep belief net to capture audio information; (3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the mouth of the primary human subject in the scene. We discuss each of these techniques, their performance characteristics and different strategies to aggregate their predictions. Our best single model was a convolutional neural network trained to predict emotions from static frames using two large data sets, the Toronto Face Database and our own set of faces images harvested from Google image search, followed by a per frame aggregation strategy that used the challenge training data. This yielded a test set accuracy of 35.58%. Using our best strategy for aggregating our top performing models into a single predictor we were able to produce an accuracy of 41.03% on the challenge test set. These compare favorably to the challenge baseline test set accuracy of 27.56%.",
      "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {\\em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.",
      "In this paper, we explore different ways to extend a recurrent neural network (RNN) to a \\textit{deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.",
      "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
      "Machine learning is everywhere in today\u2019s NLP, but by and large machine learning amounts to numerical optimization of weights for human designed representations and features. The goal of deep learning is to explore how computers can take advantage of data to develop features and representations appropriate for complex interpretation tasks. This tutorial aims to cover the basic motivation, ideas, models and learning algorithms in deep learning for natural language processing. Recently, these methods have been shown to perform very well on various NLP tasks such as language modeling, POS tagging, named entity recognition, sentiment analysis and paraphrase detection, among others. The most attractive quality of these techniques is that they can perform well without any external hand-designed resources or time-intensive feature engineering. Despite these advantages, many researchers in NLP are not familiar with these methods. Our focus is on insight and understanding, using graphical illustrations and simple, intuitive derivations. The goal of the tutorial is to make the inner workings of these techniques transparent, intuitive and their results interpretable, rather than black boxes labeled \u201dmagic here\u201d. The first part of the tutorial presents the basics of neural networks, neural word vectors, several simple models based on local windows and the math and algorithms of training via backpropagation. In this section applications include language modeling and POS tagging. In the second section we present recursive neural networks which can learn structured tree outputs as well as vector representations for phrases and sentences. We cover both equations as well as applications. We show how training can be achieved by a modified version of the backpropagation algorithm introduced before. These modifications allow the algorithm to work on tree structures. Applications include sentiment analysis and paraphrase detection. We also draw connections to recent work in semantic compositionality in vector spaces. The principle goal, again, is to make these methods appear intuitive and interpretable",
      "Several interesting generative learning algorithms involve a complex probability distribution over many random variables, involving intractable normalization constants or latent variable normalization. Some of them may even not have an analytic expression for the unnormalized probability function and no tractable approximation. This makes it difficult to estimate the quality of these models, once they have been trained, or to monitor their quality (e.g. for early stopping) while training. A previously proposed method is based on constructing a non-parametric density estimator of the model's probability function from samples generated by the model. We revisit this idea, propose a more efficient estimator, and prove that it provides a lower bound on the true test log-likelihood, and an unbiased estimator as the number of generated samples goes to infinity, although one that incorporates the effect of poor mixing. We further propose a biased variant of the estimator that can be used reliably with a finite number of samples for the purpose of model comparison.",
      "We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining.",
      "Stochastic neurons and hard non-linearities can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we \"back-propagate\" through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of {\\em conditional computation}, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful."
    ],
    "domain": [
      "Deep Learning",
      "Neural Networks",
      "Affective Computing",
      "Generative Models"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "994cf795-e9b3-43d1-a6ea-faa7ecb19355": {
    "pk": "994cf795-e9b3-43d1-a6ea-faa7ecb19355",
    "name": "Geoffrey Hinton",
    "bio": "I am a researcher dedicated to advancing the fields of computer vision and machine learning through innovative methodologies and frameworks. My recent work focuses on unifying diverse computer vision tasks, such as object detection and image captioning, under a shared pixel-to-sequence interface. This approach allows for a single model architecture to handle multiple tasks without the need for task-specific customizations, demonstrating competitive performance against specialized models.\n\nI have also explored dynamic evaluation techniques for language models, introducing Fast Weight Layers (FWLs) that enhance performance while minimizing computational costs. My research extends to novel learning procedures, such as the Forward-Forward algorithm, which simplifies the training process by utilizing two forward passes instead of traditional backpropagation.\n\nIn addition, I have developed innovative solutions for panoptic segmentation and discrete data generation through diffusion models, achieving state-of-the-art results in various benchmarks. My work on representation learning in medical AI, particularly the REMEDIS framework, addresses the challenges of data-efficient generalization, significantly improving diagnostic accuracy with minimal retraining data.\n\nI am passionate about creating flexible and efficient learning frameworks that not only enhance model performance but also provide insights into the underlying processes of neural networks. My goal is to bridge the gap between complex tasks and effective learning strategies, ultimately contributing to the broader impact of AI in real-world applications.",
    "collaborators": [
      "David J. Fleet",
      "Ting Chen",
      "Simon Kornblith",
      "Mohammad Norouzi",
      "Saurabh Saxena",
      "Lala Li",
      "Shekoofeh Azizi",
      "J. Freyberg",
      "Sebastien Baur",
      "S. S. Mahdavi",
      "Ellery Wulczyn",
      "Boris Babenko",
      "Aaron Loh",
      "Po-Hsuan Cameron Chen",
      "Yuan Liu",
      "Pinal Bavishi",
      "S. McKinney",
      "Jim Winkens",
      "Abhijit Guha Roy",
      "Zach Beaver",
      "Justin D. Krogue",
      "M. Etemadi",
      "Umesh Telang",
      "Yun Liu",
      "L. Peng",
      "G. Corrado",
      "D. Webster",
      "N. Houlsby",
      "A. Karthikesalingam",
      "Vivek Natarajan",
      "Mengye Ren",
      "Renjie Liao",
      "S. Sabour",
      "Richard F. Rashid",
      "Laura Culp",
      "Basil Mustafa",
      "Nenad Toma\u0161ev",
      "Jovana Mitrovic",
      "Patricia Strachan",
      "Megan Walker",
      "Fiona Ryan",
      "R. Gartner",
      "Jessica Bundy",
      "Maria Jung",
      "Tyler J King",
      "Jane B. Sprott",
      "Fernando \u00c1vila",
      "J. Briggs",
      "Daniel Konikof",
      "Alex Luscombe",
      "Audrey Macklin",
      "H. Pelvin",
      "Tsung-Yi Lin",
      "Kevin Clark",
      "Kelvin Guu",
      "Ming-Wei Chang",
      "Panupong Pasupat",
      "Ruixiang Zhang",
      "Laura J. Culp",
      "L. Culp",
      "B. Mustafa",
      "Patricia MacWilliams",
      "Megan Wilson",
      "F. Ryan",
      "Xiaodong He",
      "Jianfeng Gao",
      "L. Deng",
      "S. Yih",
      "Yu",
      "J. Markoff",
      "Dong Yu",
      "Yoshua Bengio",
      "Yann LeCun",
      "A. Tagliasacchi",
      "S. Yazdani",
      "Geoffrey I. Webb",
      "Johannes F\u00fcrnkranz",
      "Claude Sammut",
      "Joerg Sander",
      "M. Vlachos",
      "Yee Whye Teh",
      "Ying Yang",
      "D. Mladen\u00ed",
      "J. Brank",
      "M. Grobelnik",
      "Ying Zhao",
      "G. Karypis",
      "Susan Craw",
      "M. Puterman",
      "J. Patrick",
      "Aniruddh Raghu",
      "M. Raghu",
      "D. Duvenaud"
    ],
    "pub_titles": [
      "Volume 19, Number 5",
      "A Unified Sequence Interface for Vision Tasks",
      "Meta-Learning Fast Weight Language Models",
      "The Forward-Forward Algorithm: Some Preliminary Investigations",
      "Scaling Forward Gradient With Local Losses",
      "A Generalist Framework for Panoptic Segmentation of Images and Videos",
      "Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning",
      "Gaussian-Bernoulli RBMs Without Tears",
      "Testing GLOM's ability to infer wholes from ambiguous parts",
      "Robust and Efficient Medical Imaging with Self-Supervision",
      "Pix2seq: A Language Modeling Framework for Object Detection",
      "Deep Learning for Natural Language Processing",
      "How to Represent Part-Whole Hierarchies in a Neural Network",
      "Deep learning for AI",
      "Unsupervised part representation by Flow Capsules",
      "The Next Generation of Neural Networks",
      "Teaching with Commentaries"
    ],
    "pub_abstracts": [
      "September/October 2023",
      "While language tasks are naturally expressed in a single, unified, modeling framework, i.e., generating sequences of tokens, this has not been the case in computer vision. As a result, there is a proliferation of distinct architectures and loss functions for different vision tasks. In this work we show that a diverse set of\"core\"computer vision tasks can also be unified if formulated in terms of a shared pixel-to-sequence interface. We focus on four tasks, namely, object detection, instance segmentation, keypoint detection, and image captioning, all with diverse types of outputs, e.g., bounding boxes or dense masks. Despite that, by formulating the output of each task as a sequence of discrete tokens with a unified interface, we show that one can train a neural network with a single model architecture and loss function on all these tasks, with no task-specific customization. To solve a specific task, we use a short prompt as task description, and the sequence output adapts to the prompt so it can produce task-specific output. We show that such a model can achieve competitive performance compared to well-established task-specific models.",
      "Dynamic evaluation of language models (LMs) adapts model parameters at test time using gradient information from previous tokens and substantially improves LM performance. However, it requires over 3x more compute than standard inference. We present Fast Weight Layers (FWLs), a neural component that provides the benefits of dynamic evaluation much more efficiently by expressing gradient updates as linear attention. A key improvement over dynamic evaluation is that FWLs can also be applied at training time, so the model learns to make good use of gradient updates. FWLs can easily be added on top of existing transformer models, require relatively little extra compute or memory to run, and significantly improve language modeling perplexity.",
      "The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation. The Forward-Forward algorithm replaces the forward and backward passes of backpropagation by two forward passes, one with positive (i.e. real) data and the other with negative data which could be generated by the network itself. Each layer has its own objective function which is simply to have high goodness for positive data and low goodness for negative data. The sum of the squared activities in a layer can be used as the goodness but there are many other possibilities, including minus the sum of the squared activities. If the positive and negative passes could be separated in time, the negative passes could be done offline, which would make the learning much simpler in the positive pass and allow video to be pipelined through the network without ever storing activities or stopping to propagate derivatives.",
      "Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. However, the standard forward gradient algorithm, when applied naively, suffers from high variance when the number of parameters to be learned is large. In this paper, we propose a series of architectural and algorithmic modifications that together make forward gradient learning practical for standard deep learning benchmark tasks. We show that it is possible to substantially reduce the variance of the forward gradient estimator by applying perturbations to activations rather than weights. We further improve the scalability of forward gradient by introducing a large number of local greedy loss functions, each of which involves only a small number of learnable parameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more suitable for local learning. Our approach matches backprop on MNIST and CIFAR-10 and significantly outperforms previously proposed backprop-free algorithms on ImageNet.",
      "Panoptic segmentation assigns semantic and instance ID labels to every pixel of an image. As permutations of instance IDs are also valid solutions, the task requires learning of high-dimensional one-to-many mapping. As a result, state-of-the-art approaches use customized architectures and task-specific loss functions. We formulate panoptic segmentation as a discrete data generation problem, without relying on inductive bias of the task. A diffusion model is proposed to model panoptic masks, with a simple architecture and generic loss function. By simply adding past predictions as a conditioning signal, our method is capable of modeling video (in a streaming setting) and thereby learns to track object instances automatically. With extensive experiments, we demonstrate that our simple approach can perform competitively to state-of-the-art specialist methods in similar settings. 1",
      "We present Bit Diffusion: a simple and generic approach for generating discrete data with continuous state and continuous time diffusion models. The main idea behind our approach is to first represent the discrete data as binary bits, and then train a continuous diffusion model to model these bits as real numbers which we call analog bits. To generate samples, the model first generates the analog bits, which are then thresholded to obtain the bits that represent the discrete variables. We further propose two simple techniques, namely Self-Conditioning and Asymmetric Time Intervals, which lead to a significant improvement in sample quality. Despite its simplicity, the proposed approach can achieve strong performance in both discrete image generation and image captioning tasks. For discrete image generation, we significantly improve previous state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens) and ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the best autoregressive model in both sample quality (measured by FID) and efficiency. For image captioning on MS-COCO dataset, our approach achieves competitive results compared to autoregressive models.",
      "We revisit the challenging problem of training Gaussian-Bernoulli restricted Boltzmann machines (GRBMs), introducing two innovations. We propose a novel Gibbs-Langevin sampling algorithm that outperforms existing methods like Gibbs sampling. We propose a modified contrastive divergence (CD) algorithm so that one can generate images with GRBMs starting from noise. This enables direct comparison of GRBMs with deep generative models, improving evaluation protocols in the RBM literature. Moreover, we show that modified CD and gradient clipping are enough to robustly train GRBMs with large learning rates, thus removing the necessity of various tricks in the literature. Experiments on Gaussian Mixtures, MNIST, FashionMNIST, and CelebA show GRBMs can generate good samples, despite their single-hidden-layer architecture. Our code is released at: \\url{https://github.com/lrjconan/GRBM}.",
      "The GLOM architecture proposed by Hinton [2021] is a recurrent neural network for parsing an image into a hierarchy of wholes and parts. When a part is ambiguous, GLOM assumes that the ambiguity can be resolved by allowing the part to make multi-modal predictions for the pose and identity of the whole to which it belongs and then using attention to similar predictions coming from other possibly ambiguous parts to settle on a common mode that is predicted by several different parts. In this study, we describe a highly simplified version of GLOM that allows us to assess the effectiveness of this way of dealing with ambiguity. Our results show that, with supervised training, GLOM is able to successfully form islands of very similar embedding vectors for all of the locations occupied by the same object and it is also robust to strong noise injections in the input and to out-of-distribution input transformations.",
      "Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal\"out-of-distribution\"performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and expensive to annotate [2]. Thus, the problem of\"data-efficient generalization\"presents an ongoing difficulty for Medical AI development. Although progress in representation learning shows promise, their benefits have not been rigorously studied, specifically for out-of-distribution settings. To meet these challenges, we present REMEDIS, a unified representation learning strategy to improve robustness and data-efficiency of medical imaging AI. REMEDIS uses a generic combination of large-scale supervised transfer learning with self-supervised learning and requires little task-specific customization. We study a diverse range of medical imaging tasks and simulate three realistic application scenarios using retrospective data. REMEDIS exhibits significantly improved in-distribution performance with up to 11.5% relative improvement in diagnostic accuracy over a strong supervised baseline. More importantly, our strategy leads to strong data-efficient generalization of medical imaging AI, matching strong supervised baselines using between 1% to 33% of retraining data across tasks. These results suggest that REMEDIS can significantly accelerate the life-cycle of medical imaging AI development thereby presenting an important step forward for medical imaging AI to deliver broad impact.",
      "We present Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, we cast object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural network to perceive the image and generate the desired sequence. Our approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task-specific data augmentations, our approach makes minimal assumptions about the task, yet it achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms.",
      ",",
      "Abstract This article does not describe a working system. Instead, it presents a single idea about representation that allows advances made by several different groups to be combined into an imaginary system called GLOM.1 The advances include transformers, neural fields, contrastive representation learning, distillation, and capsules. GLOM answers the question: How can a neural network with a fixed architecture parse an image into a part-whole hierarchy that has a different structure for each image? The idea is simply to use islands of identical vectors to represent the nodes in the parse tree. If GLOM can be made to work, it should significantly improve the interpretability of the representations produced by transformer-like systems when applied to vision or language.",
      "How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?",
      "Capsule networks are designed to parse an image into a hierarchy of objects, parts and relations. While promising, they remain limited by an inability to learn effective low level part descriptions. To address this issue we propose a novel self-supervised method for learning part descriptors of an image. During training, we exploit motion as a powerful perceptual cue for part definition, using an expressive decoder for part generation and layered image formation with occlusion. Experiments demonstrate robust part discovery in the presence of multiple objects, cluttered backgrounds, and significant occlusion. The resulting part descriptors, a.k.a. part capsules, are decoded into shape masks, filling in occluded pixels, along with relative depth on single images. We also report unsupervised object classification using our capsule parts in a stacked capsule autoencoder.",
      "The most important unsolved problem with artificial neural networks is how to do unsupervised learning as effectively as the brain. There are currently two main approaches to unsupervised learning. In the first approach, exemplified by BERT and Variational Autoencoders, a deep neural network is used to reconstruct its input. This is problematic for images because the deepest layers of the network need to encode the fine details of the image. An alternative approach, introduced by Becker and Hinton in 1992, is to train two copies of a deep neural network to produce output vectors that have high mutual information when given two different crops of the same image as their inputs. This approach was designed to allow the representations to be untethered from irrelevant details of the input. The method of optimizing mutual information used by Becker and Hinton was flawed (for a subtle reason that I will explain) so Pacannaro and Hinton (2001) replaced it by a discriminative objective in which one vector representation must select a corresponding vector representation from among many alternatives. With faster hardware, contrastive learning of representations has recently become very popular and is proving to be very effective, but it suffers from a major flaw: To learn pairs of representation vectors that have N bits of mutual information we need to contrast the correct corresponding vector with about 2N incorrect alternatives. I will describe a novel and effective way of dealing with this limitation. I will also show that this leads to a simple way of implementing perceptual learning in cortex.",
      "Effective training of deep neural networks can be challenging, and there remain many open questions on how to best learn these models. Recently developed methods to improve neural network training examine teaching: providing learned information during the training process to improve downstream model performance. In this paper, we take steps towards extending the scope of teaching. We propose a flexible teaching framework using commentaries, meta-learned information helpful for training on a particular task or dataset. We present an efficient and scalable gradient-based method to learn commentaries, leveraging recent work on implicit differentiation. We explore diverse applications of commentaries, from learning weights for individual training examples, to parameterizing label-dependent data augmentation policies, to representing attention masks that highlight salient image regions. In these settings, we find that commentaries can improve training speed and/or performance and also provide fundamental insights about the dataset and training process."
    ],
    "domain": [
      "Computer Vision",
      "Natural Language Processing",
      "Neural Networks",
      "Representation Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "be76cb2d-9483-49ba-93e3-29c96509ab30": {
    "pk": "be76cb2d-9483-49ba-93e3-29c96509ab30",
    "name": "Oriol Vinyals",
    "bio": "I am a researcher deeply engaged in the intersection of multimodal machine learning and generative models, with a focus on enhancing the understanding and performance of complex tasks such as event argument role labeling (EARL) and long-context reasoning. My recent work, including the development of GenEARL, showcases my commitment to creating innovative frameworks that leverage generative models to improve performance in challenging tasks without the need for extensive training data. \n\nI have also contributed to the Gemini family of models, which excel in multimodal reasoning and have set new benchmarks in medical applications, demonstrating the potential of AI in critical domains. My exploration of lightweight models, such as Gemma, reflects my dedication to making advanced AI accessible and efficient. \n\nIn addition to my work on specific models, I am interested in understanding the dynamics of large language models and their multitasking capabilities. My research has revealed insights into task competition and the emergence of abilities in these models, paving the way for more effective training strategies. \n\nI am passionate about applying my findings to real-world challenges, such as improving weather forecasting with GraphCast and optimizing video compression using reinforcement learning. My goal is to push the boundaries of what is possible in AI, ensuring that our models not only perform well but also adapt seamlessly to new tasks and domains.",
    "collaborators": [
      "Sebastian Borgeaud",
      "Katie Millican",
      "Jean-Baptiste Alayrac",
      "Elena Buchatskaya",
      "Julian Schrittwieser",
      "Roman Ring",
      "Eliza Rutherford",
      "Zhitao Gong",
      "Tom Hennigan",
      "Eric Noland",
      "D. Hassabis",
      "Karsten Roth",
      "Zeynep Akata",
      "Antoine Miech",
      "Iain Barr",
      "Karel Lenc",
      "A. Mensch",
      "Malcolm Reynolds",
      "Sina Samangooei",
      "Andy Brock",
      "Andrew Zisserman",
      "Lisa Anne Hendricks",
      "Machel Reid",
      "Eli Collins",
      "Siamak Shakeri",
      "Aakanksha Chowdhery",
      "Petko Georgiev",
      "Jean-Baptiste Lespiau",
      "Charline Le Lan",
      "Paul Michel",
      "Evan Senter",
      "Mateo Wirth",
      "Amol Mandhane",
      "Minh Giang",
      "R. Comanescu",
      "Alek Andreev",
      "K. Kavukcuoglu",
      "Joelle Barral",
      "D. Mankowitz",
      "A. Zhernov",
      "T. Hubert",
      "Jeff Donahue",
      "Pauline Luc",
      "Yana Hasson",
      "Serkan Cabi",
      "Tengda Han",
      "Marianne Monteiro",
      "Jacob Menick",
      "Aida Nematzadeh",
      "Sahand Sharifzadeh",
      "Ricardo Barreira",
      "Tom Brown",
      "Benjamin Mann",
      "Jared Kaplan",
      "Pranav Shyam",
      "Jordan Hoffmann",
      "Trevor Cai",
      "Diego de",
      "Las Casas",
      "Johannes Welbl",
      "Aidan Clark",
      "Rohan Anil",
      "P. Barham",
      "Ross McIlroy",
      "Melvin Johnson",
      "Erica Moreira",
      "H. Michalewski",
      "James Keeling",
      "Oscar Chang",
      "George Tucker",
      "Tom\u00e1s Kocisk\u00fd",
      "Evgenii Eltyshev",
      "Ambrose Slone",
      "Ben Caine",
      "J Christopher Love",
      "N. Houlsby",
      "Luheng He",
      "Yong Cheng",
      "Yujia Li",
      "Albert Webson",
      "Rahma Chaabouni",
      "T. Paine",
      "Behnam Neyshabur",
      "Jack W. Rae",
      "Boxi Wu",
      "Basil Mustafa",
      "Emilio Parisotto",
      "Chenjie Gu",
      "A. Pritzel",
      "J. Mao-Jones",
      "Hannah Sheahan",
      "James Svensson",
      "Bogdan Damoc",
      "George van den Driessche",
      "Justin Chiu",
      "Adri\u00e0 Recasens",
      "S'ebastien M. R. Arnold",
      "Lisa Lee",
      "Kartikeya Badola",
      "Joshua Newlan"
    ],
    "pub_titles": [
      "GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling",
      "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "Capabilities of Gemini Models in Medicine",
      "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
      "Gemma: Open Models Based on Gemini Research and Technology",
      "A Practitioner's Guide to Continual Multimodal Pretraining",
      "Gemma 2: Improving Open Language Models at a Practical Size",
      "AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning",
      "Waffling around for Performance: Visual Classification with Random Words and Broad Concepts",
      "Learning skillful medium-range global weather forecasting",
      "Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model",
      "Optimizing Memory Mapping Using Deep Reinforcement Learning",
      "General-purpose, long-context autoregressive modeling with Perceiver AR",
      "Flamingo: a Visual Language Model for Few-Shot Learning",
      "Hierarchical Perceiver",
      "Non-isotropy Regularization for Proxy-based Deep Metric Learning",
      "A Generalist Agent",
      "MuZero with Self-competition for Rate Control in VP9 Video Compression"
    ],
    "pub_abstracts": [
      "Multimodal event argument role labeling (EARL), a task that assigns a role for each event participant (object) in an image is a complex challenge. It requires reasoning over the entire image, the depicted event, and the interactions between various objects participating in the event. Existing models heavily rely on high-quality event-annotated training data to understand the event semantics and structures, and they fail to generalize to new event types and domains. In this paper, we propose GenEARL, a training-free generative framework that harness the power of the modern generative models to understand event task descriptions given image contexts to perform the EARL task. Specifically, GenEARL comprises two stages of generative prompting with a frozen vision-language model (VLM) and a frozen large language model (LLM). First, a generative VLM learns the semantics of the event argument roles and generates event-centric object descriptions based on the image. Subsequently, a LLM is prompted with the generated object descriptions with a predefined template for EARL (i.e., assign an object with an event argument role). We show that GenEARL outperforms the contrastive pretraining (CLIP) baseline by 9.4% and 14.2% accuracy for zero-shot EARL on the M2E2 and SwiG datasets, respectively. In addition, we outperform CLIP-Event by 22% precision on M2E2 dataset. The framework also allows flexible adaptation and generalization to unseen domains.",
      "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
      "Excellence in a wide variety of medical applications poses considerable challenges for AI, requiring advanced reasoning, access to up-to-date medical knowledge and understanding of complex multimodal data. Gemini models, with strong general capabilities in multimodal and long-context reasoning, offer exciting possibilities in medicine. Building on these core strengths of Gemini, we introduce Med-Gemini, a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly use web search, and that can be efficiently tailored to novel modalities using custom encoders. We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health&medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. Taken together, our results offer compelling evidence for Med-Gemini's potential, although further rigorous evaluation will be crucial before real-world deployment in this safety-critical domain.",
      "Large language models exhibit strong multi-tasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows, large language models exhibit emerging abilities where certain tasks can abruptly jump from poor to respectable performance. Such phenomena motivate a deeper understanding of how individual tasks evolve during multitasking. To this aim, we study a multitask representation learning setup where tasks can have distinct distributions , quantified by their covariance priors. Through random matrix theory, we precisely characterize the optimal linear representation for few-shot learning that minimizes the average test risk in terms of task covariances. When tasks have equal sample sizes, we prove a reduction to an equivalent problem with a single effective covariance from which the individual task risks of the original problem can be deduced. Importantly, we introduce \u201c task competition \u201d to explain how tasks with dominant covariance eigen-spectrum emerge faster than others. We show that task competition can potentially explain the inverse scaling of certain tasks i.e. reduced test accuracy as the model grows. Overall, this work sheds light on the risk and emergence of individual tasks and uncovers new high-dimensional phenomena (including multiple-descent risk curves) that arise in multitask representation learning.",
      "This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.",
      "Multimodal foundation models serve numerous applications at the intersection of vision and language. Still, despite being pretrained on extensive data, they become outdated over time. To keep models updated, research into continual pretraining mainly explores scenarios with either (1) infrequent, indiscriminate updates on large-scale new data, or (2) frequent, sample-level updates. However, practical model deployment often operates in the gap between these two limit cases, as real-world applications often demand adaptation to specific subdomains, tasks or concepts -- spread over the entire, varying life cycle of a model. In this work, we complement current perspectives on continual pretraining through a research test bed as well as provide comprehensive guidance for effective continual model updates in such scenarios. We first introduce FoMo-in-Flux, a continual multimodal pretraining benchmark with realistic compute constraints and practical deployment requirements, constructed over 63 datasets with diverse visual and semantic coverage. Using FoMo-in-Flux, we explore the complex landscape of practical continual pretraining through multiple perspectives: (1) A data-centric investigation of data mixtures and stream orderings that emulate real-world deployment situations, (2) a method-centric investigation ranging from simple fine-tuning and traditional continual learning strategies to parameter-efficient updates and model merging, (3) meta learning rate schedules and mechanistic design choices, and (4) the influence of model and compute scaling. Together, our insights provide a practitioner's guide to continual multimodal pretraining for real-world deployment. Our benchmark and code is here: https://github.com/ExplainableML/fomo_in_flux.",
      "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community.",
      "StarCraft II is one of the most challenging simulated reinforcement learning environments; it is partially observable, stochastic, multi-agent, and mastering StarCraft II requires strategic planning over long time horizons with real-time low-level execution. It also has an active professional competitive scene. StarCraft II is uniquely suited for advancing offline RL algorithms, both because of its challenging nature and because Blizzard has released a massive dataset of millions of StarCraft II games played by human players. This paper leverages that and establishes a benchmark, called AlphaStar Unplugged, introducing unprecedented challenges for offline reinforcement learning. We define a dataset (a subset of Blizzard's release), tools standardizing an API for machine learning methods, and an evaluation protocol. We also present baseline agents, including behavior cloning, offline variants of actor-critic and MuZero. We improve the state of the art of agents using only offline data, and we achieve 90% win rate against previously published AlphaStar behavior cloning agent.",
      "The visual classification performance of vision-language models such as CLIP has been shown to benefit from additional semantic knowledge from large language models (LLMs) such as GPT-3. In particular, averaging over LLM-generated class descriptors, e.g. \"waffle, which has a round shape\", can notably improve generalization performance. In this work, we critically study this behavior and propose WaffleCLIP, a framework for zero-shot visual classification which simply replaces LLM-generated descriptors with random character and word descriptors. Without querying external models, we achieve comparable performance gains on a large number of visual classification tasks. This allows WaffleCLIP to both serve as a low-cost alternative, as well as a sanity check for any future LLM-based vision-language model extensions. We conduct an extensive experimental study on the impact and shortcomings of additional semantics introduced with LLM-generated descriptors, and showcase how - if available - semantic context is better leveraged by querying LLMs for high-level concepts, which we show can be done to jointly resolve potential class name ambiguities. Code is available here: https://github.com/ExplainableML/WaffleCLIP.",
      "Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning\u2013based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25\u00b0 resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. Editor\u2019s summary The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning\u2013based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. \u2014H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting.",
      "Training deep networks requires various design decisions regarding for instance their architecture, data augmentation, or optimization. In this work, we find these training variations to result in networks learning unique feature sets from the data. Using public model libraries comprising thousands of models trained on canonical datasets like ImageNet, we observe that for arbitrary pairings of pretrained models, one model extracts significant data context unavailable in the other -- independent of overall performance. Given any arbitrary pairing of pretrained models and no external rankings (such as separate test sets, e.g. due to data privacy), we investigate if it is possible to transfer such\"complementary\"knowledge from one model to another without performance degradation -- a task made particularly difficult as additional knowledge can be contained in stronger, equiperformant or weaker models. Yet facilitating robust transfer in scenarios agnostic to pretrained model pairings would unlock auxiliary gains and knowledge fusion from any model repository without restrictions on model and problem specifics - including from weaker, lower-performance models. This work therefore provides an initial, in-depth exploration on the viability of such general-purpose knowledge transfer. Across large-scale experiments, we first reveal the shortcomings of standard knowledge distillation techniques, and then propose a much more general extension through data partitioning for successful transfer between nearly all pretrained models, which we show can also be done unsupervised. Finally, we assess both the scalability and impact of fundamental model properties on successful model-agnostic knowledge transfer.",
      "Resource scheduling and allocation is a critical component of many high impact systems ranging from congestion control to cloud computing. Finding more optimal solutions to these problems often has significant impact on resource and time savings, reducing device wear-and-tear, and even potentially improving carbon emissions. In this paper, we focus on a specific instance of a scheduling problem, namely the memory mapping problem that occurs during compilation of machine learning programs: That is, mapping tensors to different memory layers to optimize execution time. We introduce an approach for solving the memory mapping problem using Reinforcement Learning. RL is a solution paradigm well-suited for sequential decision making problems that are amenable to planning, and combinatorial search spaces with high-dimensional data inputs. We formulate the problem as a single-player game, which we call the mallocGame, such that high-reward trajectories of the game correspond to efficient memory mappings on the target hardware. We also introduce a Reinforcement Learning agent, mallocMuZero, and show that it is capable of playing this game to discover new and improved memory mapping solutions that lead to faster execution times on real ML workloads on ML accelerators. We compare the performance of mallocMuZero to the default solver used by the Accelerated Linear Algebra (XLA) compiler on a benchmark of realistic ML workloads. In addition, we show that mallocMuZero is capable of improving the execution time of the recently published AlphaTensor matrix multiplication model.",
      "Real-world data is high-dimensional: a book, image, or musical performance can easily contain hundreds of thousands of elements even after compression. However, the most commonly used autoregressive models, Transformers, are prohibitively expensive to scale to the number of inputs and layers needed to capture this long-range structure. We develop Perceiver AR, an autoregressive, modality-agnostic architecture which uses cross-attention to map long-range inputs to a small number of latents while also maintaining end-to-end causal masking. Perceiver AR can directly attend to over a hundred thousand tokens, enabling practical long-context density estimation without the need for hand-crafted sparsity patterns or memory mechanisms. When trained on images or music, Perceiver AR generates outputs with clear long-term coherence and structure. Our architecture also obtains state-of-the-art likelihood on long-sequence benchmarks, including 64 x 64 ImageNet images and PG-19 books.",
      "Building models that can be rapidly adapted to novel tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research. We introduce Flamingo, a family of Visual Language Models (VLM) with this ability. We propose key architectural innovations to: (i) bridge powerful pretrained vision-only and language-only models, (ii) handle sequences of arbitrarily interleaved visual and textual data, and (iii) seamlessly ingest images or videos as inputs. Thanks to their flexibility, Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities. We perform a thorough evaluation of our models, exploring and measuring their ability to rapidly adapt to a variety of image and video tasks. These include open-ended tasks such as visual question-answering, where the model is prompted with a question which it has to answer; captioning tasks, which evaluate the ability to describe a scene or an event; and close-ended tasks such as multiple-choice visual question-answering. For tasks lying anywhere on this spectrum, a single Flamingo model can achieve a new state of the art with few-shot learning, simply by prompting the model with task-specific examples. On numerous benchmarks, Flamingo outperforms models fine-tuned on thousands of times more task-specific data.",
      "General perception systems such as Perceivers can process arbitrary modalities in any combination and are able to handle up to a few hundred thousand inputs. They achieve this generality by using exclusively global attention operations. This however hinders them from scaling up to the inputs sizes required to process raw high-resolution images or video. In this paper, we show that some degree of locality can be introduced back into these models, greatly improving their efficiency while preserving their generality. To scale them further, we introduce a self-supervised approach that enables learning dense low-dimensional positional embeddings for very large signals. We call the resulting model a Hierarchical Perceiver (HiP). In sum our contributions are: 1) scaling Perceiver-type models to raw high-resolution images and audio+video, 2) showing the feasibility of learning 1M+ positional embeddings from scratch using masked auto-encoding, 3) demonstrating competitive performance on raw data from ImageNet, AudioSet, PASCAL VOC, ModelNet40 and Kinetics datasets with the same exact, unchanged model and without specialized preprocessing or any tokenization.",
      "Deep Metric Learning (DML) aims to learn representation spaces on which semantic relations can simply be expressed through predefined distance metrics. Best performing approaches commonly leverage class proxies as sample stand-ins for better convergence and generalization. However, these proxy-methods solely optimize for sample-proxy distances. Given the inherent non-bijectiveness of used distance functions, this can induce locally isotropic sample distributions, leading to crucial semantic context being missed due to difficulties resolving local structures and intraclass relations between samples. To alleviate this problem, we propose non-isotropy regularization $(\\mathbb{NIR})$ for proxy-based Deep Metric Learning. By leveraging Normalizing Flows, we enforce unique translatability of samples from their respective class proxies. This allows us to explicitly induce a non-isotropic distribution of samples around a proxy to optimize for. In doing so, we equip proxy-based objectives to better learn local structures. Extensive experiments highlight consistent generalization benefits of NIR while achieving competitive and state-of-the-art performance on the standard benchmarks CUB200-2011, Cars196 and Stanford Online Products. In addition, we find the superior convergence properties of proxy-based methods to still be retained or even improved, making NIR very attractive for practical usage. Code available at github.com/ExplainableML/NonIsotropicProxyDML.",
      "Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato.",
      "Video streaming usage has seen a significant rise as entertainment, education, and business increasingly rely on online video. Optimizing video compression has the potential to increase access and quality of content to users, and reduce energy use and costs overall. In this paper, we present an application of the MuZero algorithm to the challenge of video compression. Specifically, we target the problem of learning a rate control policy to select the quantization parameters (QP) in the encoding process of libvpx, an open source VP9 video compression library widely used by popular video-on-demand (VOD) services. We treat this as a sequential decision making problem to maximize the video quality with an episodic constraint imposed by the target bitrate. Notably, we introduce a novel self-competition based reward mechanism to solve constrained RL with variable constraint satisfaction difficulty, which is challenging for existing constrained RL methods. We demonstrate that the MuZero-based rate control achieves an average 6.28% reduction in size of the compressed videos for the same delivered video quality level (measured as PSNR BD-rate) compared to libvpx's two-pass VBR rate control policy, while having better constraint satisfaction behavior."
    ],
    "domain": [
      "Multimodal Learning",
      "Reinforcement Learning",
      "Deep Learning",
      "Natural Language Processing"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "0144157b-9040-4a58-a17e-b0488cce7896": {
    "pk": "0144157b-9040-4a58-a17e-b0488cce7896",
    "name": "Jeff Dean",
    "bio": "I am a researcher deeply engaged in the intersection of machine learning and systems design, with a particular focus on optimizing large-scale computational frameworks. My recent work includes the development of Pathways, a sophisticated orchestration layer for accelerators that enables efficient parallel computations across thousands of devices while maintaining high performance for current models. This system exemplifies my commitment to pushing the boundaries of machine learning infrastructure, allowing for the exploration of innovative research ideas.\n\nThroughout my career, I have contributed to significant advancements in neural networks and their applications, particularly in natural language processing and computer vision. My work on Google's Neural Machine Translation (GNMT) system highlights my dedication to improving translation accuracy and efficiency, addressing challenges such as rare word handling and computational costs. Additionally, I have explored the potential of learned indexes to replace traditional data structures, demonstrating how deep learning can revolutionize data management systems.\n\nI am passionate about making machine learning accessible and effective for a wide range of applications, as evidenced by my contributions to TensorFlow, which has become a cornerstone for researchers and developers alike. My research not only focuses on theoretical advancements but also emphasizes practical implementations that can be leveraged in real-world scenarios, ultimately aiming to enhance the capabilities of AI across various domains.",
    "collaborators": [
      "G. Corrado",
      "Sanjay Ghemawat",
      "M. Isard",
      "M. Devin",
      "Jonathon Shlens",
      "P. Barham",
      "Sherry Moore",
      "G. Irving",
      "Z. Chen",
      "R. Monga",
      "Vincent Vanhoucke",
      "Quoc V. Le",
      "Samy Bengio",
      "Marc'Aurelio Ranzato",
      "Tomas Mikolov",
      "Yonghui Wu",
      "I. Goodfellow",
      "A. Harp",
      "Yangqing Jia",
      "R. J\u00f3zefowicz",
      "Mart\u00edn Abadi",
      "Andy Davis",
      "M. Kudlur",
      "J. Levenberg",
      "D. Murray",
      "Benoit Steiner",
      "P. Tucker",
      "Vijay Vasudevan",
      "Pete Warden",
      "M. Wicke",
      "Yuan Yu",
      "Lukasz Kaiser",
      "M. Schuster",
      "I. Sutskever",
      "O. Vinyals",
      "Mohammad Norouzi",
      "Andrea Frome",
      "Y. Singer",
      "Patrick Nguyen",
      "A. Senior",
      "Aakanksha Chowdhery",
      "S. Hand",
      "D. Hurt",
      "Hyeontaek Lim",
      "Ruoming Pang",
      "Sudip Roy",
      "Brennan Saeta",
      "Parker Schuh",
      "Ryan Sepassi",
      "Laurent El Shafey",
      "C. A. Thekkath",
      "E. Real",
      "Thomas Breuel",
      "Tim Kraska",
      "Alex Beutel",
      "Ed H. Chi",
      "N. Polyzotis",
      "A. Jaffey",
      "Jianmin Chen",
      "Xiaoqiang Zhang",
      "Ashish Agarwal",
      "E. Brevdo",
      "C. Citro",
      "Dandelion Man\u00e9",
      "C. Olah",
      "Kunal Talwar",
      "F. Vi\u00e9gas",
      "M. Wattenberg",
      "Xiaoqiang Zheng",
      "Wolfgang Macherey",
      "M. Krikun",
      "Yuan Cao",
      "Qin Gao",
      "Klaus Macherey",
      "J. Klingner",
      "Apurva Shah",
      "Melvin Johnson",
      "Xiaobing Liu",
      "Stephan Gouws",
      "Yoshikiyo Kato",
      "Taku Kudo",
      "H. Kazawa",
      "K. Stevens",
      "George Kurian",
      "Nishant Patil",
      "Wei Wang",
      "C. Young",
      "Jason R. Smith",
      "Jason Riesa",
      "Alex Rudnick",
      "Macduff Hughes",
      "D. Erhan",
      "Eugene Ie",
      "Andrew Rabinovich",
      "Matthew D. Zeiler",
      "Mark Z. Mao",
      "K. Yang",
      "Geoffrey E. Hinton",
      "Kai Chen",
      "G. Heigold"
    ],
    "pub_titles": [
      "Pathways: Asynchronous Distributed Dataflow for ML",
      "A Golden Decade of Deep Learning: Computing Systems & Applications",
      "The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design",
      "The Case for Learned Index Structures",
      "DLVM: A MODERN COMPILER FRAMEWORK FOR NEURAL NETWORK DSLS",
      "Large-Scale Deep Learning For Building Intelligent Computer Systems",
      "TensorFlow: A system for large-scale machine learning",
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
      "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
      "The rise of cloud computing systems",
      "DeViSE: A Deep Visual-Semantic Embedding Model",
      "Using Web Co-occurrence Statistics for Improving Image Categorization",
      "On rectified linear units for speech processing",
      "Distributed Representations of Words and Phrases and their Compositionality",
      "Multilingual acoustic models using distributed deep neural networks",
      "The tail at scale",
      "Zero-Shot Learning by Convex Combination of Semantic Embeddings"
    ],
    "pub_abstracts": [
      "We present the design of a new large scale orchestration layer for accelerators. Our system, Pathways, is explicitly designed to enable exploration of new systems and ML research ideas, while retaining state of the art performance for current models. Pathways uses a sharded dataflow graph of asynchronous operators that consume and produce futures, and efficiently gang-schedules heterogeneous parallel computations on thousands of accelerators while coordinating data transfers over their dedicated interconnects. Pathways makes use of a novel asynchronous distributed dataflow design that lets the control plane execute in parallel despite dependencies in the data plane. This design, with careful engineering, allows Pathways to adopt a single-controller model that makes it easier to express complex new parallelism patterns. We demonstrate that Pathways can achieve performance parity (~100% accelerator utilization) with state-of-the-art systems when running SPMD computations over 2048 TPUs, while also delivering throughput comparable to the SPMD case for Transformer models that are pipelined across 16 stages, or sharded across two islands of accelerators connected over a data center network.",
      "Abstract The past decade has seen tremendous progress in the field of artificial intelligence thanks to the resurgence of neural networks through deep learning. This has helped improve the ability for computers to see, hear, and understand the world around them, leading to dramatic advances in the application of AI to many fields of science and other areas of human endeavor. In this essay, I examine the reasons for this progress, including the confluence of progress in computing hardware designed to accelerate machine learning and the emergence of open-source software frameworks to dramatically expand the set of people who can use machine learning effectively. I also present a broad overview of some of the areas in which machine learning has been applied over the past decade. Finally, I sketch out some likely directions from which further progress in artificial intelligence will come.",
      "The past decade has seen a remarkable series of advances in machine learning, and in particular deep learning approaches based on artificial neural networks, to improve our abilities to build more accurate systems across a broad range of areas, including computer vision, speech recognition, language translation, and natural language understanding tasks. This paper is a companion paper to a keynote talk at the 2020 International Solid-State Circuits Conference (ISSCC) discussing some of the advances in machine learning, and their implications on the kinds of computational devices we need to build, especially in the post-Moore's Law-era. It also discusses some of the ways that machine learning may also be able to help with some aspects of the circuit design process. Finally, it provides a sketch of at least one interesting direction towards much larger-scale multi-task models that are sparsely activated and employ much more dynamic, example- and task-based routing than the machine learning models of today.",
      "Indexes are models: a \\btree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term \\em learned indexes. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show that our learned indexes can have significant advantages over traditional indexes. More importantly, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work provides just a glimpse of what might be possible.",
      "Many current approaches to deep learning make use of high-level toolkits such as TensorFlow, Torch, or Caffe. Toolkits such as Caffe have a layer-based programming framework with hard-coded gradients specified for each layer type, making research using novel layer types problematic. Toolkits such as Torch and TensorFlow define a computation graph in a host language such as Python, where each node represents a linear algebra operation parallelized as a compute kernel on GPU and stores the result of evaluation; some of these toolkits subsequently perform runtime interpretation over that graph, storing the results of forward calculations and reverse-accumulated gradients at each node. This approach is more flexible, but these toolkits take a very limited and ad-hoc approach to performing optimization. Also problematic are the facts that most toolkits lack type safety, and target only a single (usually GPU) architecture, limiting users\u2019 abilities to make use of heterogeneous and emerging hardware architectures. We introduce a novel framework for high-level programming that addresses all of the above shortcomings.",
      "For the past five years, the Google Brain team has focused on conducting research in difficult problems in artificial intelligence, on building large-scale computer systems for machine learning research, and, in collaboration with many teams at Google, on applying our research and systems to dozens of Google products. Our group has recently open-sourced the TensorFlow system (tensorflow.org), a system designed to easily express machine ideas, and to quickly train, evaluate and deploy machine learning systems. In this talk, I'll highlight some of the design decisions we made in building TensorFlow, discuss research results produced within our group, and describe ways in which these ideas have been applied to a variety of problems in Google's products, usually in close collaboration with other teams. This talk describes joint work with many people at Google.",
      "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",
      "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
      "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system.",
      "In this talk I will describe the development of systems that underlie modern cloud computing systems. This development shares much of its motivation with the related fields of transaction processing systems and high performance computing, but because of scale, these systems tend to have more emphasis on fault tolerance using software techniques. Important developments in the development of modern cloud systems include very high performance distributed file system, such as the Google File System (Ghemawat et al., SOSP 2003), reliable computational frameworks such as MapReduce (Dean & Ghemawat, OSDI 2004) and Dryad (Isard et al., 2007), and large scale structured storage systems such as BigTable (Chang et al. 2006), Dynamo (DeCandia et al., 2007), and Spanner (Corbett et al., 2012). Scheduling computations can either be done using virtual machines (exemplified by VMWare's products), or as individual processes or containers. The development of public cloud platforms such as AWS, Microsoft Azure, and Google Cloud Platform, allow external developers to utilize these large-scale services to build new and interesting services and products, benefiting from the economies of scale of large datacenters and the ability to grow and shrink computing resources on demand across millions of customers.",
      "Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.",
      "Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.",
      "Deep neural networks have recently become the gold standard for acoustic modeling in speech recognition systems. The key computational unit of a deep network is a linear projection followed by a point-wise non-linearity, which is typically a logistic function. In this work, we show that we can improve generalization and make training of deep networks faster and simpler by substituting the logistic units with rectified linear units. These units are linear when their input is positive and zero otherwise. In a supervised setting, we can successfully train very deep nets from random initialization on a large vocabulary speech recognition task achieving lower word error rates than using a logistic network with the same topology. Similarly in an unsupervised setting, we show how we can learn sparse features that can be useful for discriminative tasks. All our experiments are executed in a distributed environment using several hundred machines and several hundred hours of speech data.",
      "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.    An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.",
      "Today's speech recognition technology is mature enough to be useful for many practical applications. In this context, it is of paramount importance to train accurate acoustic models for many languages within given resource constraints such as data, processing power, and time. Multilingual training has the potential to solve the data issue and close the performance gap between resource-rich and resource-scarce languages. Neural networks lend themselves naturally to parameter sharing across languages, and distributed implementations have made it feasible to train large networks. In this paper, we present experimental results for cross- and multi-lingual network training of eleven Romance languages on 10k hours of data in total. The average relative gains over the monolingual baselines are 4%/2% (data-scarce/data-rich languages) for cross- and 7%/2% for multi-lingual training. However, the additional gain from jointly training the languages on all data comes at an increased training time of roughly four weeks, compared to two weeks (monolingual) and one week (crosslingual).",
      "Software techniques that tolerate latency variability are vital to building responsive large-scale Web services.",
      "Abstract: Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional \\nway{} classification framing of image understanding, particularly in terms of the promise for zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing \\nway{} image classifier and a semantic word embedding model, which contains the $\\n$ class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task."
    ],
    "domain": [
      "Machine Learning",
      "Deep Learning",
      "Neural Networks",
      "Computer Vision"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "14ee7bb9-eb0e-4350-8b68-3728df1e3f59": {
    "pk": "14ee7bb9-eb0e-4350-8b68-3728df1e3f59",
    "name": "Cynthia Rudin",
    "bio": "I am a researcher dedicated to advancing methods for observational causal inference and machine learning, with a strong emphasis on interpretability, scalability, and practical application. My work revolves around developing frameworks like Model-to-Match, which combines outcome modeling with matching techniques to enhance treatment effect estimation while ensuring auditability and flexibility. I have also contributed to the field of nonlinear dynamical systems through my algorithm, OKRidge, which efficiently solves sparse ridge regression problems.\n\nA significant aspect of my research is the exploration of the Rashomon set, which allows for the identification of diverse, near-optimal models. This work culminated in the development of Timbertrek, an interactive visualization tool that empowers users to navigate and select models based on their specific needs and values. My commitment to interpretability extends to various domains, including healthcare, where I have designed interpretable deep learning models for clinical decision-making.\n\nI am particularly passionate about bridging the gap between complex machine learning models and domain expertise, ensuring that our methodologies not only perform well but are also understandable and actionable. My research aims to create tools that facilitate better decision-making in high-stakes environments, ultimately contributing to more responsible and effective applications of machine learning in society.",
    "collaborators": [
      "M. Seltzer",
      "Chudi Zhong",
      "Jiachang Liu",
      "Zhi Chen",
      "A. Volfovsky",
      "Rui Xin",
      "Quinn Lanners",
      "Harsh Parikh",
      "David Page",
      "Takuya Takagi",
      "Sam Rosen",
      "Stephen Hahn",
      "Rico Zhu",
      "Simon Mak",
      "Yue Jiang",
      "Marco Morucci",
      "Jacob Peloquin",
      "A. Kirillova",
      "L. Brinson",
      "K. Gall",
      "Fernanda Bravo",
      "Yaron Shaposhnik",
      "Yuting Yuan",
      "Chunxiao Li",
      "T. McCormick",
      "Boxuan Li",
      "A. Barnett",
      "Vaibhav Sharma",
      "Neel Gajjar",
      "Jerry Fang",
      "F. Schwartz",
      "J. Lo",
      "Y. Mansour",
      "Michal Moshkovitz",
      "Haiyang Huang",
      "Vaishali Jain",
      "Ted Enamorado",
      "Zijie J. Wang",
      "Duen Horng Chau",
      "Ali Behrouz",
      "Mathias L\u00e9cuyer"
    ],
    "pub_titles": [
      "Variable importance matching for causal inference",
      "OKRidge: Scalable Optimal k-Sparse Ridge Regression for Learning Dynamical Systems",
      "From Feature Importance to Distance Metric: An Almost Exact Matching Approach for Causal Inference",
      "Exploring and Interacting with the Set of Good Sparse Generalized Additive Models",
      "An Interpretable, Flexible, and Interactive Probabilistic Framework for Melody Generation",
      "Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics",
      "Interpretable Prediction Rules for Congestion Risk in Intensive Care Units",
      "Fast Sparse Classification for Generalized Linear and Additive Models",
      "Rethinking Nonlinear Instrumental Variable Models through Prediction Validity",
      "FasterRisk: Fast and Accurate Interpretable Risk Scores",
      "Optimal Sparse Regression Trees",
      "Interpretable deep learning models for better clinician-AI communication in clinical mammography",
      "There is no Accuracy-Interpretability Tradeoff in Reinforcement Learning for Mazes",
      "SegDiscover: Visual Concept Discovery via Unsupervised Semantic Segmentation",
      "Exploring the Whole Rashomon Set of Sparse Decision Trees",
      "TimberTrek: Exploring and Curating Sparse Decision Trees with Interactive Visualization",
      "Fast optimization of weighted sparse decision trees for use in optimal treatment regimes and optimal policy design"
    ],
    "pub_abstracts": [
      "Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, accurate for treatment effect estimation, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the method's auditability, accuracy, and scalability as well as extensions to more general nonparametric outcome modeling.",
      "We consider an important problem in scientific discovery, namely identifying sparse governing equations for nonlinear dynamical systems. This involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. We propose a fast algorithm, OKRidge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an ADMM-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. We also propose a method to warm-start our solver, which leverages a beam search. Experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing MIP formulations solved by the commercial solver Gurobi.",
      ",",
      "In real applications, interaction between machine learning models and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present algorithms to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity, direct editing); and (3) investigating sudden changes in the shape functions. Experiments demonstrate the fidelity of the approximated Rashomon set and its effectiveness in solving practical challenges.",
      "The fast-growing demand for algorithmic music generation is found throughout entertainment, art, education, etc. Unfortunately, most recent models are practically impossible to interpret or musically fine-tune, as they use deep neural networks with thousands of parameters. We introduce an interpretable, flexible, and interactive model, SchenkComposer, for melody generation that empowers users to be creative in all aspects of the music generation pipeline and allows them to learn from the process. We divide the task of melody generation into steps based on the process that a human composer using music-theoretical domain knowledge might use. First, the model determines phrase structure based on form analysis and identifies an appropriate number of measures. Using concepts from Schenkerian analysis, the model then finds a fitting harmonic rhythm, middleground harmonic progression, foreground rhythm, and melody in a hierarchical, scaffolded approach using a probabilistic context-free grammar based on musical contours. By incorporating theories of musical form and harmonic structure, our model produces music with long-term structural coherence. In extensive human experiments, we find that music generated with our approach successfully passes a Turing test in human experiments while current state-of-the-art approaches fail, and we further demonstrate superior performance and preference for our melodies compared to existing melody generation methods. Additionally, we developed and deployed a public website for SchenkComposer, and conducted preliminary user surveys. Through analysis, we show the strong viability and enjoyability of SchenkComposer.",
      "We introduce Matched Machine Learning, a framework that combines the flexibility of machine learning black boxes with the interpretability of matching, a longstanding tool in observational causal inference. Interpretability is paramount in many high-stakes application of causal inference. Current tools for nonparametric estimation of both average and individualized treatment effects are black-boxes that do not allow for human auditing of estimates. Our framework uses machine learning to learn an optimal metric for matching units and estimating outcomes, thus achieving the performance of machine learning black-boxes, while being interpretable. Our general framework encompasses several published works as special cases. We provide asymptotic inference theory for our proposed framework, enabling users to construct approximate confidence intervals around estimates of both individualized and average treatment effects. We show empirically that instances of Matched Machine Learning perform on par with black-box machine learning methods and better than existing matching methods for similar problems. Finally, in our application we show how Matched Machine Learning can be used to perform causal inference even when covariate data are highly complex: we study an image dataset, and produce high quality matches and estimates of treatment effects.",
      "We study the problem of predicting congestion risk in intensive care units (ICUs). Congestion is associated with poor service experience, high costs, and poor health outcomes. By predicting future congestion, decision makers can initiate preventive measures, such as rescheduling activities or increasing short-term capacity, to mitigate the effects of congestion. To this end, we consider well-established queueing models of ICUs and define \u201chigh-risk states\u201d as system states that are likely to lead to congestion in the near future. We strive to formulate rules for determining whether a given system state is high risk. We design the rules to be interpretable (informally, easy to understand) for their practical appeal to stakeholders. We show that for simple Markovian queueing systems, such as the [Formula: see text] queue with multiple patient classes, our rules take the form of linear and quadratic functions on the state space. For more general queueing systems, we employ methods from queueing theory, simulation, and machine learning (ML) to devise interpretable prediction rules, and we demonstrate their effectiveness through an extensive computational study, which includes a large-scale ICU model validated using data. Our study shows that congestion risk can be effectively and transparently predicted using linear ML models and interpretable features engineered from the queueing model representation of the system. History: This paper has been accepted for the Service Science/Stochastic Systems Joint Special Issue. Supplemental Material: The online appendix is available at https://doi.org/10.1287/stsy.2022.0018 .",
      "We present fast classification techniques for sparse generalized linear and additive models. These techniques can handle thousands of features and thousands of observations in minutes, even in the presence of many highly correlated features. For fast sparse logistic regression, our computational speed-up over other best-subset search techniques owes to linear and quadratic surrogate cuts for the logistic loss that allow us to efficiently screen features for elimination, as well as use of a priority queue that favors a more uniform exploration of features. As an alternative to the logistic loss, we propose the exponential loss, which permits an analytical solution to the line search at each iteration. Our algorithms are generally 2 to 5 times faster than previous approaches. They produce interpretable models that have accuracy comparable to black box models on challenging datasets.",
      "Instrumental variables (IV) are widely used in the social and health sciences in situations where a researcher would like to measure a causal effect but cannot perform an experiment. For valid causal inference in an IV model, there must be external (exogenous) variation that (i) has a sufficiently large impact on the variable of interest (called the relevance assumption) and where (ii) the only pathway through which the external variation impacts the outcome is via the variable of interest (called the exclusion restriction). For statistical inference, researchers must also make assumptions about the functional form of the relationship between the three variables. Current practice assumes (i) and (ii) are met, then postulates a functional form with limited input from the data. In this paper, we describe a framework that leverages machine learning to validate these typically unchecked but consequential assumptions in the IV framework, providing the researcher empirical evidence about the quality of the instrument given the data at hand. Central to the proposed approach is the idea of prediction validity. Prediction validity checks that error terms \u2013 which should be independent from the instrument \u2013 cannot be modeled with machine learning any better than a model that is identically zero. We use prediction validity to develop both one-stage and two-stage approaches for IV, and demonstrate their performance on an example relevant to climate change policy.",
      "Over the last century, risk scores have been the most popular form of predictive model used in healthcare and criminal justice. Risk scores are sparse linear models with integer coefficients; often these models can be memorized or placed on an index card. Typically, risk scores have been created either without data or by rounding logistic regression coefficients, but these methods do not reliably produce high-quality risk scores. Recent work used mathematical programming, which is computationally slow. We introduce an approach for efficiently producing a collection of high-quality risk scores learned from data. Specifically, our approach produces a pool of almost-optimal sparse continuous solutions, each with a different support set, using a beam-search algorithm. Each of these continuous solutions is transformed into a separate risk score through a\"star ray\"search, where a range of multipliers are considered before rounding the coefficients sequentially to maintain low logistic loss. Our algorithm returns all of these high-quality risk scores for the user to consider. This method completes within minutes and can be valuable in a broad variety of applications.",
      "Regression trees are one of the oldest forms of AI models, and their predictions can be made without a calculator, which makes them broadly useful, particularly for high-stakes applications. Within the large literature on regression trees, there has been little effort towards full provable optimization, mainly due to the computational hardness of the problem. This work proposes a dynamic-programming-with-bounds approach to the construction of provably-optimal sparse regression trees. We leverage a novel lower bound based on an optimal solution to the k-Means clustering algorithm on one dimensional data. We are often able to find optimal sparse trees in seconds, even for challenging datasets that involve large numbers of samples and highly-correlated features.",
      "There is increasing interest in using deep learning and computer vision to help guide clinical decisions, such as whether to order a biopsy based on a mammogram. Existing networks are typically black box, unable to explain how they make their predictions. We present an interpretable deep-learning network which explains its predictions in terms of BI-RADS features mass shape and mass margin. Our model predicts mass margin and mass shape, then uses the logits from those interpretable models to predict malignancy, also using an interpretable model. The interpretable mass margin model explains its predictions using a prototypical parts model. The interpretable mass shape model predicts segmentations, fits an ellipse, then determines shape based on the goodness of fit and eccentricity of the fitted ellipse. While including mass shape logits in the malignancy prediction model did not improve performance, we present this technique as part of a framework for better clinician-AI communication.",
      "Interpretability is an essential building block for trustworthiness in reinforcement learning systems. However, interpretability might come at the cost of deteriorated performance, leading many researchers to build complex models. Our goal is to analyze the cost of interpretability. We show that in certain cases, one can achieve policy interpretability while maintaining its optimality. We focus on a classical problem from reinforcement learning: mazes with $k$ obstacles in $\\mathbb{R}^d$. We prove the existence of a small decision tree with a linear function at each inner node and depth $O(\\log k + 2^d)$ that represents an optimal policy. Note that for the interesting case of a constant $d$, we have $O(\\log k)$ depth. Thus, in this setting, there is no accuracy-interpretability tradeoff. To prove this result, we use a new\"compressing\"technique that might be useful in additional settings.",
      "Visual concept discovery has long been deemed important to improve interpretability of neural networks, because a bank of semantically meaningful concepts would provide us with a starting point for building machine learning models that exhibit intelligible reasoning process. Previous methods have disadvantages: either they rely on labelled support sets that incorporate human biases for objects that are\"useful,\"or they fail to identify multiple concepts that occur within a single image. We reframe the concept discovery task as an unsupervised semantic segmentation problem, and present SegDiscover, a novel framework that discovers semantically meaningful visual concepts from imagery datasets with complex scenes without supervision. Our method contains three important pieces: generating concept primitives from raw images, discovering concepts by clustering in the latent space of a self-supervised pretrained encoder, and concept refinement via neural network smoothing. Experimental results provide evidence that our method can discover multiple concepts within a single image and outperforms state-of-the-art unsupervised methods on complex datasets such as Cityscapes and COCO-Stuff. Our method can be further used as a neural network explanation tool by comparing results obtained by different encoders.",
      "In any given machine learning problem, there might be many models that explain the data almost equally well. However, most learning algorithms return only one of these models, leaving practitioners with no practical way to explore alternative models that might have desirable properties beyond what could be expressed by a loss function. The Rashomon set is the set of these all almost-optimal models. Rashomon sets can be large in size and complicated in structure, particularly for highly nonlinear function classes that allow complex interaction terms, such as decision trees. We provide the first technique for completely enumerating the Rashomon set for sparse decision trees; in fact, our work provides the first complete enumeration of any Rashomon set for a non-trivial problem with a highly nonlinear discrete function class. This allows the user an unprecedented level of control over model choice among all models that are approximately equally good. We represent the Rashomon set in a specialized data structure that supports efficient querying and sampling. We show three applications of the Rashomon set: 1) it can be used to study variable importance for the set of almost-optimal trees (as opposed to a single tree), 2) the Rashomon set for accuracy enables enumeration of the Rashomon sets for balanced accuracy and F1-score, and 3) the Rashomon set for a full dataset can be used to produce Rashomon sets constructed with only subsets of the data set. Thus, we are able to examine Rashomon sets across problems with a new lens, enabling users to choose models rather than be at the mercy of an algorithm that produces only a single model.",
      "Given thousands of equally accurate machine learning (ML) models, how can users choose among them? A recent ML technique enables domain experts and data scientists to generate a complete Rashomon set for sparse decision trees-a huge set of almost-optimal inter-pretable ML models. To help ML practitioners identify models with desirable properties from this Rashomon set, we develop Tim-bertrek, the first interactive visualization system that summarizes thousands of sparse decision trees at scale. Two usage scenarios high-light how Timbertrek can empower users to easily explore, compare, and curate models that align with their domain knowledge and values. Our open-source tool runs directly in users' computational notebooks and web browsers, lowering the barrier to creating more responsible ML models. Timbertrek is available at the following public demo link: https: //poloclub. github. io/timbertrek.",
      "Sparse decision trees are one of the most common forms of interpretable models. While recent advances have produced algorithms that fully optimize sparse decision trees for prediction, that work does not address policy design, because the algorithms cannot handle weighted data samples. Specifically, they rely on the discreteness of the loss function, which means that real-valued weights cannot be directly used. For example, none of the existing techniques produce policies that incorporate inverse propensity weighting on individual data points. We present three algorithms for efficient sparse weighted decision tree optimization. The first approach directly optimizes the weighted loss function; however, it tends to be computationally inefficient for large datasets. Our second approach, which scales more efficiently, transforms weights to integer values and uses data duplication to transform the weighted decision tree optimization problem into an unweighted (but larger) counterpart. Our third algorithm, which scales to much larger datasets, uses a randomized procedure that samples each data point with a probability proportional to its weight. We present theoretical bounds on the error of the two fast methods and show experimentally that these methods can be two orders of magnitude faster than the direct optimization of the weighted loss, without losing significant accuracy."
    ],
    "domain": [
      "Causal Inference",
      "Machine Learning",
      "Interpretability",
      "Decision Trees"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "13289ce2-2acd-4eb9-a43a-971d09ee4ab6": {
    "pk": "13289ce2-2acd-4eb9-a43a-971d09ee4ab6",
    "name": "Sebastian Raschka",
    "bio": "I am a researcher with a diverse background in machine learning, bioinformatics, and computational biology. My work primarily focuses on developing innovative algorithms and models that enhance privacy, improve predictive analytics, and deepen our understanding of biological interactions. \n\nOne of my notable contributions is the design of a convolutional autoencoder that protects gender privacy in face images while maintaining recognition accuracy. This project involved a novel semi-adversarial training scheme, showcasing my ability to blend machine learning techniques with practical applications in privacy protection.\n\nIn the realm of bioinformatics, I have explored protein-ligand interactions through my SiteInterlock approach, which leverages rigidity theory to predict native binding modes. This work not only enhances the accuracy of binding predictions but also provides insights into the cooperative nature of molecular interactions.\n\nAdditionally, I have developed tools for sentiment analysis in music, utilizing naive Bayes classifiers to predict emotional responses based on lyrics. My passion for teaching and sharing knowledge is reflected in my contributions to literature on Python machine learning, where I guide readers through the complexities of data science and predictive analytics.\n\nOverall, my research is driven by a commitment to bridging theoretical concepts with real-world applications, whether it\u2019s through enhancing privacy in facial recognition or advancing our understanding of molecular biology.",
    "collaborators": [
      "R. Olson",
      "Pronojit Saha",
      "Nathan",
      "Randy J. Carnevale",
      "Ted",
      "kadarakos",
      "ktkirk",
      "Daniel",
      "derekjanni",
      "screwed",
      "Vahid Mirjalili",
      "F. O'Donovan",
      "Grishma Jena",
      "A. Namboodiri",
      "A. Ross",
      "S. Turner",
      "Daniel S. Standage",
      "Cui Jie",
      "Phelim Bradley",
      "Daniel E Cook",
      "deepstop",
      "\u00c9. Normandeau",
      "HLiang",
      "Joseph Bemister-Buffington",
      "L. Kuhn",
      "Akshay Varik",
      "weixuanfu",
      "Randal S. Olson"
    ],
    "pub_titles": [
      "Semi-adversarial Networks: Convolutional Autoencoders for Imparting Privacy to Face Images",
      "BioPandas: Working with molecular structures in pandas DataFrames",
      "MusicMood: Predicting the mood of music from song lyrics using machine learning",
      "Detecting the native ligand orientation by interfacial rigidity: SiteInterlock",
      "Python machine learning : unlock deeper insights into machine learning with this vital guide to cutting-edge predictive analytics",
      "Naive Bayes and Text Classification I - Introduction and Theory",
      "An Overview of General Performance Metrics of Binary Classifier Systems",
      "Statistical Identification of Potential CLAVATA2 Interactors by Fluorescence Resonance Energy Transfer Analysis"
    ],
    "pub_abstracts": [
      "In this paper, we design and evaluate a convolutional autoencoder that perturbs an input face image to impart privacy to a subject. Specifically, the proposed autoencoder transforms an input face image such that the transformed image can be successfully used for face recognition but not for gender classification. In order to train this autoencoder, we propose a novel training scheme, referred to as semi-adversarial training in this work. The training is facilitated by attaching a semi-adversarial module consisting of an auxiliary gender classifier and an auxiliary face matcher to the autoencoder. The objective function utilized for training this network has three terms: one to ensure that the perturbed image is a realistic face image; another to ensure that the gender attributes of the face are confounded; and a third to ensure that biometric recognition performance due to the perturbed image is not impacted. Extensive experiments confirm the efficacy of the proposed architecture in extending gender privacy to face images.",
      "Furthermore, useful small-molecule related functions are provided for reading and parsing millions of small molecule structures (from multi-MOL2 files (Tripos 2007)) fast and efficiently in virtual screening applications. Inbuilt functions for filtering molecules by the presence of functional groups and their pair-wise distances to each other make BioPandas a particularly attractive utility library for virtual screening and protein-ligand docking applications.",
      "Sentiment prediction of contemporary music can have a wide-range of applications in modern society, for instance, selecting music for public institutions such as hospitals or restaurants to potentially improve the emotional well-being of personnel, patients, and customers, respectively. In this project, music recommendation system built upon on a naive Bayes classifier, trained to predict the sentiment of songs based on song lyrics alone. The experimental results show that music corresponding to a happy mood can be detected with high precision based on text features obtained from song lyrics.",
      "Understanding the physical attributes of protein\u2010ligand interfaces, the source of most biological activity, is a fundamental problem in biophysics. Knowing the characteristic features of interfaces also enables the design of molecules with potent and selective interactions. Prediction of native protein\u2010ligand interactions has traditionally focused on the development of physics\u2010based potential energy functions, empirical scoring functions that are fit to binding data, and knowledge\u2010based potentials that assess the likelihood of pairwise interactions. Here we explore a new approach, testing the hypothesis that protein\u2010ligand binding results in computationally detectable rigidification of the protein\u2010ligand interface. Our SiteInterlock approach uses rigidity theory to efficiently measure the relative interfacial rigidity of a series of small\u2010molecule ligand orientations and conformations for a number of protein complexes. In the majority of cases, SiteInterlock detects a near\u2010native binding mode as being the most rigid, with particularly robust performance relative to other methods when the ligand\u2010free conformation of the protein is provided. The interfacial rigidification of both the protein and ligand prove to be important characteristics of the native binding mode. This measure of rigidity is also sensitive to the spatial coupling of interactions and bond\u2010rotational degrees of freedom in the interface. While the predictive performance of SiteInterlock is competitive with the best of the five other scoring functions tested, its measure of rigidity encompasses cooperative rather than just additive binding interactions, providing novel information for detecting native\u2010like complexes. SiteInterlock shows special strength in enhancing the prediction of native complexes by ruling out inaccurate poses. Proteins 2016; 84:1888\u20131901. \u00a9 2016 Wiley Periodicals, Inc.",
      "Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analytics About This Book * Leverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualization * Learn effective strategies and best practices to improve and optimize machine learning systems and algorithms * Ask and answer tough questions of your data with robust statistical models, built for a range of datasets Who This Book Is For If you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource. What You Will Learn * Explore how to use different machine learning models to ask different questions of your data * Learn how to build neural networks using Keras and Theano * Find out how to write clean and elegant Python code that will optimize the strength of your algorithms * Discover how to embed your machine learning model in a web application for increased accessibility * Predict continuous target outcomes using regression analysis * Uncover hidden patterns and structures in data with clustering * Organize data using effective pre-processing techniques * Get to grips with sentiment analysis to delve deeper into textual and social media data In Detail Machine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success. Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization. Style and approach Python Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.",
      "Naive Bayes classifiers, a family of classifiers that are based on the popular Bayes' probability theorem, are known for creating simple yet well performing models, especially in the fields of document classification and disease prediction. In this article, we will look at the main concepts of naive Bayes classification in the context of document categorization.",
      "This document provides a brief overview of different metrics and terminology that is used to measure the performance of binary classification systems.",
      "The overall goal of this study was to identify potential interactors of the CLAVATA2 (CLV2) membrane receptor, which is participating in the stem cell signaling pathway of the model plant Arabidopsis thaliana. In order to investigate the physical interaction between those proteins, a fluorescence resonance energy transfer (FRET) analysis was conducted. Data have been collected all by myself during my undergraduate laboratory experiences in August, 2011, at the Department of Developmental Genetics at Heinrich-Heine University D\u00fcsseldorf."
    ],
    "domain": [
      "Machine Learning",
      "Computer Vision",
      "Bioinformatics",
      "Sentiment Analysis"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "660ac6f5-6dea-40ba-bdd9-e56de39a7aaf": {
    "pk": "660ac6f5-6dea-40ba-bdd9-e56de39a7aaf",
    "name": "Rupesh Kumar Srivastava",
    "bio": "I am a researcher dedicated to advancing the fields of machine learning and optimization, with a particular focus on the intersection of neural networks and design optimization under uncertainty. My work has explored innovative approaches to automatically generate image descriptions using multimodal models, achieving state-of-the-art results on benchmarks like Microsoft COCO. I have delved into the dynamics of neural network activation functions, revealing how local competition among neurons can enhance performance and mitigate issues like catastrophic forgetting.\n\nMy research also emphasizes the application of evolutionary algorithms (EAs) in design optimization, particularly in scenarios where uncertainty is a significant factor. I have developed bi-objective evolutionary approaches that leverage evidence theory to optimize design objectives while minimizing the plausibility of constraint violations. This work has demonstrated substantial computational efficiencies, particularly through GPU-based parallelization, allowing for rapid evaluations in complex design problems.\n\nAdditionally, I am intrigued by the concept of curiosity-driven problem-solving, as exemplified by the POWERPLAY framework, which fosters the development of artificial explorers capable of generating and solving novel problems. My recent efforts in Generalized Compressed Network Search (GCNS) aim to enhance neural network efficiency by identifying critical frequencies for better compression and generalization.\n\nOverall, my research is characterized by a commitment to pushing the boundaries of machine learning and optimization, with a focus on practical applications and innovative methodologies that address real-world challenges.",
    "collaborators": [
      "J. Schmidhuber",
      "K. Deb",
      "Faustino J. Gomez",
      "Jonathan Masci",
      "Bas R. Steunebrink",
      "Hao Fang",
      "Saurabh Gupta",
      "F. Iandola",
      "L. Deng",
      "Piotr Doll\u00e1r",
      "Jianfeng Gao",
      "Xiaodong He",
      "Margaret Mitchell",
      "John C. Platt",
      "C. L. Zitnick",
      "G. Zweig",
      "Rupesh Tulshyan",
      "Sohrob Kazerounian",
      "Marijn F. Stollenga"
    ],
    "pub_titles": [
      "From captions to visual concepts and back",
      "Understanding Locally Competitive Networks",
      "An evolutionary algorithm based approach to design optimization using evidence theory",
      "Compete to Compute",
      "An evolutionary based Bayesian design optimization approach under incomplete information",
      "Continually adding self-invented problems to the repertoire: First experiments with POWERPLAY",
      "Generalized compressed network search",
      "An EA-based approach to design optimization using evidence theory"
    ],
    "pub_abstracts": [
      "This paper presents a novel approach for automatically generating image descriptions: visual detectors, language models, and multimodal similarity models learnt directly from a dataset of image captions. We use multiple instance learning to train visual detectors for words that commonly occur in captions, including many different parts of speech such as nouns, verbs, and adjectives. The word detector outputs serve as conditional inputs to a maximum-entropy language model. The language model learns from a set of over 400,000 image descriptions to capture the statistics of word usage. We capture global semantics by re-ranking caption candidates using sentence-level features and a deep multimodal similarity model. Our system is state-of-the-art on the official Microsoft COCO benchmark, producing a BLEU-4 score of 29.1%. When human judges compare the system captions to ones written by other people on our held-out test set, the system captions have equal or better quality 34% of the time.",
      "Recently proposed neural network activation functions such as rectified linear, maxout, and local winner-take-all have allowed for faster and more effective training of deep neural architectures on large and complex datasets. The common trait among these functions is that they implement local competition between small groups of computational units within a layer, so that only part of the network is activated for any given input pattern. In this paper, we attempt to visualize and understand this self-modularization, and suggest a unified explanation for the beneficial properties of such networks. We also show how our insights can be directly useful for efficiently performing retrieval over large datasets using neural networks.",
      "For problems involving uncertainties in design variables and parameters, a bi-objective evolutionary algorithm (EA) based approach to design optimization using evidence theory is proposed and implemented in this paper. In addition to a functional objective, a plausibility measure of failure of constraint satisfaction is minimized. Despite some interests in classical optimization literature, this is the first attempt to use evidence theory with an EA. Due to EA\u2019s flexibility in its operators, non-requirement of any gradient, its ability to handle multiple conflicting objectives, and ease of parallelization, evidence-based design optimization using an EA is promising. Results on a test problem and a couple of engineering design problems show that the modified evolutionary multi-objective optimization (EMO) algorithm is capable of finding a widely distributed trade-off frontier showing different optimal solutions corresponding to different levels of plausibility failure limits. Furthermore, a single-objective evidence based EA is found to produce better optimal solutions than a previously reported classical optimization procedure. The use of a GPU based parallel computing platform demonstrates EA\u2019s performance enhancement around 160 to 700 times in implementing plausibility computations. Handling uncertainties of different types are getting increasingly popular in applied optimization studies and this EA based study should motivate further studies in handling uncertainties.",
      "Local competition among neighboring neurons is common in biological neural networks (NNs). In this paper, we apply the concept to gradient-based, backprop-trained artificial multilayer NNs. NNs with competing linear units tend to outperform those with non-competing nonlinear units, and avoid catastrophic forgetting when training sets change over time.",
      "Design optimization in the absence of complete information about uncertain quantities has been recently gaining consideration, as expensive repetitive computation tasks are becoming tractable due to the invention of faster and parallel computers. This work uses Bayesian inference to quantify design reliability when only sample measurements of the uncertain quantities are available. A generalized Bayesian reliability based design optimization algorithm has been proposed and implemented for numerical as well as engineering design problems. The approach uses an evolutionary algorithm (EA) to obtain a trade-off front between design objectives and reliability. The Bayesian approach provides a well-defined link between the amount of available information and the reliability through a confidence measure, and the EA acts as an efficient optimizer for a discrete and multi-dimensional objective space. Additionally, a GPU-based parallelization study shows computational speed-up of close to 100 times in a simulated scenario wherein the constraint qualification checks may be time consuming and could render a sequential implementation that can be impractical for large sample sets. These results show promise for the use of a parallel implementation of EAs in handling design optimization problems under uncertainties.",
      "Pure scientists do not only invent new methods to solve given problems. They also invent new problems. The recent POWERPLAY framework formalizes this type of curiosity and creativity in a new, general, yet practical way. To acquire problem solving prowess through playing, POWERPLAY-based artificial explorers by design continually come up with the fastest to find, initially novel, but eventually solvable problems. They also continually simplify or speed up solutions to previous problems. We report on results of first experiments with POWERPLAY. A self-delimiting recurrent neural network (SLIM RNN) is used as a general computational architecture to implement the system's solver. Its weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. In open-ended fashion, our POWERPLAY-driven RNNs learn to become increasingly general problem solvers, continually adding new problem solving procedures to the growing repertoire, exhibiting interesting developmental stages.",
      "This paper presents initial results of Generalized Compressed Network Search (GCNS), a method for automatically identifying the important frequencies for neural networks encoded as a set of Fourier-type coefficients (i.e. \"compressed\" networks). GCNS achieves better compression than our previous approach, and promises better generalization capabilities. Results for a high-dimensional Octopus arm control problem show that a high fitness 3680-weight network can be encoded using less than 10 coefficients, using the frequencies identified by GCNS.",
      "For problems involving uncertainties in design variables and parameters, a bi-objective evolutionary algorithm (EA) based approach to design optimization using evidence theory is proposed and implemented in this paper. In addition to a functional objective, a plausibility measure of failure of constraint satisfaction is minimized. Despite some interests in classical optimization literature, such a consideration in EA is rare. Due to EA's flexibility in its operators, non-requirement of any gradient, its ability to handle multiple conflicting objectives, and ease of parallelization, evidence-based design optimization using an EA is promising. Results on a test problem and a couple of engineering design problems show that the modified evolutionary multi-objective optimization (EMO) algorithm is capable of finding a widely distributed trade-off frontier showing different optimal solutions corresponding to different levels of plausibility failure limits. Furthermore, a single-objective evidence based EA is found to produce better optimal solutions than a previously reported classical optimization procedure. Handling uncertainties of different types are getting increasingly popular in applied optimization studies and more such studies using EAs will make EAs more useful and pragmatic in practical optimization problem-solving tasks."
    ],
    "domain": [
      "Computer Vision",
      "Neural Networks",
      "Evolutionary Algorithms",
      "Design Optimization"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "86ae7766-7ca5-4702-aa08-3f1cc1223d1a": {
    "pk": "86ae7766-7ca5-4702-aa08-3f1cc1223d1a",
    "name": "Jan Koutn\u00edk",
    "bio": "I am a researcher specializing in the intersection of neuroevolution and reinforcement learning (RL), with a focus on developing innovative neural network architectures that can effectively handle high-dimensional input spaces. My work has led to significant advancements in evolving compact recurrent neural networks (RNNs) that can control complex tasks, such as driving in the TORCS racing simulator, using only visual input. By employing deep learning techniques, I have successfully transformed high-dimensional visual data into compact feature vectors, enabling the evolution of efficient neural controllers.\n\nOne of my notable contributions is the introduction of the Clockwork RNN (CW-RNN), which partitions the hidden layer into modules that process inputs at varying temporal granularities. This architecture not only simplifies the model but also enhances performance across various tasks, including audio signal generation and handwriting recognition. Additionally, I have explored indirect encoding methods for neural networks, utilizing Fourier coefficients to represent weight matrices, which significantly reduces the search space dimensionality and accelerates convergence in complex RL tasks.\n\nMy research also includes the development of benchmarks, such as the Super Mario Bros. RL benchmark, which allows for the investigation of learning strategies in high-dimensional environments. Through my work, I aim to push the boundaries of neuroevolution and RL, making these powerful techniques more accessible and effective for a wide range of applications.",
    "collaborators": [
      "J. Schmidhuber",
      "Faustino J. Gomez",
      "M. Snorek",
      "Jan Drchal",
      "Giuseppe Cuccu",
      "V. K\u016frkov\u00e1",
      "Roman Neruda",
      "Klaus Greff",
      "Bas R. Steunebrink",
      "K. Th\u00f3risson",
      "Eric Nivel",
      "T. Glasmachers",
      "V. Graziano",
      "P. Kord\u00edk",
      "O. Kov\u00e1r\u00edk",
      "Miroslav epek",
      "J. Togelius",
      "S. Karakovskiy",
      "Ondrej Kapral",
      "Zden\u011bk Buk"
    ],
    "pub_titles": [
      "Evolving deep unsupervised convolutional networks for vision-based reinforcement learning",
      "A Clockwork RNN",
      "Evolving large-scale neural networks for vision-based TORCS",
      "Evolving large-scale neural networks for vision-based reinforcement learning",
      "Complexity search for compressed neural networks",
      "A Frequency-Domain Encoding for Neuroevolution",
      "Searching for Minimal Neural Networks in Fourier Space",
      "Evolving neural networks in compressed weight space",
      "Super mario evolution",
      "HyperNEAT controlled robots learn how to drive on roads in simulated environment"
    ],
    "pub_abstracts": [
      "Dealing with high-dimensional input spaces, like visual input, is a challenging task for reinforcement learning (RL). Neuroevolution (NE), used for continuous RL problems, has to either reduce the problem dimensionality by (1) compressing the representation of the neural network controllers or (2) employing a pre-processor (compressor) that transforms the high-dimensional raw inputs into low-dimensional features. In this paper, we are able to evolve extremely small recurrent neural network (RNN) controllers for a task that previously required networks with over a million weights. The high-dimensional visual input, which the controller would normally receive, is first transformed into a compact feature vector through a deep, max-pooling convolutional neural network (MPCNN). Both the MPCNN preprocessor and the RNN controller are evolved successfully to control a car in the TORCS racing simulator using only visual input. This is the first use of deep learning in the context evolutionary RL.",
      "Sequence prediction and classification are ubiquitous and challenging problems in machine learning that can require identifying complex dependencies between temporally distant inputs. Recurrent Neural Networks (RNNs) have the ability, in theory, to cope with these temporal dependencies by virtue of the short-term memory implemented by their recurrent (feedback) connections. However, in practice they are difficult to train successfully when long-term memory is required. This paper introduces a simple, yet powerful modification to the simple RNN (SRN) architecture, the Clockwork RNN (CW-RNN), in which the hidden layer is partitioned into separate modules, each processing inputs at its own temporal granularity, making computations only at its prescribed clock rate. Rather than making the standard RNN models more complex, CW-RNN reduces the number of SRN parameters, improves the performance significantly in the tasks tested, and speeds up the network evaluation. The network is demonstrated in preliminary experiments involving three tasks: audio signal generation, TIMIT spoken word classification, where it outperforms both SRN and LSTM networks, and online handwriting recognition, where it outperforms SRNs.",
      "The TORCS racing simulator has become a standard testbed used in many recent reinforcement learning competitions, where an agent must learn to drive a car around a track using a small set of task-specific features. In this paper, large, recurrent neural networks (with over 1 million weights) are evolved to solve a much more challenging version of the task that instead uses only a stream of images from the driver\u2019s perspective as input. Evolving such large nets is made possible by representing them in the frequency domain as a set of coefficients that are transformed into weight matrices via an inverse Fourier-type transform. To our knowledge this is the first attempt to tackle TORCS using vision, and successfully evolve a neural network controllers of this size.",
      "The idea of using evolutionary computation to train artificial neural networks, or neuroevolution (NE), for reinforcement learning (RL) tasks has now been around for over 20 years. However, as RL tasks become more challenging, the networks required become larger, as do their genomes. But, scaling NE to large nets (i.e. tens of thousands of weights) is infeasible using direct encodings that map genes one-to-one to network components. In this paper, we scale-up our compressed network encoding where network weight matrices are represented indirectly as a set of Fourier-type coefficients, to tasks that require very-large networks due to the high-dimensionality of their input space. The approach is demonstrated successfully on two reinforcement learning tasks in which the control networks receive visual input: (1) a vision-based version of the octopus control task requiring networks with over 3 thousand weights, and (2) a version of the TORCS driving game where networks with over 1 million weights are evolved to drive a car around a track using video images from the driver's perspective.",
      "In this paper, we introduce a method, called Compressed Network Complexity Search (CNCS), for automatically determining the complexity of compressed networks (neural networks encoded indirectly by Fourier-type coefficients) that favors parsimonious solutions. CNCS maintains a probability distribution over complexity classes that it uses to select which class to optimize. Class probabilities are adapted based on their expected fitness, starting with a prior biased toward the simplest networks. Experiments on a challenging non-linear version of the helicopter hovering task, show that the method consistently finds simple solutions.",
      "Neuroevolution has yet to scale up to complex reinforcement learning tasks that require large networks. Networks with many inputs (e.g. raw video) imply a very high dimensional search space if encoded directly. Indirect methods use a more compact genotype representation that is transformed into networks of potentially arbitrary size. In this paper, we present an indirect method where networks are encoded by a set of Fourier coefficients which are transformed into network weight matrices via an inverse Fourier-type transform. Because there often exist network solutions whose weight matrices contain regularity (i.e. adjacent weights are correlated), the number of coefficients required to represent these networks in the frequency domain is much smaller than the number of weights (in the same way that natural images can be compressed by ignore high-frequency components). This \"compressed\" encoding is compared to the direct approach where search is conducted in the weight space on the high-dimensional octopus arm task. The results show that representing networks in the frequency domain can reduce the search-space dimensionality by as much as two orders of magnitude, both accelerating convergence and yielding more general solutions.",
      "The principle of minimum description length suggests looking for the simplest network that works well on the training examples, where simplicity is measured by network description size based on a reasonable programming language for encoding networks. Previous work used an assembler-like universal network encoding language (NEL) and Speed Priorbased search (related to Levin\u2019s Universal Search) to quickly find low-complexity nets with excellent generalization performance. Here we define a more natural and often more practical NEL whose instructions are frequency domain coefficients. Frequency coefficients may get encoded by few bits, hence huge weight matrices may just be low-complexity superpositions of patterns computed by programs with few elementary instructions. On various benchmarks this weight matrix encoding greatly accelerates the search. The scheme was tested on pole-balancing, long-term dependency T-maze, and ball throwing. Some of the solutions turn out to be unexpectedly simple as they are computable by fairly short bit",
      "We propose a new indirect encoding scheme for neural networks in which the weight matrices are represented in the frequency domain by sets Fourier coefficients. This scheme exploits spatial regularities in the matrix to reduce the dimensionality of the representation by ignoring high-frequency coefficients, as is done in lossy image compression. We compare the efficiency of searching in this \"compressed\" network space to searching in the space of directly encoded networks, using the CoSyNE neuroevolution algorithm on three benchmark problems: pole-balancing, ball throwing and octopus arm control. The results show that this encoding can dramatically reduce the search space dimensionality such that solutions can be found in significantly fewer evaluations",
      "We introduce a new reinforcement learning benchmark based on the classic platform game Super Mario Bros. The benchmark has a high-dimensional input space, and achieving a good score requires sophisticated and varied strategies. However, it has tunable difficulty, and at the lowest difficulty setting decent score can be achieved using rudimentary strategies and a small fraction of the input space. To investigate the properties of the benchmark, we evolve neural network-based controllers using different network architectures and input spaces. We show that it is relatively easy to learn basic strategies capable of clearing individual levels of low difficulty, but that these controllers have problems with generalization to unseen levels and with taking larger parts of the input space into account. A number of directions worth exploring for learning betterperforming strategies are discussed.",
      "In this paper we describe simulation of autonomous robots controlled by recurrent neural networks, which are evolved through indirect encoding using HyperNEAT algorithm. The robots utilize 180 degree wide sensor array. Thanks to the scalability of the neural network generated by HyperNEAT, the sensor array can have various resolution. This would allow to use camera as an input for neural network controller used in real robot. The robots were simulated using software simulation environment. In the experiments the robots were trained to drive with imaximum average speed. Such fitness forces them to learn how to drive on roads and avoid collisions. Evolved neural networks show excellent scalability. Scaling of the sensory input breaks performance of the robots, which should be gained back with re-training of the robot with a different sensory input resolution."
    ],
    "domain": [
      "Reinforcement Learning",
      "Neuroevolution",
      "Neural Networks",
      "Deep Learning"
    ],
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "8bb82077-222d-4e19-b754-7bb824bb421b": {
    "pk": "8bb82077-222d-4e19-b754-7bb824bb421b",
    "name": "Bas R. Steunebrink",
    "bio": "I am a researcher dedicated to exploring the intersection of artificial intelligence and human communication, with a particular focus on how artificial agents can learn language and social skills through observation. My work has led to the development of the auto-catalytic, endogenous, reflective architecture (AERA), which enables agents to learn complex multimodal language by observing human interactions in real-time scenarios, such as mock television interviews. Through my experiments, I have demonstrated that agents can acquire a rich understanding of language, including pragmatics, semantics, and syntax, without any pre-defined grammar, relying solely on high-level goals and a small ontology.\n\nI am also deeply interested in the broader implications of artificial general intelligence (AGI) and the importance of self-reflective systems. My research emphasizes the need for AGI systems to reason about their own code and improve autonomously, which I believe is crucial for achieving true intelligence. Additionally, I have explored the role of emotions in decision-making, proposing that understanding human emotions can enhance the design of artificial agents, allowing them to interact more effectively with humans.\n\nMy work is driven by a desire to bridge the gap between cognitive science and AI, advocating for a more holistic approach to understanding intelligence. I aim to create systems that not only perform tasks but also learn and adapt in dynamic environments, ultimately contributing to the development of intelligent agents that can thrive in the complexities of human society.",
    "collaborators": [
      "J. Schmidhuber",
      "M. Dastani",
      "K. Th\u00f3risson",
      "J. Meyer",
      "Eric Nivel",
      "H. Dindo",
      "G. Pezzulo",
      "D. Ognibene",
      "Helgi P\u00e1ll Helgason",
      "A. Chella",
      "R. Sanz",
      "Manuel Rodr\u00edguez",
      "C. Hern\u00e1ndez",
      "G. Jonsson",
      "C. H. Corbato",
      "R. Srivastava",
      "Nivel Nivel",
      "R. S. Bravo",
      "Manuel Hernandez",
      "Pei Wang",
      "Kristinn R. \u00de\u00f3risson",
      "J. Koutn\u00edk",
      "M. Rodriguez",
      "Marijn F. Stollenga"
    ],
    "pub_titles": [
      "AUTONOMOUS ACQUISITION OF NATURAL LANGUAGE",
      "Autonomous Acquisition of Natural Situated Communication",
      "What Should AGI Learn From AI & CogSci ?",
      "Bounded Recursive Self-Improvement",
      "Continually adding self-invented problems to the repertoire: First experiments with POWERPLAY",
      "Towards an Actual G\u00f6del Machine Implementation: a Lesson in Self-Reflective Systems",
      "Emotions to control agent deliberation",
      "The logical structure of emotions",
      "Modularity in BDI-Based Multi-agent Programming Languages",
      "The OCC Model Revisited",
      "A Formal Model of Emotions: Integrating Qualitative and Quantitative Aspects"
    ],
    "pub_abstracts": [
      "An important part of human intelligence is the ability to use language. Humans learn how to use language in a society of language users, which is probably the most effective way to learn a language from the ground up. Principles that might allow an artificial agents to learn language this way are not known at present. Here we present a framework which begins to address this challenge. Our auto-catalytic, endogenous, reflective architecture (AERA) supports the creation of agents that can learn natural language by observation. We present results from two experiments where our S1 agent learns human communication by observing two humans interacting in a realtime mock television interview, using gesture and situated language. Results show that S1 can learn multimodal complex language and multimodal communicative acts, using a vocabulary of 100 words with numerous sentence formats, by observing unscripted interaction between the humans, with no grammar being provided to it a priori, and only high-level information about the format of the human interaction in the form of high-level goals of the interviewer and interviewee and a small ontology. The agent learns both the pragmatics, semantics, and syntax of complex sentences spoken by the human subjects on the topic of recycling of objects such as aluminum cans, glass bottles, plastic, and wood, as well as use of manual deictic reference and anaphora.",
      "An important part of human intelligence, both historically and operationally, is our ability to communicate. We learn how to communicate, and maintain our communicative skills, in a society of communicators \u2013 a highly effective way to reach and maintain proficiency in this complex skill. Principles that might allow artificial agents to learn language this way are in completely known at present \u2013 the multi-dimensional nature of socio-communicative skills are beyond every machine learning framework so far proposed. Our work begins to address the challenge of proposing a way for observation-based machine learning of natural language and communication. Our framework can learn complex communicative skills with minimal up-front knowledge. The system learns by incrementally producing predictive models of causal relationships in observed data, guided by goal-inference and reasoning using forward-inverse models. We present results from two experiments where our S1 agent learns human communication by observing two humans interacting in a realtime TV-style interview, using multimodal communicative gesture and situated language to talk about recycling of various materials and objects. S1 can learn multimodal complex language and multimodal communicative acts, a vocabulary of 100 words forming natural sentences with relatively complex sentence structure, including manual deictic reference and anaphora. S1 is seeded only with high-level information about goals of the interviewer and interviewee, and a small ontology; no grammar or other information is provided to S1 a priori. The agent learns the pragmatics, semantics, and syntax of complex utterances spoken and gestures from scratch, by observing the humans compare and contrast the cost and pollution related to recycling aluminum cans, glass bottles, newspaper, plastic, and wood. After 20 hours of observation S1 can perform an unscripted TV interview with a human, in the same style, without making mistakes.",
      "While the fields of artificial intelligence (AI) and cognitive science (CogSci) both originated from a deep interest in the same phenomenon \u2013 intelligence \u2013 and both setting themselves high aims in their early days, each has since greatly narrowed its focus, and all but abandoned their core subject for a more limited version of the phenomenon. The many non-obvious causes for this change over the decades are perhaps understandable, but they have significantly reduced the potential of both fields to impact our understanding of the fundamentals of intelligence \u2013 in the wild and in the laboratory. This position paper argues that researchers in the field of artificial general intelligence (AGI) should carefully posit their research objectives and methodology to avoid repeating the same mistakes. 1 The Big Picture of Intelligence and Cognition Roughly speaking, artificial intelligence (AI) and cognitive science (CogSci) come from the same observation and imagination, namely that in a certain sense, the human mind and the electronic computer are \u2013 or can become \u2013 similar to each other. The similarities (and differences) have been suggested by many people, including Wiener [26], Turing [16], von Neumann [9], McCulloch and Pitt [7], though each from a different perspective. Initiated in this atmosphere, AI and CogSci can be seen as two sides of the same coin: while the former attempts to build a mind-like machine [11], the latter tries to study the mind as a machine [1]. Their relation is like that between engineering and science in general, that is, there is a strong mutual dependence. It is obvious that, to build an intelligent system, one has to have a clear idea about how intelligence works, and most of our knowledge on that topic comes from the study of the human mind. On the other hand, to evaluate the correctness of a theory of cognition, a straightforward way is to model it in an artifact to see if it produces the expected results. Given this relation, it is natural for AI to get inspiration from CogSci, as well as for CogSci to use AI models. Various theories have been proposed both to explain the phenomena observed in human cognition and to guide the design of machine intelligence (cf. [8, 10]). However, as the difficulties in this research became more and more clear, the mainstream in both fields gradually departed from the original objective to",
      "We have designed a machine that becomes increasingly better at behaving in underspecified circumstances, in a goal-directed way, on the job, by modeling itself and its environment as experience accumulates. Based on principles of autocatalysis, endogeny, and reflectivity, the work provides an architectural blueprint for constructing systems with high levels of operational autonomy in underspecified circumstances, starting from a small seed. Through value-driven dynamic priority scheduling controlling the parallel execution of a vast number of reasoning threads, the system achieves recursive self-improvement after it leaves the lab, within the boundaries imposed by its designers. A prototype system has been implemented and demonstrated to learn a complex real-world task, real-time multimodal dialogue with humans, by on-line observation. Our work presents solutions to several challenges that must be solved for achieving artificial general intelligence.",
      "Pure scientists do not only invent new methods to solve given problems. They also invent new problems. The recent POWERPLAY framework formalizes this type of curiosity and creativity in a new, general, yet practical way. To acquire problem solving prowess through playing, POWERPLAY-based artificial explorers by design continually come up with the fastest to find, initially novel, but eventually solvable problems. They also continually simplify or speed up solutions to previous problems. We report on results of first experiments with POWERPLAY. A self-delimiting recurrent neural network (SLIM RNN) is used as a general computational architecture to implement the system's solver. Its weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. In open-ended fashion, our POWERPLAY-driven RNNs learn to become increasingly general problem solvers, continually adding new problem solving procedures to the growing repertoire, exhibiting interesting developmental stages.",
      "Recently, interest has been revived in self-reflective systems in the context of Artificial General Intelligence (AGI). An AGI system should be intelligent enough to be able to reason about its own program code, and make modifications where it sees fit, improving on the initial code written by human programmers. A pertinent example is the GA\u00b6del Machine, which employs a proof searcher\u00e2\u20ac\u201din parallel to its regular problem solves duties\u00e2\u20ac\u201dto find a self-rewrite of which it can prove that it will be beneficial.",
      "The execution of an artificial agent is usually implemented with a sense--reason--act cycle. This cycle includes tasks such as event processing, generating and revising plans, and selecting actions to execute. However, there are typically many choices in the design of such a cycle, which are often hard-coded in the cycle in an ad hoc way. The question of this paper is how one decides, in a principled way, how often and which reasoning rules to apply, how to interleave the execution of plans, or when to start replanning. This paper proposes and formalizes the eliciting conditions of hope, fear, joy, and distress according to a well-known psychological model of human emotion. These conditions are then used to reduce the choices an agent can make in each state. They formalize the idea that emotions focus an agent's attention on what is important in each state.",
      "Even though emotions sometimes lead us astray, there is mounting evidence from psychology and neurology that emotions have---on the whole---a positive effect on intelligent decision making and acting. Emotions help both overtly and covertly by focusing a person's attention to what is important and pruning unpromising directions of reasoning. Like humans, artificial agents---such as robots and virtual characters---have to act intelligently under resource constraints. A deep understanding of how human emotions function as innate and learned heuristics can help us in designing more effective artificial agents. Even if one does not want artificial agents to behave emotionally, it will still be useful to make these agents have knowledge of human emotions, so that they can take these into account when interacting or cooperating with humans. In order to incorporate emotions in artificial agents, a bridge must be built from psychological models of human emotions to computer science. This is done in this dissertation by capturing an emotion theory in a formal agent specification language. This formalization both serves as a foundation for the implementation of emotions in artificial agents, and enables us to formally analyze properties of the psychological model, leading to a more precise understanding of the workings of human emotions",
      "This paper proposes a module-based vision for designing BDI-based multi-agent programming languages. The introduced concept of modules enables common programming techniques such as encapsulation and information hiding for BDI-based programs, and facilitates the implementation of agent roles and profiles. This vision is applied to a BDI-based agent programming language to which specific programming constructs are added to allow the implementation of modules. The syntax and intuitive semantics of module based programming constructs are explained. An example is presented to illustrate how modules can be used to implement BDI-based multi-agent systems."
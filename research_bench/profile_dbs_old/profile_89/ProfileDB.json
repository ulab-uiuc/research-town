{
  "2e8a4f52-64fc-4b8d-9b89-f226dd704e56": {
    "pk": "2e8a4f52-64fc-4b8d-9b89-f226dd704e56",
    "project_name": null,
    "name": "Haoran Zhang",
    "bio": "I am a researcher dedicated to advancing the fields of automated essay scoring, machine learning, and network analysis. My recent work has focused on developing innovative models that enhance the accuracy and efficiency of scoring systems for educational assessments, particularly through the use of co-attention mechanisms and neural networks. I have explored the intersection of technology and healthcare, particularly in improving fetal MRI techniques and creating ultra-low-cost smartphone microscopy solutions for home health surveillance.\n\nIn addition to my contributions to educational technology, I have delved into the complexities of signed networks and longitudinal networks, proposing novel models that account for the unique characteristics of these structures. My research also includes the development of a signed \u03b2-model for directed signed networks, which addresses the challenges of uncertainty quantification in node ranking.\n\nI am passionate about bridging the gap between theoretical advancements and practical applications, as evidenced by my work on learning predictive checklists for clinical decision support. My goal is to create tools that not only enhance performance in their respective domains but also provide meaningful insights and support for users. Through my research, I aim to contribute to a deeper understanding of complex systems and improve the tools available for both education and healthcare.",
    "collaborators": [
      "Diane Litman",
      "Junhui Wang",
      "Yun Wang",
      "Jianying Li",
      "Weiyi Zhang",
      "Zirui Zuo",
      "Jianlong Yang",
      "Daojian Zeng",
      "Ranran Haoran Zhang",
      "Qianying Liu"
    ],
    "domain": [
      "Natural Language Processing",
      "Machine Learning",
      "Medical Imaging",
      "Network Analysis"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "f088e8d8-fea3-4e84-8b53-c41409cb1a59": {
    "pk": "f088e8d8-fea3-4e84-8b53-c41409cb1a59",
    "project_name": null,
    "name": "Shuanghao Bai",
    "bio": "I am a researcher dedicated to enhancing the robustness and adaptability of vision-language models (VLMs) in the face of adversarial challenges and domain discrepancies. My recent work has focused on developing innovative strategies to improve the adversarial robustness of models like CLIP against multimodal attacks, demonstrating that fine-tuning against these attacks can yield superior performance compared to traditional image-based approaches.\n\nI have also explored the potential of multilayer perceptrons (MLPs) in cross-domain few-shot classification, revealing their ability to enhance discriminative capabilities and mitigate distribution shifts. My research extends to soft prompt generation for domain generalization, where I introduced a generative approach to create instance-specific prompts that significantly improve performance across various benchmarks.\n\nIn addition, I have tackled the complexities of source-free domain generalization by proposing the Prompt-Driven Text Adapter (PromptTA), which effectively captures domain knowledge and enhances model adaptability. My work on neural Granger causality has led to the development of a Jacobian Regularizer-based approach, streamlining the modeling of multivariate relationships while maintaining scalability.\n\nThrough extensive experimentation across multiple datasets, I strive to push the boundaries of VLMs and their applications, ensuring that they are not only powerful but also resilient and adaptable in real-world scenarios. My commitment to advancing the field is reflected in my contributions to open-source resources, making my findings accessible to the broader research community.",
    "collaborators": [
      "Wanqi Zhou",
      "Badong Chen",
      "Zhirong Luan",
      "Qibin Zhao",
      "Donglin Wang",
      "Yuedi Zhang",
      "Haoran Zhang",
      "Jingwen Fu",
      "Shujian Yu",
      "Min Zhang"
    ],
    "domain": [
      "Vision-Language Models",
      "Adversarial Robustness",
      "Domain Generalization",
      "Neural Networks"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "655d4fd1-d2d0-4e31-ac3f-9c9e846e40c1": {
    "pk": "655d4fd1-d2d0-4e31-ac3f-9c9e846e40c1",
    "project_name": null,
    "name": "Wanqi Zhou",
    "bio": "I am a researcher dedicated to enhancing the robustness and adaptability of vision-language models (VLMs) in the face of adversarial challenges and domain discrepancies. My recent work has focused on developing innovative strategies to improve the adversarial robustness of models like CLIP against multimodal attacks, demonstrating that fine-tuning against these attacks can yield greater resilience than traditional image-based approaches.\n\nI have also explored the potential of multilayer perceptrons (MLPs) in cross-domain few-shot classification, revealing their ability to enhance discriminative capabilities and mitigate distribution shifts. My research extends to prompt learning, where I introduced the Soft Prompt Generation (SPG) framework, which effectively generates instance-specific prompts for unseen domains, achieving state-of-the-art performance in domain generalization tasks.\n\nIn addition, I have tackled the challenges of source-free domain generalization by proposing the Prompt-Driven Text Adapter (PromptTA), which captures comprehensive domain knowledge and improves performance across various benchmarks. My work on neural Granger causality has led to the Jacobian Regularizer-based Neural Granger Causality (JRNGC) approach, which simplifies the modeling of complex relationships while maintaining high scalability.\n\nOverall, my research aims to bridge the gap between theoretical advancements and practical applications, ensuring that VLMs are not only powerful but also robust and adaptable in real-world scenarios. I am passionate about pushing the boundaries of machine learning and contributing to the development of more resilient AI systems.",
    "collaborators": [
      "Shuanghao Bai",
      "Badong Chen",
      "Zhirong Luan",
      "Qibin Zhao",
      "Donglin Wang",
      "Yuedi Zhang",
      "Haoran Zhang",
      "Jingwen Fu",
      "Shujian Yu",
      "Min Zhang"
    ],
    "domain": [
      "Vision-Language Models",
      "Adversarial Robustness",
      "Domain Generalization",
      "Neural Networks"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "a893b396-e0d1-471b-8333-75dac7fc1bf1": {
    "pk": "a893b396-e0d1-471b-8333-75dac7fc1bf1",
    "project_name": null,
    "name": "Jingwen Fu",
    "bio": "I am a researcher dedicated to advancing the fields of machine learning and deep learning, with a particular focus on generalization, optimization, and practical applications in computer vision. My recent work explores the generalization characteristics of iterative learning algorithms, where I introduced novel bounds for generalization error using information-theoretic techniques. This research not only bridges theoretical insights with practical applications, particularly in large language models, but also enhances our understanding of how learning trajectories influence model performance.\n\nI have also tackled challenges in automatic defect recognition in steel production, achieving remarkable accuracy through a hybrid approach that combines pretrained models with custom classifiers. My exploration of compositional generalization (CG) from a task-agnostic perspective has led to significant theoretical contributions, including the first No Free Lunch theorem in CG and a novel generalization bound applicable across various CG problems.\n\nIn the realm of optimization, I have derived new convergence guarantees for the Adam optimizer, closing gaps in existing literature and establishing tight upper bounds for its performance. My work on source-free domain generalization has resulted in the Prompt-Driven Text Adapter (PromptTA), which captures domain knowledge more effectively, achieving state-of-the-art results across multiple benchmarks.\n\nAdditionally, I have developed innovative solutions for mobile GUI understanding and visual place recognition, focusing on reducing reliance on human-created metadata and enhancing feature stability in dynamic environments. My research aims to push the boundaries of what is possible in machine learning, making significant strides toward practical, efficient, and robust AI systems.",
    "collaborators": [
      "Nanning Zheng",
      "Zhizheng Zhang",
      "Yan Lu",
      "Yuwang Wang",
      "Bohan Wang",
      "Huishuai Zhang",
      "Wei Chen",
      "Xiaoyan Zhu",
      "Yingbin Li",
      "Dacheng Yin"
    ],
    "domain": [
      "Machine Learning",
      "Deep Learning",
      "Computer Vision",
      "Generalization Theory"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "9eeffa75-04af-4009-8375-21e0cff140fe": {
    "pk": "9eeffa75-04af-4009-8375-21e0cff140fe",
    "project_name": null,
    "name": "Badong Chen",
    "bio": "I am a researcher dedicated to advancing the fields of generative models, graph neural networks, and robust machine learning. My recent work has focused on the adversarial robustness of generative autoencoders, where I explored the vulnerabilities of variational autoencoders (VAEs) in latent spaces and proposed methods to enhance their resilience through adversarial training. I have also developed a novel Multi-View Graph Neural Network (RSEA-MVGNN) that effectively combines diverse graph structures by leveraging view-specific uncertainties, significantly improving representation learning.\n\nIn addition to my work on GNNs, I have contributed to robust adaptive filtering algorithms for impulsive noise environments, demonstrating superior performance over traditional methods. My research extends to the development of innovative models like the Error Loss Network (ELN) for supervised learning, which provides a unified framework for various error loss functions.\n\nI am particularly interested in the intersection of machine learning and neuroscience, as evidenced by my work on the Granger Causality-Inspired Graph Neural Network (CI-GNN), which offers interpretable models for psychiatric diagnosis. My recent projects also include enhancing the robustness of vision-language models against multimodal adversarial attacks and improving crowd counting techniques through adaptive selection networks.\n\nOverall, my research aims to bridge theoretical advancements with practical applications, ensuring that machine learning models are not only effective but also robust and interpretable in real-world scenarios.",
    "collaborators": [
      "Haiquan Zhao",
      "Lu Lu",
      "Long Shi",
      "Wentao Ma",
      "Shujian Yu",
      "Yuehai Chen",
      "Jing Yang",
      "Shaoyi Du",
      "Mingfei Lu",
      "Junyu Chen"
    ],
    "domain": [
      "Generative Models",
      "Graph Neural Networks",
      "Robustness",
      "Multi-View Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
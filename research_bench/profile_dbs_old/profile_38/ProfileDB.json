{
  "6110db16-3ce1-48a8-8c55-eda672aaf5d4": {
    "pk": "6110db16-3ce1-48a8-8c55-eda672aaf5d4",
    "project_name": null,
    "name": "Mathieu Bazinet",
    "bio": "I am a researcher dedicated to exploring the intricacies of sample compression theory and its implications for machine learning, particularly in the context of deep learning. My recent work focuses on developing a comprehensive framework for deriving sample compression bounds that extend beyond the traditional zero-one loss, allowing for real-valued losses. This advancement is crucial as it addresses the limitations of existing methods, particularly when applied to complex models like neural networks and decision forests.\n\nThrough my research, I have empirically validated the tightness and versatility of these new bounds, demonstrating their effectiveness across various model types. I am particularly excited about the Pick-To-Learn (P2L) meta-algorithm, which I have integrated into my work to transform training methods into sample-compressed predictors. My goal is to provide robust generalization guarantees that can enhance the performance and efficiency of machine learning models, ultimately contributing to the broader understanding of how we can leverage sample compression in practical applications.",
    "collaborators": [
      "Valentina Zantedeschi",
      "Pascal Germain"
    ],
    "domain": [
      "Sample Compression",
      "Generalization",
      "Machine Learning",
      "Deep Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "eb2ea0a9-3a9f-4ca2-afc6-5fc24742aa78": {
    "pk": "eb2ea0a9-3a9f-4ca2-afc6-5fc24742aa78",
    "project_name": null,
    "name": "Valentina Zantedeschi",
    "bio": "I am a researcher deeply engaged in the intersection of machine learning, statistical theory, and data-driven decision-making. My work spans a variety of topics, including the theoretical foundations of Lipschitz continuity in metrics, the development of local Support Vector Machines (L$^3$-SVMs) with strong generalization guarantees, and the exploration of decentralized machine learning frameworks that prioritize user privacy.\n\nI have a keen interest in adversarial robustness in deep neural networks, where I proposed a novel defense mechanism that enhances model stability against adversarial attacks. My research also delves into the learning of binary decision trees, where I introduced a method that simultaneously optimizes discrete and continuous parameters, yielding competitive performance in both supervised and unsupervised settings.\n\nIn the realm of probabilistic forecasting, I conducted a systematic study of proper scoring rules for multivariate time series, revealing critical insights into their reliability. I also contributed to the development of a new model for multivariate time series prediction based on copula theory, achieving state-of-the-art results across various tasks.\n\nMy recent work includes the introduction of innovative datasets like Cumulo for cloud classification and RepLiQA for robust evaluation of language models, addressing the challenges of data leakage in model training. I am passionate about leveraging large language models to automate data insight discovery and improve decision-making processes. Overall, my research aims to push the boundaries of machine learning theory and its practical applications, fostering advancements that benefit both academia and industry.",
    "collaborators": [
      "Nicolas Chapados",
      "R\u00e9mi Emonet",
      "Alexandre Drouin",
      "Marc Sebban",
      "Matt J. Kusner",
      "\u00c9tienne Marcotte",
      "Pascal Germain",
      "Emilie Morvant",
      "Amaury Habrard",
      "Perouz Taslakian"
    ],
    "domain": [
      "Machine Learning",
      "Causal Inference",
      "Adversarial Learning",
      "Time Series Analysis"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "c14f8068-4322-4cc7-9c60-ecf2242227f5": {
    "pk": "c14f8068-4322-4cc7-9c60-ecf2242227f5",
    "project_name": null,
    "name": "Pascal Germain",
    "bio": "I am a researcher deeply engaged in the intersection of machine learning, interpretability, and PAC-Bayesian theory. My recent work focuses on developing binary activated neural networks that serve as interpretable predictors for regression tasks on tabular data. I emphasize the importance of explainability and interpretability, advocating for a unified approach that leverages the strengths of both concepts. My contributions include theoretical advancements in domain adaptation, where I have derived tighter PAC-Bayesian bounds and developed novel algorithms that enhance performance across various tasks.\n\nI have also explored the theoretical underpinnings of Variational Autoencoders (VAEs) and generative models, providing statistical guarantees that improve their practical applications. My research extends to the development of algorithms that utilize sample compression theory, ensuring generalization across different types of models, including decision trees and neural networks.\n\nIn addition, I have proposed innovative methods for explainable AI, such as Phoneme Discretized Saliency Maps, which enhance the interpretability of AI-generated voice detection. My work is driven by a commitment to making machine learning models not only effective but also understandable, particularly in high-stakes decision-making contexts. Through my research, I aim to bridge the gap between complex models and their interpretability, ensuring that machine learning can be both powerful and transparent.",
    "collaborators": [
      "Emilie Morvant",
      "Amaury Habrard",
      "Fran\u00e7ois Laviolette",
      "Benjamin Leblanc",
      "Ga\u00ebl Letarte",
      "Benjamin Guedj",
      "Sokhna Diarra Mbacke",
      "Florence Clerc",
      "Paul Viallard",
      "Francois Laviolette"
    ],
    "domain": [
      "PAC-Bayesian Theory",
      "Interpretability",
      "Domain Adaptation",
      "Neural Networks"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
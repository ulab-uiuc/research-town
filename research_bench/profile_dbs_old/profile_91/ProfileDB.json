{
  "770e34cb-44ea-4554-bdc0-93896b8c8181": {
    "pk": "770e34cb-44ea-4554-bdc0-93896b8c8181",
    "project_name": null,
    "name": "Hongnan Ma",
    "bio": "I am a researcher dedicated to enhancing the interpretability of time series forecasting models through explainable AI techniques. My recent work focuses on developing frameworks that bridge the gap between complex model predictions and user understanding. One of my key contributions is TSFeatLIME, an extension of TSLIME specifically designed for univariate time series forecasting. This framework integrates auxiliary features and leverages pairwise Euclidean distances to improve the fidelity of surrogate models, making them more aligned with the original model's behavior.\n\nUnderstanding the effectiveness of these explanations for diverse user groups is a central theme in my research. I conducted a comprehensive user study involving 160 participants to evaluate how well individuals from various backgrounds could grasp and predict model outputs based on the explanations provided. The findings revealed that TSFeatLIME significantly enhances the ability of non-experts to understand model behavior, demonstrating the importance of accessible explanations in AI. My work aims to make advanced forecasting techniques not only powerful but also comprehensible, ensuring that users can effectively leverage these models in real-world applications.",
    "collaborators": [
      "Kevin McAreavey",
      "Weiru Liu"
    ],
    "domain": [
      "Time Series Forecasting",
      "Explainable AI",
      "Machine Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "4760e99b-1e6f-4d28-91f1-5162eeb3e6c0": {
    "pk": "4760e99b-1e6f-4d28-91f1-5162eeb3e6c0",
    "project_name": null,
    "name": "Kevin McAreavey",
    "bio": "I am a researcher dedicated to enhancing explainability in artificial intelligence (AI) and its applications across various domains. My recent work has focused on developing robust definitions of contrastive explanations, building on the foundational Halpern-Pearl framework. I have critically analyzed existing definitions and proposed improved variants that maintain the essence of contrastive explanations while addressing inherent issues.\n\nIn the realm of reinforcement learning, I introduced Counterfactual Shapley Values (CSV), a novel approach that integrates counterfactual analysis with Shapley Values to enhance transparency in decision-making processes. My research extends to practical applications, such as temporal planning for smart homes, where I designed a custom planner that accommodates dynamic energy tariffs and user requirements, demonstrating the positive impact of contrastive explanations on user satisfaction.\n\nI have also explored the challenges of explainable AI in time series forecasting, developing the TSFeatLIME framework to improve the interpretability of complex models. My qualitative field study on AI cyberattacks revealed insights into user engagement with explainable AI features, highlighting the need for alignment between user expectations and AI capabilities.\n\nAdditionally, I have investigated the determinism of game engines in autonomous vehicle simulations, identifying non-deterministic behaviors and proposing methods to enhance simulation precision. My work aims to bridge the gap between advanced AI systems and user understanding, ensuring that technology remains accessible and beneficial to all.",
    "collaborators": [
      "Weiru Liu",
      "Yiwei Shi",
      "Qi Zhang",
      "Xiaowei Liu",
      "Hongnan Ma",
      "Kim Bauters",
      "Dennis Ivory",
      "George Loukas",
      "Manos Panaousis",
      "Hsueh-Ju Chen"
    ],
    "domain": [
      "Explainable AI",
      "Counterfactual Analysis",
      "Reinforcement Learning",
      "Time Series Forecasting"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "0c40bdee-f118-40e8-8a34-443d36f6e28e": {
    "pk": "0c40bdee-f118-40e8-8a34-443d36f6e28e",
    "project_name": null,
    "name": "Weiru Liu",
    "bio": "I am a researcher deeply engaged in the intersection of mathematics, artificial intelligence, and machine learning, with a particular focus on explainability and decision-making in complex systems. My recent work has explored the Gaussian Minkowski problem, where I demonstrated that if the Gaussian surface area measure is proportional to the spherical Lebesgue measure, the corresponding convex body must be a centered disk. This foundational result has implications for understanding convex bodies in various dimensions.\n\nIn the realm of artificial intelligence, I have developed novel approaches to enhance explainability in reinforcement learning through Counterfactual Shapley Values, which quantify the contributions of different state dimensions to action choices. My research also extends to practical applications, such as designing a custom planner for smart homes that incorporates contrastive explanations, significantly improving user satisfaction and understanding.\n\nI am particularly interested in addressing the challenges posed by misinformation in social networks. My work on predicting user engagement with misinformation using graph neural networks has shown promising results, leveraging continual learning strategies to adapt to the dynamic nature of social media.\n\nAdditionally, I have contributed to the understanding of belief merging in AI, proposing a new merging operator that effectively handles uncertainty while maintaining consistency. My research aims to bridge theoretical advancements with practical applications, ensuring that complex models remain interpretable and beneficial in real-world scenarios. Through my work, I strive to push the boundaries of knowledge in both mathematical theory and its applications in AI, ultimately enhancing decision-making processes across various domains.",
    "collaborators": [
      "Kevin McAreavey",
      "Jun Hong",
      "Shibing Chen",
      "Yibin Feng",
      "Guilin Qi",
      "David A. Bell",
      "Hongbo Bo",
      "Ryan McConville",
      "Yiwei Shi",
      "Qi Zhang"
    ],
    "domain": [
      "Convex Geometry",
      "Reinforcement Learning",
      "Explainable AI",
      "Graph Neural Network"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
{
  "cf3c41b5-b49a-482a-ab52-4ed83690eef5": {
    "pk": "cf3c41b5-b49a-482a-ab52-4ed83690eef5",
    "project_name": null,
    "name": "Carlos E. Luis",
    "bio": "I am a researcher specializing in multiagent systems and trajectory generation, with a particular focus on distributed model predictive control. My recent work introduces a novel algorithm that enhances the scalability and efficiency of offline trajectory generation for multiple agents. A key innovation in my approach is the on-demand collision avoidance strategy, which allows agents to predict future states and share this information with their neighbors. This capability enables real-time collision detection and avoidance while ensuring that agents move toward their goals effectively.\n\nOne of the standout features of my algorithm is its remarkable reduction in computation time\u2014over 85% compared to traditional optimization methods based on sequential convex programming\u2014while maintaining a high level of plan optimality. I have validated this approach through extensive simulations and real-world experiments, successfully coordinating teams of up to 25 quadrotors in confined indoor environments. My research aims to push the boundaries of multiagent coordination, making it more efficient and practical for real-world applications.",
    "collaborators": [
      "Angela P. Schoellig"
    ],
    "domain": [
      "Multiagent Systems",
      "Trajectory Generation",
      "Distributed Control",
      "Collision Avoidance"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "8722106f-0f40-4291-afca-aa7c8bb6373a": {
    "pk": "8722106f-0f40-4291-afca-aa7c8bb6373a",
    "project_name": null,
    "name": "Alessandro G. Bottero",
    "bio": "I am a researcher dedicated to advancing the field of sequential decision-making, particularly in the context of reinforcement learning and safe exploration. My recent work focuses on developing innovative methods to quantify uncertainty and optimize decision-making under constraints. I have proposed an information-theoretic safe exploration criterion that leverages Gaussian process posteriors, allowing for efficient evaluations in continuous domains without the need for additional hyperparameters. \n\nIn my exploration of model-based reinforcement learning, I introduced a new uncertainty Bellman equation that provides sharper estimates of value distributions, significantly improving sample efficiency in both tabular and continuous control tasks. My work on Epistemic Quantile-Regression (EQR) further enhances policy optimization by learning value distribution functions, demonstrating performance benefits over traditional methods.\n\nI am particularly interested in addressing the challenges posed by partial observability in reinforcement learning. By integrating a Kalman filter layer into model-free architectures, I have created a mechanism for probabilistic filtering of latent state representations, which has proven effective in tasks requiring uncertainty reasoning.\n\nThrough my research, I aim to bridge the gap between theoretical advancements and practical applications, ensuring that my contributions lead to more robust and efficient decision-making frameworks in complex environments.",
    "collaborators": [
      "Carlos E. Luis",
      "Julia Vinogradska",
      "Felix Berkenkamp",
      "Jan Peters"
    ],
    "domain": [
      "Reinforcement Learning",
      "Bayesian Optimization",
      "Uncertainty Quantification",
      "Gaussian Processes"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "49034d0d-29fd-40f3-b90b-a3bf60df32e4": {
    "pk": "49034d0d-29fd-40f3-b90b-a3bf60df32e4",
    "project_name": null,
    "name": "Julia Vinogradska",
    "bio": "I am a researcher specializing in Bayesian optimization, reinforcement learning, and uncertainty quantification. My work focuses on enhancing decision-making processes in complex environments, particularly under conditions of limited data and uncertainty. I have developed innovative methods that leverage Gaussian processes for transfer learning, enabling efficient optimization in low-data regimes. My contributions include the introduction of a novel closed-form boosted GP transfer model and an information-theoretic safe exploration criterion that enhances data efficiency in continuous domains.\n\nI am particularly interested in the intersection of uncertainty quantification and reinforcement learning. My research has led to the development of algorithms like Epistemic Quantile-Regression (EQR) and Q-Uncertainty Soft Actor-Critic (QU-SAC), which improve sample efficiency and decision-making under uncertainty. Additionally, I have explored the use of Kalman filter layers in reinforcement learning architectures to better handle partial observability, demonstrating significant performance improvements in tasks requiring uncertainty reasoning.\n\nThrough my work, I aim to bridge the gap between theoretical advancements and practical applications, providing robust solutions for real-world decision-making challenges. My research not only contributes to the academic community but also has the potential to impact various fields, including engineering and automated systems.",
    "collaborators": [
      "Felix Berkenkamp",
      "Alessandro G. Bottero",
      "Carlos E. Luis",
      "Jan Peters",
      "Petru Tighineanu",
      "Kathrin Skubch",
      "Paul Baireuther",
      "Attila Reiss",
      "Lukas Grossberger",
      "Stefan Falkner"
    ],
    "domain": [
      "Bayesian Optimization",
      "Reinforcement Learning",
      "Gaussian Processes",
      "Uncertainty Quantification"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "ef2a8feb-b3ea-4f8a-9bc8-104707f4adf3": {
    "pk": "ef2a8feb-b3ea-4f8a-9bc8-104707f4adf3",
    "project_name": null,
    "name": "Felix Berkenkamp",
    "bio": "I am a researcher dedicated to advancing the field of safe and efficient learning algorithms, particularly in the context of control systems and reinforcement learning. My work focuses on developing methods that not only optimize performance but also ensure safety in safety-critical applications. I have pioneered learning-based model predictive control schemes that provide high-probability safety guarantees, allowing for safe exploration of dynamic systems. \n\nMy research also delves into Bayesian optimization, where I have introduced algorithms that adaptively estimate hyperparameters, ensuring convergence to optimal solutions without prior knowledge. I have explored the intersection of control theory and machine learning, demonstrating how to leverage statistical models to derive stability guarantees and optimize policies safely.\n\nIn addition, I have developed innovative approaches for safe exploration in reinforcement learning, addressing the challenges posed by distribution shifts in off-policy settings. My work emphasizes the importance of epistemic uncertainty and the need for robust exploration strategies that can adapt to real-world complexities.\n\nThrough my contributions, I aim to bridge the gap between theoretical advancements and practical applications, ensuring that learning algorithms can be safely deployed in real-world scenarios, particularly in robotics and autonomous systems. My ongoing research continues to explore new frontiers in safe learning, with a commitment to enhancing the reliability and efficiency of intelligent systems.",
    "collaborators": [
      "Andreas Krause",
      "Matteo Turchetta",
      "Angela P. Schoellig",
      "Torsten Koller",
      "Melrose Roderick",
      "Sebastian Curi",
      "Fatemeh Sheikholeslami",
      "Zico Kolter",
      "Lukas P. Fr\u00f6hlich",
      "Maksym Lefarov"
    ],
    "domain": [
      "Reinforcement Learning",
      "Bayesian Optimization",
      "Control Theory",
      "Safety Assurance"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "940d7f87-f016-4808-8c35-677e0aaf639a": {
    "pk": "940d7f87-f016-4808-8c35-677e0aaf639a",
    "project_name": null,
    "name": "Jan Peters",
    "bio": "I am a researcher specializing in robotics, particularly in the area of multi-task learning and control systems. My recent work focuses on the decomposition of complex robotic tasks into manageable sub-tasks, which can be executed simultaneously. I have developed a novel learning approach that enables the creation of prioritized control laws based on motor primitives. This framework allows higher-priority primitives to override conflicting lower-priority commands, significantly enhancing the performance of robotic systems.\n\nIn my research, I emphasize the importance of the dominance structure of these motor primitives, as it plays a crucial role in achieving optimal task execution. I have applied this approach to practical scenarios, such as a ball bouncing task using a Barrett WAM robot, demonstrating the effectiveness of my method in real-world applications. My goal is to advance the field of robotics by creating more efficient and adaptable control systems that can handle the complexities of simultaneous task execution.",
    "collaborators": [
      "Jens Kober"
    ],
    "domain": [
      "Robotics",
      "Control Systems",
      "Machine Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
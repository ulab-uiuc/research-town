{
  "0caeaa3f-5b71-4be3-8930-d72b8e61ee8b": {
    "pk": "0caeaa3f-5b71-4be3-8930-d72b8e61ee8b",
    "project_name": null,
    "name": "Hongliang Zhong",
    "bio": "I am a researcher dedicated to advancing the field of 3D content generation and manipulation. My recent work focuses on innovative methods for object insertion and material editing within 3D scenes. One of my key contributions is the development of MVInpainter, a multi-view diffusion model that enhances object insertion by ensuring view consistency and high-quality results through a ControlNet-based conditional injection module. This approach allows for harmonious and diverse object insertions, significantly outperforming existing techniques.\n\nAdditionally, I introduced VQ-NeRF, a two-branch neural network model that leverages Vector Quantization to address the challenges of material decomposition and editing in 3D scenes. By combining continuous and discrete representations, my model not only reduces noise in material decomposition but also facilitates intuitive material editing through an interactive interface. This work represents a significant step forward in enabling discrete material editing, making it easier for users to manipulate 3D scenes effectively.\n\nThrough my research, I aim to push the boundaries of 3D content creation, making it more versatile and user-friendly, while also contributing to the broader understanding of how to integrate advanced machine learning techniques into 3D graphics.",
    "collaborators": [
      "Jingbo Zhang",
      "Jing Liao",
      "Can Wang"
    ],
    "domain": [
      "3D Graphics",
      "Object Insertion",
      "Neural Networks",
      "Material Editing"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "701ce85d-df20-4e73-a8b5-70f386a63de9": {
    "pk": "701ce85d-df20-4e73-a8b5-70f386a63de9",
    "project_name": null,
    "name": "Can Wang",
    "bio": "I am a researcher dedicated to enhancing predictive modeling in various domains, particularly in sales forecasting and traffic dynamics. My work addresses the challenges of traditional forecasting methods, which often rely heavily on historical data and manual feature engineering. I have developed a novel approach that utilizes Convolutional Neural Networks (CNNs) to automatically extract effective features from raw log data, significantly improving sales forecast accuracy. \n\nIn the realm of traffic forecasting, I have introduced an Adaptive Graph Convolutional Recurrent Network (AGCRN) that captures fine-grained spatial and temporal correlations without relying on pre-defined graphs. This model incorporates two innovative modules: Node Adaptive Parameter Learning (NAPL) for capturing node-specific patterns and Data Adaptive Graph Generation (DAGG) for inferring inter-dependencies among traffic series. My experiments demonstrate that AGCRN outperforms state-of-the-art methods, showcasing the potential of adaptive learning in complex data environments.\n\nAdditionally, I have explored facial expression recognition through an unsupervised adversarial domain adaptation method that effectively addresses pose and subject variations. By employing a combination of adversarial learning strategies and feature disentanglement, my approach enhances the robustness of expression-related features across diverse datasets.\n\nOverall, my research aims to push the boundaries of predictive analytics by leveraging advanced machine learning techniques to create more accurate and adaptable models across various applications.",
    "collaborators": [
      "Kui Zhao",
      "Lei Bai",
      "Lina Yao",
      "Can Li",
      "Xianzhi Wang",
      "Guang Liang",
      "Shangfei Wang"
    ],
    "domain": [
      "Machine Learning",
      "Graph Neural Network",
      "Computer Vision",
      "Time Series Analysis"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "63165a7b-43b0-40c6-95af-d6beb8a6dd12": {
    "pk": "63165a7b-43b0-40c6-95af-d6beb8a6dd12",
    "project_name": null,
    "name": "Jingbo Zhang",
    "bio": "I am a researcher with a diverse background in theoretical physics, computer vision, and machine learning, focusing on the intersection of these fields to solve complex problems. My recent work has explored the dynamics of Brownian particles in magnetized plasma, where I developed an effective action framework to capture non-linear corrections to the Langevin equation. This research not only deepens our understanding of particle behavior in plasma but also translates into practical applications through the formulation of a Fokker-Planck type equation.\n\nIn the realm of nuclear physics, I have investigated resonance internal conversion processes, demonstrating their potential for enhancing nuclear transition rates significantly. This work highlights the historical context and practical implications of nuclear processes, particularly in the case of specific isotopes.\n\nMy contributions to computer vision include developing a novel optimization approach for 3D reconstruction using differentiable rendering. This method integrates camera pose, geometry, and texture optimization into a unified framework, addressing common artifacts in RGB-D sensor data. Additionally, I have pioneered techniques for object insertion in 3D content through a multi-view diffusion model, enhancing scene recreation and object quality.\n\nMost recently, I introduced VQ-NeRF, a two-branch neural network model that leverages vector quantization for material decomposition and editing in 3D scenes. This innovative approach allows for discrete material editing, significantly improving usability and performance in both synthetic and real-world applications. My work aims to bridge theoretical insights with practical applications, driving advancements in both fundamental science and technology.",
    "collaborators": [
      "Jing Liao",
      "Hongliang Zhong",
      "Yanyan Bu",
      "Biye Zhang",
      "Feodor Karpeshin",
      "Weining Zhang",
      "Ziyu Wan",
      "Hang Yang",
      "Qichun Feng",
      "Can Wang"
    ],
    "domain": [
      "Computational Physics",
      "3D Reconstruction",
      "Neural Networks",
      "Quantum Mechanics"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "d256924f-833e-4483-aa3c-420602fe2197": {
    "pk": "d256924f-833e-4483-aa3c-420602fe2197",
    "project_name": null,
    "name": "Jing Liao",
    "bio": "I am a researcher deeply engaged in the field of visual in-context learning (ICL) and its applications in image processing and generation. My recent work, particularly with Analogist, has focused on enhancing visual ICL by integrating both visual and textual prompting techniques, allowing for more nuanced analogical reasoning without the need for extensive fine-tuning. This approach has proven effective across a variety of visual tasks, showcasing the flexibility and power of combining different modalities.\n\nIn addition to ICL, I have developed innovative solutions for 3D reconstruction and image restoration, such as the RaFE pipeline, which addresses the challenges of low-quality input images in Neural Radiance Fields (NeRF). My work in generative adversarial networks (GANs) has also led to the creation of CariGANs, a pioneering method for unpaired photo-to-caricature translation that allows for user-controlled exaggeration and style transfer.\n\nI am particularly passionate about advancing the capabilities of neural style transfer, both in single-style and multi-style contexts, and have introduced frameworks that enhance the quality and diversity of stylization results. My research extends to colorization techniques, where I developed UniColor, a unified framework that supports multiple modalities for colorization tasks.\n\nThrough my work, I aim to push the boundaries of what is possible in visual learning and image generation, making these technologies more accessible and effective for a wide range of applications. I am committed to sharing my findings and tools with the community to foster further innovation in this exciting field.",
    "collaborators": [
      "Shiyuan Yang",
      "Lu Yuan",
      "Zhitong Huang",
      "Nanxuan Zhao",
      "Zheng Gu",
      "Jing Huo",
      "Yang Gao",
      "Zhongkai Wu",
      "Ziyu Wan",
      "Jing Zhang"
    ],
    "domain": [
      "Computer Vision",
      "Generative Models",
      "Image Processing",
      "Deep Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
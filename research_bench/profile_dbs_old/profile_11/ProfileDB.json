{
  "50ea7df5-458a-4520-97f1-c7406c4bbce5": {
    "pk": "50ea7df5-458a-4520-97f1-c7406c4bbce5",
    "project_name": null,
    "name": "Owen Henkel",
    "bio": "I am a researcher dedicated to harnessing the power of machine learning and large language models (LLMs) to enhance educational assessment and learning outcomes. My work primarily focuses on developing scalable and effective methods for evaluating student performance, particularly in low-resource settings. I have explored innovative approaches, such as using non-expert crowdworkers and comparative judgment to assess complex student responses, demonstrating significant improvements in inter-rater reliability.\n\nMy research also delves into the integration of LLMs within Intelligent Tutoring Systems (ITSs), where I have evaluated their safety and effectiveness through extensive empirical studies. For instance, I found that GPT-4 can grade open-ended responses with near-human accuracy, suggesting its potential as a valuable tool for formative assessments in K-12 education.\n\nAdditionally, I have investigated the use of large-scale speech models to automate the evaluation of oral reading fluency, achieving promising results that align closely with expert human graders. My recent work with the AMMORE dataset further highlights the capabilities of LLMs in grading challenging student answers, revealing how even modest improvements in grading accuracy can significantly impact the assessment of student mastery.\n\nOverall, my research aims to bridge the gap between advanced AI technologies and practical educational applications, ultimately striving to improve learning experiences for students across diverse contexts.",
    "collaborators": [
      "Libby Hills",
      "Bill Roberts",
      "Hannah Horne-Robinson",
      "Joshua McGrane",
      "Zachary Levonian",
      "Adam Boxer",
      "Nessie Kozhakhmetova",
      "Amanda Lee",
      "Maria Dyshel",
      "Nabil Ch"
    ],
    "domain": [
      "Machine Learning",
      "Educational Technology",
      "Natural Language Processing",
      "Assessment Automation"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "76786820-8c0a-4b02-b740-00a130098f84": {
    "pk": "76786820-8c0a-4b02-b740-00a130098f84",
    "project_name": null,
    "name": "Hannah Horne-Robinson",
    "bio": "As a researcher deeply immersed in the field of graph neural networks (GNNs) and machine learning, my work focuses on enhancing the capabilities and understanding of these powerful models. My recent publications reflect a commitment to addressing the limitations of existing GNN architectures. For instance, I developed Position-aware GNNs (P-GNNs) to better capture the positional context of nodes within graphs, significantly improving performance in tasks like link prediction and community detection.\n\nI also introduced Identity-aware GNNs (ID-GNNs), which extend the expressive power of traditional GNNs by incorporating node identity during message passing. This innovation has led to substantial accuracy improvements across various prediction tasks. My exploration of dynamic graphs culminated in the ROLAND framework, which allows static GNNs to adapt to dynamic environments, thereby enhancing their scalability and effectiveness.\n\nIn addition to architectural advancements, I have investigated the interplay between neural network structures and their predictive performance through relational graphs. My work aims to systematically study the design space of GNNs, providing guidelines for optimizing architectures across different tasks. I am also passionate about making AutoML more efficient, as demonstrated by my development of AutoTransfer, which leverages prior architectural knowledge to streamline the search for optimal models.\n\nOverall, my research is driven by a desire to push the boundaries of what GNNs can achieve, making them more adaptable, interpretable, and effective in real-world applications.",
    "collaborators": [],
    "domain": [
      "Graph Neural Network",
      "Machine Learning",
      "Multi-task Learning",
      "AutoML"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "1b67cdb0-ae54-4982-8d07-3ee9f115995a": {
    "pk": "1b67cdb0-ae54-4982-8d07-3ee9f115995a",
    "project_name": null,
    "name": "Maria Dyshel",
    "bio": "I am a researcher dedicated to enhancing educational assessment through the innovative use of large language models (LLMs). My recent work centers around the AMMORE dataset, which comprises 53,000 math open-response question-answer pairs sourced from Rori, a learning platform utilized by students across several African countries. This dataset not only serves as a vital resource for analyzing student math acquisition in underrepresented educational contexts but also facilitates the exploration of advanced grading techniques.\n\nIn my research, I conducted experiments to evaluate the effectiveness of LLMs in grading challenging student responses. I discovered that employing chain-of-thought prompting significantly improved grading accuracy, elevating the overall performance from 98.7% to an impressive 99.9%. Furthermore, I investigated the implications of this enhanced accuracy on student mastery estimation using a Bayesian Knowledge Tracing model. The results revealed that even modest improvements in grading precision could lead to substantial changes in assessing student understanding, reducing misclassification rates from 6.9% to 2.6%.\n\nThrough my work, I aim to demonstrate the potential of LLMs as valuable tools in K-12 mathematics education, advocating for the broader adoption of open-ended questions in formative assessments. I am passionate about leveraging technology to create more equitable and effective educational experiences for students.",
    "collaborators": [
      "Owen Henkel",
      "Hannah Horne-Robinson",
      "Nabil Ch",
      "Baptiste Moreau-Pernet",
      "Ralph Abood"
    ],
    "domain": [
      "Natural Language Processing",
      "Educational Technology",
      "Machine Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "420ba272-ac5b-42d6-82c6-2818b2ce2fe1": {
    "pk": "420ba272-ac5b-42d6-82c6-2818b2ce2fe1",
    "project_name": null,
    "name": "Nabil Ch",
    "bio": "I am a researcher dedicated to the exploration of Generalized Parton Distributions (GPDs) and their implications in hadron physics. My recent work focuses on extending GPDs to the full kinematic domain through a novel procedure that addresses both polynomiality and positivity, which are crucial for the consistency of these distributions. By applying this method to models of Light-front wave-functions, particularly within the framework of the chiral quark soliton model, I have demonstrated how to achieve a systematic phenomenology of GPD models using the PARTONS framework and Deeply Virtual Compton Scattering (DVCS) data.\n\nMy research aims to bridge the gap between GPDs and Transverse Momentum Distributions (TMDs), ultimately contributing to the field of hadron tomography. I am passionate about developing theoretical tools that enhance our understanding of the internal structure of hadrons and their dynamics, and I strive to create a unified phenomenological approach that can be applied across various models and experimental data. Through my work, I hope to advance the field of particle physics and contribute to a deeper understanding of the fundamental constituents of matter.",
    "collaborators": [
      "Nabil Chouika"
    ],
    "domain": [
      "Quantum Field Theory",
      "Generalized Parton Distributions",
      "Hadron Physics"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "dbe0e1df-3c46-4f80-8465-3e4fb9455a35": {
    "pk": "dbe0e1df-3c46-4f80-8465-3e4fb9455a35",
    "project_name": null,
    "name": "Baptiste Moreau-Pernet",
    "bio": "As a researcher deeply immersed in the field of graph neural networks (GNNs) and their applications, my work focuses on enhancing the capabilities and understanding of these powerful models. My recent publications reflect a commitment to addressing the limitations of existing GNN architectures. For instance, I developed Position-aware GNNs (P-GNNs) to better capture the positional context of nodes within graphs, significantly improving performance in tasks like link prediction and community detection.\n\nI also introduced Identity-aware GNNs (ID-GNNs), which extend the expressive power of traditional GNNs by incorporating node identities during message passing. This innovation has led to substantial accuracy improvements across various prediction tasks. My exploration of dynamic graphs culminated in the ROLAND framework, which allows static GNNs to adapt to dynamic environments, showcasing the scalability and efficiency of my approaches.\n\nIn addition to architectural advancements, I have delved into the design space of GNNs, systematically studying over 315,000 designs to provide guidelines for optimal model selection across different tasks. My work on AutoML, particularly with FALCON and AutoTransfer, aims to streamline the search for effective neural architectures by leveraging prior knowledge, thus reducing computational costs.\n\nOverall, my research is driven by a passion for pushing the boundaries of GNNs and making them more accessible and effective for real-world applications. I am excited about the future directions of this field and the potential for my contributions to inspire further innovations.",
    "collaborators": [],
    "domain": [
      "Graph Neural Network",
      "Machine Learning",
      "Multi-task Learning",
      "AutoML"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "2d62e707-3a82-4837-988a-6e119cac0709": {
    "pk": "2d62e707-3a82-4837-988a-6e119cac0709",
    "project_name": null,
    "name": "Ralph Abood",
    "bio": "I am a researcher dedicated to enhancing educational assessment through the innovative use of large language models (LLMs). My recent work centers around the AMMORE dataset, which comprises 53,000 math open-response question-answer pairs sourced from Rori, a learning platform utilized by students across several African countries. This dataset not only serves as a vital resource for analyzing student math acquisition in underrepresented educational contexts but also facilitates the exploration of advanced grading techniques.\n\nIn my research, I conducted experiments to evaluate the effectiveness of LLMs in grading challenging student responses. By employing various approaches, including zero-shot, few-shot, and chain-of-thought prompting, I discovered that the chain-of-thought method significantly improved grading accuracy, elevating it from 98.7% to an impressive 99.9%. Furthermore, I investigated the consequential validity of these improvements by integrating the LLM-generated grades into a Bayesian Knowledge Tracing model, revealing that even modest enhancements in grading accuracy can lead to substantial shifts in estimating student mastery.\n\nMy findings underscore the potential of LLMs as transformative tools in K-12 mathematics education, advocating for the broader adoption of open-ended questions in formative assessments. I am passionate about leveraging technology to create more equitable and effective educational experiences for students.",
    "collaborators": [
      "Owen Henkel",
      "Hannah Horne-Robinson",
      "Maria Dyshel",
      "Nabil Ch",
      "Baptiste Moreau-Pernet"
    ],
    "domain": [
      "Natural Language Processing",
      "Educational Technology",
      "Machine Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
{
  "5e0005fb-6a41-49c7-92bf-e8aa2c2db4ae": {
    "pk": "5e0005fb-6a41-49c7-92bf-e8aa2c2db4ae",
    "project_name": null,
    "name": "Nam Hyeon-Woo",
    "bio": "I am a researcher dedicated to enhancing the efficiency and understanding of machine learning models, particularly in the realms of federated learning and vision-language models. My recent work has led to the development of FedPara, a communication-efficient parameterization for federated learning that significantly reduces model upload and download burdens while maintaining performance. This innovation not only streamlines communication costs but also extends to personalized federated learning through pFedPara, which optimizes parameter management for better adaptability.\n\nIn addition to federated learning, I have delved into the intricacies of vision-language models (VLMs). I introduced a novel eye examination process to assess how VLMs perceive images, revealing critical insights into their sensitivities to color, shape, and semantic recognition. This work, supported by the LENS dataset, aims to inform the design of VLMs and enhance their performance in real-world applications.\n\nFurthermore, I have explored the role of attention mechanisms in Vision Transformers (ViTs). My research on Context Broadcasting (CB) has shown that enhancing spatial interactions through uniform attention can improve model capacity and generalizability without incurring significant computational costs. Through these contributions, I strive to push the boundaries of machine learning, making models more efficient and interpretable while addressing real-world challenges.",
    "collaborators": [
      "Tae-Hyun Oh",
      "Moon Ye-Bin",
      "Wonseok Choi",
      "Lee Hyun",
      "Kim Yu-Ji",
      "Byeongho Heo",
      "Dongyoon Han",
      "Seong Joon Oh"
    ],
    "domain": [
      "Federated Learning",
      "Vision Language Models",
      "Vision Transformers",
      "Machine Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "07a06be9-22eb-4ff5-bc5f-bc3215fe790f": {
    "pk": "07a06be9-22eb-4ff5-bc5f-bc3215fe790f",
    "project_name": null,
    "name": "Moon Ye-Bin",
    "bio": "I am a researcher dedicated to enhancing the capabilities and trustworthiness of vision-language models (VLMs) and addressing challenges in visual perception and data imbalance. My recent work focuses on understanding and mitigating hallucination in VLMs, where I developed the BEfore-AFter hallucination dataset (BEAF) and introduced novel metrics to evaluate VLM performance in real-world scenarios. This research aims to improve the reliability of VLM outputs, enabling users to trust the results more fully.\n\nIn addition to VLMs, I have explored weakly-supervised low-shot instance segmentation through my method, ENInst, which enhances model performance by refining instance masks and improving classification accuracy. This approach demonstrates significant efficiency gains compared to fully-supervised models.\n\nI also proposed TextManiA, a text-driven manifold augmentation technique that enriches visual feature spaces by leveraging the semantic power of language models. This work highlights the potential of language encoders to enhance visual representation, particularly in scenarios with scarce or imbalanced data.\n\nLastly, I have investigated the use of synthetic data to combat data imbalance issues in training datasets. My method, SYNAuG, shows that combining synthetic data with real samples can lead to impressive performance improvements across various tasks. Through these contributions, I aim to push the boundaries of how we understand and utilize VLMs and machine learning models in general.",
    "collaborators": [
      "Tae-Hyun Oh",
      "Nam Hyeon-Woo",
      "Wonseok Choi",
      "Dongmin Choi",
      "Yongjin Kwon",
      "Junsik Kim",
      "Jisoo Kim",
      "Hongyeob Kim",
      "Kilho Son",
      "Nayeong Kim"
    ],
    "domain": [
      "Vision Language Models",
      "Data Augmentation",
      "Instance Segmentation",
      "Synthetic Data"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "1ac1429c-fa9b-44a8-a4fb-d0d829da2b57": {
    "pk": "1ac1429c-fa9b-44a8-a4fb-d0d829da2b57",
    "project_name": null,
    "name": "Wonseok Choi",
    "bio": "I am a researcher dedicated to advancing the fields of cryptography, machine learning, and blockchain technology. My recent work focuses on addressing critical challenges in fully homomorphic encryption (FHE) and vision-language models (VLMs). I developed Cheddar, an FHE library optimized for CUDA GPUs, which significantly enhances performance for encrypted data processing, achieving up to 25.6 times faster execution compared to previous implementations.\n\nIn the realm of VLMs, I have explored their vulnerabilities, particularly the issue of hallucination, by creating the BEAF dataset and introducing new metrics to assess their understanding of visual scenes. My research also delves into mitigating data imbalance in training datasets through synthetic data generation with SYNAuG, demonstrating its effectiveness across various tasks.\n\nAdditionally, I have investigated the visual perception capabilities of VLMs through a novel eye examination process, revealing insights into their sensitivities to color, shape, and semantic recognition. My work extends to blockchain technology, where I proposed a decentralized system for compliance with the Financial Action Task Force's travel rule, ensuring secure data exchange.\n\nThrough empirical analysis of over 592 cryptocurrency projects, I have highlighted the challenges of code maintenance and security vulnerabilities, providing a critical perspective on the cryptocurrency landscape. My research aims to bridge theoretical advancements with practical applications, ultimately enhancing the reliability and security of emerging technologies.",
    "collaborators": [
      "Moon Ye-Bin",
      "Nam Hyeon-Woo",
      "Tae-Hyun Oh",
      "Jongmin Kim",
      "Jung Ho Ahn",
      "Nayeong Kim",
      "Suha Kwak",
      "Lee Hyun",
      "Chaehyeon Lee",
      "Changhoon Kang"
    ],
    "domain": [
      "Cryptography",
      "Vision Language Models",
      "Data Imbalance",
      "Blockchain"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "73c5456a-6ac7-4ef2-b09c-3b9fb0f46bcc": {
    "pk": "73c5456a-6ac7-4ef2-b09c-3b9fb0f46bcc",
    "project_name": null,
    "name": "Lee Hyun",
    "bio": "As a researcher deeply immersed in the field of graph neural networks (GNNs) and machine learning, my work focuses on enhancing the capabilities and understanding of these powerful models. My recent publications reflect a commitment to addressing the limitations of existing GNN architectures and exploring innovative solutions. For instance, I developed Position-aware GNNs (P-GNNs) to better capture the positional context of nodes within graphs, significantly improving performance in tasks like link prediction and community detection.\n\nI also introduced Identity-aware GNNs (ID-GNNs), which extend the expressive power of traditional GNNs by incorporating node identity during message passing. This advancement has led to substantial accuracy improvements across various prediction tasks. Additionally, I proposed the ROLAND framework, which enables the adaptation of static GNNs to dynamic graphs, addressing the challenges posed by evolving data structures.\n\nMy research extends beyond GNNs; I have investigated the relationship between neural network architectures and their predictive performance through a novel relational graph representation. This work has opened new avenues for designing more effective neural architectures.\n\nI am passionate about systematically exploring the design space of GNNs, leading to the development of tools like GraphGym, which facilitates the exploration of different GNN designs and tasks. My goal is to bridge the gap between theoretical advancements and practical applications, ultimately contributing to the evolution of machine learning methodologies.",
    "collaborators": [],
    "domain": [
      "Graph Neural Network",
      "Machine Learning",
      "Multi-task Learning",
      "AutoML"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "6a15850f-026a-42f3-8985-4cdef6e809cd": {
    "pk": "6a15850f-026a-42f3-8985-4cdef6e809cd",
    "project_name": null,
    "name": "Tae-Hyun Oh",
    "bio": "As a researcher deeply immersed in the field of graph neural networks (GNNs) and their applications, my work focuses on enhancing the capabilities and understanding of these powerful models. My recent publications reflect a commitment to addressing the limitations of existing GNN architectures. For instance, I developed Position-aware GNNs (P-GNNs) to better capture the positional context of nodes within graphs, significantly improving performance on tasks like link prediction and community detection.\n\nI also introduced Identity-aware GNNs (ID-GNNs), which extend the expressive power of traditional GNNs by incorporating node identity during message passing. This innovation has led to substantial accuracy improvements across various prediction tasks. My exploration of dynamic graphs culminated in the ROLAND framework, which allows static GNNs to adapt to dynamic environments, showcasing the scalability and efficiency of my approaches.\n\nIn addition to architectural advancements, I have delved into the design space of GNNs, systematically studying over 315,000 designs to provide guidelines for optimal model selection across different tasks. My work on AutoML, particularly with FALCON and AutoTransfer, aims to streamline the search for effective neural architectures by leveraging prior knowledge, thus reducing computational costs.\n\nOverall, my research is driven by a passion for understanding and improving the interplay between graph structures and machine learning, with the goal of making GNNs more accessible and effective for real-world applications.",
    "collaborators": [],
    "domain": [
      "Graph Neural Network",
      "Machine Learning",
      "Multi-task Learning",
      "AutoML"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
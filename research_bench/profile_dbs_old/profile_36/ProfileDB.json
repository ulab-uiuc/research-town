{
  "3c0c357f-74cb-4699-8dc9-24590ea70740": {
    "pk": "3c0c357f-74cb-4699-8dc9-24590ea70740",
    "project_name": null,
    "name": "Rwiddhi Chakraborty",
    "bio": "I am a researcher dedicated to addressing biases in deep learning and enhancing model robustness through innovative methodologies. My recent work includes a thorough investigation of the ReBias framework, where I successfully reproduced results on the biased MNIST dataset and critically analyzed its claims, contributing valuable insights for future research. I developed ExMap, an unsupervised mechanism that leverages explainability heatmaps to enhance group robustness in classifiers, demonstrating its effectiveness in bridging performance gaps with supervised methods.\n\nAdditionally, I have focused on optimizing the computation of Surprise Adequacy (SA) metrics, significantly reducing evaluation time while maintaining accuracy, which is crucial for effective deep learning testing. My work on CONBIAS introduced a novel framework for diagnosing and mitigating concept co-occurrence biases in visual datasets, utilizing knowledge graphs to enhance dataset reliability and model performance.\n\nI also tackled the hubness problem in transductive few-shot learning, proposing methods to distribute representations uniformly on the hypersphere, which not only mitigates hubness but also improves classification accuracy. My research aims to provide practical solutions and frameworks that empower the machine learning community to build fairer and more reliable models.",
    "collaborators": [
      "Shubhayu Das",
      "Adrian Sletten",
      "Michael Kampffmeyer",
      "Michael Weiss",
      "Paolo Tonella",
      "Yinong Wang",
      "Jialu Gao",
      "Runkai Zheng",
      "Cheng Zhang",
      "Fernando De la Torre"
    ],
    "domain": [
      "Bias Mitigation",
      "Deep Learning",
      "Image Recognition",
      "Few-Shot Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "63d883c9-f0fb-4469-b6e0-4b14b235ec74": {
    "pk": "63d883c9-f0fb-4469-b6e0-4b14b235ec74",
    "project_name": null,
    "name": "Yinong Wang",
    "bio": "I am a researcher dedicated to advancing the fields of medical imaging and natural language processing (NLP) through innovative methodologies and deep learning techniques. My recent work has focused on the classification and segmentation of vertebral compression fractures (VCFs), where I developed a robust classification system utilizing automated measurements from CT studies. This system has shown promising accuracy in distinguishing between osteoporotic and neoplastic fractures, which is crucial for treatment planning.\n\nIn addition to fracture classification, I have explored advanced segmentation techniques for the vertebral column, employing multi-atlas joint label fusion to enhance accuracy in the presence of pathologies. My research also addresses the challenges of bias in deep learning models, leading to the creation of CONBIAS, a framework designed to diagnose and mitigate concept co-occurrence biases in visual datasets. This work emphasizes the importance of reliable data for effective model performance.\n\nMoreover, I have ventured into the realm of computer-aided detection (CADe) for spine fractures, applying deep convolutional networks to automate the detection of posterior element fractures, achieving significant sensitivity rates. My interests extend to NLP, where I proposed Robust Embeddings via Distributions (RED) to enhance model robustness in noisy environments.\n\nThrough my research, I aim to bridge the gap between advanced computational techniques and practical applications in healthcare and language processing, ultimately contributing to improved diagnostic and treatment outcomes.",
    "collaborators": [
      "Jianhua Yao",
      "Joseph E. Burns",
      "Ronald M. Summers",
      "Holger R. Roth",
      "Jiawei Liu",
      "Qiang Wang",
      "Huijie Fan",
      "Yandong Tang",
      "Liangqiong Qu",
      "Rwiddhi Chakraborty"
    ],
    "domain": [
      "Medical Imaging",
      "Deep Learning",
      "Natural Language Processing",
      "Computer Vision"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "99ed0cca-266b-446f-beca-359fd8d4396f": {
    "pk": "99ed0cca-266b-446f-beca-359fd8d4396f",
    "project_name": null,
    "name": "Jialu Gao",
    "bio": "I am a researcher dedicated to advancing the intersection of robotics and generative models, particularly in the realm of visual understanding and manipulation. My recent work, encapsulated in the Learning from the Void (LfVoid) framework, explores how pre-trained text-to-image generative models can enhance robot learning by enabling agents to edit observations based on natural language instructions. This innovative approach allows robots to achieve specific goals, such as cleaning tasks, without requiring extensive in-domain training, leveraging the vast knowledge embedded in web-scale generative models.\n\nIn addition to my work on generative models, I am also deeply invested in addressing biases in visual datasets. My framework, CONBIAS, provides a systematic method for diagnosing and mitigating concept co-occurrence biases, which can lead to unreliable predictions in deep learning models. By representing datasets as knowledge graphs, I enable a thorough analysis of concept imbalances and propose a novel balancing strategy that significantly enhances model performance across various tasks.\n\nThrough these projects, I aim to bridge the gap between advanced machine learning techniques and practical applications in robotics, ensuring that our systems are not only effective but also fair and reliable. I am excited about the potential of generative models in robotics and the ongoing challenge of creating unbiased datasets for robust AI systems.",
    "collaborators": [
      "Kaizhe Hu",
      "Guowei Xu",
      "Huazhe Xu",
      "Rwiddhi Chakraborty",
      "Yinong Wang",
      "Runkai Zheng",
      "Cheng Zhang",
      "Fernando De la Torre"
    ],
    "domain": [
      "Robotics",
      "Generative Models",
      "Bias Mitigation",
      "Deep Learning"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "91935feb-4ac0-4676-8c4f-150f810884ff": {
    "pk": "91935feb-4ac0-4676-8c4f-150f810884ff",
    "project_name": null,
    "name": "Runkai Zheng",
    "bio": "I am a researcher dedicated to enhancing the robustness and performance of deep learning models, particularly in the context of adversarial attacks and biases in datasets. My recent work has focused on addressing vulnerabilities in Deep Neural Networks (DNNs) through innovative methods such as Channel Lipschitzness based Pruning (CLP), which effectively identifies and mitigates backdoor attacks by analyzing channel sensitivity. I have also explored the integration of expert knowledge into Bayesian optimization, leveraging multi-task learning to accelerate optimization processes.\n\nIn the realm of Fine-Grained Visual Classification (FGVC), I proposed a novel minimax loss framework that enforces feature uniqueness, significantly improving classification performance without additional computational costs. My research extends to Vision Transformers (ViTs), where I introduced SpecFormer, a model designed to enhance robustness against adversarial attacks through theoretical foundations and practical implementations.\n\nRecognizing the importance of addressing biases in training data, I developed CONBIAS, a framework for diagnosing and mitigating concept co-occurrence biases in visual datasets. This work not only improves model generalization but also contributes to the responsible deployment of AI systems.\n\nAdditionally, I have conducted a thorough evaluation of ChatGPT's robustness, revealing insights into its performance under adversarial conditions and out-of-distribution scenarios. My research aims to push the boundaries of deep learning, ensuring that models are not only powerful but also reliable and fair in their predictions.",
    "collaborators": [
      "Li Liu",
      "Xixu Hu",
      "Jindong Wang",
      "Xing Xie",
      "Rongjun Tang",
      "Jianze Li",
      "Daolang Huang",
      "Louis Filstroff",
      "Petrus Mikkola",
      "Samuel Kaski"
    ],
    "domain": [
      "Adversarial Machine Learning",
      "Deep Learning",
      "Computer Vision",
      "Bayesian Optimization"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "d3845323-e572-4fe5-ba63-806a563fbf9b": {
    "pk": "d3845323-e572-4fe5-ba63-806a563fbf9b",
    "project_name": null,
    "name": "Cheng Zhang",
    "bio": "I am a researcher with a diverse background in mathematical modeling, machine learning, and computational methods. My work spans various domains, including dynamical systems, phylogenetics, and variational inference. Recently, I have focused on developing innovative approaches to complex problems, such as creating a novel structural representation method for phylogenetic inference that leverages learnable topological features. This method enhances the efficiency of phylogenetic analysis without requiring extensive domain expertise.\n\nIn the realm of nonlinear dynamics, I have contributed to the understanding of soliton solutions for the focusing nonlinear Schr\u00f6dinger equation, employing integrable boundary conditions to derive explicit solutions. My research also extends to variational Bayesian phylogenetic inference, where I introduced VBPI-NF, a framework that utilizes normalizing flows to improve the estimation of phylogenetic posteriors.\n\nAdditionally, I have explored advanced forecasting methods for univariate random walks, proposing a decision fusion approach that integrates various machine learning models to enhance prediction accuracy. My work on particle-based variational inference has led to the development of the generalized Wasserstein gradient descent framework, which offers strong convergence guarantees and improved performance in real-world applications.\n\nOverall, my research is characterized by a commitment to bridging theoretical insights with practical applications, aiming to advance our understanding of complex systems and improve methodologies across various fields.",
    "collaborators": [
      "Ziheng Cheng",
      "Shiyue Zhang",
      "Longlin Yu"
    ],
    "domain": [
      "Mathematics",
      "Phylogenetics",
      "Machine Learning",
      "Nonlinear Dynamics"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  },
  "0fa45d96-27ed-4470-a682-7ff23859b9ed": {
    "pk": "0fa45d96-27ed-4470-a682-7ff23859b9ed",
    "project_name": null,
    "name": "Fernando De la Torre",
    "bio": "I am a researcher deeply engaged in the intersection of computer vision and generative modeling, with a particular focus on enhancing the capabilities of text-to-image diffusion models and exploring innovative applications in human pose estimation and virtual reality. My recent work has introduced Contrastive Guidance, a method that allows for fine-grained control over image factors in text-to-image generation, significantly improving the usability of these models.\n\nI have also developed the Supervised Descent Method (SDM), which addresses the challenges of nonlinear optimization in computer vision, achieving state-of-the-art results in facial feature detection and image alignment tasks. My exploration of using WiFi signals for dense human pose estimation has opened new avenues for low-cost and privacy-preserving human sensing technologies, demonstrating that we can achieve comparable performance to traditional image-based methods.\n\nIn the realm of generative models, I have proposed a Gaussian formulation of the latent space for diffusion models, leading to the development of CycleDiffusion for unpaired image-to-image translation. This work highlights the potential of diffusion models as zero-shot image editors, showcasing their versatility and effectiveness.\n\nMy research also includes the Generative Visual Prompt (PromptGen) framework, which enables controlled sampling from generative models, addressing biases and enhancing the quality of generated outputs. Lastly, I am pioneering advancements in VR telepresence with Modular Codec Avatars, aiming to create hyper-realistic avatars that enhance user interaction in virtual environments. Through these contributions, I strive to push the boundaries of what is possible in computer vision and generative modeling.",
    "collaborators": [
      "Chen Henry Wu",
      "Chen Wu",
      "Xuehan Xiong",
      "Jiaqi Geng",
      "Dong Huang",
      "Saman Motamed",
      "Shaunak Srivastava",
      "Hang Chu",
      "Shugao Ma",
      "Sanja Fidler"
    ],
    "domain": [
      "Computer Vision",
      "Generative Models",
      "Human Pose Estimation",
      "Diffusion Models"
    ],
    "institute": null,
    "embed": null,
    "is_leader_candidate": true,
    "is_member_candidate": true,
    "is_reviewer_candidate": true,
    "is_chair_candidate": true
  }
}
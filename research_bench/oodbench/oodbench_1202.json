{
    "1406.2661": {
        "paper_data": {
            "title": "Generative Adversarial Networks",
            "url": "http://arxiv.org/abs/1406.2661v1",
            "arxiv_id": "1406.2661",
            "authors": [
                "Ian J. Goodfellow",
                "Jean Pouget-Abadie",
                "Mehdi Mirza",
                "Bing Xu",
                "David Warde-Farley",
                "Sherjil Ozair",
                "Aaron Courville",
                "Yoshua Bengio"
            ],
            "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
            "introduction": " Introduction The promise of deep learning is to discover rich, hierarchical models [2] that represent probability distributions over the kinds of data encountered in artiﬁcial intelligence applications, such as natural images, audio waveforms containing speech, and symbols in natural language corpora. So far, the most striking successes in deep learning have involved discriminative models, usually those that map a high-dimensional, rich sensory input to a class label [14, 22]. These striking successes have primarily been based on the backpropagation and dropout algorithms, using piecewise linear units [19, 9, 10] which have a particularly well-behaved gradient . Deep generative models have had less of an impact, due to the difﬁculty of approximating many intractable probabilistic computations that arise in maximum likelihood estimation and related strategies, and due to difﬁculty of leveraging the beneﬁts of piecewise linear units in the generative context. We propose a new generative model estimation procedure that sidesteps these difﬁculties.1 In the proposed adversarial nets framework, the generative model is pitted against an adversary: a discriminative model that learns to determine whether a sample is from the model distribution or the data distribution. The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods for coordinating GandDor determining better distributions to sample zfrom during training. This paper has demonstrated the viability of the adversarial modeling framework, suggesting that these research directions could prove useful. Related work An alternative to directed graphical models with latent variables are undirected graphical models with latent variables, such as restricted Boltzmann machines (RBMs) [27, 16], deep Boltzmann machines (DBMs) [26] and their numerous variants. The interactions within such models are represented as the product of unnormalized potential functions, normalized by a global summa- tion/integration over all states of the random variables. This quantity (the partition function ) and its gradient are intractable for all but the most trivial instances, although they can be estimated by Markov chain Monte Carlo (MCMC) results of this section are done in a non- parametric setting, e.g. we represent a model with inﬁnite capacity by studying convergence in the space of probability density functions. We will show in section 4.1 that this minimax game has a global optimum for pg=pdata. We will then show in section 4.2 that Algorithm 1 optimizes Eq 1, thus obtaining the desired result. 3Algorithm 1 Minibatch stochastic gradient descent training of generative adversarial nets. The number of steps to apply to the discriminator, k, is a hyperparameter. We used k= 1, the least expensive option, in our Results are reported in Table 1. This method of estimating the likelihood has somewhat high variance and does not perform well in high dimensional spaces but it is the best method available to our knowledge. Advances in generative models that can sample but not estimate likelihood directly motivate further research into how to evaluate such models. In Figures 2 and 3 we show samples drawn from the generator net after training. While we make no claim that these samples are better than samples generated by existing experiments. 4.1 Global Optimality of pg=pdata We ﬁrst consider the optimal discriminator",
            "references": []
        },
        "author_data": {
            "d67b8a7e-d46c-47b8-a2c1-bfe526d90369": {
                "pk": "d67b8a7e-d46c-47b8-a2c1-bfe526d90369",
                "project_name": null,
                "name": "Ian J. Goodfellow",
                "bio": "I am a researcher deeply engaged in the exploration of machine learning, particularly in the realms of neural networks and probabilistic models. My work has primarily focused on addressing critical challenges such as catastrophic forgetting in neural networks, where models struggle to retain knowledge from previous tasks when learning new ones. Through my investigations, I have demonstrated that dropout training consistently outperforms other methods in balancing the retention of old task performance while adapting to new tasks.\n\nI have also contributed to the development of advanced models like the partially directed deep Boltzmann machine (PD-DBM) and the multi-prediction deep Boltzmann machine (MP-DBM), which enhance classification capabilities without the need for greedy layer-wise training. My research on spike-and-slab sparse coding (S3C) has led to significant improvements in object recognition tasks, particularly in scenarios with limited labeled data.\n\nIn addition to theoretical advancements, I have been involved in practical applications, such as recognizing multi-digit numbers from Street View imagery, achieving state-of-the-art accuracy through a unified deep learning approach. My work with Theano has also facilitated research in deep learning by providing a robust framework for tensor operations and automatic differentiation.\n\nOverall, my research aims to push the boundaries of machine learning by developing models that are not only effective but also interpretable, addressing the complexities of real-world data and tasks. I am passionate about leveraging these advancements to create more intelligent systems that can learn and adapt in dynamic environments.",
                "collaborators": [
                    "Yoshua Bengio",
                    "Aaron C. Courville",
                    "David Warde-Farley",
                    "Mehdi Mirza",
                    "J. Bergstra",
                    "Pascal Lamblin",
                    "Razvan Pascanu",
                    "Frédéric Bastien",
                    "Vincent Dumoulin",
                    "D. Erhan",
                    "Guillaume Desjardins",
                    "Arnaud Bergeron",
                    "Xia Da",
                    "Yaroslav Bulatov",
                    "Julian Ibarz",
                    "Sacha Arnoud",
                    "Vinay D. Shet",
                    "Christian Szegedy",
                    "Wojciech Zaremba",
                    "I. Sutskever",
                    "Joan Bruna",
                    "R. Fergus",
                    "P. Carrier",
                    "Benjamin Hamner",
                    "William J. Cukierski",
                    "Yichuan Tang",
                    "David Thaler",
                    "Dong-Hyun Lee",
                    "Yingbo Zhou",
                    "Chetan Ramaiah",
                    "Fangxiang Feng",
                    "Ruifan Li",
                    "Xiaojie Wang",
                    "Dimitris Athanasakis",
                    "J. Shawe-Taylor",
                    "Maxim Milakov",
                    "John Park",
                    "Radu Tudor Ionescu",
                    "M. Popescu",
                    "C. Grozea",
                    "Jingjing Xie",
                    "Lukasz Romaszko",
                    "Bing Xu",
                    "Chuang Zhang",
                    "Olivier Breuleux",
                    "Olivier Delalleau",
                    "Nicolas Bouchard",
                    "Daftar Pustaka",
                    "Februari",
                    "Boshra Bahrami",
                    "Mirsaeid Hosseini",
                    "Januari",
                    "Grégoire Mesnil",
                    "Yann Dauphin",
                    "Xavier Glorot",
                    "Salah Rifai",
                    "Y. Bengio",
                    "Erick Lavoie",
                    "X. Muller",
                    "Pascal Vincent"
                ],
                "pub_titles": [
                    "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
                    "On the Challenges of Physical Implementations of RBMs",
                    "Pylearn2: a machine learning research library",
                    "Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning",
                    "Multi-Prediction Deep Boltzmann Machines",
                    "Piecewise Linear Multilayer Perceptrons and Dropout",
                    "An empirical analysis of dropout in piecewise linear networks",
                    "Joint Training Deep Boltzmann Machines for Classification",
                    "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks",
                    "Maxout Networks",
                    "Intriguing properties of neural networks",
                    "Large-Scale Feature Learning With Spike-and-Slab Sparse Coding",
                    "Theano: Deep Learning on GPUs with Python",
                    "Joint Training of Partially-Directed Deep Boltzmann Machines",
                    "Theano: new features and speed improvements",
                    "Spike-and-Slab Sparse Coding for Unsupervised Feature Discovery",
                    "Joint Training of Deep Boltzmann Machines",
                    "Mining",
                    "Unsupervised and Transfer Learning Challenge: a Deep Learning Approach"
                ],
                "pub_abstracts": [
                    "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
                    "    Restricted Boltzmann machines (RBMs) are powerful machine learning models, but learning and some kinds of inference in the model require sampling-based approximations, which, in classical digital computers, are implemented using expensive MCMC. Physical computation offers the opportunity to reduce the costof sampling by building physical systems whose natural dynamics correspond to drawing samples from the desired RBM distribution. Such a system avoids the burn-in and mixing cost of a Markov chain. However, hardware implementations of this variety usually entail limitations such as low-precision and limited range of the parameters and restrictions on the size and topology of the RBM. We conduct software simulations to determine how harmful each of these restrictions is. Our simulations are based on the D-Wave Two computer, but the issues we investigate arise in most forms of physical computation.Our findings suggest that designers of new physical computing hardware and algorithms for physical computers should focus their efforts on overcoming the limitations imposed by the topology restrictions of currently existing physical computers.   ",
                    "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
                    "We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.",
                    "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
                    "We propose a new type of hidden layer for a multilayer perceptron, and demonstrate that it obtains the best reported performance for an MLP on the MNIST dataset.",
                    "The recently introduced dropout training criterion for neural networks has been the subject of much attention due to its simplicity and remarkable effectiveness as a regularizer, as well as its interpretation as a training procedure for an exponentially large ensemble of networks that share parameters. In this work we empirically investigate several questions related to the efficacy of dropout, specifically as it concerns networks employing the popular rectified linear activation function. We investigate the quality of the test time weight-scaling inference procedure by evaluating the geometric average exactly in small models, as well as compare the performance of the geometric mean to the arithmetic mean more commonly employed by ensemble techniques. We explore the effect of tied weights on the ensemble interpretation by training ensembles of masked networks without tied weights. Finally, we investigate an alternative criterion based on a biased estimator of the maximum likelihood ensemble gradient.",
                    "We introduce a new method for training deep Boltzmann machines jointly. Prior methods of training DBMs require an initial learning pass that trains the model greedily, one layer at a time, or do not perform well on classification tasks. In our approach, we train all layers of the DBM simultaneously, using a novel training procedure called multi-prediction training. The resulting model can either be interpreted as a single generative model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent networks that share parameters and may be approximately averaged together using a novel technique we call the multi-inference trick. We show that our approach performs competitively for classification and outperforms previous methods in terms of accuracy of approximate inference and classification with missing inputs.",
                    "Abstract: Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural network that operates directly on the image pixels. We employ the DistBelief implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the performance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over $96\\%$ accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art, achieving $97.84\\%$ accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over $90\\%$ accuracy. To further explore the applicability of the proposed system to broader text recognition tasks, we apply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the most secure reverse turing tests that uses distorted text to distinguish humans from bots. We report a $99.8\\%$ accuracy on the hardest category of reCAPTCHA. Our evaluations on both tasks indicate that at specific operating thresholds, the performance of the proposed system is comparable to, and in some cases exceeds, that of human operators.",
                    "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.",
                    "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.  First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks.  Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
                    "We consider the problem of object recognition with a large number of classes. In order to overcome the low amount of labeled examples available in this setting, we introduce a new feature learning and extraction procedure based on a factor model we call spike-and-slab sparse coding (S3C). Prior work on S3C has not prioritized the ability to exploit parallel architectures and scale S3C to the enormous problem sizes needed for object recognition. We present a novel inference procedure for appropriate for use with GPUs which allows us to dramatically increase both the training set size and the amount of latent factors that S3C may be trained with. We demonstrate that this approach improves upon the supervised learning capabilities of both sparse coding and the spike-and-slab Restricted Boltzmann Machine (ssRBM) on the CIFAR-10 dataset. We use the CIFAR-100 dataset to demonstrate that our method scales to large numbers of classes better than previous methods. Finally, we use our method to win the NIPS 2011 Workshop on Challenges In Learning Hierarchical Models' Transfer Learning Challenge.",
                    "In this paper, we present Theano 1 , a framework in the Python programming language for defining, optimizing and evaluating expressions involving high-level operations on tensors. Theano offers most of NumPy’s functionality, but adds automatic symbolic differentiation, GPU support, and faster expression evaluation. Theano is a general mathematical tool, but it was developed with the goal of facilitating research in deep learning. The Deep Learning Tutorials 2 introduce recent advances in deep learning, and showcase how Theano",
                    "We introduce a deep probabilistic model which we call the partially directed deep Boltzmann machine (PD-DBM). The PD-DBM is a model of real-valued data based on the deep Boltzmann machine (DBM) and the spike-and-slab sparse coding (S3C) model. We offer a hypothesis for why DBMs may not be trained succesfully without greedy layerwise training, and motivate the PD-DBM as a modified DBM that can be trained jointly.",
                    "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.",
                    "We consider the problem of using a factor model we call {\\em spike-and-slab sparse coding} (S3C) to learn features for a classification task. The S3C model resembles both the spike-and-slab RBM and sparse coding. Since exact inference in this model is intractable, we derive a structured variational inference procedure and employ a variational EM training algorithm. Prior work on approximate inference for this model has not prioritized the ability to exploit parallel architectures and scale to enormous problem sizes. We present an inference procedure appropriate for use with GPUs which allows us to dramatically increase both the training set size and the amount of latent factors.  We demonstrate that this approach improves upon the supervised learning capabilities of both sparse coding and the ssRBM on the CIFAR-10 dataset. We evaluate our approach's potential for semi-supervised learning on subsets of CIFAR-10. We demonstrate state-of-the art self-taught learning performance on the STL-10 dataset and use our method to win the NIPS 2011 Workshop on Challenges In Learning Hierarchical Models' Transfer Learning Challenge.",
                    "We introduce a new method for training deep Boltzmann machines jointly. Prior methods require an initial learning pass that trains the deep Boltzmann machine greedily, one layer at a time, or do not perform well on classifi- cation tasks.",
                    "Purpose. To establish the feasibility of refining deep open­pit mines below the boundary of the use of combined motor­con­ veyor transport with an increased slope angles of the pit walls using the developed transport unit for reloading rocks to overlying horizons during the reactivation of pillars under transport berms. Methodology. Preparation of a digital block model of the deposit, the elaboration of 3D geomechanical models for the dynam­ ics of mining, 2D and 3D numerical simulation of the rock stress­strain state of the outcrops of opencast workings, mathematical modeling of stepwise ore reserves and mining schedule, patent research and feasibility study. Findings. It is advisable to carry out mining in terms of the marginal rock state with an increase in the slope of the pit sides below the limit of application of the cyclic and continuous method in ultra­deep open pits. Such design of pit sides is achieved when benches are mined from top to bottom within the boundaries of steeply inclined layers with the use of inter­bench loaders of the developed designed in the completion zone. Provisions for the selection and feasibility of using the loader in the deep zone are formulated based on demarcation of application zones of cyclic (road transport) and cyclic­flow (combined road­conveyor trans­ port) technologies. Originality. Schematization of the mining operation was performed based on the calculated values of safety factor of sides, which allows increasing the slope angles of the pit walls of even ultra­deep open pits in the completion zone. It was found that with deepening of mining, the zones of potential sliding move away from the loose overburden to lower ore benches closer to the final depth of the Kacharsky open pit (760 m), but the safety factor corresponds to the required value according to the design standards. Practical value. An increase in the slope of the pit walls in the completion zone can be achieved using the developed loading installation, the main difference of which is that it can be moved without dismantling under conditions of reactivation of transport pillars (with an increase in lifting height by 1.5–4.5 times compared to the known equipment).",
                    "Learning good representations from a large set of unlabeled data is a particularly challenging task. Recent work (see Bengio (2009) for a review) shows that training deep architectures is a good way to extract such representations, by extracting and disentangling gradually higher-level factors of variation characterizing the input distribution. In this paper, we describe different kinds of layers we trained for learning representations in the setting of the Unsupervised and Transfer Learning Challenge. The strategy of our team won the final phase of the challenge. It combined and stacked different one-layer unsupervised learning algorithms, adapted to each of the five datasets of the competition. This paper describes that strategy and the particular one-layer learning algorithms feeding a simple linear classifier with a tiny number of labeled training samples (1 to 64 per class)."
                ],
                "domain": [
                    "Deep Learning",
                    "Neural Networks",
                    "Representation Learning",
                    "Object Recognition"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            },
            "84e178e3-b34c-4bde-b676-4b145a51feab": {
                "pk": "84e178e3-b34c-4bde-b676-4b145a51feab",
                "project_name": null,
                "name": "Mehdi Mirza",
                "bio": "I am a researcher deeply engaged in the exploration of neural networks and their capabilities, particularly in addressing challenges like catastrophic forgetting. My work has focused on understanding how different training algorithms and activation functions impact a model's ability to retain knowledge across tasks. Through my investigations, I have found that the dropout algorithm consistently outperforms others in balancing the retention of old tasks while adapting to new ones.\n\nIn addition to my work on catastrophic forgetting, I have contributed to the development of Pylearn2, a flexible machine learning research library designed to support innovative research projects. My involvement in the Emotion Recognition in the Wild Challenge showcased my ability to integrate multiple deep learning techniques, including convolutional neural networks and deep belief networks, to analyze complex data modalities like video and audio.\n\nI also introduced the multi-prediction deep Boltzmann machine (MP-DBM), which enhances classification tasks without the need for greedy layerwise pretraining, demonstrating improved performance over traditional models. My research on maxout, a model designed to work synergistically with dropout, has led to state-of-the-art results across several benchmark datasets.\n\nOverall, my work aims to push the boundaries of what neural networks can achieve, focusing on both theoretical advancements and practical applications in machine learning.",
                "collaborators": [
                    "Yoshua Bengio",
                    "Aaron C. Courville",
                    "I. Goodfellow",
                    "David Warde-Farley",
                    "Pascal Lamblin",
                    "Razvan Pascanu",
                    "J. Bergstra",
                    "Pascal Vincent",
                    "P. Carrier",
                    "Xia Da",
                    "Vincent Dumoulin",
                    "Frédéric Bastien",
                    "Samira Ebrahimi Kahou",
                    "C. Pal",
                    "Xavier Bouthillier",
                    "Pierre Froumenty",
                    "Çaglar Gülçehre",
                    "R. Memisevic",
                    "Raul Chandias Ferrari",
                    "Sébastien Jean",
                    "Yann Dauphin",
                    "Nicolas Boulanger-Lewandowski",
                    "Abhishek Aggarwal",
                    "Jeremie Zumer",
                    "Jean-Philippe Raymond",
                    "Guillaume Desjardins",
                    "Atousa Torabi",
                    "Arjun Sharma",
                    "Emmanuel Bengio",
                    "K. Konda",
                    "Zhenzhou Wu",
                    "D. Erhan",
                    "Benjamin Hamner",
                    "William J. Cukierski",
                    "Yichuan Tang",
                    "David Thaler",
                    "Dong-Hyun Lee",
                    "Yingbo Zhou",
                    "Chetan Ramaiah",
                    "Fangxiang Feng",
                    "Ruifan Li",
                    "Xiaojie Wang",
                    "Dimitris Athanasakis",
                    "J. Shawe-Taylor",
                    "Maxim Milakov",
                    "John Park",
                    "Radu Tudor Ionescu",
                    "M. Popescu",
                    "C. Grozea",
                    "Jingjing Xie",
                    "Lukasz Romaszko",
                    "Bing Xu",
                    "Chuang Zhang",
                    "Salah Rifai"
                ],
                "pub_titles": [
                    "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
                    "Pylearn2: a machine learning research library",
                    "Combining modality specific deep neural networks for emotion recognition in video",
                    "Multi-Prediction Deep Boltzmann Machines",
                    "Maxout Networks"
                ],
                "pub_abstracts": [
                    "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
                    "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
                    "In this paper we present the techniques used for the University of Montréal's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds, including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities, including: (1) a deep convolutional neural network for the analysis of facial expressions within video frames; (2) a deep belief net to capture audio information; (3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the mouth of the primary human subject in the scene. We discuss each of these techniques, their performance characteristics and different strategies to aggregate their predictions. Our best single model was a convolutional neural network trained to predict emotions from static frames using two large data sets, the Toronto Face Database and our own set of faces images harvested from Google image search, followed by a per frame aggregation strategy that used the challenge training data. This yielded a test set accuracy of 35.58%. Using our best strategy for aggregating our top performing models into a single predictor we were able to produce an accuracy of 41.03% on the challenge test set. These compare favorably to the challenge baseline test set accuracy of 27.56%.",
                    "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
                    "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN."
                ],
                "domain": [
                    "Deep Learning",
                    "Neural Networks",
                    "Emotion Recognition",
                    "Model Optimization"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            },
            "2b3f501a-7776-4f00-be4a-55aa19473b68": {
                "pk": "2b3f501a-7776-4f00-be4a-55aa19473b68",
                "project_name": null,
                "name": "David Warde-Farley",
                "bio": "I am a researcher deeply engaged in the intersection of machine learning and environmental science, particularly focusing on atmospheric data and reinforcement learning. My recent work has centered on developing innovative methods for compressing high-dimensional atmospheric states, enabling broader access to critical weather and climate data. By leveraging neural network architectures and advanced projection techniques, I have achieved impressive compression ratios while preserving essential features, such as extreme weather events.\n\nIn addition to atmospheric modeling, I have explored biases in machine learning models through the introduction of SkewSize, a novel metric that characterizes model mistakes across subgroups, enhancing our understanding of model performance. My research also extends to algorithm design, where I developed RbmSAT, an incomplete algorithm for Maximum Satisfiability tailored for neural network accelerators, demonstrating superior performance in competitive settings.\n\nMy interests also encompass unsupervised skill learning in reinforcement learning, where I have proposed methods like DISDAIN and RVIC to enhance exploration and skill diversity. These contributions aim to empower agents to learn effectively in complex environments without relying on external rewards.\n\nOverall, my work strives to bridge theoretical advancements with practical applications, ensuring that machine learning techniques can be effectively utilized in real-world scenarios, from climate science to autonomous agents. I am passionate about pushing the boundaries of what is possible in these fields and contributing to a deeper understanding of both machine learning and the earth system.",
                "collaborators": [
                    "S. Hansen",
                    "Volodymyr Mnih",
                    "Yoshua Bengio",
                    "Simon Osindero",
                    "Kate Baumli",
                    "T. Wiele",
                    "Dzmitry Bahdanau",
                    "J. Chorowski",
                    "Aaron C. Courville",
                    "Mehdi Mirza",
                    "C. Pal",
                    "Mihaela Rosca",
                    "Guillaume Desjardins",
                    "I. Goodfellow",
                    "Sherjil Ozair",
                    "Nicolas Boulanger-Lewandowski",
                    "Xavier Bouthillier",
                    "A. D. Brébisson",
                    "Yann Dauphin",
                    "Laurent Dinh",
                    "Vincent Dumoulin",
                    "Samira Ebrahimi Kahou",
                    "Orhan Firat",
                    "Çaglar Gülçehre",
                    "Sébastien Jean",
                    "Pascal Lamblin",
                    "César Laurent",
                    "R. Memisevic",
                    "B. V. Merrienboer",
                    "Vincent Michalski",
                    "M. Pezeshki",
                    "Dmitriy Serdyuk",
                    "Pascal Vincent",
                    "Ying Zhang",
                    "Piotr Mirowski",
                    "Matthew Koichi Grimes",
                    "Yana Hasson",
                    "Hyunjik Kim",
                    "M'elanie Rey",
                    "Suman V. Ravuri",
                    "Shakir Mohamed",
                    "Isabela Albuquerque",
                    "Jessica Schrouff",
                    "Ali Taylan Cemgil",
                    "Sven Gowal",
                    "Olivia Wiles",
                    "Vinod Nair",
                    "Yujia Li",
                    "Ivan Lobov",
                    "Felix Gimeno",
                    "N. Heess",
                    "D. Strouse",
                    "Vlad Mnih",
                    "A. Mnih",
                    "Will Dabney",
                    "André Barreto",
                    "Tejas D. Kulkarni",
                    "Catalin Ionescu",
                    "Jean Pouget-Abadie",
                    "Bing Xu",
                    "Balaji Lakshminarayanan",
                    "S. Mohamed",
                    "Rami Al-Rfou",
                    "Guillaume Alain",
                    "Amjad Almahairi",
                    "Christof Angermüller",
                    "Nicolas Ballas",
                    "Frédéric Bastien",
                    "Justin Bayer",
                    "A. Belikov",
                    "A. Belopolsky",
                    "Arnaud Bergeron",
                    "J. Bergstra",
                    "Valentin Bisson",
                    "Josh Bleecher Snyder",
                    "Nicolas Bouchard",
                    "Olivier Breuleux",
                    "P. Carrier",
                    "Kyunghyun Cho",
                    "P. Christiano",
                    "Tim Cooijmans",
                    "Marc-Alexandre Côté",
                    "Myriam Côté",
                    "Olivier Delalleau",
                    "Julien Demouth",
                    "S. Dieleman",
                    "Mélanie Ducoffe",
                    "D. Erhan",
                    "Ziye Fan",
                    "M. Germain",
                    "Xavier Glorot",
                    "M. Graham",
                    "P. Hamel",
                    "Iban Harlouchet",
                    "J. Heng",
                    "Balázs Hidasi",
                    "S. Honari",
                    "Arjun Jain",
                    "Kai Jia",
                    "Mikhail Korobov"
                ],
                "pub_titles": [
                    "Neural Compression of Atmospheric States",
                    "Evaluating Model Bias Requires Characterizing its Mistakes",
                    "Solving MaxSAT with Matrix Multiplication",
                    "Entropic Desired Dynamics for Intrinsic Control",
                    "Learning more skills through optimistic exploration",
                    "Relative Variational Intrinsic Control",
                    "Q-Learning in enormous action spaces via amortized approximate maximization",
                    "Fast Task Inference with Variational Intrinsic Successor Features",
                    "Unsupervised Control Through Non-Parametric Discriminative Rewards",
                    "Generative Adversarial Networks for Image Steganography",
                    "Variational Approaches for Auto-Encoding Generative Adversarial Networks",
                    "Theano: A Python framework for fast computation of mathematical expressions",
                    "Improving Generative Adversarial Networks with Denoising Feature Matching",
                    "Blocks and Fuel: Frameworks for deep learning"
                ],
                "pub_abstracts": [
                    "Atmospheric states derived from reanalysis comprise a substantial portion of weather and climate simulation outputs. Many stakeholders -- such as researchers, policy makers, and insurers -- use this data to better understand the earth system and guide policy decisions. Atmospheric states have also received increased interest as machine learning approaches to weather prediction have shown promising results. A key issue for all audiences is that dense time series of these high-dimensional states comprise an enormous amount of data, precluding all but the most well resourced groups from accessing and using historical data and future projections. To address this problem, we propose a method for compressing atmospheric states using methods from the neural network literature, adapting spherical data to processing by conventional neural architectures through the use of the area-preserving HEALPix projection. We investigate two model classes for building neural compressors: the hyperprior model from the neural image compression literature and recent vector-quantised models. We show that both families of models satisfy the desiderata of small average error, a small number of high-error reconstructed pixels, faithful reproduction of extreme events such as hurricanes and heatwaves, preservation of the spectral power distribution across spatial scales. We demonstrate compression ratios in excess of 1000x, with compression and decompression at a rate of approximately one second per global atmospheric state.",
                    "The ability to properly benchmark model performance in the face of spurious correlations is important to both build better predictors and increase confidence that models are operating as intended. We demonstrate that characterizing (as opposed to simply quantifying) model mistakes across subgroups is pivotal to properly reflect model biases, which are ignored by standard metrics such as worst-group accuracy or accuracy gap. Inspired by the hypothesis testing framework, we introduce SkewSize, a principled and flexible metric that captures bias from mistakes in a model's predictions. It can be used in multi-class settings or generalised to the open vocabulary setting of generative models. SkewSize is an aggregation of the effect size of the interaction between two categorical variables: the spurious variable representing the bias attribute and the model's prediction. We demonstrate the utility of SkewSize in multiple settings including: standard vision models trained on synthetic data, vision models trained on ImageNet, and large scale vision-and-language models from the BLIP-2 family. In each case, the proposed SkewSize is able to highlight biases not captured by other metrics, while also providing insights on the impact of recently proposed techniques, such as instruction tuning.",
                    "We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT) specifically designed to run on neural network accelerators such as GPUs and TPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure constructs a Restricted Boltzmann Machine (RBM) with an equilibrium distribution wherein the probability of a Boolean assignment is exponential in the number of clauses it satisfies. Block Gibbs sampling is used to stochastically search the space of assignments with parallel Markov chains. Since matrix multiplication is the main computational primitive for block Gibbs sampling in an RBM, our approach leads to an elegantly simple algorithm (40 lines of JAX) well-suited for neural network accelerators. Theoretical results about RBMs guarantee that the required number of visible and hidden units of the RBM scale only linearly with the number of variables and constant-sized clauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs step scales reasonably with the instance size. Search throughput can be increased by batching parallel chains within a single accelerator as well as by distributing them across multiple accelerators. As a further enhancement, a heuristic based on unit propagation running on CPU is periodically applied to the sampled assignments. Our approach, which we term RbmSAT, is a new design point in the algorithm-hardware co-design space for MaxSAT. We present timed results on a subset of problem instances from the annual MaxSAT Evaluation's Incomplete Unweighted Track for the years 2018 to 2021. When allotted the same running time and CPU compute budget (but no TPUs), RbmSAT outperforms other participating solvers on problems drawn from three out of the four years' competitions. Given the same running time on a TPU cluster for which RbmSAT is uniquely designed, it outperforms all solvers on problems drawn from all four years.",
                    "An agent might be said, informally, to have mastery of its environment when it has maximised the effective number of states it can reliably reach. In practice, this often means maximizing the number of latent codes that can be discriminated from future states under some short time horizon (e.g. [15]). By situating these latent codes in a globally consistent coordinate system, we show that agents can reliably reach more states in the long term while still optimizing a local objective. A simple instantiation of this idea, E ntropic D esired D ynamics for I ntrinsic C on T rol (EDDICT), assumes ﬁxed additive latent dynamics, which results in tractable learning and an interpretable latent space. Compared to prior methods, EDDICT’s globally consistent codes allow it to be far more exploratory, as demonstrated by improved state coverage and increased unsupervised performance on hard exploration games such as Montezuma’s Revenge.",
                    "Unsupervised skill learning objectives (Gregor et al., 2016, Eysenbach et al., 2018) allow agents to learn rich repertoires of behavior in the absence of extrinsic rewards. They work by simultaneously training a policy to produce distinguishable latent-conditioned trajectories, and a discriminator to evaluate distinguishability by trying to infer latents from trajectories. The hope is for the agent to explore and master the environment by encouraging each skill (latent) to reliably reach different states. However, an inherent exploration problem lingers: when a novel state is actually encountered, the discriminator will necessarily not have seen enough training data to produce accurate and confident skill classifications, leading to low intrinsic reward for the agent and effective penalization of the sort of exploration needed to actually maximize the objective. To combat this inherent pessimism towards exploration, we derive an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. Our objective directly estimates the epistemic uncertainty that comes from the discriminator not having seen enough training examples, thus providing an intrinsic reward more tailored to the true objective compared to pseudocount-based methods (Burda et al., 2019). We call this exploration bonus discriminator disagreement intrinsic reward, or DISDAIN. We demonstrate empirically that DISDAIN improves skill learning both in a tabular grid world (Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we encourage researchers to treat pessimism with DISDAIN.",
                    "In the absence of external rewards, agents can still learn useful behaviors by identifying and mastering a set of diverse skills within their environment. Existing skill learning methods use mutual information objectives to incentivize each skill to be diverse and distinguishable from the rest. However, if care is not taken to constrain the ways in which the skills are diverse, trivially diverse skill sets can arise. To ensure useful skill diversity, we propose a novel skill learning objective, Relative Variational Intrinsic Control (RVIC), which incentivizes learning skills that are distinguishable in how they change the agent's relationship to its environment. The resulting set of skills tiles the space of affordances available to the agent. We qualitatively analyze skill behaviors on multiple environments and show how RVIC skills are more useful than skills discovered by existing methods in hierarchical reinforcement learning.",
                    "Applying Q-learning to high-dimensional or continuous action spaces can be difficult due to the required maximization over the set of possible actions. Motivated by techniques from amortized inference, we replace the expensive maximization over all actions with a maximization over a small subset of possible actions sampled from a learned proposal distribution. The resulting approach, which we dub Amortized Q-learning (AQL), is able to handle discrete, continuous, or hybrid action spaces while maintaining the benefits of Q-learning. Our experiments on continuous control tasks with up to 21 dimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018) and QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action spaces demonstrate that AQL can efficiently learn good policies in spaces with thousands of discrete actions.",
                    "It has been established that diverse behaviors spanning the controllable subspace of an Markov decision process can be trained by rewarding a policy for being distinguishable from other policies \\citep{gregor2016variational, eysenbach2018diversity, warde2018unsupervised}. However, one limitation of this formulation is generalizing behaviors beyond the finite set being explicitly learned, as is needed for use on subsequent tasks. Successor features \\citep{dayan93improving, barreto2017successor} provide an appealing solution to this generalization problem, but require defining the reward function as linear in some grounded feature space. In this paper, we show that these two techniques can be combined, and that each method solves the other's primary limitation. To do so we introduce Variational Intrinsic Successor FeatuRes (VISR), a novel algorithm which learns controllable features that can be leveraged to provide enhanced generalization and fast task inference through the successor feature framework. We empirically validate VISR on the full Atari suite, in a novel setup wherein the rewards are only exposed briefly after a long unsupervised phase. Achieving human-level performance on 14 games and beating all baselines, we believe VISR represents a step towards agents that rapidly learn from limited feedback.",
                    "Learning to control an environment without hand-crafted rewards or expert data remains challenging and is at the frontier of reinforcement learning research. We present an unsupervised learning algorithm to train agents to achieve perceptually-specified goals using only a stream of observations and actions. Our agent simultaneously learns a goal-conditioned policy and a goal achievement reward function that measures how similar a state is to the goal state. This dual optimization leads to a co-operative game, giving rise to a learned reward function that reflects similarity in controllable aspects of the environment instead of distance in the space of observations. We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -- Atari, the DeepMind Control Suite and DeepMind Lab.",
                    "Steganography is collection of methods to hide secret information (\"payload\") within non-secret information (\"container\"). Its counterpart, Steganalysis, is the practice of determining if a message contains a hidden payload, and recovering it if possible. Presence of hidden payloads is typically detected by a binary classifier. In the present study, we propose a new model for generating image-like containers based on Deep Convolutional Generative Adversarial Networks (DCGAN). This approach allows to generate more setganalysis-secure message embedding using standard steganography algorithms. Experiment results demonstrate that the new model successfully deceives the steganography analyzer, and for this reason, can be used in steganographic applications.",
                    "Auto-encoding generative adversarial networks (GANs) combine the standard GAN algorithm, which discriminates between real and model-generated data, with a reconstruction loss given by an auto-encoder. Such models aim to prevent mode collapse in the learned generative model by ensuring that it is grounded in all the available training data. In this paper, we develop a principle upon which auto-encoders can be combined with generative adversarial networks by exploiting the hierarchical structure of the generative model. The underlying principle shows that variational inference can be used a basic tool for learning, but with the in- tractable likelihood replaced by a synthetic likelihood, and the unknown posterior distribution replaced by an implicit distribution; both synthetic likelihoods and implicit posterior distributions can be learned using discriminators. This allows us to develop a natural fusion of variational auto-encoders and generative adversarial networks, combining the best of both these methods. We describe a unified objective for optimization, discuss the constraints needed to guide learning, connect to the wide range of existing work, and use a battery of tests to systematically and quantitatively assess the performance of our method.",
                    "Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models.  The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.",
                    "We propose an augmented training procedure for generative adversarial networks designed to address shortcomings of the original by directing the generator towards probable configurations of abstract discriminator features. We estimate and track the distribution of these features, as computed from data, with a denoising auto-encoder, and use it to propose high-level targets for the generator. We combine this new loss with the original and evaluate the hybrid criterion on the task of unsupervised image synthesis from datasets comprising a diverse set of visual categories, noting a qualitative and quantitative improvement in the “objectness” of the resulting samples.",
                    "We introduce two Python frameworks to train neural networks on large datasets: Blocks and Fuel. Blocks is based on Theano, a linear algebra compiler with CUDA-support (Bastien et al., 2012; Bergstra et al., 2010). It facilitates the training of complex neural network models by providing parametrized Theano operations, attaching metadata to Theano’s symbolic computational graph, and providing an extensive set of utilities to assist training the networks, e.g. training algorithms, logging, monitoring, visualization, and serialization. Fuel provides a standard format for machine learning datasets. It allows the user to easily iterate over large datasets, performing many types of pre-processing on the fly."
                ],
                "domain": [
                    "Machine Learning",
                    "Reinforcement Learning",
                    "Neural Networks",
                    "Generative Models"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            },
            "e72df3d5-fc04-440f-88f0-974acb1929a2": {
                "pk": "e72df3d5-fc04-440f-88f0-974acb1929a2",
                "project_name": null,
                "name": "Sherjil Ozair",
                "bio": "I am a researcher dedicated to advancing the fields of generative models, reinforcement learning, and representation learning. My recent work includes the development of Genie, an innovative generative interactive environment that leverages unlabelled Internet videos to create dynamic virtual worlds. This foundation model, with its 11 billion parameters, allows users to engage with generated environments in unprecedented ways.\n\nI have also focused on enhancing low-resource language models, particularly for Thai, by creating a synthetic data framework that emphasizes fluency, diversity, and cultural context. This work demonstrates that effective instruction-tuning can be achieved with minimal data, significantly improving performance compared to traditional methods.\n\nIn the realm of reinforcement learning, I have contributed to the establishment of benchmarks like AlphaStar Unplugged, which challenges offline RL algorithms in complex environments such as StarCraft II. My research extends to model-based approaches, where I introduced Stochastic MuZero, a method that incorporates stochastic models for improved planning in uncertain environments.\n\nAdditionally, I have explored the intricacies of mutual information in representation learning, proposing novel methods to enhance generalization and data efficiency. My work on DeepNash has pushed the boundaries of AI in imperfect information games, achieving human expert-level performance in Stratego.\n\nOverall, my research aims to bridge the gap between theoretical advancements and practical applications, fostering the development of intelligent agents capable of navigating complex, real-world scenarios.",
                "collaborators": [
                    "Aäron van den Oord",
                    "Yoshua Bengio",
                    "Ioannis Antonoglou",
                    "Julian Schrittwieser",
                    "David Silver",
                    "Yazhe Li",
                    "Alex Lamb",
                    "R. Devon Hjelm",
                    "Konrad Zolna",
                    "Nando de Freitas",
                    "Satinder Singh",
                    "Erica Moreira",
                    "L. Sifre",
                    "Petko Georgiev",
                    "O. Vinyals",
                    "Ali Razavi",
                    "Mina Khan",
                    "Ankesh Anand",
                    "Vikas Verma",
                    "David Ha",
                    "Ben Poole",
                    "Alexander A. Alemi",
                    "G. Tucker",
                    "Aaron C. Courville",
                    "Jake Bruce",
                    "Michael D. Dennis",
                    "Ashley Edwards",
                    "Jack Parker-Holder",
                    "Yuge Shi",
                    "Edward Hughes",
                    "Matthew Lai",
                    "Aditi Mavalankar",
                    "Richie Steigerwald",
                    "Chris Apps",
                    "Y. Aytar",
                    "Sarah Bechtle",
                    "Feryal M. P. Behbahani",
                    "Stephanie Chan",
                    "N. Heess",
                    "Lucy Gonzalez",
                    "Simon Osindero",
                    "Scott Reed",
                    "Jingwei Zhang",
                    "Jeff Clune",
                    "Tim Rocktaschel",
                    "Parinthapat Pengpun",
                    "Can Udomcharoenchaikit † Weerayut Buaphet",
                    "Peerat Limkonchotiwat",
                    "Xuan-Phi Nguyen",
                    "Wenxuan Zhang",
                    "Xin Li",
                    "Mahani Aljunied",
                    "Qingyu Tan",
                    "Liying Cheng",
                    "Guanzheng Chen",
                    "Yue Deng",
                    "Sen Yang",
                    "Chaoqun Liu",
                    "Haim-ing Bao",
                    "Mo Bavarian",
                    "J. Belgum",
                    "Ir-wan Bello",
                    "Jake Berdine",
                    "Gabriel Bernadett-Shapiro",
                    "Christopher Berner",
                    "Lenny Bogdonoff",
                    "Oleg Boiko",
                    "Made-laine Boyd",
                    "Anna-Luisa Brakman",
                    "Greg Brock-man",
                    "Tim Brooks",
                    "M. Brundage",
                    "Kevin Button",
                    "Trevor Cai",
                    "Rosie Campbell",
                    "Andrew Cann",
                    "Brittany Carey",
                    "Chelsea Carlson",
                    "Rory Carmichael",
                    "Brooke Chan",
                    "Che Chang",
                    "Fotis Chantzis",
                    "Derek Chen",
                    "Sully Chen",
                    "Ruby Chen",
                    "Jason Chen",
                    "Mark Chen",
                    "B. Chess",
                    "Chester Cho",
                    "Hyung Casey Chu",
                    "Won Chung",
                    "Dave Cummings",
                    "Jeremiah Currier",
                    "Yunxing Dai",
                    "Tarun Goel",
                    "Gabriel Gogineni",
                    "Rapha Goh",
                    "Jonathan Gontijo-Lopes",
                    "Morgan Gordon",
                    "Scott Grafstein"
                ],
                "pub_titles": [
                    "Genie: Generative Interactive Environments",
                    "Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai",
                    "AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning",
                    "[Re] Explaining in Style: Training a GAN to explain a classifier in StyleSpace",
                    "Model-based language-instructed reinforcement learning",
                    "Planning in Stochastic Environments with a Learned Model",
                    "Mastering the game of Stratego with model-free multiagent reinforcement learning",
                    "Pretrained Encoders are All You Need",
                    "Procedural Generalization by Planning with Self-Supervised World Models",
                    "Vector Quantized Models for Planning",
                    "SketchTransfer: A New Dataset for Exploring Detail-Invariance and the Abstractions Learned by Deep Networks",
                    "Unsupervised State Representation Learning in Atari",
                    "On Variational Bounds of Mutual Information",
                    "The Journey is the Reward: Unsupervised Learning of Influential Trajectories",
                    "SketchTransfer: A Challenging New Task for Exploring Detail-Invariance and the Abstractions Learned by Deep Networks",
                    "Wasserstein Dependency Measure for Representation Learning",
                    "Learning Generative Models with Locally Disentangled Latent Factors",
                    "Mutual Information Neural Estimation",
                    "On variational lower bounds of mutual information",
                    "Generative Adversarial Networks for Image Steganography"
                ],
                "pub_abstracts": [
                    "We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of action-controllable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.",
                    "We present a synthetic data approach for instruction-tuning large language models (LLMs) for low-resource languages in a data-efficient manner, specifically focusing on Thai. We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity, and cultural context. We propose a seed-data-free framework for generating synthetic instruction-tuning data that incorporates these essential properties. Our framework employs an LLM to generate diverse topics, retrieve relevant contexts from Wikipedia, and create instructions for various tasks, such as question answering, summarization, and conversation. The experimental results show that our best-performing synthetic dataset, which incorporates all three key properties, achieves competitive performance using only 5,000 instructions when compared to state-of-the-art Thai LLMs trained on hundreds of thousands of instructions. Our code and dataset are publicly available at https://github.com/parinzee/seed-free-synthetic-instruct.",
                    "StarCraft II is one of the most challenging simulated reinforcement learning environments; it is partially observable, stochastic, multi-agent, and mastering StarCraft II requires strategic planning over long time horizons with real-time low-level execution. It also has an active professional competitive scene. StarCraft II is uniquely suited for advancing offline RL algorithms, both because of its challenging nature and because Blizzard has released a massive dataset of millions of StarCraft II games played by human players. This paper leverages that and establishes a benchmark, called AlphaStar Unplugged, introducing unprecedented challenges for offline reinforcement learning. We define a dataset (a subset of Blizzard's release), tools standardizing an API for machine learning methods, and an evaluation protocol. We also present baseline agents, including behavior cloning, offline variants of actor-critic and MuZero. We improve the state of the art of agents using only offline data, and we achieve 90% win rate against previously published AlphaStar behavior cloning agent.",
                    "StylEx is an approach for classifier-conditioned training of a StyleGAN2 [6], intending to capture classifier-specific 3 attributes in its disentangled StyleSpace [15]. Attributes can be adjusted to generate counterfactual explanations of 4 the classifier decisions. StylEx is domain and classifier-agnostic, while its explanations are claimed to be human5 interpretable, distinct, coherent and sufficient to produce flipped classifier decisions. We verify these claims by 6 reproducing a selection of the experiments in the paper. 7",
                    "We explore how we can build accurate world 001 models which are partially specified by lan-002 guage and how we can plan with them in the 003 face of novelty and uncertainty. We propose the 004 first Model-Based Reinforcement Learning ap-005 proach to tackle the environment Read To Fight 006 Monsters (Zhong et al., 2019), a grounded 007 policy learning problem. In RTFM an agent 008 has to reason over a set of rules and a goal, 009 both described in a language manual, and the 010 observations, while taking into account the 011 uncertainty arising from the stochasticity of 012 the environment, in order to generalize suc-013 cessfully its policy to test episodes. We pro-014 vide a sample-efficient proof-of-concept of the 015 model-based approach for the basic dynamic 016 task of RTFM. Furthermore, we show that the 017 main open challenge of RTFM is learning the 018 language-dependent reward function and sug-019 gest that future research should focus primarily 020 on that task. 021",
                    "Model-based reinforcement learning has proven highly successful. However, learning a model in isolation from its use during planning is problematic in complex environments. To date, the most effective techniques have instead combined value-equivalent model learning with powerful tree-search methods. This approach is exempliﬁed by MuZero , which has achieved state-of-the-art performance in a wide range of domains, from board games to visually rich environments, with discrete and continuous action spaces, in online and ofﬂine settings. However, previous instantiations of this approach were limited to the use of deterministic models. This limits their performance in environments that are inherently stochastic, partially observed, or so large and complex that they appear stochastic to a ﬁnite agent. In this paper we extend this approach to learn and plan with stochastic models. Specifically, we introduce a new algorithm, Stochastic MuZero , that learns a stochastic model incorporating afterstates, and uses this model to perform a stochastic tree search. Stochastic MuZero matched or exceeded the state of the art in a set of canonical single and multi-agent environments, including 2048 and backgammon, while maintaining the superhuman performance of standard MuZero in the game of Go.",
                    "We introduce DeepNash, an autonomous agent that plays the imperfect information game Stratego at a human expert level. Stratego is one of the few iconic board games that artificial intelligence (AI) has not yet mastered. It is a game characterized by a twin challenge: It requires long-term strategic thinking as in chess, but it also requires dealing with imperfect information as in poker. The technique underpinning DeepNash uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego through self-play from scratch. DeepNash beat existing state-of-the-art AI methods in Stratego and achieved a year-to-date (2022) and all-time top-three ranking on the Gravon games platform, competing with human expert players. Description Machine learning to play Stratego Stratego is a popular two-player imperfect information board game. Because of its complexity stemming from its enormous game tree, decision-making under imperfect information, and a piece deployment phase at the start, Stratego poses a challenge for artificial intelligence (AI). Previous computer programs only performed at an amateur level at best. Perolat et al. introduce a model-free multiagent reinforcement learning methodology and show that it can achieve human expert–level performance in Stratego. The present work not only adds to the growing list of games that AI systems can play as well or even better than humans but may also facilitate further applications of reinforcement learning methods in real-world, large-scale multiagent problems that are characterized by imperfect information and thus are currently unsolvable. —YS Reinforcement learning achieves human expert–level performance in the large-scale imperfect information board game Stratego.",
                    "Data-efficiency and generalization are key challenges in deep learning and deep reinforcement learning as many models are trained on large-scale, domain-specific, and expensive-to-label datasets. Self-supervised models trained on large-scale uncurated datasets have shown successful transfer to diverse settings. We investigate using pretrained image representations and spatio-temporal attention for state representation learning in Atari. We also explore fine-tuning pretrained representations with self-supervised techniques, i.e., contrastive predictive coding, spatio-temporal contrastive learning, and augmentations. Our results show that pretrained representations are at par with state-of-the-art self-supervised methods trained on domain-specific data. Pretrained representations, thus, yield data and compute-efficient state representations. https://github.com/PAL-ML/PEARL_v1",
                    "One of the key promises of model-based reinforcement learning is the ability to generalize using an internal model of the world to make predictions in novel environments and tasks. However, the generalization ability of model-based agents is not well understood because existing work has focused on model-free agents when benchmarking generalization. Here, we explicitly measure the generalization ability of model-based agents in comparison to their model-free counterparts. We focus our analysis on MuZero (Schrittwieser et al., 2020), a powerful model-based agent, and evaluate its performance on both procedural and task generalization. We identify three factors of procedural generalization -- planning, self-supervised representation learning, and procedural data diversity -- and show that by combining these techniques, we achieve state-of-the art generalization performance and data efficiency on Procgen (Cobbe et al., 2019). However, we find that these factors do not always provide the same benefits for the task generalization benchmarks in Meta-World (Yu et al., 2019), indicating that transfer remains a challenge and may require different approaches than procedural generalization. Overall, we suggest that building generalizable agents requires moving beyond the single-task, model-free paradigm and towards self-supervised model-based agents that are trained in rich, procedural, multi-task environments.",
                    "Recent developments in the field of model-based RL have proven successful in a range of environments, especially ones where planning is essential. However, such successes have been limited to deterministic fully-observed environments. We present a new approach that handles stochastic and partially-observable environments. Our key insight is to use discrete autoencoders to capture the multiple possible effects of an action in a stochastic environment. We use a stochastic variant of Monte Carlo tree search to plan over both the agent's actions and the discrete latent variables representing the environment's response. Our approach significantly outperforms an offline version of MuZero on a stochastic interpretation of chess where the opponent is considered part of the environment. We also show that our approach scales to DeepMind Lab, a first-person 3D environment with large visual observations and partial observability.",
                    "Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). This capability goes beyond visual data: humans are easily able to recognize isolated melodies from musical pieces when heard for the first time, even if the only piece they've listened to previously is from an orchestra. Thus the failure of machine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST \\xrightarrow SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today's best methods but has substantial room for improvement.",
                    "State representation learning, or the ability to capture latent generative factors of an environment, is crucial for building intelligent agents that can perform a wide variety of tasks. Learning such representations without supervision from rewards is a challenging open problem. We introduce a method that learns state representations by maximizing mutual information across spatially and temporally distinct features of a neural encoder of the observations. We also introduce a new benchmark based on Atari 2600 games where we evaluate representations based on how well they capture the ground truth state variables. We believe this new framework for evaluating representation learning models will be crucial for future representation learning research. Finally, we compare our technique with other state-of-the-art generative and contrastive representation learning methods. The code associated with this work is available at this https URL",
                    "Estimating and optimizing Mutual Information (MI) is core to many problems in machine learning; however, bounding MI in high dimensions is challenging. To establish tractable and scalable objectives, recent work has turned to variational bounds parameterized by neural networks, but the relationships and tradeoffs between these bounds remains unclear. In this work, we unify these recent developments in a single framework. We find that the existing variational lower bounds degrade when the MI is large, exhibiting either high bias or high variance. To address this problem, we introduce a continuum of lower bounds that encompasses previous bounds and flexibly trades off bias and variance. On high-dimensional, controlled problems, we empirically characterize the bias and variance of the bounds and their gradients and demonstrate the effectiveness of our new bounds for estimation and representation learning.",
                    "Unsupervised exploration and representation learning become increasingly important when learning in diverse and sparse environments. The information-theoretic principle of empowerment formalizes an unsupervised exploration objective through an agent trying to maximize its influence on the future states of its environment. Previous approaches carry certain limitations in that they either do not employ closed-loop feedback or do not have an internal state. As a consequence, a privileged final state is taken as an influence measure, rather than the full trajectory. We provide a model-free method which takes into account the whole trajectory while still offering the benefits of option-based approaches. We successfully apply our approach to settings with large action spaces, where discovery of meaningful action sequences is particularly difficult.",
                    "Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). The failure of ma- chine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST → SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today’s best methods but has substantial room for improvement.",
                    "Mutual information maximization has emerged as a powerful learning objective for unsupervised representation learning obtaining state-of-the-art performance in applications such as object recognition, speech recognition, and reinforcement learning. However, such approaches are fundamentally limited since a tight lower bound of mutual information requires sample size exponential in the mutual information. This limits the applicability of these approaches for prediction tasks with high mutual information, such as in video understanding or reinforcement learning. In these settings, such techniques are prone to overfit, both in theory and in practice, and capture only a few of the relevant factors of variation. This leads to incomplete representations that are not optimal for downstream tasks. In this work, we empirically demonstrate that mutual information-based representation learning approaches do fail to learn complete representations on a number of designed and real-world tasks. To mitigate these problems we introduce the Wasserstein dependency measure, which learns more complete representations by using the Wasserstein distance instead of the KL divergence in the mutual information estimator. We show that a practical approximation to this theoretically motivated solution, constructed using Lipschitz constraint techniques from the GAN literature, achieves substantially improved results on tasks where incomplete representations are a major challenge.",
                    "One of the most successful techniques in generative models has been decomposing a complicated generation task into a series of simpler generation tasks. For example, generating an image at a low resolution and then learning to refine that into a high resolution image often improves results substantially. Here we explore a novel strategy for decomposing generation for complicated objects in which we first generate latent variables which describe a subset of the observed variables, and then map from these latent variables to the observed space. We show that this allows us to achieve decoupled training of complicated generative models and present both theoretical and experimental results supporting the benefit of such an approach.",
                    "We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.",
                    "Estimating and maximizing mutual information (MI) is core to many objectives in machine learning, but tractably lower bounding MI in high dimensions is challenging. Recent work has introduced variational lower bounds with neural networks to attack this problem, but the tradeoffs and relationships between these techniques remains unclear. Here, we present several results that begin to demys-tify these techniques: we show that the bias-corrected gradient in MINE (Belghazi et al., 2018) can be derived as an unbiased gradient of a new lower bound on MI, present a stabler Jensen-Shannon-based training algorithm for the critic, provide a new interpretation of contrastive predictive coding (CPC, van den Oord et al. (2018)) and prove this variant is a lower bound on MI, and demonstrate the batch-size dependence of CPC. Empirically, we show that the effectiveness of these bounds depends on properties of the data being modeled and the structure of the critic, with no one bound uniformly dominating.",
                    "Steganography is collection of methods to hide secret information (\"payload\") within non-secret information (\"container\"). Its counterpart, Steganalysis, is the practice of determining if a message contains a hidden payload, and recovering it if possible. Presence of hidden payloads is typically detected by a binary classifier. In the present study, we propose a new model for generating image-like containers based on Deep Convolutional Generative Adversarial Networks (DCGAN). This approach allows to generate more setganalysis-secure message embedding using standard steganography algorithms. Experiment results demonstrate that the new model successfully deceives the steganography analyzer, and for this reason, can be used in steganographic applications."
                ],
                "domain": [
                    "Generative Models",
                    "Reinforcement Learning",
                    "Representation Learning",
                    "Machine Learning"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            },
            "889412ee-3cc2-4643-8f4b-270de4eee311": {
                "pk": "889412ee-3cc2-4643-8f4b-270de4eee311",
                "project_name": null,
                "name": "Yoshua Bengio",
                "bio": "I am a researcher deeply engaged in the exploration of neural networks and their applications across various domains, particularly focusing on the challenges of catastrophic forgetting, generative models, and deep learning methodologies. My work has investigated the nuances of how neural networks retain knowledge when transitioning between tasks, revealing that dropout algorithms consistently outperform others in balancing the retention of old tasks while adapting to new ones.\n\nI have also contributed to advancements in scene classification by leveraging object detection features, demonstrating significant improvements in accuracy while reducing dimensionality. My research extends to the realm of recommendation systems, where I developed calibration techniques to mitigate biases in off-policy evaluations, particularly in video game matchmaking.\n\nIn the generative modeling space, I introduced multimodal transition distributions for Generative Stochastic Networks (GSNs), enhancing their ability to capture complex data distributions. My work on deep recurrent neural networks (RNNs) has led to novel architectures that improve performance in tasks like polyphonic music prediction and language modeling.\n\nAdditionally, I have explored the intersection of deep learning and affective computing, aiming to model emotions through advanced AI techniques. My commitment to making deep learning accessible is reflected in my tutorials, which demystify complex algorithms for natural language processing.\n\nOverall, my research is driven by a passion for understanding and improving the capabilities of machine learning models, with a focus on practical applications and theoretical advancements that push the boundaries of what is possible in AI.",
                "collaborators": [
                    "Aaron C. Courville",
                    "I. Goodfellow",
                    "Mehdi Mirza",
                    "Çaglar Gülçehre",
                    "Razvan Pascanu",
                    "Pascal Vincent",
                    "Eric Thibodeau-Laufer",
                    "Raul Chandias Ferrari",
                    "Kyunghyun Cho",
                    "Vincent Dumoulin",
                    "L. Yao",
                    "David Warde-Farley",
                    "Pascal Lamblin",
                    "Yann Dauphin",
                    "Xia Da",
                    "Grégoire Mesnil",
                    "Salah Rifai",
                    "Antoine Bordes",
                    "Xavier Glorot",
                    "Li Yao",
                    "Olivier Delalleau",
                    "Sherjil Ozair",
                    "J. Bergstra",
                    "Frédéric Bastien",
                    "H. P. Martínez",
                    "Georgios N. Yannakakis",
                    "Samira Ebrahimi Kahou",
                    "C. Pal",
                    "Xavier Bouthillier",
                    "Pierre Froumenty",
                    "R. Memisevic",
                    "Sébastien Jean",
                    "P. Carrier",
                    "Nicolas Boulanger-Lewandowski",
                    "Abhishek Aggarwal",
                    "Jeremie Zumer",
                    "Jean-Philippe Raymond",
                    "Guillaume Desjardins",
                    "Atousa Torabi",
                    "Arjun Sharma",
                    "Emmanuel Bengio",
                    "K. Konda",
                    "Zhenzhou Wu",
                    "R. Socher",
                    "Christopher D. Manning",
                    "Guillaume Alain",
                    "J. Yosinski",
                    "Nicholas Léonard"
                ],
                "pub_titles": [
                    "An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks",
                    "Unsupervised and Transfer Learning under Uncertainty - From Object Detections to Scene Categorization",
                    "Stacked calibration of off-policy policy evaluation for video game matchmaking",
                    "On the Challenges of Physical Implementations of RBMs",
                    "Multimodal Transitions for Generative Stochastic Networks",
                    "Pylearn2: a machine learning research library",
                    "Big Neural Networks Waste Capacity",
                    "Estimating or Propagating Gradients Through Stochastic Neurons",
                    "Learning deep physiological models of affect",
                    "Scaling Up Spike-and-Slab Models for Unsupervised Feature Learning",
                    "Combining modality specific deep neural networks for emotion recognition in video",
                    "Knowledge Matters: Importance of Prior Information for Optimization",
                    "How to Construct Deep Recurrent Neural Networks",
                    "Multi-Prediction Deep Boltzmann Machines",
                    "Deep Learning for NLP (without Magic)",
                    "Bounding the Test Log-Likelihood of Generative Models",
                    "Deep Generative Stochastic Networks Trainable by Backprop",
                    "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"
                ],
                "pub_abstracts": [
                    "Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models \"forget\" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",
                    "Classifying scenes (e.g. into “street”, “home” or “leisure”) is an important but complicated task nowadays, because images come with variability, ambiguity, and a wide range of illumination or scale conditions. Standard approaches build an intermediate representation of the global image and learn classifiers on it. Recently, it has been proposed to depict an image as an aggregation of its contained objects:the representation on which classifiers are trained is composed of many heterogeneous feature vectors derived from various object detectors. In this paper, we propose to study different approaches to efficiently combine the data extracted by these detectors. We use the features provided by Object-Bank (Li-Jia Li and Fei-Fei, 2010a) (177 different object detectors producing 252 attributes each), and show on several benchmarks for scene categorization that careful combinations, taking into account the structure of the data, allows to greatly improve over original results (from +5% to +11%) while drastically reducing the dimensionality of the representation by 97% (from",
                    "We consider an industrial strength application of recommendation systems for video-game matchmaking in which off-policy policy evaluation is important but where standard approaches can hardly be applied. The objective of the policy is to sequentially form teams of players from those waiting to be matched, in such a way as to produce well-balanced matches. Unfortunately, the available training data comes from a policy that is not known perfectly and that is not stochastic, making it impossible to use methods based on importance weights. Furthermore, we observe that when the estimated reward function and the policy are obtained by training from the same off-policy dataset, the policy evaluation using the estimated reward function is biased. We present a simple calibration procedure that is similar to stacked regression and that removes most of the bias, in the experiments we performed. Data collected during beta tests of Ghost Recon Online, a first person shooter from Ubisoft, were used for the experiments.",
                    "    Restricted Boltzmann machines (RBMs) are powerful machine learning models, but learning and some kinds of inference in the model require sampling-based approximations, which, in classical digital computers, are implemented using expensive MCMC. Physical computation offers the opportunity to reduce the costof sampling by building physical systems whose natural dynamics correspond to drawing samples from the desired RBM distribution. Such a system avoids the burn-in and mixing cost of a Markov chain. However, hardware implementations of this variety usually entail limitations such as low-precision and limited range of the parameters and restrictions on the size and topology of the RBM. We conduct software simulations to determine how harmful each of these restrictions is. Our simulations are based on the D-Wave Two computer, but the issues we investigate arise in most forms of physical computation.Our findings suggest that designers of new physical computing hardware and algorithms for physical computers should focus their efforts on overcoming the limitations imposed by the topology restrictions of currently existing physical computers.   ",
                    "Generative Stochastic Networks (GSNs) have been recently introduced as an alternative to traditional probabilistic modeling: instead of parametrizing the data distribution directly, one parametrizes a transition operator for a Markov chain whose stationary distribution is an estimator of the data generating distribution. The result of training is therefore a machine that generates samples through this Markov chain. However, the previously introduced GSN consistency theorems suggest that in order to capture a wide class of distributions, the transition operator in general should be multimodal, something that has not been done before this paper. We introduce for the first time multimodal transition distributions for GSNs, in particular using models in the NADE family (Neural Autoregressive Density Estimator) as output distributions of the transition operator. A NADE model is related to an RBM (and can thus model multimodal distributions) but its likelihood (and likelihood gradient) can be computed easily. The parameters of the NADE are obtained as a learned function of the previous state of the learned Markov chain. Experiments clearly illustrate the advantage of such multimodal transition distributions over unimodal GSNs.",
                    "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.",
                    "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact there are highly diminishing returns for capacity in terms of training error, leading to underfitting. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.",
                    "Stochastic neurons can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such s tochastic neurons, i.e., can we “back-propagate” through these stochastic neurons? We examine this question, existing approaches, and present two novel families of solutions, applicable in different settings. In particular, it is demonstrate d that a simple biologically plausible formula gives rise to an an unbiased (but noisy) estimator of the gradient with respect to a binary stochastic neuron firing proba bility. Unlike other estimators which view the noise as a small perturbation in order to estimate gradients by finite differences, this estimator is unbiased even w ithout assuming that the stochastic perturbation is small. This estimator is also in teresting because it can be applied in very general settings which do not allow gradient back-propagation, including the estimation of the gradient with respect to futur e rewards, as required in reinforcement learning setups. We also propose an approach to approximating this unbiased but high-variance estimator by learning to predict it using a biased estimator. The second approach we propose assumes that an estimator of the gradient can be back-propagated and it provides an unbiased estimator of the gradient, but can only work with non-linearities unlike the hard threshold, but like the rectifier, that are not flat for all of their range. This is similar to trad itional sigmoidal units but has the advantage that for many inputs, a hard decision (e.g., a 0 output) can be produced, which would be convenient for conditional computation and achieving sparse representations and sparse gradients.",
                    "More than 15 years after the early studies in Affective Computing (AC), [1] the problem of detecting and modeling emotions in the context of human-computer interaction (HCI) remains complex and largely unexplored. The detection and modeling of emotion is, primarily, the study and use of artificial intelligence (AI) techniques for the construction of computational models of emotion. The key challenges one faces when attempting to model emotion [2] are inherent in the vague definitions and fuzzy boundaries of emotion, and in the modeling methodology followed. In this context, open research questions are still present in all key components of the modeling process. These include, first, the appropriateness of the modeling tool employed to map emotional manifestations and responses to annotated affective states; second, the processing of signals that express these manifestations (i.e., model input); and third, the way affective annotation (i.e., model output) is handled. This paper touches upon all three key components of an affective model (i.e., input, model, output) and introduces the use of deep learning (DL) [3], [4], [5] methodologies for affective modeling from multiple physiological signals.",
                    "We describe the use of two spike-and-slab models for modeling real-valued data, with an emphasis on their applications to object recognition. The first model, which we call spike-and-slab sparse coding (S3C), is a preexisting model for which we introduce a faster approximate inference algorithm. We introduce a deep variant of S3C, which we call the partially directed deep Boltzmann machine (PD-DBM) and extend our S3C inference algorithm for use on this model. We describe learning procedures for each. We demonstrate that our inference procedure for S3C enables scaling the model to unprecedented large problem sizes, and demonstrate that using S3C as a feature extractor results in very good object recognition performance, particularly when the number of labeled examples is low. We show that the PD-DBM generates better samples than its shallow counterpart, and that unlike DBMs or DBNs, the PD-DBM may be trained successfully without greedy layerwise training.",
                    "In this paper we present the techniques used for the University of Montréal's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds, including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities, including: (1) a deep convolutional neural network for the analysis of facial expressions within video frames; (2) a deep belief net to capture audio information; (3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the mouth of the primary human subject in the scene. We discuss each of these techniques, their performance characteristics and different strategies to aggregate their predictions. Our best single model was a convolutional neural network trained to predict emotions from static frames using two large data sets, the Toronto Face Database and our own set of faces images harvested from Google image search, followed by a per frame aggregation strategy that used the challenge training data. This yielded a test set accuracy of 35.58%. Using our best strategy for aggregating our top performing models into a single predictor we were able to produce an accuracy of 41.03% on the challenge test set. These compare favorably to the challenge baseline test set accuracy of 27.56%.",
                    "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {\\em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.",
                    "In this paper, we explore different ways to extend a recurrent neural network (RNN) to a \\textit{deep} RNN. We start by arguing that the concept of depth in an RNN is not as clear as it is in feedforward neural networks. By carefully analyzing and understanding the architecture of an RNN, however, we find three points of an RNN which may be made deeper; (1) input-to-hidden function, (2) hidden-to-hidden transition and (3) hidden-to-output function. Based on this observation, we propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an alternative interpretation of these deep RNNs using a novel framework based on neural operators. The proposed deep RNNs are empirically evaluated on the tasks of polyphonic music prediction and language modeling. The experimental result supports our claim that the proposed deep RNNs benefit from the depth and outperform the conventional, shallow RNNs.",
                    "We introduce the multi-prediction deep Boltzmann machine (MP-DBM). The MP-DBM can be seen as a single probabilistic model trained to maximize a variational approximation to the generalized pseudolikelihood, or as a family of recurrent nets that share parameters and approximately solve different inference problems. Prior methods of training DBMs either do not perform well on classification tasks or require an initial learning pass that trains the DBM greedily, one layer at a time. The MP-DBM does not require greedy layerwise pretraining, and outperforms the standard DBM at classification, classification with missing inputs, and mean field prediction tasks.1",
                    "Machine learning is everywhere in today’s NLP, but by and large machine learning amounts to numerical optimization of weights for human designed representations and features. The goal of deep learning is to explore how computers can take advantage of data to develop features and representations appropriate for complex interpretation tasks. This tutorial aims to cover the basic motivation, ideas, models and learning algorithms in deep learning for natural language processing. Recently, these methods have been shown to perform very well on various NLP tasks such as language modeling, POS tagging, named entity recognition, sentiment analysis and paraphrase detection, among others. The most attractive quality of these techniques is that they can perform well without any external hand-designed resources or time-intensive feature engineering. Despite these advantages, many researchers in NLP are not familiar with these methods. Our focus is on insight and understanding, using graphical illustrations and simple, intuitive derivations. The goal of the tutorial is to make the inner workings of these techniques transparent, intuitive and their results interpretable, rather than black boxes labeled ”magic here”. The first part of the tutorial presents the basics of neural networks, neural word vectors, several simple models based on local windows and the math and algorithms of training via backpropagation. In this section applications include language modeling and POS tagging. In the second section we present recursive neural networks which can learn structured tree outputs as well as vector representations for phrases and sentences. We cover both equations as well as applications. We show how training can be achieved by a modified version of the backpropagation algorithm introduced before. These modifications allow the algorithm to work on tree structures. Applications include sentiment analysis and paraphrase detection. We also draw connections to recent work in semantic compositionality in vector spaces. The principle goal, again, is to make these methods appear intuitive and interpretable",
                    "Several interesting generative learning algorithms involve a complex probability distribution over many random variables, involving intractable normalization constants or latent variable normalization. Some of them may even not have an analytic expression for the unnormalized probability function and no tractable approximation. This makes it difficult to estimate the quality of these models, once they have been trained, or to monitor their quality (e.g. for early stopping) while training. A previously proposed method is based on constructing a non-parametric density estimator of the model's probability function from samples generated by the model. We revisit this idea, propose a more efficient estimator, and prove that it provides a lower bound on the true test log-likelihood, and an unbiased estimator as the number of generated samples goes to infinity, although one that incorporates the effect of poor mixing. We further propose a biased variant of the estimator that can be used reliably with a finite number of samples for the purpose of model comparison.",
                    "We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining.",
                    "Stochastic neurons and hard non-linearities can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we \"back-propagate\" through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of {\\em conditional computation}, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful."
                ],
                "domain": [
                    "Deep Learning",
                    "Neural Networks",
                    "Affective Computing",
                    "Generative Models"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            }
        },
        "reference_proposal": "**[Question 1] - What is the problem?**  \nHow can we effectively estimate generative models in deep learning to overcome the challenges of intractable probabilistic computations and improve the performance of generative adversarial networks (GANs)?\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem is crucial for advancing the field of deep learning, particularly in the development of generative models that can produce high-quality samples from complex data distributions. By improving generative model estimation, we can enhance applications in various domains such as image synthesis, natural language processing, and audio generation. This research could lead to more robust and efficient generative models, fostering further exploration and innovation in machine learning techniques and their practical applications.\n\n**[Question 3] - Why is it hard?**  \nThe challenges in solving this problem stem from the inherent complexity of approximating intractable probabilistic computations involved in maximum likelihood estimation. Naive approaches may fail due to the high variance in likelihood estimation and the difficulties in leveraging piecewise linear units in generative contexts. Additionally, the competition between the generative and discriminative models in the adversarial framework introduces complexities in training dynamics, requiring careful tuning and optimization to achieve convergence.\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has been limited by the intractability of the partition function in undirected graphical models and the challenges associated with Markov chain Monte Carlo methods. These barriers have hindered the development of effective generative models. Our approach differs by introducing a novel adversarial framework that allows for a more efficient estimation of generative models, sidestepping the difficulties of traditional methods and providing a new perspective on model training.\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves the use of adversarial nets, where a generative model is trained in competition with a discriminative model. We will utilize a dataset of natural images and employ metrics such as Inception Score and Fréchet Inception Distance to evaluate the quality of generated samples. The expected outcomes include demonstrating the viability of the adversarial modeling framework and producing high-quality samples that effectively represent the underlying data distribution, thereby advancing the state of generative modeling in deep learning."
    },
    "1503.02531": {
        "paper_data": {
            "title": "Distilling the Knowledge in a Neural Network",
            "url": "http://arxiv.org/abs/1503.02531v1",
            "arxiv_id": "1503.02531",
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean"
            ],
            "abstract": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.",
            "introduction": " Introduction Manyinsectshavea larvalformthat isoptimizedforextract ingenergyandnutrientsfromthe envi- ronmentand a completely differentadult form that is optimi zed for the verydifferent requirements oftravelingandreproduction. Inlarge-scalemachinelear ning,wetypicallyuseverysimilarmodels for the training stage and the deployment stage despite thei r very different requirements: For tasks likespeechandobjectrecognition,trainingmustextracts tructurefromverylarge,highlyredundant datasets but it does not need to operate in real time and it can use a huge amount of computation. Deploymentto a largenumberofusers, however,hasmuchmore stringentrequirementsonlatency and computational resources. The analogy with insects sugg ests that we should be willing to train verycumbersomemodelsifthatmakesiteasiertoextractstr ucturefromthedata. Thecumbersome model could be an ensemble of separately trained modelsor a s ingle very large model trained with a very strong regularizer such as dropout [9]. Once the cumbe rsome model has been trained, we canthenuseadifferentkindoftraining,whichwecall“dist illation”totransfertheknowledgefrom the cumbersome model to a small model that is more suitable fo r deployment. A version of this strategy has already been pioneered by Rich Caruana and his c ollaborators [1]. In their important paper they demonstrate convincingly that the knowledge acq uired by a large ensemble of models canbetransferredto asinglesmall model. A conceptual block that may have prevented more investigati onof this very promising approach is thatwetendtoidentifytheknowledgeinatrainedmodelwith thelearnedparametervaluesandthis makesithardtoseehowwecanchangetheformofthemodelbutk eepthesameknowledge. Amore abstract view of the knowledge, that frees it from any partic ular instantiation, is that it is a learned ∗Alsoafﬁliatedwiththe Universityof Toronto andthe Canadi an Institute for Advanced Research. †Equal contribution. 1mapping from input vectors to output vectors. For cumbersom e models that learn to discriminate between a large number of classes, the normal training objec tive is to maximize the average log probability of the correct answer, but a side-effect of the l earning is that the trained model assigns probabilitiesto all of the incorrect answers and even when t hese probabilitiesare very small, some ofthemaremuchlargerthanothers. Therelativeprobabilit iesofincorrectanswerstellusalotabout howthe cumbersomemodeltendsto generalize. An imageof a BM W, forexample,mayonlyhave averysmallchanceofbeingmistakenforagarbagetruck,but thatmistakeisstill manytimesmore probablethanmistakingit foracarrot. It is generallyacceptedthat the objectivefunctionused fo r trainingshouldreﬂect the true objective of the user as closely as possible. Despite this, modelsare u sually trained to optimizeperformance on the training data when the real objective is to generalize well to new data. It would clearly be better to train models to generalize well, but this requir es information about the correct way to generalize and this information is not normally available. When we are distilling the knowledge fromalargemodelintoasmallone,however,wecantrainthes mallmodeltogeneralizeinthesame way as the large model. If the cumbersome model generalizes w ell because, for example, it is the averageofalargeensembleofdifferentmodels,asmallmode ltrainedtogeneralizeinthesameway willtypicallydomuchbetterontestdatathanasmallmodelt hatistrainedinthenormalwayonthe sametrainingset aswasusedto traintheensemble. An obviousway to transferthe generalizationability of the cumbersomemodelto a small model is to use the class probabilities produced by the cumbersome mo del as “soft targets” for training the small model. For this transfer stage, we coulduse the same tr ainingset or a separate “transfer”set. When the cumbersome model is a large ensemble of simpler mode ls, we can use an arithmetic or geometricmeanof their individualpredictivedistributio nsas the soft targets. When the soft targets havehighentropy,theyprovidemuchmoreinformationpertr ainingcasethanhardtargetsandmuch lessvarianceinthegradientbetweentrainingcases,sothe smallmodelcanoftenbetrainedonmuch lessdatathantheoriginalcumbersomemodelandusinga much higherlearningrate. For tasks like MNIST in which the cumbersomemodel almost alw ays producesthe correct answer with very high conﬁdence, much of the informationabout the l earned functionresides in the ratios of very small probabilities in the soft targets. For example , one version of a 2 may be given a probability of 10−6of being a 3 and 10−9of being a 7 whereas for another version it may be the other way around. This is valuable",
            "references": []
        },
        "author_data": {
            "994cf795-e9b3-43d1-a6ea-faa7ecb19355": {
                "pk": "994cf795-e9b3-43d1-a6ea-faa7ecb19355",
                "project_name": null,
                "name": "Geoffrey Hinton",
                "bio": "I am a researcher dedicated to advancing the fields of computer vision and machine learning through innovative methodologies and frameworks. My recent work focuses on unifying diverse computer vision tasks, such as object detection and image captioning, under a shared pixel-to-sequence interface. This approach allows for a single model architecture to handle multiple tasks without the need for task-specific customizations, demonstrating competitive performance against specialized models.\n\nI have also explored dynamic evaluation techniques for language models, introducing Fast Weight Layers (FWLs) that enhance performance while minimizing computational costs. My research extends to novel learning procedures, such as the Forward-Forward algorithm, which simplifies the training process by utilizing two forward passes instead of traditional backpropagation.\n\nIn addition, I have developed innovative solutions for panoptic segmentation and discrete data generation through diffusion models, achieving state-of-the-art results in various benchmarks. My work on representation learning in medical AI, particularly the REMEDIS framework, addresses the challenges of data-efficient generalization, significantly improving diagnostic accuracy with minimal retraining data.\n\nI am passionate about creating flexible and efficient learning frameworks that not only enhance model performance but also provide insights into the underlying processes of neural networks. My goal is to bridge the gap between complex tasks and effective learning strategies, ultimately contributing to the broader impact of AI in real-world applications.",
                "collaborators": [
                    "David J. Fleet",
                    "Ting Chen",
                    "Simon Kornblith",
                    "Mohammad Norouzi",
                    "Saurabh Saxena",
                    "Lala Li",
                    "Shekoofeh Azizi",
                    "J. Freyberg",
                    "Sebastien Baur",
                    "S. S. Mahdavi",
                    "Ellery Wulczyn",
                    "Boris Babenko",
                    "Aaron Loh",
                    "Po-Hsuan Cameron Chen",
                    "Yuan Liu",
                    "Pinal Bavishi",
                    "S. McKinney",
                    "Jim Winkens",
                    "Abhijit Guha Roy",
                    "Zach Beaver",
                    "Justin D. Krogue",
                    "M. Etemadi",
                    "Umesh Telang",
                    "Yun Liu",
                    "L. Peng",
                    "G. Corrado",
                    "D. Webster",
                    "N. Houlsby",
                    "A. Karthikesalingam",
                    "Vivek Natarajan",
                    "Mengye Ren",
                    "Renjie Liao",
                    "S. Sabour",
                    "Richard F. Rashid",
                    "Laura Culp",
                    "Basil Mustafa",
                    "Nenad Tomašev",
                    "Jovana Mitrovic",
                    "Patricia Strachan",
                    "Megan Walker",
                    "Fiona Ryan",
                    "R. Gartner",
                    "Jessica Bundy",
                    "Maria Jung",
                    "Tyler J King",
                    "Jane B. Sprott",
                    "Fernando Ávila",
                    "J. Briggs",
                    "Daniel Konikof",
                    "Alex Luscombe",
                    "Audrey Macklin",
                    "H. Pelvin",
                    "Tsung-Yi Lin",
                    "Kevin Clark",
                    "Kelvin Guu",
                    "Ming-Wei Chang",
                    "Panupong Pasupat",
                    "Ruixiang Zhang",
                    "Laura J. Culp",
                    "L. Culp",
                    "B. Mustafa",
                    "Patricia MacWilliams",
                    "Megan Wilson",
                    "F. Ryan",
                    "Xiaodong He",
                    "Jianfeng Gao",
                    "L. Deng",
                    "S. Yih",
                    "Yu",
                    "J. Markoff",
                    "Dong Yu",
                    "Yoshua Bengio",
                    "Yann LeCun",
                    "A. Tagliasacchi",
                    "S. Yazdani",
                    "Geoffrey I. Webb",
                    "Johannes Fürnkranz",
                    "Claude Sammut",
                    "Joerg Sander",
                    "M. Vlachos",
                    "Yee Whye Teh",
                    "Ying Yang",
                    "D. Mladení",
                    "J. Brank",
                    "M. Grobelnik",
                    "Ying Zhao",
                    "G. Karypis",
                    "Susan Craw",
                    "M. Puterman",
                    "J. Patrick",
                    "Aniruddh Raghu",
                    "M. Raghu",
                    "D. Duvenaud"
                ],
                "pub_titles": [
                    "Volume 19, Number 5",
                    "A Unified Sequence Interface for Vision Tasks",
                    "Meta-Learning Fast Weight Language Models",
                    "The Forward-Forward Algorithm: Some Preliminary Investigations",
                    "Scaling Forward Gradient With Local Losses",
                    "A Generalist Framework for Panoptic Segmentation of Images and Videos",
                    "Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning",
                    "Gaussian-Bernoulli RBMs Without Tears",
                    "Testing GLOM's ability to infer wholes from ambiguous parts",
                    "Robust and Efficient Medical Imaging with Self-Supervision",
                    "Pix2seq: A Language Modeling Framework for Object Detection",
                    "Deep Learning for Natural Language Processing",
                    "How to Represent Part-Whole Hierarchies in a Neural Network",
                    "Deep learning for AI",
                    "Unsupervised part representation by Flow Capsules",
                    "The Next Generation of Neural Networks",
                    "Teaching with Commentaries"
                ],
                "pub_abstracts": [
                    "September/October 2023",
                    "While language tasks are naturally expressed in a single, unified, modeling framework, i.e., generating sequences of tokens, this has not been the case in computer vision. As a result, there is a proliferation of distinct architectures and loss functions for different vision tasks. In this work we show that a diverse set of\"core\"computer vision tasks can also be unified if formulated in terms of a shared pixel-to-sequence interface. We focus on four tasks, namely, object detection, instance segmentation, keypoint detection, and image captioning, all with diverse types of outputs, e.g., bounding boxes or dense masks. Despite that, by formulating the output of each task as a sequence of discrete tokens with a unified interface, we show that one can train a neural network with a single model architecture and loss function on all these tasks, with no task-specific customization. To solve a specific task, we use a short prompt as task description, and the sequence output adapts to the prompt so it can produce task-specific output. We show that such a model can achieve competitive performance compared to well-established task-specific models.",
                    "Dynamic evaluation of language models (LMs) adapts model parameters at test time using gradient information from previous tokens and substantially improves LM performance. However, it requires over 3x more compute than standard inference. We present Fast Weight Layers (FWLs), a neural component that provides the benefits of dynamic evaluation much more efficiently by expressing gradient updates as linear attention. A key improvement over dynamic evaluation is that FWLs can also be applied at training time, so the model learns to make good use of gradient updates. FWLs can easily be added on top of existing transformer models, require relatively little extra compute or memory to run, and significantly improve language modeling perplexity.",
                    "The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation. The Forward-Forward algorithm replaces the forward and backward passes of backpropagation by two forward passes, one with positive (i.e. real) data and the other with negative data which could be generated by the network itself. Each layer has its own objective function which is simply to have high goodness for positive data and low goodness for negative data. The sum of the squared activities in a layer can be used as the goodness but there are many other possibilities, including minus the sum of the squared activities. If the positive and negative passes could be separated in time, the negative passes could be done offline, which would make the learning much simpler in the positive pass and allow video to be pipelined through the network without ever storing activities or stopping to propagate derivatives.",
                    "Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. However, the standard forward gradient algorithm, when applied naively, suffers from high variance when the number of parameters to be learned is large. In this paper, we propose a series of architectural and algorithmic modifications that together make forward gradient learning practical for standard deep learning benchmark tasks. We show that it is possible to substantially reduce the variance of the forward gradient estimator by applying perturbations to activations rather than weights. We further improve the scalability of forward gradient by introducing a large number of local greedy loss functions, each of which involves only a small number of learnable parameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more suitable for local learning. Our approach matches backprop on MNIST and CIFAR-10 and significantly outperforms previously proposed backprop-free algorithms on ImageNet.",
                    "Panoptic segmentation assigns semantic and instance ID labels to every pixel of an image. As permutations of instance IDs are also valid solutions, the task requires learning of high-dimensional one-to-many mapping. As a result, state-of-the-art approaches use customized architectures and task-specific loss functions. We formulate panoptic segmentation as a discrete data generation problem, without relying on inductive bias of the task. A diffusion model is proposed to model panoptic masks, with a simple architecture and generic loss function. By simply adding past predictions as a conditioning signal, our method is capable of modeling video (in a streaming setting) and thereby learns to track object instances automatically. With extensive experiments, we demonstrate that our simple approach can perform competitively to state-of-the-art specialist methods in similar settings. 1",
                    "We present Bit Diffusion: a simple and generic approach for generating discrete data with continuous state and continuous time diffusion models. The main idea behind our approach is to first represent the discrete data as binary bits, and then train a continuous diffusion model to model these bits as real numbers which we call analog bits. To generate samples, the model first generates the analog bits, which are then thresholded to obtain the bits that represent the discrete variables. We further propose two simple techniques, namely Self-Conditioning and Asymmetric Time Intervals, which lead to a significant improvement in sample quality. Despite its simplicity, the proposed approach can achieve strong performance in both discrete image generation and image captioning tasks. For discrete image generation, we significantly improve previous state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens) and ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the best autoregressive model in both sample quality (measured by FID) and efficiency. For image captioning on MS-COCO dataset, our approach achieves competitive results compared to autoregressive models.",
                    "We revisit the challenging problem of training Gaussian-Bernoulli restricted Boltzmann machines (GRBMs), introducing two innovations. We propose a novel Gibbs-Langevin sampling algorithm that outperforms existing methods like Gibbs sampling. We propose a modified contrastive divergence (CD) algorithm so that one can generate images with GRBMs starting from noise. This enables direct comparison of GRBMs with deep generative models, improving evaluation protocols in the RBM literature. Moreover, we show that modified CD and gradient clipping are enough to robustly train GRBMs with large learning rates, thus removing the necessity of various tricks in the literature. Experiments on Gaussian Mixtures, MNIST, FashionMNIST, and CelebA show GRBMs can generate good samples, despite their single-hidden-layer architecture. Our code is released at: \\url{https://github.com/lrjconan/GRBM}.",
                    "The GLOM architecture proposed by Hinton [2021] is a recurrent neural network for parsing an image into a hierarchy of wholes and parts. When a part is ambiguous, GLOM assumes that the ambiguity can be resolved by allowing the part to make multi-modal predictions for the pose and identity of the whole to which it belongs and then using attention to similar predictions coming from other possibly ambiguous parts to settle on a common mode that is predicted by several different parts. In this study, we describe a highly simplified version of GLOM that allows us to assess the effectiveness of this way of dealing with ambiguity. Our results show that, with supervised training, GLOM is able to successfully form islands of very similar embedding vectors for all of the locations occupied by the same object and it is also robust to strong noise injections in the input and to out-of-distribution input transformations.",
                    "Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal\"out-of-distribution\"performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and expensive to annotate [2]. Thus, the problem of\"data-efficient generalization\"presents an ongoing difficulty for Medical AI development. Although progress in representation learning shows promise, their benefits have not been rigorously studied, specifically for out-of-distribution settings. To meet these challenges, we present REMEDIS, a unified representation learning strategy to improve robustness and data-efficiency of medical imaging AI. REMEDIS uses a generic combination of large-scale supervised transfer learning with self-supervised learning and requires little task-specific customization. We study a diverse range of medical imaging tasks and simulate three realistic application scenarios using retrospective data. REMEDIS exhibits significantly improved in-distribution performance with up to 11.5% relative improvement in diagnostic accuracy over a strong supervised baseline. More importantly, our strategy leads to strong data-efficient generalization of medical imaging AI, matching strong supervised baselines using between 1% to 33% of retraining data across tasks. These results suggest that REMEDIS can significantly accelerate the life-cycle of medical imaging AI development thereby presenting an important step forward for medical imaging AI to deliver broad impact.",
                    "We present Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, we cast object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural network to perceive the image and generate the desired sequence. Our approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task-specific data augmentations, our approach makes minimal assumptions about the task, yet it achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms.",
                    ",",
                    "Abstract This article does not describe a working system. Instead, it presents a single idea about representation that allows advances made by several different groups to be combined into an imaginary system called GLOM.1 The advances include transformers, neural fields, contrastive representation learning, distillation, and capsules. GLOM answers the question: How can a neural network with a fixed architecture parse an image into a part-whole hierarchy that has a different structure for each image? The idea is simply to use islands of identical vectors to represent the nodes in the parse tree. If GLOM can be made to work, it should significantly improve the interpretability of the representations produced by transformer-like systems when applied to vision or language.",
                    "How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?",
                    "Capsule networks are designed to parse an image into a hierarchy of objects, parts and relations. While promising, they remain limited by an inability to learn effective low level part descriptions. To address this issue we propose a novel self-supervised method for learning part descriptors of an image. During training, we exploit motion as a powerful perceptual cue for part definition, using an expressive decoder for part generation and layered image formation with occlusion. Experiments demonstrate robust part discovery in the presence of multiple objects, cluttered backgrounds, and significant occlusion. The resulting part descriptors, a.k.a. part capsules, are decoded into shape masks, filling in occluded pixels, along with relative depth on single images. We also report unsupervised object classification using our capsule parts in a stacked capsule autoencoder.",
                    "The most important unsolved problem with artificial neural networks is how to do unsupervised learning as effectively as the brain. There are currently two main approaches to unsupervised learning. In the first approach, exemplified by BERT and Variational Autoencoders, a deep neural network is used to reconstruct its input. This is problematic for images because the deepest layers of the network need to encode the fine details of the image. An alternative approach, introduced by Becker and Hinton in 1992, is to train two copies of a deep neural network to produce output vectors that have high mutual information when given two different crops of the same image as their inputs. This approach was designed to allow the representations to be untethered from irrelevant details of the input. The method of optimizing mutual information used by Becker and Hinton was flawed (for a subtle reason that I will explain) so Pacannaro and Hinton (2001) replaced it by a discriminative objective in which one vector representation must select a corresponding vector representation from among many alternatives. With faster hardware, contrastive learning of representations has recently become very popular and is proving to be very effective, but it suffers from a major flaw: To learn pairs of representation vectors that have N bits of mutual information we need to contrast the correct corresponding vector with about 2N incorrect alternatives. I will describe a novel and effective way of dealing with this limitation. I will also show that this leads to a simple way of implementing perceptual learning in cortex.",
                    "Effective training of deep neural networks can be challenging, and there remain many open questions on how to best learn these models. Recently developed methods to improve neural network training examine teaching: providing learned information during the training process to improve downstream model performance. In this paper, we take steps towards extending the scope of teaching. We propose a flexible teaching framework using commentaries, meta-learned information helpful for training on a particular task or dataset. We present an efficient and scalable gradient-based method to learn commentaries, leveraging recent work on implicit differentiation. We explore diverse applications of commentaries, from learning weights for individual training examples, to parameterizing label-dependent data augmentation policies, to representing attention masks that highlight salient image regions. In these settings, we find that commentaries can improve training speed and/or performance and also provide fundamental insights about the dataset and training process."
                ],
                "domain": [
                    "Computer Vision",
                    "Natural Language Processing",
                    "Neural Networks",
                    "Representation Learning"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            },
            "be76cb2d-9483-49ba-93e3-29c96509ab30": {
                "pk": "be76cb2d-9483-49ba-93e3-29c96509ab30",
                "project_name": null,
                "name": "Oriol Vinyals",
                "bio": "I am a researcher deeply engaged in the intersection of multimodal machine learning and generative models, with a focus on enhancing the understanding and performance of complex tasks such as event argument role labeling (EARL) and long-context reasoning. My recent work, including the development of GenEARL, showcases my commitment to creating innovative frameworks that leverage generative models to improve performance in challenging tasks without the need for extensive training data. \n\nI have also contributed to the Gemini family of models, which excel in multimodal reasoning and have set new benchmarks in medical applications, demonstrating the potential of AI in critical domains. My exploration of lightweight models, such as Gemma, reflects my dedication to making advanced AI accessible and efficient. \n\nIn addition to my work on specific models, I am interested in understanding the dynamics of large language models and their multitasking capabilities. My research has revealed insights into task competition and the emergence of abilities in these models, paving the way for more effective training strategies. \n\nI am passionate about applying my findings to real-world challenges, such as improving weather forecasting with GraphCast and optimizing video compression using reinforcement learning. My goal is to push the boundaries of what is possible in AI, ensuring that our models not only perform well but also adapt seamlessly to new tasks and domains.",
                "collaborators": [
                    "Sebastian Borgeaud",
                    "Katie Millican",
                    "Jean-Baptiste Alayrac",
                    "Elena Buchatskaya",
                    "Julian Schrittwieser",
                    "Roman Ring",
                    "Eliza Rutherford",
                    "Zhitao Gong",
                    "Tom Hennigan",
                    "Eric Noland",
                    "D. Hassabis",
                    "Karsten Roth",
                    "Zeynep Akata",
                    "Antoine Miech",
                    "Iain Barr",
                    "Karel Lenc",
                    "A. Mensch",
                    "Malcolm Reynolds",
                    "Sina Samangooei",
                    "Andy Brock",
                    "Andrew Zisserman",
                    "Lisa Anne Hendricks",
                    "Machel Reid",
                    "Eli Collins",
                    "Siamak Shakeri",
                    "Aakanksha Chowdhery",
                    "Petko Georgiev",
                    "Jean-Baptiste Lespiau",
                    "Charline Le Lan",
                    "Paul Michel",
                    "Evan Senter",
                    "Mateo Wirth",
                    "Amol Mandhane",
                    "Minh Giang",
                    "R. Comanescu",
                    "Alek Andreev",
                    "K. Kavukcuoglu",
                    "Joelle Barral",
                    "D. Mankowitz",
                    "A. Zhernov",
                    "T. Hubert",
                    "Jeff Donahue",
                    "Pauline Luc",
                    "Yana Hasson",
                    "Serkan Cabi",
                    "Tengda Han",
                    "Marianne Monteiro",
                    "Jacob Menick",
                    "Aida Nematzadeh",
                    "Sahand Sharifzadeh",
                    "Ricardo Barreira",
                    "Tom Brown",
                    "Benjamin Mann",
                    "Jared Kaplan",
                    "Pranav Shyam",
                    "Jordan Hoffmann",
                    "Trevor Cai",
                    "Diego de",
                    "Las Casas",
                    "Johannes Welbl",
                    "Aidan Clark",
                    "Rohan Anil",
                    "P. Barham",
                    "Ross McIlroy",
                    "Melvin Johnson",
                    "Erica Moreira",
                    "H. Michalewski",
                    "James Keeling",
                    "Oscar Chang",
                    "George Tucker",
                    "Tomás Kociský",
                    "Evgenii Eltyshev",
                    "Ambrose Slone",
                    "Ben Caine",
                    "J Christopher Love",
                    "N. Houlsby",
                    "Luheng He",
                    "Yong Cheng",
                    "Yujia Li",
                    "Albert Webson",
                    "Rahma Chaabouni",
                    "T. Paine",
                    "Behnam Neyshabur",
                    "Jack W. Rae",
                    "Boxi Wu",
                    "Basil Mustafa",
                    "Emilio Parisotto",
                    "Chenjie Gu",
                    "A. Pritzel",
                    "J. Mao-Jones",
                    "Hannah Sheahan",
                    "James Svensson",
                    "Bogdan Damoc",
                    "George van den Driessche",
                    "Justin Chiu",
                    "Adrià Recasens",
                    "S'ebastien M. R. Arnold",
                    "Lisa Lee",
                    "Kartikeya Badola",
                    "Joshua Newlan"
                ],
                "pub_titles": [
                    "GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling",
                    "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
                    "Capabilities of Gemini Models in Medicine",
                    "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
                    "Gemma: Open Models Based on Gemini Research and Technology",
                    "A Practitioner's Guide to Continual Multimodal Pretraining",
                    "Gemma 2: Improving Open Language Models at a Practical Size",
                    "AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning",
                    "Waffling around for Performance: Visual Classification with Random Words and Broad Concepts",
                    "Learning skillful medium-range global weather forecasting",
                    "Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model",
                    "Optimizing Memory Mapping Using Deep Reinforcement Learning",
                    "General-purpose, long-context autoregressive modeling with Perceiver AR",
                    "Flamingo: a Visual Language Model for Few-Shot Learning",
                    "Hierarchical Perceiver",
                    "Non-isotropy Regularization for Proxy-based Deep Metric Learning",
                    "A Generalist Agent",
                    "MuZero with Self-competition for Rate Control in VP9 Video Compression"
                ],
                "pub_abstracts": [
                    "Multimodal event argument role labeling (EARL), a task that assigns a role for each event participant (object) in an image is a complex challenge. It requires reasoning over the entire image, the depicted event, and the interactions between various objects participating in the event. Existing models heavily rely on high-quality event-annotated training data to understand the event semantics and structures, and they fail to generalize to new event types and domains. In this paper, we propose GenEARL, a training-free generative framework that harness the power of the modern generative models to understand event task descriptions given image contexts to perform the EARL task. Specifically, GenEARL comprises two stages of generative prompting with a frozen vision-language model (VLM) and a frozen large language model (LLM). First, a generative VLM learns the semantics of the event argument roles and generates event-centric object descriptions based on the image. Subsequently, a LLM is prompted with the generated object descriptions with a predefined template for EARL (i.e., assign an object with an event argument role). We show that GenEARL outperforms the contrastive pretraining (CLIP) baseline by 9.4% and 14.2% accuracy for zero-shot EARL on the M2E2 and SwiG datasets, respectively. In addition, we outperform CLIP-Event by 22% precision on M2E2 dataset. The framework also allows flexible adaptation and generalization to unseen domains.",
                    "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
                    "Excellence in a wide variety of medical applications poses considerable challenges for AI, requiring advanced reasoning, access to up-to-date medical knowledge and understanding of complex multimodal data. Gemini models, with strong general capabilities in multimodal and long-context reasoning, offer exciting possibilities in medicine. Building on these core strengths of Gemini, we introduce Med-Gemini, a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly use web search, and that can be efficiently tailored to novel modalities using custom encoders. We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health&medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. Taken together, our results offer compelling evidence for Med-Gemini's potential, although further rigorous evaluation will be crucial before real-world deployment in this safety-critical domain.",
                    "Large language models exhibit strong multi-tasking capabilities, however, their learning dynamics as a function of task characteristics, sample size, and model complexity remain mysterious. For instance, it is known that, as the model size grows, large language models exhibit emerging abilities where certain tasks can abruptly jump from poor to respectable performance. Such phenomena motivate a deeper understanding of how individual tasks evolve during multitasking. To this aim, we study a multitask representation learning setup where tasks can have distinct distributions , quantified by their covariance priors. Through random matrix theory, we precisely characterize the optimal linear representation for few-shot learning that minimizes the average test risk in terms of task covariances. When tasks have equal sample sizes, we prove a reduction to an equivalent problem with a single effective covariance from which the individual task risks of the original problem can be deduced. Importantly, we introduce “ task competition ” to explain how tasks with dominant covariance eigen-spectrum emerge faster than others. We show that task competition can potentially explain the inverse scaling of certain tasks i.e. reduced test accuracy as the model grows. Overall, this work sheds light on the risk and emergence of individual tasks and uncovers new high-dimensional phenomena (including multiple-descent risk curves) that arise in multitask representation learning.",
                    "This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.",
                    "Multimodal foundation models serve numerous applications at the intersection of vision and language. Still, despite being pretrained on extensive data, they become outdated over time. To keep models updated, research into continual pretraining mainly explores scenarios with either (1) infrequent, indiscriminate updates on large-scale new data, or (2) frequent, sample-level updates. However, practical model deployment often operates in the gap between these two limit cases, as real-world applications often demand adaptation to specific subdomains, tasks or concepts -- spread over the entire, varying life cycle of a model. In this work, we complement current perspectives on continual pretraining through a research test bed as well as provide comprehensive guidance for effective continual model updates in such scenarios. We first introduce FoMo-in-Flux, a continual multimodal pretraining benchmark with realistic compute constraints and practical deployment requirements, constructed over 63 datasets with diverse visual and semantic coverage. Using FoMo-in-Flux, we explore the complex landscape of practical continual pretraining through multiple perspectives: (1) A data-centric investigation of data mixtures and stream orderings that emulate real-world deployment situations, (2) a method-centric investigation ranging from simple fine-tuning and traditional continual learning strategies to parameter-efficient updates and model merging, (3) meta learning rate schedules and mechanistic design choices, and (4) the influence of model and compute scaling. Together, our insights provide a practitioner's guide to continual multimodal pretraining for real-world deployment. Our benchmark and code is here: https://github.com/ExplainableML/fomo_in_flux.",
                    "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community.",
                    "StarCraft II is one of the most challenging simulated reinforcement learning environments; it is partially observable, stochastic, multi-agent, and mastering StarCraft II requires strategic planning over long time horizons with real-time low-level execution. It also has an active professional competitive scene. StarCraft II is uniquely suited for advancing offline RL algorithms, both because of its challenging nature and because Blizzard has released a massive dataset of millions of StarCraft II games played by human players. This paper leverages that and establishes a benchmark, called AlphaStar Unplugged, introducing unprecedented challenges for offline reinforcement learning. We define a dataset (a subset of Blizzard's release), tools standardizing an API for machine learning methods, and an evaluation protocol. We also present baseline agents, including behavior cloning, offline variants of actor-critic and MuZero. We improve the state of the art of agents using only offline data, and we achieve 90% win rate against previously published AlphaStar behavior cloning agent.",
                    "The visual classification performance of vision-language models such as CLIP has been shown to benefit from additional semantic knowledge from large language models (LLMs) such as GPT-3. In particular, averaging over LLM-generated class descriptors, e.g. \"waffle, which has a round shape\", can notably improve generalization performance. In this work, we critically study this behavior and propose WaffleCLIP, a framework for zero-shot visual classification which simply replaces LLM-generated descriptors with random character and word descriptors. Without querying external models, we achieve comparable performance gains on a large number of visual classification tasks. This allows WaffleCLIP to both serve as a low-cost alternative, as well as a sanity check for any future LLM-based vision-language model extensions. We conduct an extensive experimental study on the impact and shortcomings of additional semantics introduced with LLM-generated descriptors, and showcase how - if available - semantic context is better leveraged by querying LLMs for high-level concepts, which we show can be done to jointly resolve potential class name ambiguities. Code is available here: https://github.com/ExplainableML/WaffleCLIP.",
                    "Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning–based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. Editor’s summary The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting.",
                    "Training deep networks requires various design decisions regarding for instance their architecture, data augmentation, or optimization. In this work, we find these training variations to result in networks learning unique feature sets from the data. Using public model libraries comprising thousands of models trained on canonical datasets like ImageNet, we observe that for arbitrary pairings of pretrained models, one model extracts significant data context unavailable in the other -- independent of overall performance. Given any arbitrary pairing of pretrained models and no external rankings (such as separate test sets, e.g. due to data privacy), we investigate if it is possible to transfer such\"complementary\"knowledge from one model to another without performance degradation -- a task made particularly difficult as additional knowledge can be contained in stronger, equiperformant or weaker models. Yet facilitating robust transfer in scenarios agnostic to pretrained model pairings would unlock auxiliary gains and knowledge fusion from any model repository without restrictions on model and problem specifics - including from weaker, lower-performance models. This work therefore provides an initial, in-depth exploration on the viability of such general-purpose knowledge transfer. Across large-scale experiments, we first reveal the shortcomings of standard knowledge distillation techniques, and then propose a much more general extension through data partitioning for successful transfer between nearly all pretrained models, which we show can also be done unsupervised. Finally, we assess both the scalability and impact of fundamental model properties on successful model-agnostic knowledge transfer.",
                    "Resource scheduling and allocation is a critical component of many high impact systems ranging from congestion control to cloud computing. Finding more optimal solutions to these problems often has significant impact on resource and time savings, reducing device wear-and-tear, and even potentially improving carbon emissions. In this paper, we focus on a specific instance of a scheduling problem, namely the memory mapping problem that occurs during compilation of machine learning programs: That is, mapping tensors to different memory layers to optimize execution time. We introduce an approach for solving the memory mapping problem using Reinforcement Learning. RL is a solution paradigm well-suited for sequential decision making problems that are amenable to planning, and combinatorial search spaces with high-dimensional data inputs. We formulate the problem as a single-player game, which we call the mallocGame, such that high-reward trajectories of the game correspond to efficient memory mappings on the target hardware. We also introduce a Reinforcement Learning agent, mallocMuZero, and show that it is capable of playing this game to discover new and improved memory mapping solutions that lead to faster execution times on real ML workloads on ML accelerators. We compare the performance of mallocMuZero to the default solver used by the Accelerated Linear Algebra (XLA) compiler on a benchmark of realistic ML workloads. In addition, we show that mallocMuZero is capable of improving the execution time of the recently published AlphaTensor matrix multiplication model.",
                    "Real-world data is high-dimensional: a book, image, or musical performance can easily contain hundreds of thousands of elements even after compression. However, the most commonly used autoregressive models, Transformers, are prohibitively expensive to scale to the number of inputs and layers needed to capture this long-range structure. We develop Perceiver AR, an autoregressive, modality-agnostic architecture which uses cross-attention to map long-range inputs to a small number of latents while also maintaining end-to-end causal masking. Perceiver AR can directly attend to over a hundred thousand tokens, enabling practical long-context density estimation without the need for hand-crafted sparsity patterns or memory mechanisms. When trained on images or music, Perceiver AR generates outputs with clear long-term coherence and structure. Our architecture also obtains state-of-the-art likelihood on long-sequence benchmarks, including 64 x 64 ImageNet images and PG-19 books.",
                    "Building models that can be rapidly adapted to novel tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research. We introduce Flamingo, a family of Visual Language Models (VLM) with this ability. We propose key architectural innovations to: (i) bridge powerful pretrained vision-only and language-only models, (ii) handle sequences of arbitrarily interleaved visual and textual data, and (iii) seamlessly ingest images or videos as inputs. Thanks to their flexibility, Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities. We perform a thorough evaluation of our models, exploring and measuring their ability to rapidly adapt to a variety of image and video tasks. These include open-ended tasks such as visual question-answering, where the model is prompted with a question which it has to answer; captioning tasks, which evaluate the ability to describe a scene or an event; and close-ended tasks such as multiple-choice visual question-answering. For tasks lying anywhere on this spectrum, a single Flamingo model can achieve a new state of the art with few-shot learning, simply by prompting the model with task-specific examples. On numerous benchmarks, Flamingo outperforms models fine-tuned on thousands of times more task-specific data.",
                    "General perception systems such as Perceivers can process arbitrary modalities in any combination and are able to handle up to a few hundred thousand inputs. They achieve this generality by using exclusively global attention operations. This however hinders them from scaling up to the inputs sizes required to process raw high-resolution images or video. In this paper, we show that some degree of locality can be introduced back into these models, greatly improving their efficiency while preserving their generality. To scale them further, we introduce a self-supervised approach that enables learning dense low-dimensional positional embeddings for very large signals. We call the resulting model a Hierarchical Perceiver (HiP). In sum our contributions are: 1) scaling Perceiver-type models to raw high-resolution images and audio+video, 2) showing the feasibility of learning 1M+ positional embeddings from scratch using masked auto-encoding, 3) demonstrating competitive performance on raw data from ImageNet, AudioSet, PASCAL VOC, ModelNet40 and Kinetics datasets with the same exact, unchanged model and without specialized preprocessing or any tokenization.",
                    "Deep Metric Learning (DML) aims to learn representation spaces on which semantic relations can simply be expressed through predefined distance metrics. Best performing approaches commonly leverage class proxies as sample stand-ins for better convergence and generalization. However, these proxy-methods solely optimize for sample-proxy distances. Given the inherent non-bijectiveness of used distance functions, this can induce locally isotropic sample distributions, leading to crucial semantic context being missed due to difficulties resolving local structures and intraclass relations between samples. To alleviate this problem, we propose non-isotropy regularization $(\\mathbb{NIR})$ for proxy-based Deep Metric Learning. By leveraging Normalizing Flows, we enforce unique translatability of samples from their respective class proxies. This allows us to explicitly induce a non-isotropic distribution of samples around a proxy to optimize for. In doing so, we equip proxy-based objectives to better learn local structures. Extensive experiments highlight consistent generalization benefits of NIR while achieving competitive and state-of-the-art performance on the standard benchmarks CUB200-2011, Cars196 and Stanford Online Products. In addition, we find the superior convergence properties of proxy-based methods to still be retained or even improved, making NIR very attractive for practical usage. Code available at github.com/ExplainableML/NonIsotropicProxyDML.",
                    "Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato.",
                    "Video streaming usage has seen a significant rise as entertainment, education, and business increasingly rely on online video. Optimizing video compression has the potential to increase access and quality of content to users, and reduce energy use and costs overall. In this paper, we present an application of the MuZero algorithm to the challenge of video compression. Specifically, we target the problem of learning a rate control policy to select the quantization parameters (QP) in the encoding process of libvpx, an open source VP9 video compression library widely used by popular video-on-demand (VOD) services. We treat this as a sequential decision making problem to maximize the video quality with an episodic constraint imposed by the target bitrate. Notably, we introduce a novel self-competition based reward mechanism to solve constrained RL with variable constraint satisfaction difficulty, which is challenging for existing constrained RL methods. We demonstrate that the MuZero-based rate control achieves an average 6.28% reduction in size of the compressed videos for the same delivered video quality level (measured as PSNR BD-rate) compared to libvpx's two-pass VBR rate control policy, while having better constraint satisfaction behavior."
                ],
                "domain": [
                    "Multimodal Learning",
                    "Reinforcement Learning",
                    "Deep Learning",
                    "Natural Language Processing"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            },
            "0144157b-9040-4a58-a17e-b0488cce7896": {
                "pk": "0144157b-9040-4a58-a17e-b0488cce7896",
                "project_name": null,
                "name": "Jeff Dean",
                "bio": "I am a researcher deeply engaged in the intersection of machine learning and systems design, with a particular focus on optimizing large-scale computational frameworks. My recent work includes the development of Pathways, a sophisticated orchestration layer for accelerators that enables efficient parallel computations across thousands of devices while maintaining high performance for current models. This system exemplifies my commitment to pushing the boundaries of machine learning infrastructure, allowing for the exploration of innovative research ideas.\n\nThroughout my career, I have contributed to significant advancements in neural networks and their applications, particularly in natural language processing and computer vision. My work on Google's Neural Machine Translation (GNMT) system highlights my dedication to improving translation accuracy and efficiency, addressing challenges such as rare word handling and computational costs. Additionally, I have explored the potential of learned indexes to replace traditional data structures, demonstrating how deep learning can revolutionize data management systems.\n\nI am passionate about making machine learning accessible and effective for a wide range of applications, as evidenced by my contributions to TensorFlow, which has become a cornerstone for researchers and developers alike. My research not only focuses on theoretical advancements but also emphasizes practical implementations that can be leveraged in real-world scenarios, ultimately aiming to enhance the capabilities of AI across various domains.",
                "collaborators": [
                    "G. Corrado",
                    "Sanjay Ghemawat",
                    "M. Isard",
                    "M. Devin",
                    "Jonathon Shlens",
                    "P. Barham",
                    "Sherry Moore",
                    "G. Irving",
                    "Z. Chen",
                    "R. Monga",
                    "Vincent Vanhoucke",
                    "Quoc V. Le",
                    "Samy Bengio",
                    "Marc'Aurelio Ranzato",
                    "Tomas Mikolov",
                    "Yonghui Wu",
                    "I. Goodfellow",
                    "A. Harp",
                    "Yangqing Jia",
                    "R. Józefowicz",
                    "Martín Abadi",
                    "Andy Davis",
                    "M. Kudlur",
                    "J. Levenberg",
                    "D. Murray",
                    "Benoit Steiner",
                    "P. Tucker",
                    "Vijay Vasudevan",
                    "Pete Warden",
                    "M. Wicke",
                    "Yuan Yu",
                    "Lukasz Kaiser",
                    "M. Schuster",
                    "I. Sutskever",
                    "O. Vinyals",
                    "Mohammad Norouzi",
                    "Andrea Frome",
                    "Y. Singer",
                    "Patrick Nguyen",
                    "A. Senior",
                    "Aakanksha Chowdhery",
                    "S. Hand",
                    "D. Hurt",
                    "Hyeontaek Lim",
                    "Ruoming Pang",
                    "Sudip Roy",
                    "Brennan Saeta",
                    "Parker Schuh",
                    "Ryan Sepassi",
                    "Laurent El Shafey",
                    "C. A. Thekkath",
                    "E. Real",
                    "Thomas Breuel",
                    "Tim Kraska",
                    "Alex Beutel",
                    "Ed H. Chi",
                    "N. Polyzotis",
                    "A. Jaffey",
                    "Jianmin Chen",
                    "Xiaoqiang Zhang",
                    "Ashish Agarwal",
                    "E. Brevdo",
                    "C. Citro",
                    "Dandelion Mané",
                    "C. Olah",
                    "Kunal Talwar",
                    "F. Viégas",
                    "M. Wattenberg",
                    "Xiaoqiang Zheng",
                    "Wolfgang Macherey",
                    "M. Krikun",
                    "Yuan Cao",
                    "Qin Gao",
                    "Klaus Macherey",
                    "J. Klingner",
                    "Apurva Shah",
                    "Melvin Johnson",
                    "Xiaobing Liu",
                    "Stephan Gouws",
                    "Yoshikiyo Kato",
                    "Taku Kudo",
                    "H. Kazawa",
                    "K. Stevens",
                    "George Kurian",
                    "Nishant Patil",
                    "Wei Wang",
                    "C. Young",
                    "Jason R. Smith",
                    "Jason Riesa",
                    "Alex Rudnick",
                    "Macduff Hughes",
                    "D. Erhan",
                    "Eugene Ie",
                    "Andrew Rabinovich",
                    "Matthew D. Zeiler",
                    "Mark Z. Mao",
                    "K. Yang",
                    "Geoffrey E. Hinton",
                    "Kai Chen",
                    "G. Heigold"
                ],
                "pub_titles": [
                    "Pathways: Asynchronous Distributed Dataflow for ML",
                    "A Golden Decade of Deep Learning: Computing Systems & Applications",
                    "The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design",
                    "The Case for Learned Index Structures",
                    "DLVM: A MODERN COMPILER FRAMEWORK FOR NEURAL NETWORK DSLS",
                    "Large-Scale Deep Learning For Building Intelligent Computer Systems",
                    "TensorFlow: A system for large-scale machine learning",
                    "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
                    "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
                    "The rise of cloud computing systems",
                    "DeViSE: A Deep Visual-Semantic Embedding Model",
                    "Using Web Co-occurrence Statistics for Improving Image Categorization",
                    "On rectified linear units for speech processing",
                    "Distributed Representations of Words and Phrases and their Compositionality",
                    "Multilingual acoustic models using distributed deep neural networks",
                    "The tail at scale",
                    "Zero-Shot Learning by Convex Combination of Semantic Embeddings"
                ],
                "pub_abstracts": [
                    "We present the design of a new large scale orchestration layer for accelerators. Our system, Pathways, is explicitly designed to enable exploration of new systems and ML research ideas, while retaining state of the art performance for current models. Pathways uses a sharded dataflow graph of asynchronous operators that consume and produce futures, and efficiently gang-schedules heterogeneous parallel computations on thousands of accelerators while coordinating data transfers over their dedicated interconnects. Pathways makes use of a novel asynchronous distributed dataflow design that lets the control plane execute in parallel despite dependencies in the data plane. This design, with careful engineering, allows Pathways to adopt a single-controller model that makes it easier to express complex new parallelism patterns. We demonstrate that Pathways can achieve performance parity (~100% accelerator utilization) with state-of-the-art systems when running SPMD computations over 2048 TPUs, while also delivering throughput comparable to the SPMD case for Transformer models that are pipelined across 16 stages, or sharded across two islands of accelerators connected over a data center network.",
                    "Abstract The past decade has seen tremendous progress in the field of artificial intelligence thanks to the resurgence of neural networks through deep learning. This has helped improve the ability for computers to see, hear, and understand the world around them, leading to dramatic advances in the application of AI to many fields of science and other areas of human endeavor. In this essay, I examine the reasons for this progress, including the confluence of progress in computing hardware designed to accelerate machine learning and the emergence of open-source software frameworks to dramatically expand the set of people who can use machine learning effectively. I also present a broad overview of some of the areas in which machine learning has been applied over the past decade. Finally, I sketch out some likely directions from which further progress in artificial intelligence will come.",
                    "The past decade has seen a remarkable series of advances in machine learning, and in particular deep learning approaches based on artificial neural networks, to improve our abilities to build more accurate systems across a broad range of areas, including computer vision, speech recognition, language translation, and natural language understanding tasks. This paper is a companion paper to a keynote talk at the 2020 International Solid-State Circuits Conference (ISSCC) discussing some of the advances in machine learning, and their implications on the kinds of computational devices we need to build, especially in the post-Moore's Law-era. It also discusses some of the ways that machine learning may also be able to help with some aspects of the circuit design process. Finally, it provides a sketch of at least one interesting direction towards much larger-scale multi-task models that are sparsely activated and employ much more dynamic, example- and task-based routing than the machine learning models of today.",
                    "Indexes are models: a \\btree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term \\em learned indexes. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show that our learned indexes can have significant advantages over traditional indexes. More importantly, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work provides just a glimpse of what might be possible.",
                    "Many current approaches to deep learning make use of high-level toolkits such as TensorFlow, Torch, or Caffe. Toolkits such as Caffe have a layer-based programming framework with hard-coded gradients specified for each layer type, making research using novel layer types problematic. Toolkits such as Torch and TensorFlow define a computation graph in a host language such as Python, where each node represents a linear algebra operation parallelized as a compute kernel on GPU and stores the result of evaluation; some of these toolkits subsequently perform runtime interpretation over that graph, storing the results of forward calculations and reverse-accumulated gradients at each node. This approach is more flexible, but these toolkits take a very limited and ad-hoc approach to performing optimization. Also problematic are the facts that most toolkits lack type safety, and target only a single (usually GPU) architecture, limiting users’ abilities to make use of heterogeneous and emerging hardware architectures. We introduce a novel framework for high-level programming that addresses all of the above shortcomings.",
                    "For the past five years, the Google Brain team has focused on conducting research in difficult problems in artificial intelligence, on building large-scale computer systems for machine learning research, and, in collaboration with many teams at Google, on applying our research and systems to dozens of Google products. Our group has recently open-sourced the TensorFlow system (tensorflow.org), a system designed to easily express machine ideas, and to quickly train, evaluate and deploy machine learning systems. In this talk, I'll highlight some of the design decisions we made in building TensorFlow, discuss research results produced within our group, and describe ways in which these ideas have been applied to a variety of problems in Google's products, usually in close collaboration with other teams. This talk describes joint work with many people at Google.",
                    "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",
                    "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
                    "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system.",
                    "In this talk I will describe the development of systems that underlie modern cloud computing systems. This development shares much of its motivation with the related fields of transaction processing systems and high performance computing, but because of scale, these systems tend to have more emphasis on fault tolerance using software techniques. Important developments in the development of modern cloud systems include very high performance distributed file system, such as the Google File System (Ghemawat et al., SOSP 2003), reliable computational frameworks such as MapReduce (Dean & Ghemawat, OSDI 2004) and Dryad (Isard et al., 2007), and large scale structured storage systems such as BigTable (Chang et al. 2006), Dynamo (DeCandia et al., 2007), and Spanner (Corbett et al., 2012). Scheduling computations can either be done using virtual machines (exemplified by VMWare's products), or as individual processes or containers. The development of public cloud platforms such as AWS, Microsoft Azure, and Google Cloud Platform, allow external developers to utilize these large-scale services to build new and interesting services and products, benefiting from the economies of scale of large datacenters and the ability to grow and shrink computing resources on demand across millions of customers.",
                    "Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.",
                    "Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.",
                    "Deep neural networks have recently become the gold standard for acoustic modeling in speech recognition systems. The key computational unit of a deep network is a linear projection followed by a point-wise non-linearity, which is typically a logistic function. In this work, we show that we can improve generalization and make training of deep networks faster and simpler by substituting the logistic units with rectified linear units. These units are linear when their input is positive and zero otherwise. In a supervised setting, we can successfully train very deep nets from random initialization on a large vocabulary speech recognition task achieving lower word error rates than using a logistic network with the same topology. Similarly in an unsupervised setting, we show how we can learn sparse features that can be useful for discriminative tasks. All our experiments are executed in a distributed environment using several hundred machines and several hundred hours of speech data.",
                    "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.    An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.",
                    "Today's speech recognition technology is mature enough to be useful for many practical applications. In this context, it is of paramount importance to train accurate acoustic models for many languages within given resource constraints such as data, processing power, and time. Multilingual training has the potential to solve the data issue and close the performance gap between resource-rich and resource-scarce languages. Neural networks lend themselves naturally to parameter sharing across languages, and distributed implementations have made it feasible to train large networks. In this paper, we present experimental results for cross- and multi-lingual network training of eleven Romance languages on 10k hours of data in total. The average relative gains over the monolingual baselines are 4%/2% (data-scarce/data-rich languages) for cross- and 7%/2% for multi-lingual training. However, the additional gain from jointly training the languages on all data comes at an increased training time of roughly four weeks, compared to two weeks (monolingual) and one week (crosslingual).",
                    "Software techniques that tolerate latency variability are vital to building responsive large-scale Web services.",
                    "Abstract: Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional \\nway{} classification framing of image understanding, particularly in terms of the promise for zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing \\nway{} image classifier and a semantic word embedding model, which contains the $\\n$ class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task."
                ],
                "domain": [
                    "Machine Learning",
                    "Deep Learning",
                    "Neural Networks",
                    "Computer Vision"
                ],
                "institute": null,
                "embed": null,
                "is_leader_candidate": true,
                "is_member_candidate": true,
                "is_reviewer_candidate": true,
                "is_chair_candidate": true
            }
        },
        "reference_proposal": "**[Question 1] - What is the problem?**  \nHow can we effectively transfer knowledge from cumbersome machine learning models, which are optimized for training on large datasets, to smaller models that are more suitable for real-time deployment?\n\n---\n\n**[Question 2] - Why is it interesting and important?**  \nSolving this problem has significant implications for the research community as it addresses the gap between model training and deployment, which is crucial for practical applications in areas like speech and object recognition. By improving the efficiency of model deployment without sacrificing performance, this research could lead to advancements in real-time applications, enabling broader use of machine learning in resource-constrained environments. Furthermore, it could inspire future research into more sophisticated knowledge transfer techniques, enhancing our understanding of model generalization and efficiency.\n\n---\n\n**[Question 3] - Why is it hard?**  \nThe challenges in solving this problem stem from the inherent differences in requirements between training and deployment stages. Cumbersome models, while effective in extracting structure from large datasets, may not generalize well when distilled into smaller models. Naive approaches may fail because they do not account for the complex relationships and probabilistic information captured by the larger models. Additionally, technical obstacles include the need for effective methods to represent and transfer knowledge without losing critical information, as well as the difficulty in defining appropriate training objectives that align with real-world performance metrics.\n\n---\n\n**[Question 4] - Why hasn't it been solved before?**  \nPrevious research has often focused on optimizing models for either training or deployment, but not on the transition between the two. A conceptual barrier has been the tendency to equate knowledge with learned parameter values, making it difficult to see how to change model forms while retaining knowledge. Existing solutions have not adequately addressed the need for a more abstract understanding of knowledge representation. Our approach differs by emphasizing the use of soft targets derived from the cumbersome model to guide the training of smaller models, thereby facilitating a more effective transfer of generalization capabilities.\n\n---\n\n**[Question 5] - What are the key components of my approach and results?**  \nOur proposed methodology involves training a cumbersome model (potentially an ensemble of models) on a large dataset to extract rich probabilistic information. We will then use this model to generate soft targets, which will serve as the training signal for a smaller model. The dataset will include both the original training set and a separate transfer set, if necessary. We will evaluate the performance of the distilled model using metrics such as accuracy and generalization on test data. The expected outcome"
    }
}
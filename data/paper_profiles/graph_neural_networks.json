{
  "80337083-e21b-45b0-9b0f-0d4b11c95b89": {
    "pk": "80337083-e21b-45b0-9b0f-0d4b11c95b89",
    "title": "NPGA: Neural Parametric Gaussian Avatars",
    "abstract": "The creation of high-fidelity, digital versions of human heads is an important stepping stone in the process of further integrating virtual components into our everyday lives. Constructing such avatars is a challenging research problem, due to a high demand for photo-realism and real-time rendering performance. In this work, we propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings. We build our method around 3D Gaussian Splatting for its highly efficient rendering and to inherit the topological flexibility of point clouds. In contrast to previous work, we condition our avatars' dynamics on the rich expression space of neural parametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we distill the backward deformation field of our underlying NPHM into forward deformations which are compatible with rasterization-based rendering. All remaining fine-scale, expression-dependent details are learned from the multi-view videos. To increase the representational capacity of our avatars, we augment the canonical Gaussian point cloud using per-primitive latent features which govern its dynamic behavior. To regularize this increased dynamic expressivity, we propose Laplacian terms on the latent features and predicted dynamics. We evaluate our method on the public NeRSemble dataset, demonstrating that NPGA significantly outperforms the previous state-of-the-art avatars on the self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from real-world monocular videos.",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Martin R\u00fcnz",
      "Lourdes Agapito",
      "Matthias Nie\u00dfner"
    ],
    "url": "http://arxiv.org/abs/2405.19331v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "07b7755f-103a-49aa-bba8-f53d1c7a8d01": {
    "pk": "07b7755f-103a-49aa-bba8-f53d1c7a8d01",
    "title": "Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models",
    "abstract": "In this paper, we introduce a new task: Zero-Shot 3D Reasoning Segmentation for parts searching and localization for objects, which is a new paradigm to 3D segmentation that transcends limitations for previous category-specific 3D semantic segmentation, 3D instance segmentation, and open-vocabulary 3D segmentation. We design a simple baseline method, Reasoning3D, with the capability to understand and execute complex commands for (fine-grained) segmenting specific parts for 3D meshes with contextual awareness and reasoned answers for interactive segmentation. Specifically, Reasoning3D leverages an off-the-shelf pre-trained 2D segmentation network, powered by Large Language Models (LLMs), to interpret user input queries in a zero-shot manner. Previous research have shown that extensive pre-training endows foundation models with prior world knowledge, enabling them to comprehend complex commands, a capability we can harness to \"segment anything\" in 3D with limited 3D datasets (source efficient). Experimentation reveals that our approach is generalizable and can effectively localize and highlight parts of 3D objects (in 3D mesh) based on implicit textual queries, including these articulated 3d objects and real-world scanned data. Our method can also generate natural language explanations corresponding to these 3D models and the decomposition. Moreover, our training-free approach allows rapid deployment and serves as a viable universal baseline for future research of part-level 3d (semantic) object understanding in various fields including robotics, object manipulation, part assembly, autonomous driving applications, augment reality and virtual reality (AR/VR), and medical applications. The code, the model weight, the deployment guide, and the evaluation protocol are: http://tianrun-chen.github.io/Reason3D/",
    "authors": [
      "Tianrun Chen",
      "Chunan Yu",
      "Jing Li",
      "Jianqi Zhang",
      "Lanyun Zhu",
      "Deyi Ji",
      "Yong Zhang",
      "Ying Zang",
      "Zejian Li",
      "Lingyun Sun"
    ],
    "url": "http://arxiv.org/abs/2405.19326v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fba30ad5-5982-4abb-9481-9d0bb0b28d3f": {
    "pk": "fba30ad5-5982-4abb-9481-9d0bb0b28d3f",
    "title": "ACE: A general-purpose non-Markovian open quantum systems simulation toolkit based on process tensors",
    "abstract": "We describe a general-purpose computational toolkit for simulating open quantum systems, which provides numerically exact solutions for composites of zero-dimensional quantum systems that may be strongly coupled to multiple, quite general non-Markovian environments. It is based on process tensor matrix product operators (PT-MPOs), which efficiently encapsulate environment influences. The code features implementations of several PT-MPO algorithms, in particular, Automated Compression of Environments (ACE) for general environments comprised of independent modes as well as schemes for generalized spin boson models. The latter includes a divide-and-conquer scheme for periodic PT-MPOs, which enable million time step simulations for realistic models. PT-MPOs can be precalculated and reused for efficiently probing different time-dependent system Hamiltonians. They can also be stacked together and combined to provide numerically complete solutions of small networks of open quantum systems. The code is written in C++ and is fully controllable by configuration files, for which we have developed a versatile and compact human-readable format.",
    "authors": [
      "Moritz Cygorek",
      "Erik M. Gauger"
    ],
    "url": "http://arxiv.org/abs/2405.19319v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e2c3aa7b-b3e4-4ecf-b4b4-bff2b66b3cf5": {
    "pk": "e2c3aa7b-b3e4-4ecf-b4b4-bff2b66b3cf5",
    "title": "Network Connectivity--Information Freshness Tradeoff in Information Dissemination Over Networks",
    "abstract": "We consider a gossip network consisting of a source generating updates and $n$ nodes connected according to a given graph structure. The source keeps updates of a process, that might be generated or observed, and shares them with the gossiping network. The nodes in the network communicate with their neighbors and disseminate these version updates using a push-style gossip strategy. We use the version age metric to quantify the timeliness of information at the nodes. We first find an upper bound for the average version age for a set of nodes in a general network. Using this, we find the average version age scaling of a node in several network graph structures, such as two-dimensional grids, generalized rings and hyper-cubes. Prior to our work, it was known that when $n$ nodes are connected on a ring the version age scales as $O(n^{\\frac{1}{2}})$, and when they are connected on a fully-connected graph the version age scales as $O(\\log n)$. Ours is the first work to show an age scaling result for a connectivity structure other than the ring and the fully-connected network, which constitute the two extremes of network connectivity. Our work helps fill the gap between these two extremes by analyzing a large variety of graphs with intermediate connectivity, thus providing insight into the relationship between the connectivity structure of the network and the version age, and uncovering a network connectivity--information freshness tradeoff.",
    "authors": [
      "Arunabh Srivastava",
      "Sennur Ulukus"
    ],
    "url": "http://arxiv.org/abs/2405.19310v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4b09726e-4afd-478b-8e6c-2a36254d2cef": {
    "pk": "4b09726e-4afd-478b-8e6c-2a36254d2cef",
    "title": "SDPRLayers: Certifiable Backpropagation Through Polynomial Optimization Problems in Robotics",
    "abstract": "Differentiable optimization is a powerful new paradigm capable of reconciling model-based and learning-based approaches in robotics. However, the majority of robotics optimization problems are non-convex and current differentiable optimization techniques are therefore prone to convergence to local minima. When this occurs, the gradients provided by these existing solvers can be wildly inaccurate and will ultimately corrupt the training process. On the other hand, any non-convex robotics problems can be framed as polynomial optimization problems and, in turn, admit convex relaxations that can be used to recover a global solution via so-called certifiably correct methods. We present SDPRLayers, an approach that leverages these methods as well as state-of-the-art convex implicit differentiation techniques to provide certifiably correct gradients throughout the training process. We introduce this approach and showcase theoretical results that provide conditions under which correctness of the gradients is guaranteed. We demonstrate our approach on two simple-but-demonstrative simulated examples, which expose the potential pitfalls of existing, state-of-the-art, differentiable optimization methods. We apply our method in a real-world application: we train a deep neural network to detect image keypoints for robot localization in challenging lighting conditions. An open-source, PyTorch implementation of SDPRLayers will be made available upon paper acceptance.",
    "authors": [
      "Connor Holmes",
      "Frederike D\u00fcmbgen",
      "Timothy D. Barfoot"
    ],
    "url": "http://arxiv.org/abs/2405.19309v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "327ca9e2-aa9d-4150-a5dc-3f3f3e8a924b": {
    "pk": "327ca9e2-aa9d-4150-a5dc-3f3f3e8a924b",
    "title": "Multi-qubit circuit synthesis and Hermitian lattices",
    "abstract": "We present new optimal and heuristic algorithms for exact synthesis of multi-qubit unitaries and isometries. For example, our algorithms find Clifford and T circuits for unitaries with entries in $\\mathbb{Z}[i,1/\\sqrt{2}]$. The optimal algorithms are the A* search instantiated with a new data structure for graph vertices and new consistent heuristic functions. We also prove that for some gate sets, best-first search synthesis relying on the same heuristic is efficient. For example, for two-qubit Clifford and T circuits, our best-first search runtime is proportional to the T-count of the unitary. Our algorithms rely on Hermite and Smith Normal Forms of matrices with entries in a ring of integers of a number field, and we leverage the theory of and algorithms for Hermitian lattices over number fields to prove efficiency. These new techniques are of independent interest for future work on multi-qubit exact circuit synthesis and related questions.",
    "authors": [
      "Vadym Kliuchnikov",
      "Sebastian Sch\u00f6nnenbeck"
    ],
    "url": "http://arxiv.org/abs/2405.19302v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2eb94cc6-5009-4757-b327-353c4a7f8a96": {
    "pk": "2eb94cc6-5009-4757-b327-353c4a7f8a96",
    "title": "Neural Isometries: Taming Transformations for Equivariant ML",
    "abstract": "Real-world geometry and 3D vision tasks are replete with challenging symmetries that defy tractable analytical expression. In this paper, we introduce Neural Isometries, an autoencoder framework which learns to map the observation space to a general-purpose latent space wherein encodings are related by isometries whenever their corresponding observations are geometrically related in world space. Specifically, we regularize the latent space such that maps between encodings preserve a learned inner product and commute with a learned functional operator, in the same manner as rigid-body transformations commute with the Laplacian. This approach forms an effective backbone for self-supervised representation learning, and we demonstrate that a simple off-the-shelf equivariant network operating in the pre-trained latent space can achieve results on par with meticulously-engineered, handcrafted networks designed to handle complex, nonlinear symmetries. Furthermore, isometric maps capture information about the respective transformations in world space, and we show that this allows us to regress camera poses directly from the coefficients of the maps between encodings of adjacent views of a scene.",
    "authors": [
      "Thomas W. Mitchel",
      "Michael Taylor",
      "Vincent Sitzmann"
    ],
    "url": "http://arxiv.org/abs/2405.19296v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b712b4cb-aabf-4921-841a-9bc8c3c7ab12": {
    "pk": "b712b4cb-aabf-4921-841a-9bc8c3c7ab12",
    "title": "3D Neural Edge Reconstruction",
    "abstract": "Real-world objects and environments are predominantly composed of edge features, including straight lines and curves. Such edges are crucial elements for various applications, such as CAD modeling, surface meshing, lane mapping, etc. However, existing traditional methods only prioritize lines over curves for simplicity in geometric modeling. To this end, we introduce EMAP, a new method for learning 3D edge representations with a focus on both lines and curves. Our method implicitly encodes 3D edge distance and direction in Unsigned Distance Functions (UDF) from multi-view edge maps. On top of this neural representation, we propose an edge extraction algorithm that robustly abstracts parametric 3D edges from the inferred edge points and their directions. Comprehensive evaluations demonstrate that our method achieves better 3D edge reconstruction on multiple challenging datasets. We further show that our learned UDF field enhances neural surface reconstruction by capturing more details.",
    "authors": [
      "Lei Li",
      "Songyou Peng",
      "Zehao Yu",
      "Shaohui Liu",
      "R\u00e9mi Pautrat",
      "Xiaochuan Yin",
      "Marc Pollefeys"
    ],
    "url": "http://arxiv.org/abs/2405.19295v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "baca25a8-ecad-4697-86a6-89dcae3c8663": {
    "pk": "baca25a8-ecad-4697-86a6-89dcae3c8663",
    "title": "Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation",
    "abstract": "Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual translation, the imbalance in data volumes across different languages spreads to the vocabulary, exacerbating translations involving low-resource languages. While byte-based tokenization addresses these issues, byte-based models struggle with the low information density inherent in UTF-8 byte sequences. Previous works enhance token semantics through local contextualization but fail to select an appropriate contextualizing scope based on the input. Consequently, we propose the Multi-Scale Contextualization (MSC) method, which learns contextualized information of varying scales across different hidden state dimensions. It then leverages the attention module to dynamically integrate the multi-scale contextualized information. Experiments show that MSC significantly outperforms subword-based and other byte-based methods in both multilingual and out-of-domain scenarios. Code can be found in https://github.com/ictnlp/Multiscale-Contextualization.",
    "authors": [
      "Langlin Huang",
      "Yang Feng"
    ],
    "url": "http://arxiv.org/abs/2405.19290v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5c9d9bc7-c4e8-4fde-a357-505dc49ca8f9": {
    "pk": "5c9d9bc7-c4e8-4fde-a357-505dc49ca8f9",
    "title": "Genuine topological Anderson insulator from impurity induced chirality reversal",
    "abstract": "We investigate a model of Dirac fermions with Haldane type mass impurities which open a global topological gap even in the dilute limit. Surprisingly, we find that the chirality of this mass term, i.e., the sign of the Chern number, can be reversed by tuning the magnitude of the single-impurity scattering. Consequently, the disorder induces a phase disconnected from the clean topological phase, i.e., a genuine topological Anderson insulator. In seeming contradiction to the expectation that mass disorder is an irrelevant perturbation to the clean integer quantum Hall transition, the tri-critical point separating these two Chern insulating phases and a thermal metal phase is located at zero impurity density and connected to the appearance of a zero energy bound state in the continuum corresponding to a divergent Haldane mass impurity. Our conclusions based on the T-matrix expansion are substantiated by large scale Chebyshev-Polynomial-Green-Function numerics. We discuss possible experimental platforms.",
    "authors": [
      "Avedis Neehus",
      "Frank Pollmann",
      "Johannes Knolle"
    ],
    "url": "http://arxiv.org/abs/2405.19289v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mes-hall",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2e76be6e-0896-470a-acc4-bc1fa2abd738": {
    "pk": "2e76be6e-0896-470a-acc4-bc1fa2abd738",
    "title": "MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection",
    "abstract": "Abstract Meaning Representation (AMR) is a semantic formalism that captures the core meaning of an utterance. There has been substantial work developing AMR corpora in English and more recently across languages, though the limited size of existing datasets and the cost of collecting more annotations are prohibitive. With both engineering and scientific questions in mind, we introduce MASSIVE-AMR, a dataset with more than 84,000 text-to-graph annotations, currently the largest and most diverse of its kind: AMR graphs for 1,685 information-seeking utterances mapped to 50+ typologically diverse languages. We describe how we built our resource and its unique features before reporting on experiments using large language models for multilingual AMR and SPARQL parsing as well as applying AMRs for hallucination detection in the context of knowledge base question answering, with results shedding light on persistent issues using LLMs for structured parsing.",
    "authors": [
      "Michael Regan",
      "Shira Wein",
      "George Baker",
      "Emilio Monti"
    ],
    "url": "http://arxiv.org/abs/2405.19285v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4411b059-4a39-4636-8445-9ad075c895a9": {
    "pk": "4411b059-4a39-4636-8445-9ad075c895a9",
    "title": "Programmable Motion Generation for Open-Set Motion Control Tasks",
    "abstract": "Character animation in real-world scenarios necessitates a variety of constraints, such as trajectories, key-frames, interactions, etc. Existing methodologies typically treat single or a finite set of these constraint(s) as separate control tasks. They are often specialized, and the tasks they address are rarely extendable or customizable. We categorize these as solutions to the close-set motion control problem. In response to the complexity of practical motion control, we propose and attempt to solve the open-set motion control problem. This problem is characterized by an open and fully customizable set of motion control tasks. To address this, we introduce a new paradigm, programmable motion generation. In this paradigm, any given motion control task is broken down into a combination of atomic constraints. These constraints are then programmed into an error function that quantifies the degree to which a motion sequence adheres to them. We utilize a pre-trained motion generation model and optimize its latent code to minimize the error function of the generated motion. Consequently, the generated motion not only inherits the prior of the generative model but also satisfies the required constraints. Experiments show that we can generate high-quality motions when addressing a wide range of unseen tasks. These tasks encompass motion control by motion dynamics, geometric constraints, physical laws, interactions with scenes, objects or the character own body parts, etc. All of these are achieved in a unified approach, without the need for ad-hoc paired training data collection or specialized network designs. During the programming of novel tasks, we observed the emergence of new skills beyond those of the prior model. With the assistance of large language models, we also achieved automatic programming. We hope that this work will pave the way for the motion control of general AI agents.",
    "authors": [
      "Hanchao Liu",
      "Xiaohang Zhan",
      "Shaoli Huang",
      "Tai-Jiang Mu",
      "Ying Shan"
    ],
    "url": "http://arxiv.org/abs/2405.19283v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b9b967b5-fc34-429a-9d98-47568109516c": {
    "pk": "b9b967b5-fc34-429a-9d98-47568109516c",
    "title": "Understanding and Minimising Outlier Features in Neural Network Training",
    "abstract": "Outlier Features (OF) are neurons whose activation magnitudes significantly exceed the average over a neural network's (NN) width. They are well known to emerge during standard transformer training and have the undesirable effect of hindering quantisation in afflicted models. Despite their practical importance, little is known behind why OFs emerge during training, nor how one can minimise them.   Our work focuses on the above questions, first identifying several quantitative metrics, such as the kurtosis over neuron activation norms, to measure OFs. With these metrics, we study how architectural and optimisation choices influence OFs, and provide practical insights to minimise OFs during training. As highlights, we emphasise the importance of controlling signal propagation throughout training, and propose the Outlier Protected transformer block, which removes standard Pre-Norm layers to mitigate OFs, without loss of convergence speed or training stability. Overall, our findings shed new light on our understanding of, our ability to prevent, and the complexity of this important facet in NN training dynamics.",
    "authors": [
      "Bobby He",
      "Lorenzo Noci",
      "Daniele Paliotta",
      "Imanol Schlag",
      "Thomas Hofmann"
    ],
    "url": "http://arxiv.org/abs/2405.19279v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "26ffbf9d-6236-4026-8553-c2c8af32e634": {
    "pk": "26ffbf9d-6236-4026-8553-c2c8af32e634",
    "title": "Causal Data Fusion with Quantum Confounders",
    "abstract": "From the modern perspective of causal inference, Bell's theorem -- a fundamental signature of quantum theory -- is a particular case where quantum correlations are incompatible with the classical theory of causality, and the generalization of Bell's theorem to quantum networks has led to several breakthrough results and novel applications. Here, we consider the problem of causal data fusion, where we piece together multiple datasets collected under heterogeneous conditions. In particular, we show quantum experiments can generate observational and interventional data with a non-classical signature when pieced together that cannot be reproduced classically. We prove this quantum non-classicality emerges from the fusion of the datasets and is present in a plethora of scenarios, even where standard Bell non-classicality is impossible. Furthermore, we show that non-classicality genuine to the fusion of multiple data tables is achievable with quantum resources. Our work shows incorporating interventions -- a central tool in causal inference -- can be a powerful tool to detect non-classicality beyond the violation of a standard Bell inequality. In a companion article \"Quantum Non-classicality from Causal Data Fusion\", we extend our investigation considering all latent exogenous causal structures with 3 observable variables.",
    "authors": [
      "Pedro Lauand",
      "Bereket Ngussie Bekele",
      "Elie Wolfe"
    ],
    "url": "http://arxiv.org/abs/2405.19278v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e1c601dd-4103-4fc6-83ff-ad610edbf3e3": {
    "pk": "e1c601dd-4103-4fc6-83ff-ad610edbf3e3",
    "title": "Deep Latent Variable Modeling of Physiological Signals",
    "abstract": "A deep latent variable model is a powerful method for capturing complex distributions. These models assume that underlying structures, but unobserved, are present within the data. In this dissertation, we explore high-dimensional problems related to physiological monitoring using latent variable models. First, we present a novel deep state-space model to generate electrical waveforms of the heart using optically obtained signals as inputs. This can bring about clinical diagnoses of heart disease via simple assessment through wearable devices. Second, we present a brain signal modeling scheme that combines the strengths of probabilistic graphical models and deep adversarial learning. The structured representations can provide interpretability and encode inductive biases to reduce the data complexity of neural oscillations. The efficacy of the learned representations is further studied in epilepsy seizure detection formulated as an unsupervised learning problem. Third, we propose a framework for the joint modeling of physiological measures and behavior. Existing methods to combine multiple sources of brain data provided are limited. Direct analysis of the relationship between different types of physiological measures usually does not involve behavioral data. Our method can identify the unique and shared contributions of brain regions to behavior and can be used to discover new functions of brain regions. The success of these innovative computational methods would allow the translation of biomarker findings across species and provide insight into neurocognitive analysis in numerous biological studies and clinical diagnoses, as well as emerging consumer applications.",
    "authors": [
      "Khuong Vo"
    ],
    "url": "http://arxiv.org/abs/2405.19277v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "90f76b38-abb1-4246-a482-3ecde1329fe4": {
    "pk": "90f76b38-abb1-4246-a482-3ecde1329fe4",
    "title": "A Recipe for Charge Density Prediction",
    "abstract": "In density functional theory, charge density is the core attribute of atomic systems from which all chemical properties can be derived. Machine learning methods are promising in significantly accelerating charge density prediction, yet existing approaches either lack accuracy or scalability. We propose a recipe that can achieve both. In particular, we identify three key ingredients: (1) representing the charge density with atomic and virtual orbitals (spherical fields centered at atom/virtual coordinates); (2) using expressive and learnable orbital basis sets (basis function for the spherical fields); and (3) using high-capacity equivariant neural network architecture. Our method achieves state-of-the-art accuracy while being more than an order of magnitude faster than existing methods. Furthermore, our method enables flexible efficiency-accuracy trade-offs by adjusting the model/basis sizes.",
    "authors": [
      "Xiang Fu",
      "Andrew Rosen",
      "Kyle Bystrom",
      "Rui Wang",
      "Albert Musaelian",
      "Boris Kozinsky",
      "Tess Smidt",
      "Tommi Jaakkola"
    ],
    "url": "http://arxiv.org/abs/2405.19276v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.comp-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "50f6d0df-b59f-4e62-b098-e6cce2a89894": {
    "pk": "50f6d0df-b59f-4e62-b098-e6cce2a89894",
    "title": "A Hanani-Tutte Theorem for Cycles",
    "abstract": "Given a drawing $D$ of a graph $G$, we define the crossing number between any two cycles $C_1,C_2$ in $D$ to be the number of crossings that involve at least one edge from each of $C_1$ and $C_2$ except the crossings between edges that are common to both cycles. We show that if the crossing number between every two cycles in $G$ is even in a drawing of $G$ on the plane, then there is a planar drawing of $G$. This result can be extended to arbitrary surfaces.",
    "authors": [
      "Sutanoya Chakraborty",
      "Arijit Ghosh"
    ],
    "url": "http://arxiv.org/abs/2405.19274v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7e331422-5502-44be-9782-2c54221fdd07": {
    "pk": "7e331422-5502-44be-9782-2c54221fdd07",
    "title": "PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications",
    "abstract": "Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce. Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures. To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline. In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation. Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models. After that, we devise a direct following preference optimization to enhance the generation of pediatrician-like humanistic responses. In the parameter-efficient secondary SFT phase, a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery. Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct doctor downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs. Our model and dataset will be open-source for community development.",
    "authors": [
      "Dingkang Yang",
      "Jinjie Wei",
      "Dongling Xiao",
      "Shunli Wang",
      "Tong Wu",
      "Gang Li",
      "Mingcheng Li",
      "Shuaibing Wang",
      "Jiawei Chen",
      "Yue Jiang",
      "Qingyao Xu",
      "Ke Li",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19266v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "db6ec24d-e4e6-4c5c-b1f7-4e8937050813": {
    "pk": "db6ec24d-e4e6-4c5c-b1f7-4e8937050813",
    "title": "A Privacy-Preserving Graph Encryption Scheme Based on Oblivious RAM",
    "abstract": "Graph encryption schemes play a crucial role in facilitating secure queries on encrypted graphs hosted on untrusted servers. With applications spanning navigation systems, network topology, and social networks, the need to safeguard sensitive data becomes paramount. Existing graph encryption methods, however, exhibit vulnerabilities by inadvertently revealing aspects of the graph structure and query patterns, posing threats to security and privacy. In response, we propose a novel graph encryption scheme designed to mitigate access pattern and query pattern leakage through the integration of oblivious RAM and trusted execution environment techniques, exemplified by a Trusted Execution Environment (TEE). Our solution establishes two key security objectives: (1) ensuring that adversaries, when presented with an encrypted graph, remain oblivious to any information regarding the underlying graph, and (2) achieving query indistinguishability by concealing access patterns. Additionally, we conducted experimentation to evaluate the efficiency of the proposed schemes when dealing with real-world location navigation services.",
    "authors": [
      "Seyni Kane",
      "Anis Bkakria"
    ],
    "url": "http://arxiv.org/abs/2405.19259v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b6a254c4-e216-49e8-bc7b-eea0802b3b0d": {
    "pk": "b6a254c4-e216-49e8-bc7b-eea0802b3b0d",
    "title": "Hybrid-Parallel: Achieving High Performance and Energy Efficient Distributed Inference on Robots",
    "abstract": "The rapid advancements in machine learning techniques have led to significant achievements in various real-world robotic tasks. These tasks heavily rely on fast and energy-efficient inference of deep neural network (DNN) models when deployed on robots. To enhance inference performance, distributed inference has emerged as a promising approach, parallelizing inference across multiple powerful GPU devices in modern data centers using techniques such as data parallelism, tensor parallelism, and pipeline parallelism. However, when deployed on real-world robots, existing parallel methods fail to provide low inference latency and meet the energy requirements due to the limited bandwidth of robotic IoT. We present Hybrid-Parallel, a high-performance distributed inference system optimized for robotic IoT. Hybrid-Parallel employs a fine-grained approach to parallelize inference at the granularity of local operators within DNN layers (i.e., operators that can be computed independently with the partial input, such as the convolution kernel in the convolution layer). By doing so, Hybrid-Parallel enables different operators of different layers to be computed and transmitted concurrently, and overlap the computation and transmission phases within the same inference task. The evaluation demonstrate that Hybrid-Parallel reduces inference time by 14.9% ~41.1% and energy consumption per inference by up to 35.3% compared to the state-of-the-art baselines.",
    "authors": [
      "Zekai Sun",
      "Xiuxian Guan",
      "Junming Wang",
      "Haoze Song",
      "Yuhao Qing",
      "Tianxiang Shen",
      "Dong Huang",
      "Fangming Liu",
      "Heming Cui"
    ],
    "url": "http://arxiv.org/abs/2405.19257v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f4e4fe26-f078-48b0-b76e-c7a54c313a66": {
    "pk": "f4e4fe26-f078-48b0-b76e-c7a54c313a66",
    "title": "Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation",
    "abstract": "Sampling invariant distributions from an Ito diffusion process presents a significant challenge in stochastic simulation. Traditional numerical solvers for stochastic differential equations require both a fine step size and a lengthy simulation period, resulting in both biased and correlated samples. Current deep learning-based method solves the stationary Fokker--Planck equation to determine the invariant probability density function in form of deep neural networks, but they generally do not directly address the problem of sampling from the computed density function. In this work, we introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker--Planck equation. Our proposed loss function is based on the weak form of the Fokker--Planck equation, integrating normalizing flows to characterize the invariant distribution and facilitate sample generation from the base distribution. Our randomized test function circumvents the need for mini-max optimization in the traditional weak formulation. Distinct from conventional generative models, our method neither necessitates the computationally intensive calculation of the Jacobian determinant nor the invertibility of the transformation map. A crucial component of our framework is the adaptively chosen family of test functions in the form of Gaussian kernel functions with centres selected from the generated data samples. Experimental results on several benchmark examples demonstrate the effectiveness of our method, which offers both low computational costs and excellent capability in exploring multiple metastable states.",
    "authors": [
      "Zhiqiang Cai",
      "Yu Cao",
      "Yuanfei Huang",
      "Xiang Zhou"
    ],
    "url": "http://arxiv.org/abs/2405.19256v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3cda8364-7135-46f4-917c-c14e4e230b09": {
    "pk": "3cda8364-7135-46f4-917c-c14e4e230b09",
    "title": "Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation",
    "abstract": "The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. Yet, addressing complex urban and environmental management problems normally requires in-depth domain science and informatics expertise. This expertise is essential for deriving data and simulation-driven for informed decision support. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated workflow that encompasses natural language processing, methontology-based prompt tuning, and transformers. This workflow automates the creation of scenario-based ontology using existing research articles and technical manuals of urban datasets and simulations. The outcomes of our methodology are knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL). These facilitate the development of urban decision support systems by enhancing the data and metadata modeling, the integration of complex datasets, the coupling of multi-domain simulation models, and the formulation of decision-making metrics and workflow. The feasibility of our methodology is evaluated through a comparative analysis that juxtaposes our AI-generated ontology with the well-known Pizza Ontology employed in tutorials for popular ontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of optimizing the complex urban system of multi-modal freight transportation by generating anthologies of various domain data and simulations to support informed decision-making.",
    "authors": [
      "Jose Tupayachi",
      "Haowen Xu",
      "Olufemi A. Omitaomu",
      "Mustafa Can Camur",
      "Aliza Sharmin",
      "Xueping Li"
    ],
    "url": "http://arxiv.org/abs/2405.19255v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8c94d40c-a6d0-41b9-82a6-92d97f1723e1": {
    "pk": "8c94d40c-a6d0-41b9-82a6-92d97f1723e1",
    "title": "Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach",
    "abstract": "In transportation networks, intersections pose significant risks of collisions due to conflicting movements of vehicles approaching from different directions. To address this issue, various tools can exert influence on traffic safety both directly and indirectly. This study focuses on investigating the impact of adaptive signal control and connected and automated vehicles (CAVs) on intersection safety using a deep reinforcement learning approach. The objective is to assess the individual and combined effects of CAVs and adaptive traffic signal control on traffic safety, considering rear-end and crossing conflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals and driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses Time To Collision (TTC) metric to evaluate safety. The findings demonstrate a significant reduction in rear-end and crossing conflicts through the combined implementation of CAVs and DQNs-based traffic signal control. Additionally, the long-term positive effects of CAVs on safety are similar to the short-term effects of combined CAVs and DQNs-based traffic signal control. Overall, the study emphasizes the potential benefits of integrating CAVs and adaptive traffic signal control approaches in order to enhance traffic safety. The findings of this study could provide valuable insights for city officials and transportation authorities in developing effective strategies to improve safety at signalized intersections.",
    "authors": [
      "Amir Hossein Karbasi",
      "Hao Yang",
      "Saiedeh Razavi"
    ],
    "url": "http://arxiv.org/abs/2405.19236v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "559c3ccf-b8f6-430f-8c86-77a66e40e167": {
    "pk": "559c3ccf-b8f6-430f-8c86-77a66e40e167",
    "title": "Forward-Backward Knowledge Distillation for Continual Clustering",
    "abstract": "Unsupervised Continual Learning (UCL) is a burgeoning field in machine learning, focusing on enabling neural networks to sequentially learn tasks without explicit label information. Catastrophic Forgetting (CF), where models forget previously learned tasks upon learning new ones, poses a significant challenge in continual learning, especially in UCL, where labeled information of data is not accessible. CF mitigation strategies, such as knowledge distillation and replay buffers, often face memory inefficiency and privacy issues. Although current research in UCL has endeavored to refine data representations and address CF in streaming data contexts, there is a noticeable lack of algorithms specifically designed for unsupervised clustering. To fill this gap, in this paper, we introduce the concept of Unsupervised Continual Clustering (UCC). We propose Forward-Backward Knowledge Distillation for unsupervised Continual Clustering (FBCC) to counteract CF within the context of UCC. FBCC employs a single continual learner (the ``teacher'') with a cluster projector, along with multiple student models, to address the CF issue. The proposed method consists of two phases: Forward Knowledge Distillation, where the teacher learns new clusters while retaining knowledge from previous tasks with guidance from specialized student models, and Backward Knowledge Distillation, where a student model mimics the teacher's behavior to retain task-specific knowledge, aiding the teacher in subsequent tasks. FBCC marks a pioneering approach to UCC, demonstrating enhanced performance and memory efficiency in clustering across various tasks, outperforming the application of clustering algorithms to the latent space of state-of-the-art UCL algorithms.",
    "authors": [
      "Mohammadreza Sadeghi",
      "Zihan Wang",
      "Narges Armanfard"
    ],
    "url": "http://arxiv.org/abs/2405.19234v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "997d7e32-9203-4723-add7-e4b2d9b360b8": {
    "pk": "997d7e32-9203-4723-add7-e4b2d9b360b8",
    "title": "Valid Conformal Prediction for Dynamic GNNs",
    "abstract": "Graph neural networks (GNNs) are powerful black-box models which have shown impressive empirical performance. However, without any form of uncertainty quantification, it can be difficult to trust such models in high-risk scenarios. Conformal prediction aims to address this problem, however, an assumption of exchangeability is required for its validity which has limited its applicability to static graphs and transductive regimes. We propose to use unfolding, which allows any existing static GNN to output a dynamic graph embedding with exchangeability properties. Using this, we extend the validity of conformal prediction to dynamic GNNs in both transductive and semi-inductive regimes. We provide a theoretical guarantee of valid conformal prediction in these cases and demonstrate the empirical validity, as well as the performance gains, of unfolded GNNs against standard GNN architectures on both simulated and real datasets.",
    "authors": [
      "Ed Davis",
      "Ian Gallagher",
      "Daniel John Lawson",
      "Patrick Rubin-Delanchy"
    ],
    "url": "http://arxiv.org/abs/2405.19230v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c218da27-7113-472d-9c3a-ebca8c31dc7e": {
    "pk": "c218da27-7113-472d-9c3a-ebca8c31dc7e",
    "title": "Motor Imagery Task Alters Dynamics of Human Body Posture",
    "abstract": "Motor Imagery (MI) is gaining traction in both rehabilitation and sports settings, but its immediate influence on human postural control is not yet clearly understood. The focus of this study is to examine the effects of MI on the dynamics of the Center of Pressure (COP), a crucial metric for evaluating postural stability. In the experiment, thirty healthy young adults participated in four different scenarios: normal standing with both open and closed eyes, and kinesthetic motor imagery focused on mediolateral (ML) and anteroposterior (AP) sway movements. A mathematical model was developed to characterize the nonlinear dynamics of the COP and to assess the impact of MI on these dynamics. Our results show a statistically significant increase (p-value<0.05) in variables such as COP path length and Long-Range Correlation (LRC) during MI compared to the closed-eye and normal standing conditions. These observations align well with psycho-neuromuscular theory, which suggests that imagining a specific movement activates neural pathways, consequently affecting postural control. This study presents compelling evidence that motor imagery not only has a quantifiable impact on COP dynamics but also that changes in the Center of Pressure (COP) are directionally consistent with the imagined movements. This finding holds significant implications for the field of rehabilitation science, suggesting that motor imagery could be strategically utilized to induce targeted postural adjustments. Nonetheless, additional research is required to fully understand the complex mechanisms that underlie this relationship and to corroborate these results across a more diverse set of populations.",
    "authors": [
      "Fatemeh Delavari",
      "Seyyed Mohammad Reza Hashemi Golpayegani",
      "Mohammad Ali Ahmadi-Pajouh"
    ],
    "url": "http://arxiv.org/abs/2405.19228v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.NC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "750fe1f5-63e1-4154-9678-6aa1603563d6": {
    "pk": "750fe1f5-63e1-4154-9678-6aa1603563d6",
    "title": "Lower Bounds on the Expressivity of Recurrent Neural Language Models",
    "abstract": "The recent successes and spread of large neural language models (LMs) call for a thorough understanding of their computational ability. Describing their computational abilities through LMs' \\emph{representational capacity} is a lively area of research. However, investigation into the representational capacity of neural LMs has predominantly focused on their ability to \\emph{recognize} formal languages. For example, recurrent neural networks (RNNs) with Heaviside activations are tightly linked to regular languages, i.e., languages defined by finite-state automata (FSAs). Such results, however, fall short of describing the capabilities of RNN \\emph{language models} (LMs), which are definitionally \\emph{distributions} over strings. We take a fresh look at the representational capacity of RNN LMs by connecting them to \\emph{probabilistic} FSAs and demonstrate that RNN LMs with linearly bounded precision can express arbitrary regular LMs.",
    "authors": [
      "Anej Svete",
      "Franz Nowak",
      "Anisha Mohamed Sahabdeen",
      "Ryan Cotterell"
    ],
    "url": "http://arxiv.org/abs/2405.19222v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4026e08a-186e-4bc3-b443-db64d8f95ffe": {
    "pk": "4026e08a-186e-4bc3-b443-db64d8f95ffe",
    "title": "HawkVision: Low-Latency Modeless Edge AI Serving",
    "abstract": "The trend of modeless ML inference is increasingly growing in popularity as it hides the complexity of model inference from users and caters to diverse user and application accuracy requirements. Previous work mostly focuses on modeless inference in data centers. To provide low-latency inference, in this paper, we promote modeless inference at the edge. The edge environment introduces additional challenges related to low power consumption, limited device memory, and volatile network environments.   To address these challenges, we propose HawkVision, which provides low-latency modeless serving of vision DNNs. HawkVision leverages a two-layer edge-DC architecture that employs confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. It also supports lossy inference under volatile network environments. Our experimental results show that HawkVision outperforms current serving systems by up to 1.6X in P99 latency for providing modeless service. Our FPGA prototype demonstrates similar performance at certain accuracy levels with up to a 3.34X reduction in power consumption.",
    "authors": [
      "ChonLam Lao",
      "Jiaqi Gao",
      "Ganesh Ananthanarayanan",
      "Aditya Akella",
      "Minlan Yu"
    ],
    "url": "http://arxiv.org/abs/2405.19213v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6b013b77-aec1-4ab3-9999-b50e8feb20fb": {
    "pk": "6b013b77-aec1-4ab3-9999-b50e8feb20fb",
    "title": "Matrix Manifold Neural Networks++",
    "abstract": "Deep neural networks (DNNs) on Riemannian manifolds have garnered increasing interest in various applied areas. For instance, DNNs on spherical and hyperbolic manifolds have been designed to solve a wide range of computer vision and nature language processing tasks. One of the key factors that contribute to the success of these networks is that spherical and hyperbolic manifolds have the rich algebraic structures of gyrogroups and gyrovector spaces. This enables principled and effective generalizations of the most successful DNNs to these manifolds. Recently, some works have shown that many concepts in the theory of gyrogroups and gyrovector spaces can also be generalized to matrix manifolds such as Symmetric Positive Definite (SPD) and Grassmann manifolds. As a result, some building blocks for SPD and Grassmann neural networks, e.g., isometric models and multinomial logistic regression (MLR) can be derived in a way that is fully analogous to their spherical and hyperbolic counterparts. Building upon these works, we design fully-connected (FC) and convolutional layers for SPD neural networks. We also develop MLR on Symmetric Positive Semi-definite (SPSD) manifolds, and propose a method for performing backpropagation with the Grassmann logarithmic map in the projector perspective. We demonstrate the effectiveness of the proposed approach in the human action recognition and node classification tasks.",
    "authors": [
      "Xuan Son Nguyen",
      "Shuo Yang",
      "Aymeric Histace"
    ],
    "url": "http://arxiv.org/abs/2405.19206v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "53d339e2-eea0-4074-8807-ef1a5a1bfb34": {
    "pk": "53d339e2-eea0-4074-8807-ef1a5a1bfb34",
    "title": "Contrastive-Adversarial and Diffusion: Exploring pre-training and fine-tuning strategies for sulcal identification",
    "abstract": "In the last decade, computer vision has witnessed the establishment of various training and learning approaches. Techniques like adversarial learning, contrastive learning, diffusion denoising learning, and ordinary reconstruction learning have become standard, representing state-of-the-art methods extensively employed for fully training or pre-training networks across various vision tasks. The exploration of fine-tuning approaches has emerged as a current focal point, addressing the need for efficient model tuning with reduced GPU memory usage and time costs while enhancing overall performance, as exemplified by methodologies like low-rank adaptation (LoRA). Key questions arise: which pre-training technique yields optimal results - adversarial, contrastive, reconstruction, or diffusion denoising? How does the performance of these approaches vary as the complexity of fine-tuning is adjusted? This study aims to elucidate the advantages of pre-training techniques and fine-tuning strategies to enhance the learning process of neural networks in independent identical distribution (IID) cohorts. We underscore the significance of fine-tuning by examining various cases, including full tuning, decoder tuning, top-level tuning, and fine-tuning of linear parameters using LoRA. Systematic summaries of model performance and efficiency are presented, leveraging metrics such as accuracy, time cost, and memory efficiency. To empirically demonstrate our findings, we focus on a multi-task segmentation-classification challenge involving the paracingulate sulcus (PCS) using different 3D Convolutional Neural Network (CNN) architectures by using the TOP-OSLO cohort comprising 596 subjects.",
    "authors": [
      "Michail Mamalakis",
      "H\u00e9lo\u00efse de Vareilles",
      "Shun-Chin Jim Wu",
      "Ingrid Agartz",
      "Lynn Egeland M\u00f8rch-Johnsen",
      "Jane Garrison",
      "Jon Simons",
      "Pietro Lio",
      "John Suckling",
      "Graham Murray"
    ],
    "url": "http://arxiv.org/abs/2405.19204v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5a725653-2abf-4437-8671-d62fbb4ee6bb": {
    "pk": "5a725653-2abf-4437-8671-d62fbb4ee6bb",
    "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
    "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study delves into the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is crucial for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.",
    "authors": [
      "Renato M. Silva",
      "Greg\u00f3rio F. Azevedo",
      "Matheus V. V. Berto",
      "Jean R. Rocha",
      "Eduardo C. Fidelis",
      "Matheus V. Nogueira",
      "Pedro H. Lisboa",
      "Tiago A. Almeida"
    ],
    "url": "http://arxiv.org/abs/2405.19202v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "797c5b08-dd5b-41e0-8020-19c1425df466": {
    "pk": "797c5b08-dd5b-41e0-8020-19c1425df466",
    "title": "Going beyond compositional generalization, DDPMs can produce zero-shot interpolation",
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable capabilities in image generation, with studies suggesting that they can generalize by composing latent factors learned from the training data. In this work, we go further and study DDPMs trained on strictly separate subsets of the data distribution with large gaps on the support of the latent factors. We show that such a model can effectively generate images in the unexplored, intermediate regions of the distribution. For instance, when trained on clearly smiling and non-smiling faces, we demonstrate a sampling procedure which can generate slightly smiling faces without reference images (zero-shot interpolation). We replicate these findings for other attributes as well as other datasets. $\\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\\text{Our code is available on GitHub.}}$",
    "authors": [
      "Justin Deschenaux",
      "Igor Krawczuk",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ],
    "url": "http://arxiv.org/abs/2405.19201v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "adf12cca-9f05-46ca-95e7-56c0d2b17642": {
    "pk": "adf12cca-9f05-46ca-95e7-56c0d2b17642",
    "title": "Sparse High Dimensional Expanders via Local Lifts",
    "abstract": "High dimensional expanders (HDXs) are a hypergraph generalization of expander graphs. They are extensively studied in the math and TCS communities due to their many applications. Like expander graphs, HDXs are especially interesting for applications when they are bounded degree, namely, if the number of edges adjacent to every vertex is bounded. However, only a handful of constructions are known to have this property, all of which rely on non-trivial algebraic techniques. In particular, no random or combinatorial construction of bounded degree HDXs is known. As a result, our understanding of these objects is limited.   The degree of an $i$-face in an HDX is the number of $(i+1)$-faces containing it. In this work we construct HDXs whose higher dimensional faces have bounded degree. This is done by giving an elementary and deterministic algorithm that takes as input a regular $k$-dimensional HDX $X$ and outputs another $k$-dimensional HDX $\\widehat{X}$ with twice as many vertices. While the degree of vertices in $\\widehat{X}$ grows, the degree of the $(k-1)$-faces in $\\widehat{X}$ stays the same. As a result, we obtain a new `algebra-free' construction of HDXs whose $(k-1)$-face degree is bounded.   Our algorithm is based on a simple and natural generalization of the construction by Bilu and Linial (Combinatorica, 2006), which build expanders using lifts coming from edge signings. Our construction is based on local lifts of HDXs, where a local lift is a complex whose top-level links are lifts of links in the original complex. We demonstrate that a local lift of an HDX is an HDX in many cases.   In addition, combining local lifts with existing bounded degree constructions creates new families of bounded degree HDXs with significantly different links than before. We use this technique to construct bounded degree high dimensional expanders with links that have arbitrarily large diameters.",
    "authors": [
      "Inbar Ben Yaacov",
      "Yotam Dikstein",
      "Gal Maor"
    ],
    "url": "http://arxiv.org/abs/2405.19191v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9abd9bcd-0ad9-4872-b191-52cb464534da": {
    "pk": "9abd9bcd-0ad9-4872-b191-52cb464534da",
    "title": "Conditional Latent ODEs for Motion Prediction in Autonomous Driving",
    "abstract": "This paper addresses imitation learning for motion prediction problem in autonomous driving, especially in multi-agent setting. Different from previous methods based on GAN, we present the conditional latent ordinary differential equation (cLODE) to leverage both the generative strength of conditional VAE and the continuous representation of neural ODE. Our network architecture is inspired from the Latent-ODE model. The experiment shows that our method outperform the baseline methods in the simulation of multi-agent driving and is very efficient in term of GPU memory consumption. Our code and docker image are publicly available: https://github.com/TruongKhang/cLODE; https://hub.docker.com/r/kim4375731/clode.",
    "authors": [
      "Khang Truong Giang",
      "Yongjae Kim",
      "Andrea Finazzi"
    ],
    "url": "http://arxiv.org/abs/2405.19183v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "aec4bc9f-a297-4a0d-b858-25c06e40c754": {
    "pk": "aec4bc9f-a297-4a0d-b858-25c06e40c754",
    "title": "Chromatic and Clique number of Generalized Sierpi\u0144ski Gasket Graph $S[G,t]$",
    "abstract": "WE study the clique number and the chromatic number of generalized Sierpinski graphs in which the base graph is an arbitrary simple graph.",
    "authors": [
      "Fatemeh Attarzadeh",
      "Ahmad Abbasi",
      "Ali Behtoei"
    ],
    "url": "http://arxiv.org/abs/2405.19172v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a97f6ef7-5f0e-48e6-8b1a-cd67b2d9b365": {
    "pk": "a97f6ef7-5f0e-48e6-8b1a-cd67b2d9b365",
    "title": "Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity",
    "abstract": "Neural operator learning models have emerged as very effective surrogates in data-driven methods for partial differential equations (PDEs) across different applications from computational science and engineering. Such operator learning models not only predict particular instances of a physical or biological system in real-time but also forecast classes of solutions corresponding to a distribution of initial and boundary conditions or forcing terms. % DeepONet is the first neural operator model and has been tested extensively for a broad class of solutions, including Riemann problems. Transformers have not been used in that capacity, and specifically, they have not been tested for solutions of PDEs with low regularity. %   In this work, we first establish the theoretical groundwork that transformers possess the universal approximation property as operator learning models.   We then apply transformers to forecast solutions of diverse dynamical systems with solutions of finite regularity for a plurality of initial conditions and forcing terms. In particular, we consider three examples: the Izhikevich neuron model, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and the one-dimensional Euler equation Riemann problem. For the latter problem, we also compare with variants of DeepONet, and we find that transformers outperform DeepONet in accuracy but they are computationally more expensive.",
    "authors": [
      "Benjamin Shih",
      "Ahmad Peyvan",
      "Zhongqiang Zhang",
      "George Em Karniadakis"
    ],
    "url": "http://arxiv.org/abs/2405.19166v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6bf9b09e-b036-4410-bf51-40b1a9b674b7": {
    "pk": "6bf9b09e-b036-4410-bf51-40b1a9b674b7",
    "title": "Hilbert Series of Bipartite Field Theories",
    "abstract": "We study the algebraic structure of the mesonic moduli spaces of bipartite field theories by computing the Hilbert series. Bipartite field theories form a large family of 4d N=1 supersymmetric gauge theories that are defined by bipartite graphs on Riemann surfaces with boundaries. By calculating the Hilbert series, we are able to identify the generators and defining generator relations of the mesonic moduli spaces of these theories. Moreover, we show that certain bipartite field theories exhibit enhanced global symmetries which can be identified through the computation of the corresponding refined Hilbert series. As part of our study, we introduce two one-parameter families of bipartite field theories defined on cylinders whose mesonic moduli spaces are all complete intersection toric Calabi-Yau 3-folds.",
    "authors": [
      "Minsung Kho",
      "Rak-Kyeong Seong"
    ],
    "url": "http://arxiv.org/abs/2405.19165v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-th",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "77587894-79f9-4ccc-b6d8-20f625d189c4": {
    "pk": "77587894-79f9-4ccc-b6d8-20f625d189c4",
    "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery",
    "abstract": "Electronic Discovery (eDiscovery) involves identifying relevant documents from a vast collection based on legal production requests. The integration of artificial intelligence (AI) and natural language processing (NLP) has transformed this process, helping document review and enhance efficiency and cost-effectiveness. Although traditional approaches like BM25 or fine-tuned pre-trained models are common in eDiscovery, they face performance, computational, and interpretability challenges. In contrast, Large Language Model (LLM)-based methods prioritize interpretability but sacrifice performance and throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid approach that combines the strengths of two worlds: a heterogeneous graph-based method for accurate document relevance prediction and subsequent LLM-driven approach for reasoning. Graph representational learning generates embeddings and predicts links, ranking the corpus for a given request, and the LLMs provide reasoning for document relevance. Our approach handles datasets with balanced and imbalanced distributions, outperforming baselines in F1-score, precision, and recall by an average of 12%, 3%, and 16%, respectively. In an enterprise context, our approach drastically reduces document review costs by 99.9% compared to manual processes and by 95% compared to LLM-based classification methods",
    "authors": [
      "Sounak Lahiri",
      "Sumit Pai",
      "Tim Weninger",
      "Sanmitra Bhattacharya"
    ],
    "url": "http://arxiv.org/abs/2405.19164v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4a8e8514-fbea-471d-8295-5fd2c8847c61": {
    "pk": "4a8e8514-fbea-471d-8295-5fd2c8847c61",
    "title": "Precision microfluidic control of neuronal ensembles in cultured cortical networks",
    "abstract": "In vitro neuronal culture is an important research platform in cellular and network neuroscience. However, neurons cultured on a homogeneous scaffold form dense, randomly connected networks and display excessively synchronized activity; this phenomenon has limited their applications in network-level studies, such as studies of neuronal ensembles, or coordinated activity by a group of neurons. Herein, we develop polydimethylsiloxane-based microfluidic devices to create small neuronal networks exhibiting a hierarchically modular structure resembling the connectivity observed in the mammalian cortex. The strength of intermodular coupling was manipulated by varying the width and height of the microchannels that connect the modules. Using fluorescent calcium imaging, we observe that the spontaneous activity in networks with smaller microchannels (2.2$-$5.5 $\\mu$m$^2$) had lower synchrony and exhibit a threefold variety of neuronal ensembles. Optogenetic stimulation demonstrates that a reduction in intermodular coupling enriches evoked neuronal activity patterns and that repeated stimulation induces plasticity in neuronal ensembles in these networks. These findings suggest that cell engineering technologies based on microfluidic devices enable in vitro reconstruction of the intricate dynamics of neuronal ensembles, thus providing a robust platform for studying neuronal ensembles in a well-defined physicochemical environment.",
    "authors": [
      "Hakuba Murota",
      "Hideaki Yamamoto",
      "Nobuaki Monma",
      "Shigeo Sato",
      "Ayumi Hirano-Iwata"
    ],
    "url": "http://arxiv.org/abs/2405.19159v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.NC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d76226ba-6e85-45bc-82a2-8dafd40fb7cb": {
    "pk": "d76226ba-6e85-45bc-82a2-8dafd40fb7cb",
    "title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning",
    "abstract": "Continual learning with deep neural networks presents challenges distinct from both the fixed-dataset and convex continual learning regimes. One such challenge is plasticity loss, wherein a neural network trained in an online fashion displays a degraded ability to fit new tasks. This problem has been extensively studied in both supervised learning and off-policy reinforcement learning (RL), where a number of remedies have been proposed. Still, plasticity loss has received less attention in the on-policy deep RL setting. Here we perform an extensive set of experiments examining plasticity loss and a variety of mitigation methods in on-policy deep RL. We demonstrate that plasticity loss is pervasive under domain shift in this regime, and that a number of methods developed to resolve it in other settings fail, sometimes even resulting in performance that is worse than performing no intervention at all. In contrast, we find that a class of ``regenerative'' methods are able to consistently mitigate plasticity loss in a variety of contexts, including in gridworld tasks and more challenging environments like Montezuma's Revenge and ProcGen.",
    "authors": [
      "Arthur Juliani",
      "Jordan T. Ash"
    ],
    "url": "http://arxiv.org/abs/2405.19153v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "04d6b53b-ba4d-435f-921c-b8a55f7dea8c": {
    "pk": "04d6b53b-ba4d-435f-921c-b8a55f7dea8c",
    "title": "CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval",
    "abstract": "Composed Image Retrieval (CIR) involves searching for target images based on an image-text pair query. While current methods treat this as a query-target matching problem, we argue that CIR triplets contain additional associations beyond this primary relation. In our paper, we identify two new relations within triplets, treating each triplet as a graph node. Firstly, we introduce the concept of text-bridged image alignment, where the query text serves as a bridge between the query image and the target image. We propose a hinge-based cross-attention mechanism to incorporate this relation into network learning. Secondly, we explore complementary text reasoning, considering CIR as a form of cross-modal retrieval where two images compose to reason about complementary text. To integrate these perspectives effectively, we design a twin attention-based compositor. By combining these complementary associations with the explicit query pair-target image relation, we establish a comprehensive set of constraints for CIR. Our framework, CaLa (Complementary Association Learning for Augmenting Composed Image Retrieval), leverages these insights. We evaluate CaLa on CIRR and FashionIQ benchmarks with multiple backbones, demonstrating its superiority in composed image retrieval.",
    "authors": [
      "Xintong Jiang",
      "Yaxiong Wang",
      "Mengjian Li",
      "Yujiao Wu",
      "Bingwen Hu",
      "Xueming Qian"
    ],
    "url": "http://arxiv.org/abs/2405.19149v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5c6851ed-6b3b-45df-819c-d688d12bd56d": {
    "pk": "5c6851ed-6b3b-45df-819c-d688d12bd56d",
    "title": "Homomorphism Counts to Trees",
    "abstract": "We construct a pair of non-isomorphic, bipartite graphs which are not distinguished by counting the number of homomorphisms to any tree. This answers a question raised by Atserias et al. (LICS 2021). In order to establish the construction, we analyse the equivalence relations induced by counting homomorphisms to trees of diameter two and three and obtain necessary and sufficient conditions for two graphs to be equivalent. We show that three is the optimal diameter for our construction.",
    "authors": [
      "Anuj Dawar"
    ],
    "url": "http://arxiv.org/abs/2405.19147v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f3f1bd5c-9642-407a-aab2-5e8106ad7a6e": {
    "pk": "f3f1bd5c-9642-407a-aab2-5e8106ad7a6e",
    "title": "DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems",
    "abstract": "The modern digital engineering design often requires costly repeated simulations for different scenarios. The prediction capability of neural networks (NNs) makes them suitable surrogates for providing design insights. However, only a few NNs can efficiently handle complex engineering scenario predictions. We introduce a new version of the neural operators called DeepOKAN, which utilizes Kolmogorov Arnold networks (KANs) rather than the conventional neural network architectures. Our DeepOKAN uses Gaussian radial basis functions (RBFs) rather than the B-splines. The DeepOKAN is used to develop surrogates for different mechanics problems. This approach should pave the way for further improving the performance of neural operators. Based on the current investigations, we observe that DeepOKANs require a smaller number of learnable parameters than current MLP-based DeepONets to achieve comparable accuracy.",
    "authors": [
      "Diab W. Abueidda",
      "Panos Pantidis",
      "Mostafa E. Mobasher"
    ],
    "url": "http://arxiv.org/abs/2405.19143v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "db905c50-4dae-4c6e-a25c-fe3e8ae81d41": {
    "pk": "db905c50-4dae-4c6e-a25c-fe3e8ae81d41",
    "title": "Resilience of mobility network to dynamic population response across COVID-19 interventions: evidences from Chile",
    "abstract": "The COVID19 pandemic highlighted the importance of non-traditional data sources, such as mobile phone data, to inform effective public health interventions and monitor adherence to such measures. Previous studies showed how socioeconomic characteristics shaped population response during restrictions and how repeated interventions eroded adherence over time. Less is known about how different population strata changed their response to repeated interventions and how this impacted the resulting mobility network. We study population response during the first and second infection waves of the COVID-19 pandemic in Chile and Spain. Via spatial lag and regression models, we investigate the adherence to mobility interventions at the municipality level in Chile, highlighting the significant role of wealth, labor structure, COVID-19 incidence, and network metrics characterizing business-as-usual municipality connectivity in shaping mobility changes during the two waves. We assess network structural similarities in the two periods by defining mobility hotspots and traveling probabilities in the two countries. As a proof of concept, we simulate and compare outcomes of an epidemic diffusion occurring in the two waves. Our analysis reveals the resilience of the mobility network across waves. We test the robustness of our findings recovering similar results for Spain. Finally, epidemic modeling suggests that historical mobility data from past waves can be leveraged to inform future disease spatial invasion models in repeated interventions. This study highlights the value of historical mobile phone data for building pandemic preparedness and lessens the need for real-time data streams for risk assessment and outbreak response. Our work provides valuable insights into the complex interplay of factors driving mobility across repeated interventions, aiding in developing targeted mitigation strategies.",
    "authors": [
      "Pasquale Casaburi",
      "Lorenzo Dall'Amico",
      "Nicol\u00f2 Gozzi",
      "Kyriaki Kalimeri",
      "Anna Sapienza",
      "Rossano Schifanella",
      "T. Di Matteo",
      "Leo Ferres",
      "Mattia Mazzoli"
    ],
    "url": "http://arxiv.org/abs/2405.19141v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.soc-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "848a84be-deed-49d3-8485-a162dafcf1cf": {
    "pk": "848a84be-deed-49d3-8485-a162dafcf1cf",
    "title": "Multi-Source Coflow Scheduling in Collaborative Edge Computing with Multihop Network",
    "abstract": "Collaborative edge computing has become a popular paradigm where edge devices collaborate by sharing resources. Data dissemination is a fundamental problem in CEC to decide what data is transmitted from which device and how. Existing works on data dissemination have not focused on coflow scheduling in CEC, which involves deciding the order of flows within and across coflows at network links. Coflow implies a set of parallel flows with a shared objective. The existing works on coflow scheduling in data centers usually assume a non-blocking switch and do not consider congestion at different links in the multi-hop path in CEC, leading to increased coflow completion time (CCT). Furthermore, existing works do not consider multiple flow sources that cannot be ignored, as data can have duplicate copies at different edge devices. This work formulates the multi-source coflow scheduling problem in CEC, which includes jointly deciding the source and flow ordering for multiple coflows to minimize the sum of CCT. This problem is shown to be NP-hard and challenging as each flow can have multiple dependent conflicts at multiple links. We propose a source and coflow-aware search and adjust (SCASA) heuristic that first provides an initial solution considering the coflow characteristics. SCASA further improves the initial solution using the source search and adjust heuristic by leveraging the knowledge of both coflows and network congestion at links. Evaluation done using simulation experiments shows that SCASA leads to up to 83% reduction in the sum of CCT compared to benchmarks without a joint solution.",
    "authors": [
      "Yuvraj Sahni",
      "Jiannong Cao",
      "Lei Yang",
      "Shengwei Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19136v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.NI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bd088a92-4fb3-46d1-931b-40a981ccdcc3": {
    "pk": "bd088a92-4fb3-46d1-931b-40a981ccdcc3",
    "title": "Photometric Completeness Modelled With Neural Networks",
    "abstract": "In almost any study involving optical/NIR photometry, understanding the completeness of detection and recovery is an essential part of the work. The recovery fraction is, in general, a function of several variables including magnitude, color, background sky noise, and crowding. We explore how completeness can be modelled, {with the use of artificial-star tests,} in a way that includes all of these parameters \\emph{simultaneously} within a neural network (NN) framework. The method is able to manage common issues including asymmetric completeness functions and the bilinear dependence of the detection limit on color index. We test the method with two sample HST (Hubble Space Telescope) datasets: the first involves photometry of the star cluster population around the giant Perseus galaxy NGC 1275, and the second involves the halo-star population in the nearby elliptical galaxy NGC 3377. The NN-based method achieves a classification accuracy of $>$\\,94\\%, and produces results entirely consistent with more traditional techniques for determining completeness. Additional advantages of the method are that none of the issues arising from binning of the data are present, and that a recovery probability can be assigned to every individual star in the real photometry. Our data, models, and code (called COINTOSS) can be found online on Zenodo at the following link: https://doi.org/10.5281/zenodo.8306488.",
    "authors": [
      "William E. Harris",
      "Joshua S. Speagle"
    ],
    "url": "http://arxiv.org/abs/2405.19135v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.IM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "dfcd27b3-9a43-4670-823d-f09c2a89cc20": {
    "pk": "dfcd27b3-9a43-4670-823d-f09c2a89cc20",
    "title": "Preamble Design and Burst-Mode DSP for Upstream Reception of 200G Coherent TDM-PON",
    "abstract": "Burst-mode DSP based on 10ns preamble is proposed for upstream reception of 200G coherent TDM-PON. The 128-symbol tone preamble is used for SOP, frequency offset, and sampling phase estimation, while the 192-symbol CAZAC preamble is used for frame synchronization and channel estimation.",
    "authors": [
      "Haide Wang",
      "Ji Zhou",
      "Jinyang Yang",
      "Zhiyang Liu",
      "Cheng Li",
      "Weiping Liu",
      "Changyuan Yu"
    ],
    "url": "http://arxiv.org/abs/2405.19133v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.NI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "210c2b09-fd71-4f94-a778-d89eaed060aa": {
    "pk": "210c2b09-fd71-4f94-a778-d89eaed060aa",
    "title": "Learning Interpretable Scheduling Algorithms for Data Processing Clusters",
    "abstract": "Workloads in data processing clusters are often represented in the form of DAG (Directed Acyclic Graph) jobs. Scheduling DAG jobs is challenging. Simple heuristic scheduling algorithms are often adopted in practice in production data centres. There is much room for scheduling performance optimisation for cost saving. Recently, reinforcement learning approaches (like decima) have been attempted to optimise DAG job scheduling and demonstrate clear performance gain in comparison to traditional algorithms. However, reinforcement learning (RL) approaches face their own problems in real-world deployment. In particular, their black-box decision making processes and generalizability in unseen workloads may add a non-trivial burden to the cluster administrators. Moreover, adapting RL models on unseen workloads often requires significant amount of training data, which leaves edge cases run in a sub-optimal mode. To fill the gap, we propose a new method to distill a simple scheduling policy based on observations of the behaviours of a complex deep learning model. The simple model not only provides interpretability of scheduling decisions, but also adaptive to edge cases easily through tuning. We show that our method achieves high fidelity to the decisions made by deep learning models and outperforms these models when additional heuristics are taken into account.",
    "authors": [
      "Zhibo Hu",
      "Chen Wang",
      "Helen",
      "Paik",
      "Yanfeng Shu",
      "Liming Zhu"
    ],
    "url": "http://arxiv.org/abs/2405.19131v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6cda9dee-cbf7-436c-8e72-4c90607fbf49": {
    "pk": "6cda9dee-cbf7-436c-8e72-4c90607fbf49",
    "title": "Federated Assemblies",
    "abstract": "A citizens' assembly is a group of people who are randomly selected to represent a larger population in a deliberation. While this approach has successfully strengthened democracy, it has certain limitations that suggest the need for assemblies to form and associate more organically. In response, we propose federated assemblies, where assemblies are interconnected, and each parent assembly is selected from members of its child assemblies. The main technical challenge is to develop random selection algorithms that meet new representation constraints inherent in this hierarchical structure. We design and analyze several algorithms that provide different representation guarantees under various assumptions on the structure of the underlying graph.",
    "authors": [
      "Daniel Halpern",
      "Ariel D. Procaccia",
      "Ehud Shapiro",
      "Nimrod Talmon"
    ],
    "url": "http://arxiv.org/abs/2405.19129v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.GT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9e12b994-fd02-47df-a316-06d0f617599b": {
    "pk": "9e12b994-fd02-47df-a316-06d0f617599b",
    "title": "Cognitive biases can move opinion dynamics from consensus to signatures of transient chaos",
    "abstract": "Interest in how democracies form consensus has increased recently, with statistical physics and economics approaches both suggesting that there is convergence to a fixed point in belief networks, but with fluctuations in opinions when there are ``stubborn'' voters. We modify a model of opinion dynamics in which agents are fully Bayesian to account for two cognitive biases: confirmation bias and in-group bias. Confirmation bias occurs when the received information is considered to be more likely when it aligns with the receiver's beliefs. In-group bias occurs when the receiver further considers the information to be more likely when the receiver's beliefs and the sender's beliefs are aligned. We find that when there are no cognitive biases, a network of agents always converges to complete consensus. With confirmation bias alone, polarization can occur. With both biases present, consensus and polarization are possible, but when agents attempt to counteract confirmation bias, there can be signatures of transient chaos and ongoing opinion fluctuations. Based on this simple model, we conjecture that complex opinion fluctuations might be a generic feature of opinion dynamics when agents are Bayesian with biases.",
    "authors": [
      "Emily Dong",
      "Sarah Marzen"
    ],
    "url": "http://arxiv.org/abs/2405.19128v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.bio-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cb7be1ee-a181-4bd2-b6df-dacd36d3595d": {
    "pk": "cb7be1ee-a181-4bd2-b6df-dacd36d3595d",
    "title": "Early Detection of Critical Urban Events using Mobile Phone Network Data",
    "abstract": "Network Signalling Data (NSD) have the potential to provide continuous spatio-temporal information about the presence, mobility, and usage patterns of cell phone services by individuals. Such information is invaluable for monitoring large urban areas and supporting the implementation of decision-making services. When analyzed in real time, NSD can enable the early detection of critical urban events, including fires, large accidents, stampedes, terrorist attacks, and sports and leisure gatherings, especially if these events significantly impact mobile phone network activity in the affected areas. This paper presents empirical evidence that advanced NSD can detect anomalies in mobile traffic service consumption, attributable to critical urban events, with fine spatial and temporal resolutions. We introduce two methodologies for real-time anomaly detection from multivariate time series extracted from large-scale NSD, utilizing a range of algorithms adapted from the state-of-the-art in unsupervised machine learning techniques for anomaly detection. Our research includes a comprehensive quantitative evaluation of these algorithms on a large-scale dataset of NSD service consumption for the Paris region. The evaluation uses an original dataset of documented critical or unusual urban events. This dataset has been built as a ground truth basis for assessing the algorithms performance. The obtained results demonstrate that our framework can detect unusual events almost instantaneously and locate the affected areas with high precision, largely outperforming random classifiers. This efficiency and effectiveness underline the potential of NSD-based anomaly detection in significantly enhancing emergency response strategies and urban planning.",
    "authors": [
      "Pierre Lemaire",
      "Angelo Furno",
      "Stefania Rubrichi",
      "Alexis Bondu",
      "Zbigniew Smoreda",
      "Cezary Ziemlicki",
      "Nour-Eddin El Faouzi",
      "Eric Gaume"
    ],
    "url": "http://arxiv.org/abs/2405.19125v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6dc13029-05ac-4872-9a78-80ad6cbd9f6c": {
    "pk": "6dc13029-05ac-4872-9a78-80ad6cbd9f6c",
    "title": "Torus diffeomorphisms with parabolic and non-proper actions on the fine curve graph and their generalized rotation sets",
    "abstract": "We prove that a generic element of the Anosov-Katok class of the torus, $\\overline{\\mathcal{O}}^{\\infty}(\\mathbb{T}^2)$, acts parabolically and non-properly on the fine curve graph $C^{\\dagger}(\\mathbb{T}^2)$. Additionally, we show that a generic element of $\\overline{\\mathcal{O}}^{\\infty}(\\mathbb{T}^2)$ admits generalized rotation sets of any point-symmetric compact convex homothety type in the plane.",
    "authors": [
      "Nastaran Einabadi"
    ],
    "url": "http://arxiv.org/abs/2405.19123v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.DS",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "48ce4791-00be-431a-84fa-6e9ee95a4a32": {
    "pk": "48ce4791-00be-431a-84fa-6e9ee95a4a32",
    "title": "Spatio-Spectral Graph Neural Networks",
    "abstract": "Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for learning on graph-structured data. However, key limitations of l-step MPGNNs are that their \"receptive field\" is typically limited to the l-hop neighborhood of a node and that information exchange between distant nodes is limited by over-squashing. Motivated by these limitations, we propose Spatio-Spectral Graph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural Networks (GNNs) that synergistically combines spatially and spectrally parametrized graph filters. Parameterizing filters partially in the frequency domain enables global yet efficient information propagation. We show that S$^2$GNNs vanquish over-squashing and yield strictly tighter approximation-theoretic error bounds than MPGNNs. Further, rethinking graph convolutions at a fundamental level unlocks new design spaces. For example, S$^2$GNNs allow for free positional encodings that make them strictly more expressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain general-purpose S$^2$GNNs, we propose spectrally parametrized filters for directed graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and graph rewirings, e.g., on the peptide long-range benchmark tasks, and are competitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs scale to millions of nodes.",
    "authors": [
      "Simon Geisler",
      "Arthur Kosmala",
      "Daniel Herbst",
      "Stephan G\u00fcnnemann"
    ],
    "url": "http://arxiv.org/abs/2405.19121v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "dd80ec7e-06a8-4e6b-91c0-5edd6b6dc50b": {
    "pk": "dd80ec7e-06a8-4e6b-91c0-5edd6b6dc50b",
    "title": "Can Graph Learning Improve Task Planning?",
    "abstract": "Task planning is emerging as an important research topic alongside the development of large language models (LLMs). It aims to break down complex user requests into solvable sub-tasks, thereby fulfilling the original requests. In this context, the sub-tasks can be naturally viewed as a graph, where the nodes represent the sub-tasks, and the edges denote the dependencies among them. Consequently, task planning is a decision-making problem that involves selecting a connected path or subgraph within the corresponding graph and invoking it. In this paper, we explore graph learning-based methods for task planning, a direction that is orthogonal to the prevalent focus on prompt design. Our interest in graph learning stems from a theoretical discovery: the biases of attention and auto-regressive loss impede LLMs' ability to effectively navigate decision-making on graphs, which is adeptly addressed by graph neural networks (GNNs). This theoretical insight led us to integrate GNNs with LLMs to enhance overall performance. Extensive experiments demonstrate that GNN-based methods surpass existing solutions even without training, and minimal training can further enhance their performance. Additionally, our approach complements prompt engineering and fine-tuning techniques, with performance further enhanced by improved prompts or a fine-tuned model.",
    "authors": [
      "Xixi Wu",
      "Yifei Shen",
      "Caihua Shan",
      "Kaitao Song",
      "Siwei Wang",
      "Bohang Zhang",
      "Jiarui Feng",
      "Hong Cheng",
      "Wei Chen",
      "Yun Xiong",
      "Dongsheng Li"
    ],
    "url": "http://arxiv.org/abs/2405.19119v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0ab09b2d-c7db-4d4f-bce7-b62e262a0493": {
    "pk": "0ab09b2d-c7db-4d4f-bce7-b62e262a0493",
    "title": "Auxiliary Knowledge-Induced Learning for Automatic Multi-Label Medical Document Classification",
    "abstract": "The International Classification of Diseases (ICD) is an authoritative medical classification system of different diseases and conditions for clinical and management purposes. ICD indexing assigns a subset of ICD codes to a medical record. Since human coding is labour-intensive and error-prone, many studies employ machine learning to automate the coding process. ICD coding is a challenging task, as it needs to assign multiple codes to each medical document from an extremely large hierarchically organized collection. In this paper, we propose a novel approach for ICD indexing that adopts three ideas: (1) we use a multi-level deep dilated residual convolution encoder to aggregate the information from the clinical notes and learn document representations across different lengths of the texts; (2) we formalize the task of ICD classification with auxiliary knowledge of the medical records, which incorporates not only the clinical texts but also different clinical code terminologies and drug prescriptions for better inferring the ICD codes; and (3) we introduce a graph convolutional network to leverage the co-occurrence patterns among ICD codes, aiming to enhance the quality of label representations. Experimental results show the proposed method achieves state-of-the-art performance on a number of measures.",
    "authors": [
      "Xindi Wang",
      "Robert E. Mercer",
      "Frank Rudzicz"
    ],
    "url": "http://arxiv.org/abs/2405.19084v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "279a9919-a956-42d1-a146-fdfe26251913": {
    "pk": "279a9919-a956-42d1-a146-fdfe26251913",
    "title": "The largest Laplacian eigenvalue and the balancedness of simplicial complexes",
    "abstract": "Let $K$ be a simplical complex, and let $\\mathcal{L}_i^{up}(K), \\mathcal{Q}_i^{up}(K)$ be the $i$-th up Laplacian and signless Laplacian of $K$, respectively. In this paper we proved that the largest eigenvalue of $\\mathcal{L}_i^{up}(K)$ is not greater than the largest eigenvalue of $\\mathcal{Q}_i^{up}(K)$; furthermore, if $K$ is $(i+1)$-path connected, then the equality holds if and only if the $i$-th incidence signed graph $B_i(K)$ of $K$ is balanced. As an application we provided an upper bound for the largest eigenvalue of the $i$-th up Laplacian of $K$, which improves the bound given by Horak and Jost and generalizes the result of Anderson and Morley on graphs.We characterized the balancedness of simplicial complexes under operations such as wedge sum, join, Cartesian product and duplication of motifs. For each $i \\ge 0$, by using wedge sum or duplication of motifs, we can construct an infinitely many $(i+1)$-path connected simplicial complexes $K$ with $B_i(K)$ being balanced.",
    "authors": [
      "Yi-Zheng Fan",
      "Hui-Feng Wu",
      "Yi Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19078v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5be004d5-017f-4fa7-8580-29b20a78a7e8": {
    "pk": "5be004d5-017f-4fa7-8580-29b20a78a7e8",
    "title": "xTern: Energy-Efficient Ternary Neural Network Inference on RISC-V-Based Edge Systems",
    "abstract": "Ternary neural networks (TNNs) offer a superior accuracy-energy trade-off compared to binary neural networks. However, until now, they have required specialized accelerators to realize their efficiency potential, which has hindered widespread adoption. To address this, we present xTern, a lightweight extension of the RISC-V instruction set architecture (ISA) targeted at accelerating TNN inference on general-purpose cores. To complement the ISA extension, we developed a set of optimized kernels leveraging xTern, achieving 67% higher throughput than their 2-bit equivalents. Power consumption is only marginally increased by 5.2%, resulting in an energy efficiency improvement by 57.1%. We demonstrate that the proposed xTern extension, integrated into an octa-core compute cluster, incurs a minimal silicon area overhead of 0.9% with no impact on timing. In end-to-end benchmarks, we demonstrate that xTern enables the deployment of TNNs achieving up to 1.6 percentage points higher CIFAR-10 classification accuracy than 2-bit networks at equal inference latency. Our results show that xTern enables RISC-V-based ultra-low-power edge AI platforms to benefit from the efficiency potential of TNNs.",
    "authors": [
      "Georg Rutishauser",
      "Joan Mihali",
      "Moritz Scherer",
      "Luca Benini"
    ],
    "url": "http://arxiv.org/abs/2405.19065v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e8df8c0e-1d75-43ef-81bc-2af0d4619905": {
    "pk": "e8df8c0e-1d75-43ef-81bc-2af0d4619905",
    "title": "SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs",
    "abstract": "While dynamic graph neural networks have shown promise in various applications, explaining their predictions on continuous-time dynamic graphs (CTDGs) is difficult. This paper investigates a new research task: self-interpretable GNNs for CTDGs. We aim to predict future links within the dynamic graph while simultaneously providing causal explanations for these predictions. There are two key challenges: (1) capturing the underlying structural and temporal information that remains consistent across both independent and identically distributed (IID) and out-of-distribution (OOD) data, and (2) efficiently generating high-quality link prediction results and explanations. To tackle these challenges, we propose a novel causal inference model, namely the Independent and Confounded Causal Model (ICCM). ICCM is then integrated into a deep learning architecture that considers both effectiveness and efficiency. Extensive experiments demonstrate that our proposed model significantly outperforms existing methods across link prediction accuracy, explanation quality, and robustness to shortcut features. Our code and datasets are anonymously released at https://github.com/2024SIG/SIG.",
    "authors": [
      "Lanting Fang",
      "Yulian Yang",
      "Kai Wang",
      "Shanshan Feng",
      "Kaiyu Feng",
      "Jie Gui",
      "Shuliang Wang",
      "Yew-Soon Ong"
    ],
    "url": "http://arxiv.org/abs/2405.19062v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "24d568c4-77e6-4f39-8631-985ef45fbe26": {
    "pk": "24d568c4-77e6-4f39-8631-985ef45fbe26",
    "title": "New perspectives on the optimal placement of detectors for suicide bombers using metaheuristics",
    "abstract": "We consider an operational model of suicide bombing attacks -- an increasingly prevalent form of terrorism -- against specific targets, and the use of protective countermeasures based on the deployment of detectors over the area under threat. These detectors have to be carefully located in order to minimize the expected number of casualties or the economic damage suffered, resulting in a hard optimization problem for which different metaheuristics have been proposed. Rather than assuming random decisions by the attacker, the problem is approached by considering different models of the latter, whereby he takes informed decisions on which objective must be targeted and through which path it has to be reached based on knowledge on the importance or value of the objectives or on the defensive strategy of the defender (a scenario that can be regarded as an adversarial game). We consider four different algorithms, namely a greedy heuristic, a hill climber, tabu search and an evolutionary algorithm, and study their performance on a broad collection of problem instances trying to resemble different realistic settings such as a coastal area, a modern urban area, and the historic core of an old town. It is shown that the adversarial scenario is harder for all techniques, and that the evolutionary algorithm seems to adapt better to the complexity of the resulting search landscape.",
    "authors": [
      "Carlos Cotta",
      "Jos\u00e9 E. Gallardo"
    ],
    "url": "http://arxiv.org/abs/2405.19060v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.NE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c25170cf-a10b-41c8-b5db-3b61b4412d78": {
    "pk": "c25170cf-a10b-41c8-b5db-3b61b4412d78",
    "title": "Neural Scene Baking for Permutation Invariant Transparency Rendering with Real-time Global Illumination",
    "abstract": "Neural rendering provides a fundamentally new way to render photorealistic images. Similar to traditional light-baking methods, neural rendering utilizes neural networks to bake representations of scenes, materials, and lights into latent vectors learned from path-tracing ground truths. However, existing neural rendering algorithms typically use G-buffers to provide position, normal, and texture information of scenes, which are prone to occlusion by transparent surfaces, leading to distortions and loss of detail in the rendered images. To address this limitation, we propose a novel neural rendering pipeline that accurately renders the scene behind transparent surfaces with global illumination and variable scenes. Our method separates the G-buffers of opaque and transparent objects, retaining G-buffer information behind transparent objects. Additionally, to render the transparent objects with permutation invariance, we designed a new permutation-invariant neural blending function. We integrate our algorithm into an efficient custom renderer to achieve real-time performance. Our results show that our method is capable of rendering photorealistic images with variable scenes and viewpoints, accurately capturing complex transparent structures along with global illumination. Our renderer can achieve real-time performance ($256\\times 256$ at 63 FPS and $512\\times 512$ at 32 FPS) on scenes with multiple variable transparent objects.",
    "authors": [
      "Ziyang Zhang",
      "Edgar Simo-Serra"
    ],
    "url": "http://arxiv.org/abs/2405.19056v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.GR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7c0781ae-ac2c-4394-bcc3-4fd72aa39429": {
    "pk": "7c0781ae-ac2c-4394-bcc3-4fd72aa39429",
    "title": "Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations",
    "abstract": "The rapid expansion of electric vehicles (EVs) has rendered the load forecasting of electric vehicle charging stations (EVCS) increasingly critical. The primary challenge in achieving precise load forecasting for EVCS lies in accounting for the nonlinear of charging behaviors, the spatial interactions among different stations, and the intricate temporal variations in usage patterns. To address these challenges, we propose a Multiscale Spatio-Temporal Enhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM incorporates a multiscale graph neural network to discern hierarchical nonlinear temporal dependencies across various time scales. Besides, it also integrates a recurrent learning component and a residual fusion mechanism, enhancing its capability to accurately capture spatial and temporal variations in charging patterns. The effectiveness of the proposed MSTEM has been validated through comparative analysis with six baseline models using three evaluation metrics. The case studies utilize real-world datasets for both fast and slow charging loads at EVCS in Perth, UK. The experimental results demonstrate the superiority of MSTEM in short-term continuous load forecasting for EVCS.",
    "authors": [
      "Zongbao Zhang",
      "Jiao Hao",
      "Wenmeng Zhao",
      "Yan Liu",
      "Yaohui Huang",
      "Xinhang Luo"
    ],
    "url": "http://arxiv.org/abs/2405.19053v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c1a550cb-9804-4572-8e35-f3a07cc5aa96": {
    "pk": "c1a550cb-9804-4572-8e35-f3a07cc5aa96",
    "title": "Quantum Circuit Switching with One-Way Repeaters in Star Networks",
    "abstract": "Distributing quantum states reliably among distant locations is a key challenge in the field of quantum networks. One-way quantum networks address this by using one-way communication and quantum error correction. Here, we analyze quantum circuit switching as a protocol to distribute quantum states in one-way quantum networks. In quantum circuit switching, pairs of users can request the delivery of multiple quantum states from one user to the other. After waiting for approval from the network, the states can be distributed either sequentially, forwarding one at a time along a path of quantum repeaters, or in parallel, sending batches of quantum states from repeater to repeater. Since repeaters can only forward a finite number of quantum states at a time, a pivotal question arises: is it advantageous to send them sequentially (allowing for multiple requests simultaneously) or in parallel (reducing processing time but handling only one request at a time)? We compare both approaches in a quantum network with a star topology. Using tools from queuing theory, we show that requests are met at a higher rate when packets are distributed in parallel, although sequential distribution can generally provide service to a larger number of users simultaneously. We also show that using a large number of quantum repeaters to combat channel losses limits the maximum distance between users, as each repeater introduces additional processing delays. These findings provide insight into the design of protocols for distributing quantum states in one-way quantum networks.",
    "authors": [
      "\u00c1lvaro G. I\u00f1esta",
      "Hyeongrak Choi",
      "Dirk Englund",
      "Stephanie Wehner"
    ],
    "url": "http://arxiv.org/abs/2405.19049v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2a2c900b-3f2b-4ab7-a835-7974a9fd96e1": {
    "pk": "2a2c900b-3f2b-4ab7-a835-7974a9fd96e1",
    "title": "To RL or not to RL? An Algorithmic Cheat-Sheet for AI-Based Radio Resource Management",
    "abstract": "Several Radio Resource Management (RRM) use cases can be framed as sequential decision planning problems, where an agent (the base station, typically) makes decisions that influence the network utility and state. While Reinforcement Learning (RL) in its general form can address this scenario, it is known to be sample inefficient. Following the principle of Occam's razor, we argue that the choice of the solution technique for RRM should be guided by questions such as, \"Is it a short or long-term planning problem?\", \"Is the underlying model known or does it need to be learned?\", \"Can we solve the problem analytically?\" or \"Is an expert-designed policy available?\". A wide range of techniques exists to address these questions, including static and stochastic optimization, bandits, model predictive control (MPC) and, indeed, RL. We review some of these techniques that have already been successfully applied to RRM, and we believe that others, such as MPC, may present exciting research opportunities for the future.",
    "authors": [
      "Lorenzo Maggi",
      "Matthew Andrews",
      "Ryo Koblitz"
    ],
    "url": "http://arxiv.org/abs/2405.19045v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.NI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "47067910-beb4-4eec-83fe-a6c7567b8cae": {
    "pk": "47067910-beb4-4eec-83fe-a6c7567b8cae",
    "title": "State Space Models are Comparable to Transformers in Estimating Functions with Dynamic Smoothness",
    "abstract": "Deep neural networks based on state space models (SSMs) are attracting much attention in sequence modeling since their computational cost is significantly smaller than that of Transformers. While the capabilities of SSMs have been primarily investigated through experimental comparisons, theoretical understanding of SSMs is still limited. In particular, there is a lack of statistical and quantitative evaluation of whether SSM can replace Transformers. In this paper, we theoretically explore in which tasks SSMs can be alternatives of Transformers from the perspective of estimating sequence-to-sequence functions. We consider the setting where the target function has direction-dependent smoothness and prove that SSMs can estimate such functions with the same convergence rate as Transformers. Additionally, we prove that SSMs can estimate the target function, even if the smoothness changes depending on the input sequence, as well as Transformers. Our results show the possibility that SSMs can replace Transformers when estimating the functions in certain classes that appear in practice.",
    "authors": [
      "Naoki Nishikawa",
      "Taiji Suzuki"
    ],
    "url": "http://arxiv.org/abs/2405.19036v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bd91dd33-54e3-48fe-97be-32a6809361be": {
    "pk": "bd91dd33-54e3-48fe-97be-32a6809361be",
    "title": "A Good Foundation is Worth Many Labels: Label-Efficient Panoptic Segmentation",
    "abstract": "A key challenge for the widespread application of learning-based models for robotic perception is to significantly reduce the required amount of annotated training data while achieving accurate predictions. This is essential not only to decrease operating costs but also to speed up deployment time. In this work, we address this challenge for PAnoptic SegmenTation with fEw Labels (PASTEL) by exploiting the groundwork paved by visual foundation models. We leverage descriptive image features from such a model to train two lightweight network heads for semantic segmentation and object boundary detection, using very few annotated training samples. We then merge their predictions via a novel fusion module that yields panoptic maps based on normalized cut. To further enhance the performance, we utilize self-training on unlabeled images selected by a feature-driven similarity scheme. We underline the relevance of our approach by employing PASTEL to important robot perception use cases from autonomous driving and agricultural robotics. In extensive experiments, we demonstrate that PASTEL significantly outperforms previous methods for label-efficient segmentation even when using fewer annotations. The code of our work is publicly available at http://pastel.cs.uni-freiburg.de.",
    "authors": [
      "Niclas V\u00f6disch",
      "K\u00fcrsat Petek",
      "Markus K\u00e4ppeler",
      "Abhinav Valada",
      "Wolfram Burgard"
    ],
    "url": "http://arxiv.org/abs/2405.19035v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b838286b-a471-467a-985c-924c525993c7": {
    "pk": "b838286b-a471-467a-985c-924c525993c7",
    "title": "CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation in Ultra-Lightweight and One-Shot Graph Classification on Edge",
    "abstract": "Graph Neural Networks (GNNs) are computationally demanding and inefficient when applied to graph classification tasks in resource-constrained edge scenarios due to their inherent process, involving multiple rounds of forward and backward propagation. As a lightweight alternative, Hyper-Dimensional Computing (HDC), which leverages high-dimensional vectors for data encoding and processing, offers a more efficient solution by addressing computational bottleneck. However, current HDC methods primarily focus on static graphs and neglect to effectively capture node attributes and structural information, which leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced expressive yet ultra-lightweight HDC model for graph classification. This model introduces a novel node encoding strategy that preserves relative distance isomorphism for accurate node connection representation. In addition, node distances are utilized as edge weights for information aggregation, and the encoded node attributes and structural information are concatenated to obtain a comprehensive graph representation. Furthermore, we explore the relationship between orthogonality and dimensionality to reduce the dimensions, thereby further enhancing computational efficiency. Compared to the SOTA GNNs, extensive experiments show that CiliaGraph reduces memory usage and accelerates training speed by an average of 292 times(up to 2341 times) and 103 times(up to 313 times) respectively while maintaining comparable accuracy.",
    "authors": [
      "Yuxi Han",
      "Jihe Wang",
      "Danghui Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19033v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3b29547e-cbd0-44ab-8499-c82f1035e67c": {
    "pk": "3b29547e-cbd0-44ab-8499-c82f1035e67c",
    "title": "SynerGraph: An Integrated Graph Convolution Network for Multimodal Recommendation",
    "abstract": "This article presents a novel approach to multimodal recommendation systems, focusing on integrating and purifying multimodal data. Our methodology starts by developing a filter to remove noise from various types of data, making the recommendations more reliable. We studied the impact of top-K sparsification on different datasets, finding optimal values that strike a balance between underfitting and overfitting concerns. The study emphasizes the significant role of textual information compared to visual data in providing a deep understanding of items. We conducted sensitivity analyses to understand how different modalities and the use of purifier circle loss affect the efficiency of the model. The findings indicate that systems that incorporate multiple modalities perform better than those relying on just one modality. Our approach highlights the importance of modality purifiers in filtering out irrelevant data, ensuring that user preferences remain relevant. Models without modality purifiers showed reduced performance, emphasizing the need for effective integration of pre-extracted features. The proposed model, which includes an novel self supervised auxiliary task, shows promise in accurately capturing user preferences. The main goal of the fusion technique is to enhance the modeling of user preferences by combining knowledge with item information, utilizing sophisticated language models. Extensive experiments show that our model produces better results than the existing state-of-the-art multimodal recommendation systems.",
    "authors": [
      "Mert Burabak",
      "Tevfik Aytekin"
    ],
    "url": "http://arxiv.org/abs/2405.19031v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fcf173a0-785b-4896-973c-9dd1c32d2883": {
    "pk": "fcf173a0-785b-4896-973c-9dd1c32d2883",
    "title": "Convex neural network synthesis for robustness in the 1-norm",
    "abstract": "With neural networks being used to control safety-critical systems, they increasingly have to be both accurate (in the sense of matching inputs to outputs) and robust. However, these two properties are often at odds with each other and a trade-off has to be navigated. To address this issue, this paper proposes a method to generate an approximation of a neural network which is certifiably more robust. Crucially, the method is fully convex and posed as a semi-definite programme. An application to robustifying model predictive control is used to demonstrate the results. The aim of this work is to introduce a method to navigate the neural network robustness/accuracy trade-off.",
    "authors": [
      "Ross Drummond",
      "Chris Guiver",
      "Matthew C. Turner"
    ],
    "url": "http://arxiv.org/abs/2405.19029v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ef5af37d-bcca-40c9-ba38-97ff6fa3d2d6": {
    "pk": "ef5af37d-bcca-40c9-ba38-97ff6fa3d2d6",
    "title": "Physics-Aware Neural Implicit Solvers for multiscale, parametric PDEs with applications in heterogeneous media",
    "abstract": "We propose Physics-Aware Neural Implicit Solvers (PANIS), a novel, data-driven framework for learning surrogates for parametrized Partial Differential Equations (PDEs). It consists of a probabilistic, learning objective in which weighted residuals are used to probe the PDE and provide a source of {\\em virtual} data i.e. the actual PDE never needs to be solved. This is combined with a physics-aware implicit solver that consists of a much coarser, discretized version of the original PDE, which provides the requisite information bottleneck for high-dimensional problems and enables generalization in out-of-distribution settings (e.g. different boundary conditions). We demonstrate its capability in the context of random heterogeneous materials where the input parameters represent the material microstructure. We extend the framework to multiscale problems and show that a surrogate can be learned for the effective (homogenized) solution without ever solving the reference problem. We further demonstrate how the proposed framework can accommodate and generalize several existing learning objectives and architectures while yielding probabilistic surrogates that can quantify predictive uncertainty.",
    "authors": [
      "Matthaios Chatzopoulos",
      "Phaedon-Stelios Koutsourelakis"
    ],
    "url": "http://arxiv.org/abs/2405.19019v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "642cf0f3-e2e4-4737-9c9e-e123c9ae81e3": {
    "pk": "642cf0f3-e2e4-4737-9c9e-e123c9ae81e3",
    "title": "Distributed Management of Fluctuating Energy Resources in Dynamic Networked Systems",
    "abstract": "Modern power systems integrate renewable distributed energy resources (DERs) as an environment-friendly enhancement to meet the ever-increasing demands. However, the inherent unreliability of renewable energy renders developing DER management algorithms imperative. We study the energy-sharing problem in a system consisting of several DERs. Each agent harvests and distributes renewable energy in its neighborhood to optimize the network's performance while minimizing energy waste. We model this problem as a bandit convex optimization problem with constraints that correspond to each node's limitations for energy production. We propose distributed decision-making policies to solve the formulated problem, where we utilize the notion of dynamic regret as the performance metric. We also include an adjustment strategy in our developed algorithm to reduce the constraint violations. Besides, we design a policy that deals with the non-stationary environment. Theoretical analysis shows the effectiveness of our proposed algorithm. Numerical experiments using a real-world dataset show superior performance of our proposal compared to state-of-the-art methods.",
    "authors": [
      "Xiaotong Cheng",
      "Ioannis Tsetis",
      "Setareh Maghsudi"
    ],
    "url": "http://arxiv.org/abs/2405.19015v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0f685d09-f606-4542-b843-034869f0c630": {
    "pk": "0f685d09-f606-4542-b843-034869f0c630",
    "title": "On Dissipativity of Cross-Entropy Loss in Training ResNets",
    "abstract": "The training of ResNets and neural ODEs can be formulated and analyzed from the perspective of optimal control. This paper proposes a dissipative formulation of the training of ResNets and neural ODEs for classification problems by including a variant of the cross-entropy as a regularization in the stage cost. Based on the dissipative formulation of the training, we prove that the trained ResNet exhibit the turnpike phenomenon. We then illustrate that the training exhibits the turnpike phenomenon by training on the two spirals and MNIST datasets. This can be used to find very shallow networks suitable for a given classification task.",
    "authors": [
      "Jens P\u00fcttschneider",
      "Timm Faulwasser"
    ],
    "url": "http://arxiv.org/abs/2405.19013v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4939c836-da63-49f3-8230-db31e708c725": {
    "pk": "4939c836-da63-49f3-8230-db31e708c725",
    "title": "Implicit Neural Image Field for Biological Microscopy Image Compression",
    "abstract": "The rapid pace of innovation in biological microscopy imaging has led to large images, putting pressure on data storage and impeding efficient sharing, management, and visualization. This necessitates the development of efficient compression solutions. Traditional CODEC methods struggle to adapt to the diverse bioimaging data and often suffer from sub-optimal compression. In this study, we propose an adaptive compression workflow based on Implicit Neural Representation (INR). This approach permits application-specific compression objectives, capable of compressing images of any shape and arbitrary pixel-wise decompression. We demonstrated on a wide range of microscopy images from real applications that our workflow not only achieved high, controllable compression ratios (e.g., 512x) but also preserved detailed information critical for downstream analysis.",
    "authors": [
      "Gaole Dai",
      "Cheng-Ching Tseng",
      "Qingpo Wuwu",
      "Rongyu Zhang",
      "Shaokang Wang",
      "Ming Lu",
      "Tiejun Huang",
      "Yu Zhou",
      "Ali Ata Tuz",
      "Matthias Gunzer",
      "Jianxu Chen",
      "Shanghang Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19012v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f44ffe90-0e0e-4f2f-bf2f-75a54249d04f": {
    "pk": "f44ffe90-0e0e-4f2f-bf2f-75a54249d04f",
    "title": "Mechanism and kinetics of sodium diffusion in Na-feldspar from neural network based atomistic simulations",
    "abstract": "Alkali diffusion is a first-order control for microstructure and compositional evolution of feldspar during cooling from high temperatures of primary magmatic or metamorphic crystallization, and knowledge of the respective diffusion coefficients is crucial for reconstructing thermal histories. Our understanding of alkali diffusion in feldspar is, however, hindered by an insufficient grasp of the underlying diffusion mechanisms. We performed molecular dynamics simulations of sodium feldspar (Albite) containing different point defects using a recently developed neural network potential. A high degree of agreement between the sodium self-diffusion coefficients obtained from model simulations and those determined experimentally in earlier studies motivated a detailed investigation into the interstitial and vacancy mechanisms, corresponding jump rates, correlation factors and anisotropy. We identified a dumbbell shaped double occupancy of an alkali site as an important point defect and a correlation effect originating from the orientation of the dumbbell as a possible cause for the $\\perp\\!\\!(001) > \\, \\perp\\!\\!(010)$ diffusion anisotropy, which has been reported in a slew of feldspar cation diffusion experiments.",
    "authors": [
      "Alexander Gorfer",
      "Rainer Abart",
      "Christoph Dellago"
    ],
    "url": "http://arxiv.org/abs/2405.19008v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mtrl-sci",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f6f54db7-5a89-4ae1-a7da-c4048ea6d617": {
    "pk": "f6f54db7-5a89-4ae1-a7da-c4048ea6d617",
    "title": "Best Ergodic Averages via Optimal Graph Filters in Reversible Markov Chains",
    "abstract": "In this paper, we address the problem of finding the best ergodic or Birkhoff averages in the ergodic theorem to ensure rapid convergence to a desired value, using graph filters. Our approach begins by representing a function on the state space as a graph signal, where the (directed) graph is formed by the transition probabilities of a reversible Markov chain. We introduce a concept of graph variation, enabling the definition of the graph Fourier transform for graph signals on this directed graph. Viewing the iteration in the ergodic theorem as a graph filter, we recognize its non-optimality and propose three optimization problems aimed at determining optimal graph filters. These optimization problems yield the Bernstein, Chebyshev, and Legendre filters. Numerical testing reveals that while the Bernstein filter performs slightly better than the traditional ergodic average, the Chebyshev and Legendre filters significantly outperform the ergodic average, demonstrating rapid convergence to the desired value.",
    "authors": [
      "Naci Saldi"
    ],
    "url": "http://arxiv.org/abs/2405.18995v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ae724d87-58f4-4950-b66a-9f7e40c5847d": {
    "pk": "ae724d87-58f4-4950-b66a-9f7e40c5847d",
    "title": "Tuning load redistribution and damage near heterogeneous interfaces",
    "abstract": "We investigate interface failure of model materials representing architected thin films in contact with heterogeneous substrates. We find that, while systems with statistically isotropic distributions of impurities derive their fracture strength from the ability to develop rough detachment fronts, materials with hierarchical microstructures confine failure near a prescribed surface, where crack growth is arrested and crack surface correlations are suppressed. We develop a theory of network Green's functions for the systems at hand, and we find that the ability of hierarchical microstructures to control failure mode and locations comes at no performance cost in terms of peak stress and specific work of failure and derives from the quenched local anistotropy of the elastic interaction kernel.",
    "authors": [
      "Christian Greff",
      "Paolo Moretti",
      "Michael Zaiser"
    ],
    "url": "http://arxiv.org/abs/2405.18994v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mtrl-sci",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7f817791-3eca-4623-bb4b-fc0efb41e6ed": {
    "pk": "7f817791-3eca-4623-bb4b-fc0efb41e6ed",
    "title": "Classification analysis of transition-metal chalcogenides and oxides using quantum machine learning",
    "abstract": "Quantum machine learning (QML) leverages the potential from machine learning to explore the subtle patterns in huge datasets of complex nature with quantum advantages. This exponentially reduces the time and resources necessary for computations. QML accelerates materials research with active screening of chemical space, identifying novel materials for practical applications and classifying structurally diverse materials given their measured properties. This study analyzes the performance of three efficient quantum machine learning algorithms viz., variational quantum eigen solver (VQE), quantum support vector machine (QSVM) and quantum neural networks (QNN) for the classification of transition metal chalcogenides and oxides (TMCs &TMOs). The analysis is performed on three datasets of different sizes containing 102, 192 and 350 materials with TMCs and TMOs labelled as +1 and -1 respectively. By employing feature selection, classical machine learning achieves 100% accuracy whereas QML achieves the highest performance of 99% and 98% for test and train data respectively on QSVC. This study establishes the competence of QML models in materials classification and explores the quantum circuits in terms of over-fitting using the circuit descriptors expressibility and entangling capability. In addition, the perspectives on QML in materials research with noisy intermediate scale quantum (NISQ) devices is given.",
    "authors": [
      "Kurudi V Vedavyasa",
      "Ashok Kumar"
    ],
    "url": "http://arxiv.org/abs/2405.18989v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mtrl-sci",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5bd74fcb-298b-41c3-a7b7-1d48b0021f97": {
    "pk": "5bd74fcb-298b-41c3-a7b7-1d48b0021f97",
    "title": "Transmission Channel Analysis in Dynamic Models",
    "abstract": "We propose a framework for the analysis of transmission channels in a large class of dynamic models. To this end, we formulate our approach both using graph theory and potential outcomes, which we show to be equivalent. Our method, labelled Transmission Channel Analysis (TCA), allows for the decomposition of total effects captured by impulse response functions into the effects flowing along transmission channels, thereby providing a quantitative assessment of the strength of various transmission channels. We establish that this requires no additional identification assumptions beyond the identification of the structural shock whose effects the researcher wants to decompose. Additionally, we prove that impulse response functions are sufficient statistics for the computation of transmission effects. We also demonstrate the empirical relevance of TCA for policy evaluation by decomposing the effects of various monetary policy shock measures into instantaneous implementation effects and effects that likely relate to forward guidance.",
    "authors": [
      "Enrico Wegner",
      "Lenard Lieb",
      "Stephan Smeekes",
      "Ines Wilms"
    ],
    "url": "http://arxiv.org/abs/2405.18987v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "econ.EM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4d2ed7ab-d3e9-440b-9632-1b62f588d5ce": {
    "pk": "4d2ed7ab-d3e9-440b-9632-1b62f588d5ce",
    "title": "Optimizing Vehicular Networks with Variational Quantum Circuits-based Reinforcement Learning",
    "abstract": "In vehicular networks (VNets), ensuring both road safety and dependable network connectivity is of utmost importance. Achieving this necessitates the creation of resilient and efficient decision-making policies that prioritize multiple objectives. In this paper, we develop a Variational Quantum Circuit (VQC)-based multi-objective reinforcement learning (MORL) framework to characterize efficient network selection and autonomous driving policies in a vehicular network (VNet). Numerical results showcase notable enhancements in both convergence rates and rewards when compared to conventional deep-Q networks (DQNs), validating the efficacy of the VQC-MORL solution.",
    "authors": [
      "Zijiang Yan",
      "Ramsundar Tanikella",
      "Hina Tabassum"
    ],
    "url": "http://arxiv.org/abs/2405.18984v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8bc344d5-f149-433d-b6d9-e7fac7d692db": {
    "pk": "8bc344d5-f149-433d-b6d9-e7fac7d692db",
    "title": "MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts",
    "abstract": "Leveraging the models' outputs, specifically the logits, is a common approach to estimating the test accuracy of a pre-trained neural network on out-of-distribution (OOD) samples without requiring access to the corresponding ground truth labels. Despite their ease of implementation and computational efficiency, current logit-based methods are vulnerable to overconfidence issues, leading to prediction bias, especially under the natural shift. In this work, we first study the relationship between logits and generalization performance from the view of low-density separation assumption. Our findings motivate our proposed method MaNo which (1) applies a data-dependent normalization on the logits to reduce prediction bias, and (2) takes the $L_p$ norm of the matrix of normalized logits as the estimation score. Our theoretical analysis highlights the connection between the provided score and the model's uncertainty. We conduct an extensive empirical study on common unsupervised accuracy estimation benchmarks and demonstrate that MaNo achieves state-of-the-art performance across various architectures in the presence of synthetic, natural, or subpopulation shifts.",
    "authors": [
      "Renchunzi Xie",
      "Ambroise Odonnat",
      "Vasilii Feofanov",
      "Weijian Deng",
      "Jianfeng Zhang",
      "Bo An"
    ],
    "url": "http://arxiv.org/abs/2405.18979v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "669fc100-d00f-4e85-ac06-ed05b3f07672": {
    "pk": "669fc100-d00f-4e85-ac06-ed05b3f07672",
    "title": "Hierarchical Classification Auxiliary Network for Time Series Forecasting",
    "abstract": "Deep learning has significantly advanced time series forecasting through its powerful capacity to capture sequence relationships. However, training these models with the Mean Square Error (MSE) loss often results in over-smooth predictions, making it challenging to handle the complexity and learn high-entropy features from time series data with high variability and unpredictability. In this work, we introduce a novel approach by tokenizing time series values to train forecasting models via cross-entropy loss, while considering the continuous nature of time series data. Specifically, we propose Hierarchical Classification Auxiliary Network, HCAN, a general model-agnostic component that can be integrated with any forecasting model. HCAN is based on a Hierarchy-Aware Attention module that integrates multi-granularity high-entropy features at different hierarchy levels. At each level, we assign a class label for timesteps to train an Uncertainty-Aware Classifier. This classifier mitigates the over-confidence in softmax loss via evidence theory. We also implement a Hierarchical Consistency Loss to maintain prediction consistency across hierarchy levels. Extensive experiments integrating HCAN with state-of-the-art forecasting models demonstrate substantial improvements over baselines on several real-world datasets. Code is available at:https://github.com/syrGitHub/HCAN.",
    "authors": [
      "Yanru Sun",
      "Zongxia Xie",
      "Dongyue Chen",
      "Emadeldeen Eldele",
      "Qinghua Hu"
    ],
    "url": "http://arxiv.org/abs/2405.18975v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "89b6996d-5789-4785-b0ba-0193bb5fa7a0": {
    "pk": "89b6996d-5789-4785-b0ba-0193bb5fa7a0",
    "title": "UniIF: Unified Molecule Inverse Folding",
    "abstract": "Molecule inverse folding has been a long-standing challenge in chemistry and biology, with the potential to revolutionize drug discovery and material science. Despite specified models have been proposed for different small- or macro-molecules, few have attempted to unify the learning process, resulting in redundant efforts. Complementary to recent advancements in molecular structure prediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified model UniIF for the inverse folding of all molecules. We do such unification in two levels: 1) Data-Level: We propose a unified block graph data form for all molecules, including the local frame building and geometric feature initialization. 2) Model-Level: We introduce a geometric block attention network, comprising a geometric interaction, interactive attention and virtual long-term dependency modules, to capture the 3D interactions of all molecules. Through comprehensive evaluations across various tasks such as protein design, RNA design, and material design, we demonstrate that our proposed method surpasses state-of-the-art methods on all tasks. UniIF offers a versatile and effective solution for general molecule inverse folding.",
    "authors": [
      "Zhangyang Gao",
      "Jue Wang",
      "Cheng Tan",
      "Lirong Wu",
      "Yufei Huang",
      "Siyuan Li",
      "Zhirui Ye",
      "Stan Z. Li"
    ],
    "url": "http://arxiv.org/abs/2405.18968v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2b185492-4f3b-4e74-850c-6204ee124af6": {
    "pk": "2b185492-4f3b-4e74-850c-6204ee124af6",
    "title": "Pessimism of the Will, Optimism of the Intellect: Fair Protocols with Malicious but Rational Agents",
    "abstract": "Fairness is a desirable and crucial property of many protocols that handle, for instance, exchanges of message.   It states that if at least one agent engaging in the protocol is honest, then either the protocol will unfold correctly and fulfill its intended goal for all participants, or it will fail for everyone.   In this work, we present a game-based framework for the study of fairness protocols, that does not define a priori an attacker model.   It is based on the notion of strong secure equilibria, and leverages the conceptual and algorithmic toolbox of game theory.   In the case of finite games, we provide decision procedures with tight complexity bounds for determining whether a protocol is immune to nefarious attacks from a coalition of participants, and whether such a protocol could exist based on the underlying graph structure and objectives.",
    "authors": [
      "L\u00e9onard Brice",
      "Jean-Fran\u00e7ois Raskin",
      "Mathieu Sassolas",
      "Guillaume Scerri",
      "Marie van den Bogaard"
    ],
    "url": "http://arxiv.org/abs/2405.18958v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.GT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e647974f-6ee5-4aa9-b2ae-777017afb715": {
    "pk": "e647974f-6ee5-4aa9-b2ae-777017afb715",
    "title": "MAGIC: Modular Auto-encoder for Generalisable Model Inversion with Bias Corrections",
    "abstract": "Scientists often model physical processes to understand the natural world and uncover the causation behind observations. Due to unavoidable simplification, discrepancies often arise between model predictions and actual observations, in the form of systematic biases, whose impact varies with model completeness. Classical model inversion methods such as Bayesian inference or regressive neural networks tend either to overlook biases or make assumptions about their nature during data preprocessing, potentially leading to implausible results. Inspired by recent work in inverse graphics, we replace the decoder stage of a standard autoencoder with a physical model followed by a bias-correction layer. This generalisable approach simultaneously inverts the model and corrects its biases in an end-to-end manner without making strong assumptions about the nature of the biases. We demonstrate the effectiveness of our approach using two physical models from disparate domains: a complex radiative transfer model from remote sensing; and a volcanic deformation model from geodesy. Our method matches or surpasses results from classical approaches without requiring biases to be explicitly filtered out, suggesting an effective pathway for understanding the causation of various physical processes.",
    "authors": [
      "Yihang She",
      "Clement Atzberger",
      "Andrew Blake",
      "Adriano Gualandi",
      "Srinivasan Keshav"
    ],
    "url": "http://arxiv.org/abs/2405.18953v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2fcfcbe4-0a61-432e-8a41-d720cd765d8b": {
    "pk": "2fcfcbe4-0a61-432e-8a41-d720cd765d8b",
    "title": "Learning to Recover from Plan Execution Errors during Robot Manipulation: A Neuro-symbolic Approach",
    "abstract": "Automatically detecting and recovering from failures is an important but challenging problem for autonomous robots. Most of the recent work on learning to plan from demonstrations lacks the ability to detect and recover from errors in the absence of an explicit state representation and/or a (sub-) goal check function. We propose an approach (blending learning with symbolic search) for automated error discovery and recovery, without needing annotated data of failures. Central to our approach is a neuro-symbolic state representation, in the form of dense scene graph, structured based on the objects present within the environment. This enables efficient learning of the transition function and a discriminator that not only identifies failures but also localizes them facilitating fast re-planning via computation of heuristic distance function. We also present an anytime version of our algorithm, where instead of recovering to the last correct state, we search for a sub-goal in the original plan minimizing the total distance to the goal given a re-planning budget. Experiments on a physics simulator with a variety of simulated failures show the effectiveness of our approach compared to existing baselines, both in terms of efficiency as well as accuracy of our recovery mechanism.",
    "authors": [
      "Namasivayam Kalithasan",
      "Arnav Tuli",
      "Vishal Bindal",
      "Himanshu Gaurav Singh",
      "Parag Singla",
      "Rohan Paul"
    ],
    "url": "http://arxiv.org/abs/2405.18948v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1d420dd4-8f78-4e6e-96b2-b8b8fc709edb": {
    "pk": "1d420dd4-8f78-4e6e-96b2-b8b8fc709edb",
    "title": "WTTFNet: A Weather-Time-Trajectory Fusion Network for Pedestrian Trajectory Prediction in Urban Complex",
    "abstract": "Pedestrian trajectory modelling in an urban complex is challenging because pedestrians can have many possible destinations, such as shops, escalators, and attractions. Moreover, weather and time-of-day may affect pedestrian behavior. In this paper, a new weather-time-trajectory fusion network (WTTFNet) is proposed to improve the performance of baseline deep neural network architecture. By incorporating weather and time-of-day information as an embedding structure, a novel WTTFNet based on gate multimodal unit is used to fuse the multimodal information and deep representation of trajectories. A joint loss function based on focal loss is used to co-optimize both the deep trajectory features and final classifier, which helps to improve the accuracy in predicting the intended destination of pedestrians and hence the trajectories under possible scenarios of class imbalances. Experimental results using the Osaka Asia and Pacific Trade Center (ATC) dataset shows improved performance of the proposed approach over state-of-the-art algorithms by 23.67% increase in classification accuracy, 9.16% and 7.07% reduction of average and final displacement error. The proposed approach may serve as an attractive approach for improving existing baseline trajectory prediction models when they are applied to scenarios with influences of weather-time conditions. It can be employed in numerous applications such as pedestrian facility engineering, public space development and technology-driven retail.",
    "authors": [
      "Ho Chun Wu",
      "Esther Hoi Shan Lau",
      "Paul Yuen",
      "Kevin Hung",
      "John Kwok Tai Chui",
      "Andrew Kwok Fai Lui"
    ],
    "url": "http://arxiv.org/abs/2405.18945v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "468952f2-ea84-4b4b-bebe-6406cdaa2c01": {
    "pk": "468952f2-ea84-4b4b-bebe-6406cdaa2c01",
    "title": "Verifiably Robust Conformal Prediction",
    "abstract": "Conformal Prediction (CP) is a popular uncertainty quantification method that provides distribution-free, statistically valid prediction sets, assuming that training and test data are exchangeable. In such a case, CP's prediction sets are guaranteed to cover the (unknown) true test output with a user-specified probability. Nevertheless, this guarantee is violated when the data is subjected to adversarial attacks, which often result in a significant loss of coverage. Recently, several approaches have been put forward to recover CP guarantees in this setting. These approaches leverage variations of randomised smoothing to produce conservative sets which account for the effect of the adversarial perturbations. They are, however, limited in that they only support $\\ell^2$-bounded perturbations and classification tasks. This paper introduces \\emph{VRCP (Verifiably Robust Conformal Prediction)}, a new framework that leverages recent neural network verification methods to recover coverage guarantees under adversarial attacks. Our VRCP method is the first to support perturbations bounded by arbitrary norms including $\\ell^1$, $\\ell^2$, and $\\ell^\\infty$, as well as regression tasks. We evaluate and compare our approach on image classification tasks (CIFAR10, CIFAR100, and TinyImageNet) and regression tasks for deep reinforcement learning environments. In every case, VRCP achieves above nominal coverage and yields significantly more efficient and informative prediction regions than the SotA.",
    "authors": [
      "Linus Jeary",
      "Tom Kuipers",
      "Mehran Hosseini",
      "Nicola Paoletti"
    ],
    "url": "http://arxiv.org/abs/2405.18942v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "be6aab89-fb86-4c0f-9ce2-5ccd539cf751": {
    "pk": "be6aab89-fb86-4c0f-9ce2-5ccd539cf751",
    "title": "HLOB -- Information Persistence and Structure in Limit Order Books",
    "abstract": "We introduce a novel large-scale deep learning model for Limit Order Book mid-price changes forecasting, and we name it `HLOB'. This architecture (i) exploits the information encoded by an Information Filtering Network, namely the Triangulated Maximally Filtered Graph, to unveil deeper and non-trivial dependency structures among volume levels; and (ii) guarantees deterministic design choices to handle the complexity of the underlying system by drawing inspiration from the groundbreaking class of Homological Convolutional Neural Networks. We test our model against 9 state-of-the-art deep learning alternatives on 3 real-world Limit Order Book datasets, each including 15 stocks traded on the NASDAQ exchange, and we systematically characterize the scenarios where HLOB outperforms state-of-the-art architectures. Our approach sheds new light on the spatial distribution of information in Limit Order Books and on its degradation over increasing prediction horizons, narrowing the gap between microstructural modeling and deep learning-based forecasting in high-frequency financial markets.",
    "authors": [
      "Antonio Briola",
      "Silvia Bartolucci",
      "Tomaso Aste"
    ],
    "url": "http://arxiv.org/abs/2405.18938v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-fin.TR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f9a3bea7-7ed7-47d3-b955-663fb0789476": {
    "pk": "f9a3bea7-7ed7-47d3-b955-663fb0789476",
    "title": "LSPI: Heterogeneous Graph Neural Network Classification Aggregation Algorithm Based on Size Neighbor Path Identification",
    "abstract": "Existing heterogeneous graph neural network algorithms (HGNNs) mostly rely on meta-paths to capture the rich semantic information contained in heterogeneous graphs (also known as heterogeneous information networks (HINs)), but most of these HGNNs focus on different ways of feature aggre gation and ignore the properties of the meta-paths themselves. This paper studies meta-paths in three commonly used data sets and finds that there are huge differences in the number of neighbors connected by different meta paths. At the same time, the noise information contained in large neigh bor paths will have an adverse impact on model performance. Therefore, this paper proposes a Heterogeneous Graph Neural Network Classification and Aggregation Algorithm Based on Large and Small Neighbor Path Iden tification(LSPI). LSPI firstly divides the meta-paths into large and small neighbor paths through the path discriminator , and in order to reduce the noise interference problem in large neighbor paths, LSPI selects neighbor nodes with higher similarity from both topology and feature perspectives, and passes small neighbor paths and filtered large neighbor paths through different graph convolution components. Aggregation is performed to obtain feature information under different subgraphs, and then LSPI uses subgraph level attention to fuse the feature information under different subgraphs to generate the final node embedding. Finally this paper verifies the superiority of the method through extensive experiments and also gives suggestions on the number of nodes to be retained in large neighbor paths through exper iments. The complete reproducible code adn data has been published at: https://github.com/liuhua811/LSPIA.",
    "authors": [
      "Yufei Zhaoa",
      "Shiduo Wanga",
      "Hua Duana"
    ],
    "url": "http://arxiv.org/abs/2405.18933v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3ae78755-d1a3-4230-84d7-0a41c14c4445": {
    "pk": "3ae78755-d1a3-4230-84d7-0a41c14c4445",
    "title": "A Mallows-like Criterion for Anomaly Detection with Random Forest Implementation",
    "abstract": "The effectiveness of anomaly signal detection can be significantly undermined by the inherent uncertainty of relying on one specified model. Under the framework of model average methods, this paper proposes a novel criterion to select the weights on aggregation of multiple models, wherein the focal loss function accounts for the classification of extremely imbalanced data. This strategy is further integrated into Random Forest algorithm by replacing the conventional voting method. We have evaluated the proposed method on benchmark datasets across various domains, including network intrusion. The findings indicate that our proposed method not only surpasses the model averaging with typical loss functions but also outstrips common anomaly detection algorithms in terms of accuracy and robustness.",
    "authors": [
      "Gaoxiang Zhao",
      "Lu Wang",
      "Xiaoqiang Wang"
    ],
    "url": "http://arxiv.org/abs/2405.18932v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2bb8ae3c-fda9-4bb0-aee7-89779faa8f14": {
    "pk": "2bb8ae3c-fda9-4bb0-aee7-89779faa8f14",
    "title": "EntProp: High Entropy Propagation for Improving Accuracy and Robustness",
    "abstract": "Deep neural networks (DNNs) struggle to generalize to out-of-distribution domains that are different from those in training despite their impressive performance. In practical applications, it is important for DNNs to have both high standard accuracy and robustness against out-of-distribution domains. One technique that achieves both of these improvements is disentangled learning with mixture distribution via auxiliary batch normalization layers (ABNs). This technique treats clean and transformed samples as different domains, allowing a DNN to learn better features from mixed domains. However, if we distinguish the domains of the samples based on entropy, we find that some transformed samples are drawn from the same domain as clean samples, and these samples are not completely different domains. To generate samples drawn from a completely different domain than clean samples, we hypothesize that transforming clean high-entropy samples to further increase the entropy generates out-of-distribution samples that are much further away from the in-distribution domain. On the basis of the hypothesis, we propose high entropy propagation~(EntProp), which feeds high-entropy samples to the network that uses ABNs. We introduce two techniques, data augmentation and free adversarial training, that increase entropy and bring the sample further away from the in-distribution domain. These techniques do not require additional training costs. Our experimental results show that EntProp achieves higher standard accuracy and robustness with a lower training cost than the baseline methods. In particular, EntProp is highly effective at training on small datasets.",
    "authors": [
      "Shohei Enomoto"
    ],
    "url": "http://arxiv.org/abs/2405.18931v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "83025b28-49b8-482d-b01b-15860938f1e5": {
    "pk": "83025b28-49b8-482d-b01b-15860938f1e5",
    "title": "Understanding and Addressing the Under-Translation Problem from the Perspective of Decoding Objective",
    "abstract": "Neural Machine Translation (NMT) has made remarkable progress over the past years. However, under-translation and over-translation remain two challenging problems in state-of-the-art NMT systems. In this work, we conduct an in-depth analysis on the underlying cause of under-translation in NMT, providing an explanation from the perspective of decoding objective. To optimize the beam search objective, the model tends to overlook words it is less confident about, leading to the under-translation phenomenon. Correspondingly, the model's confidence in predicting the End Of Sentence (EOS) diminishes when under-translation occurs, serving as a mild penalty for under-translated candidates. Building upon this analysis, we propose employing the confidence of predicting EOS as a detector for under-translation, and strengthening the confidence-based penalty to penalize candidates with a high risk of under-translation. Experiments on both synthetic and real-world data show that our method can accurately detect and rectify under-translated outputs, with minor impact on other correct translations.",
    "authors": [
      "Chenze Shao",
      "Fandong Meng",
      "Jiali Zeng",
      "Jie Zhou"
    ],
    "url": "http://arxiv.org/abs/2405.18922v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5456f86b-a171-423d-bee3-352d40b4b8eb": {
    "pk": "5456f86b-a171-423d-bee3-352d40b4b8eb",
    "title": "Exploiting Inter-Satellite Links for In-Flight Connectivity Scheme in Space-Air-Ground Integrated Networks",
    "abstract": "Space-air-ground integrated networks (SAGIN) are pivotal for achieving uninterrupted in-flight connectivity (IFC). Most existing studies, however, merely treat satellites as transparent forwarding nodes, and overlook their caching capabilities in enhancing the IFC data rate. In this paper, we consider an IFC-oriented SAGIN, where the satellites collaboratively deliver the content to airborne passengers to facilitate airborne communication. Considering the cached files instantaneously accessible via satellites, this work pioneers the integration of multiple inter-satellite links (ISLs) into the IFC framework, thereby innovating the content delivery process. To minimize the average delay of content delivery, we formulate an optimization problem and propose an exact penalty-based method to derive the satellite association scheme. Our proposed framework has a low complexity and thus paves the way for high-speed Internet connectivity to aviation passengers. Finally, simulation results are presented to demonstrate the effectiveness of our proposed IFC framework for SAGIN.",
    "authors": [
      "Qian Chen",
      "Chenyu Wu",
      "Shuai Han",
      "Weixiao Meng",
      "Tony Q. S. Quek"
    ],
    "url": "http://arxiv.org/abs/2405.18919v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8ecdf3ca-adb0-455f-aa8a-60a0b0e527f9": {
    "pk": "8ecdf3ca-adb0-455f-aa8a-60a0b0e527f9",
    "title": "Computing low-thrust transfers in the asteroid belt, a comparison between astrodynamical manipulations and a machine learning approach",
    "abstract": "Low-thrust trajectories play a crucial role in optimizing scientific output and cost efficiency in asteroid belt missions. Unlike high-thrust transfers, low-thrust trajectories require solving complex optimal control problems. This complexity grows exponentially with the number of asteroids visited due to orbital mechanics intricacies. In the literature, methods for approximating low-thrust transfers without full optimization have been proposed, including analytical and machine learning techniques. In this work, we propose new analytical approximations and compare their accuracy and performance to machine learning methods. While analytical approximations leverage orbit theory to estimate trajectory costs, machine learning employs a more black-box approach, utilizing neural networks to predict optimal transfers based on various attributes. We build a dataset of about 3 million transfers, found by solving the time and fuel optimal control problems, for different time of flights, which we also release open-source. Comparison between the two methods on this database reveals the superiority of machine learning, especially for longer transfers. Despite challenges such as multi revolution transfers, both approaches maintain accuracy within a few percent in the final mass errors, on a database of trajectories involving numerous asteroids. This work contributes to the efficient exploration of mission opportunities in the asteroid belt, providing insights into the strengths and limitations of different approximation strategies.",
    "authors": [
      "Giacomo Acciarini",
      "Laurent Beauregard",
      "Dario Izzo"
    ],
    "url": "http://arxiv.org/abs/2405.18918v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.EP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8bc61cd5-cb0a-4ab2-811c-f5872f8884d2": {
    "pk": "8bc61cd5-cb0a-4ab2-811c-f5872f8884d2",
    "title": "Causal Action Influence Aware Counterfactual Data Augmentation",
    "abstract": "Offline data are both valuable and practical resources for teaching robots complex behaviors. Ideally, learning agents should not be constrained by the scarcity of available demonstrations, but rather generalize beyond the training distribution. However, the complexity of real-world scenarios typically requires huge amounts of data to prevent neural network policies from picking up on spurious correlations and learning non-causal relationships. We propose CAIAC, a data augmentation method that can create feasible synthetic transitions from a fixed dataset without having access to online environment interactions. By utilizing principled methods for quantifying causal influence, we are able to perform counterfactual reasoning by swapping $\\it{action}$-unaffected parts of the state-space between independent trajectories in the dataset. We empirically show that this leads to a substantial increase in robustness of offline learning algorithms against distributional shift.",
    "authors": [
      "N\u00faria Armengol Urp\u00ed",
      "Marco Bagatella",
      "Marin Vlastelica",
      "Georg Martius"
    ],
    "url": "http://arxiv.org/abs/2405.18917v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8c704a2a-b169-4c8f-a4d9-c39e98cebb4f": {
    "pk": "8c704a2a-b169-4c8f-a4d9-c39e98cebb4f",
    "title": "$S$-packing colorings of distance graphs with distance sets of cardinality $2$",
    "abstract": "For a non-decreasing sequence $S=(s_1,s_2,\\ldots)$ of positive integers, a partition of the vertex set of a graph $G$ into subsets $X_1,\\ldots, X_\\ell$, such that vertices in $X_i$ are pairwise at distance greater than $s_i$ for every $i\\in\\{1,\\ldots,\\ell\\}$, is called an $S$-packing $\\ell$-coloring of $G$. The minimum $\\ell$ for which $G$ admits an $S$-packing $\\ell$-coloring is called the $S$-packing chromatic number of $G$, denoted by $\\chi_S(G)$. In this paper, we consider $S$-packing colorings of distance graphs $G(\\mathbb{Z},\\{k,t\\})$, where $k$ and $t$ are positive integers, which are the graphs whose vertex set is $\\mathbb{Z}$, and two vertices $x,y\\in \\mathbb{Z}$ are adjacent whenever $|x-y|\\in\\{k,t\\}$. We complement partial results from two earlier papers, thus determining all values of $\\chi_S(G(\\mathbb{Z},\\{k,t\\}))$ when $S$ is any sequence with $s_i\\le 2$ for all $i$. In particular, if $S=(1,1,2,2,\\ldots)$, then the $S$-packing chromatic number is $2$ if $k+t$ is even, and $4$ otherwise, while if $S=(1,2,2,\\ldots)$, then the $S$-packing chromatic number is $5$, unless $\\{k,t\\}=\\{2,3\\}$ when it is $6$; when $S=(2,2,2,\\ldots)$, the corresponding formula is more complex.",
    "authors": [
      "Bo\u0161tjan Bre\u0161ar",
      "Jasmina Ferme",
      "P\u0159emysl Holub",
      "Marko Jakovac",
      "Petra Melicharov\u00e1"
    ],
    "url": "http://arxiv.org/abs/2405.18904v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d70807e1-7a0a-4b35-84bc-b3f8a2e37b7f": {
    "pk": "d70807e1-7a0a-4b35-84bc-b3f8a2e37b7f",
    "title": "Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural Networks Using One Bayesian Test Vector",
    "abstract": "The performance of deep learning algorithms such as neural networks (NNs) has increased tremendously recently, and they can achieve state-of-the-art performance in many domains. However, due to memory and computation resource constraints, implementing NNs on edge devices is a challenging task. Therefore, hardware accelerators such as computation-in-memory (CIM) with memristive devices have been developed to accelerate the most common operations, i.e., matrix-vector multiplication. However, due to inherent device properties, external environmental factors such as temperature, and an immature fabrication process, memristors suffer from various non-idealities, including defects and variations occurring during manufacturing and runtime. Consequently, there is a lack of complete confidence in the predictions made by the model. To improve confidence in NN predictions made by hardware accelerators in the presence of device non-idealities, in this paper, we propose a Bayesian test vector generation framework that can estimate the model uncertainty of NNs implemented on memristor-based CIM hardware. Compared to the conventional point estimate test vector generation method, our method is more generalizable across different model dimensions and requires storing only one test Bayesian vector in the hardware. Our method is evaluated on different model dimensions, tasks, fault rates, and variation noise to show that it can consistently achieve $100\\%$ coverage with only $0.024$ MB of memory overhead.",
    "authors": [
      "Soyed Tuhin Ahmed",
      "Mehdi Tahoori"
    ],
    "url": "http://arxiv.org/abs/2405.18894v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3f6199e2-7a5b-4dba-9fbe-cdc6aacca782": {
    "pk": "3f6199e2-7a5b-4dba-9fbe-cdc6aacca782",
    "title": "Inverse Design of Promising Alloys for Electrocatalytic CO$_2$ Reduction via Generative Graph Neural Networks Combined with Bird Swarm Algorithm",
    "abstract": "Directly generating material structures with optimal properties is a long-standing goal in material design. One of the fundamental challenges lies in how to overcome the limitation of traditional generative models to efficiently explore the global chemical space rather than a small localized space. Herein, we develop a framework named MAGECS to address this dilemma, by integrating the bird swarm algorithm and supervised graph neural network to effectively navigate the generative model in the immense chemical space towards materials with target properties. As a demonstration, MAGECS is applied to design compelling alloy electrocatalysts for CO$_2$ reduction reaction (CO$_2$RR) and works extremely well. Specifically, the chemical space of CO$_2$RR is effectively explored, where over 250,000 promising structures with high activity have been generated and notably, the proportion of desired structures is 2.5-fold increased. Moreover, five predicted alloys, i.e., CuAl, AlPd, Sn$_2$Pd$_5$, Sn$_9$Pd$_7$, and CuAlSe$_2$ are successfully synthesized and characterized experimentally, two of which exhibit about 90% Faraday efficiency of CO$_2$RR, and CuAl achieved 76% efficiency for C$_2$ products. This pioneering application of inverse design in CO$_2$RR catalysis showcases the potential of MAGECS to dramatically accelerate the development of functional materials, paving the way for fully automated, artificial intelligence-driven material design.",
    "authors": [
      "Zhilong Song",
      "Linfeng Fan",
      "Shuaihua Lu",
      "Qionghua Zhou",
      "Chongyi Ling",
      "Jinlan Wang"
    ],
    "url": "http://arxiv.org/abs/2405.18891v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mtrl-sci",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "74bdd0fe-e0c6-4bb9-b844-dabe2fa007b9": {
    "pk": "74bdd0fe-e0c6-4bb9-b844-dabe2fa007b9",
    "title": "Learning Mixture-of-Experts for General-Purpose Black-Box Discrete Optimization",
    "abstract": "Real-world applications involve various discrete optimization problems. Designing a specialized optimizer for each of these problems is challenging, typically requiring significant domain knowledge and human efforts. Hence, developing general-purpose optimizers as an off-the-shelf tool for a wide range of problems has been a long-standing research target. This article introduces MEGO, a novel general-purpose neural optimizer trained through a fully data-driven learning-to-optimize (L2O) approach. MEGO consists of a mixture-of-experts trained on experiences from solving training problems and can be viewed as a foundation model for optimization problems with binary decision variables. When presented with a problem to solve, MEGO actively selects relevant expert models to generate high-quality solutions. MEGO can be used as a standalone sample-efficient optimizer or in conjunction with existing search methods as an initial solution generator. The generality of MEGO is validated across six problem classes, including three classic problem classes and three problem classes arising from real-world applications in compilers, network analysis, and 3D reconstruction. Trained solely on classic problem classes, MEGO performs very well on all six problem classes, significantly surpassing widely used general-purpose optimizers in both solution quality and efficiency. In some cases, MEGO even surpasses specialized state-of-the-art optimizers. Additionally, MEGO provides a similarity measure between problems, yielding a new perspective for problem classification. In the pursuit of general-purpose optimizers through L2O, MEGO represents an initial yet significant step forward.",
    "authors": [
      "Shengcai Liu",
      "Zhiyuan Wang",
      "Yew-Soon Ong",
      "Xin Yao",
      "Ke Tang"
    ],
    "url": "http://arxiv.org/abs/2405.18884v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.NE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d4d1182b-198a-4389-a7e6-63871cddd0b0": {
    "pk": "d4d1182b-198a-4389-a7e6-63871cddd0b0",
    "title": "DecomCAM: Advancing Beyond Saliency Maps through Decomposition and Integration",
    "abstract": "Interpreting complex deep networks, notably pre-trained vision-language models (VLMs), is a formidable challenge. Current Class Activation Map (CAM) methods highlight regions revealing the model's decision-making basis but lack clear saliency maps and detailed interpretability. To bridge this gap, we propose DecomCAM, a novel decomposition-and-integration method that distills shared patterns from channel activation maps. Utilizing singular value decomposition, DecomCAM decomposes class-discriminative activation maps into orthogonal sub-saliency maps (OSSMs), which are then integrated together based on their contribution to the target concept. Extensive experiments on six benchmarks reveal that DecomCAM not only excels in locating accuracy but also achieves an optimizing balance between interpretability and computational efficiency. Further analysis unveils that OSSMs correlate with discernible object components, facilitating a granular understanding of the model's reasoning. This positions DecomCAM as a potential tool for fine-grained interpretation of advanced deep learning models. The code is available at https://github.com/CapricornGuang/DecomCAM.",
    "authors": [
      "Yuguang Yang",
      "Runtang Guo",
      "Sheng Wu",
      "Yimi Wang",
      "Linlin Yang",
      "Bo Fan",
      "Jilong Zhong",
      "Juan Zhang",
      "Baochang Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.18882v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "200c7839-992b-4a8f-91e7-b44b2320e10f": {
    "pk": "200c7839-992b-4a8f-91e7-b44b2320e10f",
    "title": "Spatiotemporal Forecasting Meets Efficiency: Causal Graph Process Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have advanced spatiotemporal forecasting by leveraging relational inductive biases among sensors (or any other measuring scheme) represented as nodes in a graph. However, current methods often rely on Recurrent Neural Networks (RNNs), leading to increased runtimes and memory use. Moreover, these methods typically operate within 1-hop neighborhoods, exacerbating the reduction of the receptive field. Causal Graph Processes (CGPs) offer an alternative, using graph filters instead of MLP layers to reduce parameters and minimize memory consumption. This paper introduces the Causal Graph Process Neural Network (CGProNet), a non-linear model combining CGPs and GNNs for spatiotemporal forecasting. CGProNet employs higher-order graph filters, optimizing the model with fewer parameters, reducing memory usage, and improving runtime efficiency. We present a comprehensive theoretical and experimental stability analysis, highlighting key aspects of CGProNet. Experiments on synthetic and real data demonstrate CGProNet's superior efficiency, minimizing memory and time requirements while maintaining competitive forecasting performance.",
    "authors": [
      "Aref Einizade",
      "Fragkiskos D. Malliaros",
      "Jhony H. Giraldo"
    ],
    "url": "http://arxiv.org/abs/2405.18879v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  }
}

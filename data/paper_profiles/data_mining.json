{
  "fd7b9e9e-ba2b-41eb-a7fb-f9c6b9d26faf": {
    "pk": "fd7b9e9e-ba2b-41eb-a7fb-f9c6b9d26faf",
    "title": "X-VILA: Cross-Modality Alignment for Large Language Model",
    "abstract": "We introduce X-VILA, an omni-modality model designed to extend the capabilities of large language models (LLMs) by incorporating image, video, and audio modalities. By aligning modality-specific encoders with LLM inputs and diffusion decoders with LLM outputs, X-VILA achieves cross-modality understanding, reasoning, and generation. To facilitate this cross-modality alignment, we curate an effective interleaved any-to-any modality instruction-following dataset. Furthermore, we identify a significant problem with the current cross-modality alignment method, which results in visual information loss. To address the issue, we propose a visual alignment mechanism with a visual embedding highway module. We then introduce a resource-efficient recipe for training X-VILA, that exhibits proficiency in any-to-any modality conversation, surpassing previous approaches by large margins. X-VILA also showcases emergent properties across modalities even in the absence of similar training data. The project will be made open-source.",
    "authors": [
      "Hanrong Ye",
      "De-An Huang",
      "Yao Lu",
      "Zhiding Yu",
      "Wei Ping",
      "Andrew Tao",
      "Jan Kautz",
      "Song Han",
      "Dan Xu",
      "Pavlo Molchanov",
      "Hongxu Yin"
    ],
    "url": "http://arxiv.org/abs/2405.19335v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "851dd24c-cfb8-49ea-a0b7-747b7e961e22": {
    "pk": "851dd24c-cfb8-49ea-a0b7-747b7e961e22",
    "title": "NPGA: Neural Parametric Gaussian Avatars",
    "abstract": "The creation of high-fidelity, digital versions of human heads is an important stepping stone in the process of further integrating virtual components into our everyday lives. Constructing such avatars is a challenging research problem, due to a high demand for photo-realism and real-time rendering performance. In this work, we propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings. We build our method around 3D Gaussian Splatting for its highly efficient rendering and to inherit the topological flexibility of point clouds. In contrast to previous work, we condition our avatars' dynamics on the rich expression space of neural parametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we distill the backward deformation field of our underlying NPHM into forward deformations which are compatible with rasterization-based rendering. All remaining fine-scale, expression-dependent details are learned from the multi-view videos. To increase the representational capacity of our avatars, we augment the canonical Gaussian point cloud using per-primitive latent features which govern its dynamic behavior. To regularize this increased dynamic expressivity, we propose Laplacian terms on the latent features and predicted dynamics. We evaluate our method on the public NeRSemble dataset, demonstrating that NPGA significantly outperforms the previous state-of-the-art avatars on the self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from real-world monocular videos.",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Martin R\u00fcnz",
      "Lourdes Agapito",
      "Matthias Nie\u00dfner"
    ],
    "url": "http://arxiv.org/abs/2405.19331v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d825c7b8-3fed-48a4-9a82-fd2137e272ec": {
    "pk": "d825c7b8-3fed-48a4-9a82-fd2137e272ec",
    "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series",
    "abstract": "Large Language Models (LLMs) have made great strides in recent years to achieve unprecedented performance across different tasks. However, due to commercial interest, the most competitive models like GPT, Gemini, and Claude have been gated behind proprietary interfaces without disclosing the training details. Recently, many institutions have open-sourced several strong LLMs like LLaMA-3, comparable to existing closed-source LLMs. However, only the model's weights are provided with most details (e.g., intermediate checkpoints, pre-training corpus, and training code, etc.) being undisclosed. To improve the transparency of LLMs, the research community has formed to open-source truly open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training corpus and training code) are being provided. These models have greatly advanced the scientific study of these large models including their strengths, weaknesses, biases and risks. However, we observe that the existing truly open LLMs on reasoning, knowledge, and coding tasks are still inferior to existing state-of-the-art LLMs with similar model sizes. To this end, we open-source MAP-Neo, a highly capable and transparent bilingual language model with 7B parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs. Moreover, we open-source all details to reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning pipeline, checkpoints, and well-optimized training/evaluation framework are provided. Finally, we hope our MAP-Neo will enhance and strengthen the open research community and inspire more innovations and creativities to facilitate the further improvements of LLMs.",
    "authors": [
      "Ge Zhang",
      "Scott Qu",
      "Jiaheng Liu",
      "Chenchen Zhang",
      "Chenghua Lin",
      "Chou Leuang Yu",
      "Danny Pan",
      "Esther Cheng",
      "Jie Liu",
      "Qunshu Lin",
      "Raven Yuan",
      "Tuney Zheng",
      "Wei Pang",
      "Xinrun Du",
      "Yiming Liang",
      "Yinghao Ma",
      "Yizhi Li",
      "Ziyang Ma",
      "Bill Lin",
      "Emmanouil Benetos",
      "Huan Yang",
      "Junting Zhou",
      "Kaijing Ma",
      "Minghao Liu",
      "Morry Niu",
      "Noah Wang",
      "Quehry Que",
      "Ruibo Liu",
      "Sine Liu",
      "Shawn Guo",
      "Soren Gao",
      "Wangchunshu Zhou",
      "Xinyue Zhang",
      "Yizhi Zhou",
      "Yubo Wang",
      "Yuelin Bai",
      "Yuhan Zhang",
      "Yuxiang Zhang",
      "Zenith Wang",
      "Zhenzhu Yang",
      "Zijian Zhao",
      "Jiajun Zhang",
      "Wanli Ouyang",
      "Wenhao Huang",
      "Wenhu Chen"
    ],
    "url": "http://arxiv.org/abs/2405.19327v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0fd7c462-77f1-4272-b96c-6d2947457f19": {
    "pk": "0fd7c462-77f1-4272-b96c-6d2947457f19",
    "title": "Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models",
    "abstract": "In this paper, we introduce a new task: Zero-Shot 3D Reasoning Segmentation for parts searching and localization for objects, which is a new paradigm to 3D segmentation that transcends limitations for previous category-specific 3D semantic segmentation, 3D instance segmentation, and open-vocabulary 3D segmentation. We design a simple baseline method, Reasoning3D, with the capability to understand and execute complex commands for (fine-grained) segmenting specific parts for 3D meshes with contextual awareness and reasoned answers for interactive segmentation. Specifically, Reasoning3D leverages an off-the-shelf pre-trained 2D segmentation network, powered by Large Language Models (LLMs), to interpret user input queries in a zero-shot manner. Previous research have shown that extensive pre-training endows foundation models with prior world knowledge, enabling them to comprehend complex commands, a capability we can harness to \"segment anything\" in 3D with limited 3D datasets (source efficient). Experimentation reveals that our approach is generalizable and can effectively localize and highlight parts of 3D objects (in 3D mesh) based on implicit textual queries, including these articulated 3d objects and real-world scanned data. Our method can also generate natural language explanations corresponding to these 3D models and the decomposition. Moreover, our training-free approach allows rapid deployment and serves as a viable universal baseline for future research of part-level 3d (semantic) object understanding in various fields including robotics, object manipulation, part assembly, autonomous driving applications, augment reality and virtual reality (AR/VR), and medical applications. The code, the model weight, the deployment guide, and the evaluation protocol are: http://tianrun-chen.github.io/Reason3D/",
    "authors": [
      "Tianrun Chen",
      "Chunan Yu",
      "Jing Li",
      "Jianqi Zhang",
      "Lanyun Zhu",
      "Deyi Ji",
      "Yong Zhang",
      "Ying Zang",
      "Zejian Li",
      "Lingyun Sun"
    ],
    "url": "http://arxiv.org/abs/2405.19326v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e7d87a7b-9282-4e9b-9c0f-f8e2f9c4bc98": {
    "pk": "e7d87a7b-9282-4e9b-9c0f-f8e2f9c4bc98",
    "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution",
    "abstract": "Large language models (LLMs) often hallucinate and lack the ability to provide attribution for their generations. Semi-parametric LMs, such as kNN-LM, approach these limitations by refining the output of an LM for a given prompt using its nearest neighbor matches in a non-parametric data store. However, these models often exhibit slow inference speeds and produce non-fluent texts. In this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a novel semi-parametric language modeling approach that is capable of incorporating real-world text spans of arbitrary length into the LM generations and providing attribution to their sources. NEST performs token-level retrieval at each inference step to compute a semi-parametric mixture distribution and identify promising span continuations in a corpus. It then uses an approximate speculative decoding procedure that accepts a prefix of the retrieved span or generates a new token. NEST significantly enhances the generation quality and attribution rate of the base LM across a variety of knowledge-intensive tasks, surpassing the conventional kNN-LM method and performing competitively with in-context retrieval augmentation. In addition, NEST substantially improves the generation speed, achieving a 1.8x speedup in inference time when applied to Llama-2-Chat 70B.",
    "authors": [
      "Minghan Li",
      "Xilun Chen",
      "Ari Holtzman",
      "Beidi Chen",
      "Jimmy Lin",
      "Wen-tau Yih",
      "Xi Victoria Lin"
    ],
    "url": "http://arxiv.org/abs/2405.19325v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fc3e0877-2b8f-40ae-83ca-1cee1ddab675": {
    "pk": "fc3e0877-2b8f-40ae-83ca-1cee1ddab675",
    "title": "Are Large Language Models Chameleons?",
    "abstract": "Do large language models (LLMs) have their own worldviews and personality tendencies? Simulations in which an LLM was asked to answer subjective questions were conducted more than 1 million times. Comparison of the responses from different LLMs with real data from the European Social Survey (ESS) suggests that the effect of prompts on bias and variability is fundamental, highlighting major cultural, age, and gender biases. Methods for measuring the difference between LLMs and survey data are discussed, such as calculating weighted means and a new proposed measure inspired by Jaccard similarity. We conclude that it is important to analyze the robustness and variability of prompts before using LLMs to model individual decisions or collective behavior, as their imitation abilities are approximate at best.",
    "authors": [
      "Mingmeng Geng",
      "Sihong He",
      "Roberto Trotta"
    ],
    "url": "http://arxiv.org/abs/2405.19323v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b5f9a7e7-352e-40e9-9d6f-ecc180a02ae5": {
    "pk": "b5f9a7e7-352e-40e9-9d6f-ecc180a02ae5",
    "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF",
    "abstract": "Reinforcement learning from human feedback (RLHF) has demonstrated great promise in aligning large language models (LLMs) with human preference. Depending on the availability of preference data, both online and offline RLHF are active areas of investigation. A key bottleneck is understanding how to incorporate uncertainty estimation in the reward function learned from the preference data for RLHF, regardless of how the preference data is collected. While the principles of optimism or pessimism under uncertainty are well-established in standard reinforcement learning (RL), a practically-implementable and theoretically-grounded form amenable to large language models is not yet available, as standard techniques for constructing confidence intervals become intractable under arbitrary policy parameterizations.   In this paper, we introduce a unified approach to online and offline RLHF -- value-incentivized preference optimization (VPO) -- which regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, modulated by a $\\textit{sign}$ to indicate whether the optimism or pessimism is chosen. VPO also directly optimizes the policy with implicit reward modeling, and therefore shares a simpler RLHF pipeline similar to direct preference optimization. Theoretical guarantees of VPO are provided for both online and offline settings, matching the rates of their standard RL counterparts. Moreover, experiments on text summarization and dialog verify the practicality and effectiveness of VPO.",
    "authors": [
      "Shicong Cen",
      "Jincheng Mei",
      "Katayoon Goshvadi",
      "Hanjun Dai",
      "Tong Yang",
      "Sherry Yang",
      "Dale Schuurmans",
      "Yuejie Chi",
      "Bo Dai"
    ],
    "url": "http://arxiv.org/abs/2405.19320v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0f3b0b79-575a-446c-8503-7bfcb7c34439": {
    "pk": "0f3b0b79-575a-446c-8503-7bfcb7c34439",
    "title": "Robust Preference Optimization through Reward Model Distillation",
    "abstract": "Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning. However, typical preference datasets have only a single, or at most a few, annotation per preference pair, which causes DPO to overconfidently assign rewards that trend towards infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero. In this work, we analyze this phenomenon and propose distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM to produce probabilities that match the distribution induced by a reward model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution. Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO.",
    "authors": [
      "Adam Fisch",
      "Jacob Eisenstein",
      "Vicky Zayats",
      "Alekh Agarwal",
      "Ahmad Beirami",
      "Chirag Nagpal",
      "Pete Shaw",
      "Jonathan Berant"
    ],
    "url": "http://arxiv.org/abs/2405.19316v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b2e9819c-be05-433c-8988-ebeeb64820fd": {
    "pk": "b2e9819c-be05-433c-8988-ebeeb64820fd",
    "title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice",
    "abstract": "The observed similarities in the behavior of humans and Large Language Models (LLMs) have prompted researchers to consider the potential of using LLMs as models of human cognition. However, several significant challenges must be addressed before LLMs can be legitimately regarded as cognitive models. For instance, LLMs are trained on far more data than humans typically encounter, and may have been directly trained on human data in specific cognitive tasks or aligned with human preferences. Consequently, the origins of these behavioral similarities are not well understood. In this paper, we propose a novel way to enhance the utility of LLMs as cognitive models. This approach involves (i) leveraging computationally equivalent tasks that both an LLM and a rational agent need to master for solving a cognitive problem and (ii) examining the specific task distributions required for an LLM to exhibit human-like behaviors. We apply this approach to decision-making -- specifically risky and intertemporal choice -- where the key computationally equivalent task is the arithmetic of expected value calculations. We show that an LLM pretrained on an ecologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts human behavior better than many traditional cognitive models. Pretraining LLMs on ecologically valid arithmetic datasets is sufficient to produce a strong correspondence between these models and human decision-making. Our results also suggest that LLMs used as cognitive models should be carefully investigated via ablation studies of the pretraining data.",
    "authors": [
      "Jian-Qiao Zhu",
      "Haijiang Yan",
      "Thomas L. Griffiths"
    ],
    "url": "http://arxiv.org/abs/2405.19313v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "298f3c32-82c4-4df2-87ed-c59dfa8f04f6": {
    "pk": "298f3c32-82c4-4df2-87ed-c59dfa8f04f6",
    "title": "Causal Inference for Balanced Incomplete Block Designs",
    "abstract": "Researchers often turn to block randomization to increase the precision of their inference or due to practical considerations, such as in multi-site trials. However, if the number of treatments under consideration is large it might not be practical or even feasible to assign all treatments within each block. We develop novel inference results under the finite-population design-based framework for a natural alternative to the complete block design that does not require reducing the number of treatment arms, the balanced incomplete block design (BIBD). This includes deriving the properties of two estimators for BIBDs and proposing conservative variance estimators. To assist practitioners in understanding the trade-offs of using BIBDs over other designs, the precisions of resulting estimators are compared to standard estimators for the complete block design, the cluster-randomized design, and the completely randomized design. Simulations and a data illustration demonstrate the strengths and weaknesses of using BIBDs. This work highlights BIBDs as practical and currently underutilized designs.",
    "authors": [
      "Taehyeon Koo",
      "Nicole E. Pashley"
    ],
    "url": "http://arxiv.org/abs/2405.19312v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ME",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9c4feb72-5c01-49f1-b3a0-a9dfc895c9f6": {
    "pk": "9c4feb72-5c01-49f1-b3a0-a9dfc895c9f6",
    "title": "Visualizing the microscopic origins of topology in twisted molybdenum ditelluride",
    "abstract": "In moir\\'e materials with flat electronic bands and suitable quantum geometry, strong correlations can give rise to novel topological states of matter. The nontrivial band topology of twisted molybdenum ditelluride (tMoTe$_2$) -- responsible for its fractional quantum anomalous Hall (FQAH) states -- is predicted to arise from a layer-pseudospin skyrmion lattice. Tracing the layer polarization of wavefunctions within the moir\\'e unit cell can thus offer crucial insights into the band topology. Here, we use scanning tunneling microscopy and spectroscopy (STM/S) to probe the layer-pseudospin skyrmion textures of tMoTe$_2$. We do this by simultaneously visualizing the moir\\'e lattice structure and the spatial localization of its electronic states. We find that the wavefunctions associated with the topological flat bands exhibit a spatially-dependent layer polarization within the moir\\'e unit cell. This is in excellent agreement with our theoretical modeling, thereby revealing a direct microscopic connection between the structural properties of tMoTe$_2$ and its band topology. Our work enables new pathways for engineering FQAH states with strain, as well as future STM studies of the intertwined correlated and topological states arising in gate-tunable devices.",
    "authors": [
      "Ellis Thompson",
      "Keng Tou Chu",
      "Florie Mesple",
      "Xiao-Wei Zhang",
      "Chaowei Hu",
      "Yuzhou Zhao",
      "Heonjoon Park",
      "Jiaqi Cai",
      "Eric Anderson",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Jihui Yang",
      "Jiun-Haw Chu",
      "Xiaodong Xu",
      "Ting Cao",
      "Di Xiao",
      "Matthew Yankowitz"
    ],
    "url": "http://arxiv.org/abs/2405.19308v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mes-hall",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bfd536a9-da68-4ad1-824b-c593f21b8f45": {
    "pk": "bfd536a9-da68-4ad1-824b-c593f21b8f45",
    "title": "Data Efficient Behavior Cloning for Fine Manipulation via Continuity-based Corrective Labels",
    "abstract": "We consider imitation learning with access only to expert demonstrations, whose real-world application is often limited by covariate shift due to compounding errors during execution. We investigate the effectiveness of the Continuity-based Corrective Labels for Imitation Learning (CCIL) framework in mitigating this issue for real-world fine manipulation tasks. CCIL generates corrective labels by learning a locally continuous dynamics model from demonstrations to guide the agent back toward expert states. Through extensive experiments on peg insertion and fine grasping, we provide the first empirical validation that CCIL can significantly improve imitation learning performance despite discontinuities present in contact-rich manipulation. We find that: (1) real-world manipulation exhibits sufficient local smoothness to apply CCIL, (2) generated corrective labels are most beneficial in low-data regimes, and (3) label filtering based on estimated dynamics model error enables performance gains. To effectively apply CCIL to robotic domains, we offer a practical instantiation of the framework and insights into design choices and hyperparameter selection. Our work demonstrates CCIL's practicality for alleviating compounding errors in imitation learning on physical robots.",
    "authors": [
      "Abhay Deshpande",
      "Liyiming Ke",
      "Quinn Pfeifer",
      "Abhishek Gupta",
      "Siddhartha S. Srinivasa"
    ],
    "url": "http://arxiv.org/abs/2405.19307v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "511c1ef9-ee0e-4d8e-b9a6-864fe246c79c": {
    "pk": "511c1ef9-ee0e-4d8e-b9a6-864fe246c79c",
    "title": "Uniform-in-time estimates on the size of chaos for interacting Brownian particles",
    "abstract": "We consider a system of classical Brownian particles interacting via a smooth long-range potential in the mean-field regime, and we analyze the propagation of chaos in form of sharp, uniform-in-time estimates on many-particle correlation functions. Our results cover both the kinetic Langevin setting and the corresponding overdamped Brownian dynamics. The approach is mainly based on so-called Lions expansions, which we combine with new diagrammatic tools to capture many-particle cancellations, as well as with fine ergodic estimates on the linearized mean-field equation, and with discrete stochastic calculus with respect to initial data. In the process, we derive some new ergodic estimates for the linearized Vlasov-Fokker-Planck kinetic equation that are of independent interest. Our analysis also leads to uniform-in-time concentration estimates and to a uniform-in-time quantitative central limit theorem for the empirical measure associated with the particle dynamics.",
    "authors": [
      "Armand Bernou",
      "Mitia Duerinckx"
    ],
    "url": "http://arxiv.org/abs/2405.19306v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.AP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ac8008c5-158a-4dde-aaa3-45a5ba870920": {
    "pk": "ac8008c5-158a-4dde-aaa3-45a5ba870920",
    "title": "Morse Theory for Chromatic Delaunay Triangulations",
    "abstract": "The chromatic alpha filtration is a generalization of the alpha filtration that can encode spatial relationships among classes of labelled point cloud data, and has applications in topological data analysis of multi-species data. In this paper we introduce the chromatic Delaunay--\\v{C}ech and chromatic Delaunay--Rips filtrations, which are computationally favourable alternatives to the chromatic alpha filtration. We use generalized discrete Morse theory to show that the \\v{C}ech, chromatic Delaunay--\\v{C}ech, and chromatic alpha filtrations are related by simplicial collapses. Our result generalizes a result of Bauer and Edelsbrunner from the non-chromatic to the chromatic setting. We also show that the chromatic Delaunay--Rips filtration is locally stable to perturbations of the underlying point cloud. Our results provide theoretical justification for the use of chromatic Delaunay--\\v{C}ech and chromatic Delaunay--Rips filtrations in applications, and we demonstrate their computational advantage with numerical experiments.",
    "authors": [
      "Abhinav Natarajan",
      "Thomas Chaplin",
      "Adam Brown",
      "Maria-Jose Jimenez"
    ],
    "url": "http://arxiv.org/abs/2405.19303v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.AT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "cfb0174b-2b91-4f3f-93f4-c99970769cb7": {
    "pk": "cfb0174b-2b91-4f3f-93f4-c99970769cb7",
    "title": "Multi-qubit circuit synthesis and Hermitian lattices",
    "abstract": "We present new optimal and heuristic algorithms for exact synthesis of multi-qubit unitaries and isometries. For example, our algorithms find Clifford and T circuits for unitaries with entries in $\\mathbb{Z}[i,1/\\sqrt{2}]$. The optimal algorithms are the A* search instantiated with a new data structure for graph vertices and new consistent heuristic functions. We also prove that for some gate sets, best-first search synthesis relying on the same heuristic is efficient. For example, for two-qubit Clifford and T circuits, our best-first search runtime is proportional to the T-count of the unitary. Our algorithms rely on Hermite and Smith Normal Forms of matrices with entries in a ring of integers of a number field, and we leverage the theory of and algorithms for Hermitian lattices over number fields to prove efficiency. These new techniques are of independent interest for future work on multi-qubit exact circuit synthesis and related questions.",
    "authors": [
      "Vadym Kliuchnikov",
      "Sebastian Sch\u00f6nnenbeck"
    ],
    "url": "http://arxiv.org/abs/2405.19302v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "77eb7d13-9386-46ed-af68-f20c9522d5cd": {
    "pk": "77eb7d13-9386-46ed-af68-f20c9522d5cd",
    "title": "Safe and Efficient Estimation for Robotics through the Optimal Use of Resources",
    "abstract": "In order to operate in and interact with the physical world, robots need to have estimates of the current and future state of the environment. We thus equip robots with sensors and build models and algorithms that, given some measurements, produce estimates of the current or future states. Environments can be unpredictable and sensors are not perfect. Therefore, it is important to both use all information available, and to do so optimally: making sure that we get the best possible answer from the amount of information we have. However, in prevalent research, uncommon sensors, such as sound or radio-frequency signals, are commonly ignored for state estimation; and the most popular solvers employed to produce state estimates are only of local nature, meaning they may produce suboptimal estimates for the typically non-convex estimation problems. My research aims to use resources more optimally, by building on 1) multi-modality: using ubiquitous RF transceivers and microphones to support state estimation, 2) building certifiably optimal solvers and 3) learning and improving adequate models from data.",
    "authors": [
      "Frederike D\u00fcmbgen"
    ],
    "url": "http://arxiv.org/abs/2405.19301v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "96c6afc5-5219-4a0e-a6a2-06ad2ee97db0": {
    "pk": "96c6afc5-5219-4a0e-a6a2-06ad2ee97db0",
    "title": "Expert-Guided Extinction of Toxic Tokens for Debiased Generation",
    "abstract": "Large language models (LLMs) can elicit social bias during generations, especially when inference with toxic prompts. Controlling the sensitive attributes in generation encounters challenges in data distribution, generalizability, and efficiency. Specifically, fine-tuning and retrieval demand extensive unbiased corpus, while direct prompting requires meticulously curated instructions for correcting the output in multiple rounds of thoughts but poses challenges on memory and inference latency. In this work, we propose the Expert-Guided Extinction of Toxic Tokens for Debiased Generation (EXPOSED) to eliminate the undesired harmful outputs for LLMs without the aforementioned requirements. EXPOSED constructs a debiasing expert based on the abundant toxic corpus to expose and elicit the potentially dangerous tokens. It then processes the output to the LLMs and constructs a fair distribution by suppressing and attenuating the toxic tokens. EXPOSED is evaluated on fairness benchmarks over three LLM families. Extensive experiments demonstrate that compared with other baselines, the proposed EXPOSED significantly reduces the potential social bias while balancing fairness and generation performance.",
    "authors": [
      "Xueyao Sun",
      "Kaize Shi",
      "Haoran Tang",
      "Guandong Xu",
      "Qing Li"
    ],
    "url": "http://arxiv.org/abs/2405.19299v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "58349e9d-6320-46e5-b8cd-35062e16bb57": {
    "pk": "58349e9d-6320-46e5-b8cd-35062e16bb57",
    "title": "Genuine Retrieval of the AGN Host Stellar Population (GRAHSP)",
    "abstract": "The assembly and co-evolution of supermassive black holes (SMBH) and their host galaxy stellar population is a key open questions in galaxy evolution. Stellar mass ($M_\\star$) and star formation rate (SFR), are inferred by modeling the spectral energy distribution (SED). For galaxies triggering SMBH activity, the active galactic nucleus (AGN) contaminates the light at all wavelengths, hampering the inference of galaxy parameters. Incomplete AGN templates can lead to systematic overestimates of the stellar mass, biasing our understanding of AGN-galaxy co-evolution. This challenge has gained further impetus with the advent of sensitive wide-area surveys with millions of luminous AGN, including by eROSITA, Euclid and LSST. We aim to estimate the accuracy and bias of AGN host galaxy parameters and improve upon existing techniques. This work makes two contributions: 1) a new SED fitting code, GRAHSP, with a flexible, empirically motivated AGN model including a power law continuum emission lines, a FeII forest and a flexible infrared torus. We verify that our model reproduces published X-ray to infrared SEDs of AGN to better than 20\\% accuracy. A fully Bayesian fit with nested sampling includes uncertainties in the model and the data, making the inference highly robust. 2) we created a benchmark photometric dataset where pure quasars are merged with non-AGN pure galaxies into a hybrid (Chimera) object but with known galaxy and AGN properties. Comparing the true and retrieved $M_\\star$, SFR and AGN luminosities shows that previous codes systematically over-estimate $M_\\star$ and SFR by 0.5 dex with a wide scatter of 0.7 dex, at AGN luminosities above 10^44 erg/s. In contrast, GRAHSP shows no bias on $M_\\star$ and SFR. GRAHSP also estimates more realistic uncertainties. GRAHSP enables characterization of the environmental conditions conducive to black hole growth. (abridged)",
    "authors": [
      "Johannes Buchner",
      "Hattie Starck",
      "Mara Salvato",
      "Hagai Netzer",
      "Zsofi Igo",
      "Brivael Laloux",
      "Antonis Georgakakis",
      "Isabelle Gauger",
      "Anna Olechowska",
      "Nicolas Lopez",
      "Suraj D Shankar",
      "Junyao Li",
      "Kirpal Nandra",
      "Andrea Merloni"
    ],
    "url": "http://arxiv.org/abs/2405.19297v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.GA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3a814c62-3568-49db-8cc5-f38766a07cd4": {
    "pk": "3a814c62-3568-49db-8cc5-f38766a07cd4",
    "title": "Act Natural! Projecting Autonomous System Trajectories Into Naturalistic Behavior Sets",
    "abstract": "Autonomous agents operating around human actors must consider how their behaviors might affect those humans, even when not directly interacting with them. To this end, it is often beneficial to be predictable and appear naturalistic. Existing methods to address this problem use human actor intent modeling or imitation learning techniques, but these approaches rarely capture all possible motivations for human behavior or require significant amounts of data. In contrast, we propose a technique for modeling naturalistic behavior as a set of convex hulls computed over a relatively small dataset of human behavior. Given this set, we design an optimization-based filter which projects arbitrary trajectories into it to make them more naturalistic for autonomous agents to execute while also satisfying dynamics constraints. We demonstrate our methods on real-world human driving data from the inD intersection dataset (Bock et al., 2020).",
    "authors": [
      "Hamzah I. Khan",
      "Adam J. Thorpe",
      "David Fridovich-Keil"
    ],
    "url": "http://arxiv.org/abs/2405.19292v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.MA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f76b6816-c657-48ec-91a4-73a5db9f68f2": {
    "pk": "f76b6816-c657-48ec-91a4-73a5db9f68f2",
    "title": "Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation",
    "abstract": "Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual translation, the imbalance in data volumes across different languages spreads to the vocabulary, exacerbating translations involving low-resource languages. While byte-based tokenization addresses these issues, byte-based models struggle with the low information density inherent in UTF-8 byte sequences. Previous works enhance token semantics through local contextualization but fail to select an appropriate contextualizing scope based on the input. Consequently, we propose the Multi-Scale Contextualization (MSC) method, which learns contextualized information of varying scales across different hidden state dimensions. It then leverages the attention module to dynamically integrate the multi-scale contextualized information. Experiments show that MSC significantly outperforms subword-based and other byte-based methods in both multilingual and out-of-domain scenarios. Code can be found in https://github.com/ictnlp/Multiscale-Contextualization.",
    "authors": [
      "Langlin Huang",
      "Yang Feng"
    ],
    "url": "http://arxiv.org/abs/2405.19290v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "52923609-f6c1-4414-88a9-c0ea350957e9": {
    "pk": "52923609-f6c1-4414-88a9-c0ea350957e9",
    "title": "Archetype-Based Redshift Estimation for the Dark Energy Spectroscopic Instrument Survey",
    "abstract": "We present a computationally efficient galaxy archetype-based redshift estimation and spectral classification method for the Dark Energy Survey Instrument (DESI) survey. The DESI survey currently relies on a redshift fitter and spectral classifier using a linear combination of PCA-derived templates, which is very efficient in processing large volumes of DESI spectra within a short time frame. However, this method occasionally yields unphysical model fits for galaxies and fails to adequately absorb calibration errors that may still be occasionally visible in the reduced spectra. Our proposed approach improves upon this existing method by refitting the spectra with carefully generated physical galaxy archetypes combined with additional terms designed to absorb data reduction defects and provide more physical models to the DESI spectra. We test our method on an extensive dataset derived from the survey validation (SV) and Year 1 (Y1) data of DESI. Our findings indicate that the new method delivers marginally better redshift success for SV tiles while reducing catastrophic redshift failure by $10-30\\%$. At the same time, results from millions of targets from the main survey show that our model has relatively higher redshift success and purity rates ($0.5-0.8\\%$ higher) for galaxy targets while having similar success for QSOs. These improvements also demonstrate that the main DESI redshift pipeline is generally robust. Additionally, it reduces the false positive redshift estimation by $5-40\\%$ for sky fibers. We also discuss the generic nature of our method and how it can be extended to other large spectroscopic surveys, along with possible future improvements.",
    "authors": [
      "Abhijeet Anand",
      "Julien Guy",
      "Stephen Bailey",
      "John Moustakas",
      "J. Aguilar",
      "S. Ahlen",
      "A. Bolton",
      "A. Brodzeller",
      "D. Brooks",
      "T. Claybaugh",
      "S. Cole",
      "B. Dey",
      "K. Fanning",
      "J. Forero-Romero",
      "E. Gazta\u00f1aga",
      "S. Gontcho A Gontcho",
      "L. Le Guillou",
      "G. Gutierrez",
      "K. Honscheid",
      "C. Howlett",
      "S. Juneau",
      "D. Kirkby",
      "T. Kisner",
      "A. Kremin",
      "A. Lambert",
      "M. Landriau",
      "A. de la Macorra",
      "M. Manera",
      "A. Meisner",
      "R. Miquel",
      "E. Mueller",
      "G. Niz",
      "N. Palanque-Delabrouille",
      "W. Percival",
      "C. Poppett",
      "F. Prada",
      "A. Raichoor",
      "M. Rezaie",
      "G. Rossi",
      "E. Sanchez",
      "E. Schlafly",
      "D. Schlegel",
      "M. Schubnell",
      "D. Sprayberry",
      "G. Tarl\u00e9",
      "C. Warner",
      "B. A. Weaver",
      "R. Zhou",
      "H. Zou"
    ],
    "url": "http://arxiv.org/abs/2405.19288v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8ff7c854-e35b-4e70-96d5-1bc54c51387d": {
    "pk": "8ff7c854-e35b-4e70-96d5-1bc54c51387d",
    "title": "Efficiently manipulating Pauli strings with PauliArray",
    "abstract": "Pauli matrices and Pauli strings are widely used in quantum computing. These mathematical objects are useful to describe or manipulate the quantum state of qubits. They offer a convenient basis to express operators and observables used in different problem instances such as molecular simulation and combinatorial optimization. Therefore, it is important to have a well-rounded, versatile and efficient tool to handle a large number of Pauli strings and operators expressed in this basis. This is the objective behind the development of the PauliArray library presented in this work. This library introduces data structures to represent arrays of Pauli strings and operators as well as various methods to modify and combine them. Built using NumPy, PauliArray offers fast operations and the ability to use broadcasting to easily carry out otherwise cumbersome manipulations. Applications to the fermion-to-qubit mapping, to the estimation of expectation values and to the computation of commutators are considered to illustrate how PauliArray can simplify some relevant tasks and accomplish them faster than current libraries.",
    "authors": [
      "Maxime Dion",
      "Tania Belabbas",
      "Nolan Bastien"
    ],
    "url": "http://arxiv.org/abs/2405.19287v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f1d46886-a02c-4358-b179-3fbd373736ef": {
    "pk": "f1d46886-a02c-4358-b179-3fbd373736ef",
    "title": "Programmable Motion Generation for Open-Set Motion Control Tasks",
    "abstract": "Character animation in real-world scenarios necessitates a variety of constraints, such as trajectories, key-frames, interactions, etc. Existing methodologies typically treat single or a finite set of these constraint(s) as separate control tasks. They are often specialized, and the tasks they address are rarely extendable or customizable. We categorize these as solutions to the close-set motion control problem. In response to the complexity of practical motion control, we propose and attempt to solve the open-set motion control problem. This problem is characterized by an open and fully customizable set of motion control tasks. To address this, we introduce a new paradigm, programmable motion generation. In this paradigm, any given motion control task is broken down into a combination of atomic constraints. These constraints are then programmed into an error function that quantifies the degree to which a motion sequence adheres to them. We utilize a pre-trained motion generation model and optimize its latent code to minimize the error function of the generated motion. Consequently, the generated motion not only inherits the prior of the generative model but also satisfies the required constraints. Experiments show that we can generate high-quality motions when addressing a wide range of unseen tasks. These tasks encompass motion control by motion dynamics, geometric constraints, physical laws, interactions with scenes, objects or the character own body parts, etc. All of these are achieved in a unified approach, without the need for ad-hoc paired training data collection or specialized network designs. During the programming of novel tasks, we observed the emergence of new skills beyond those of the prior model. With the assistance of large language models, we also achieved automatic programming. We hope that this work will pave the way for the motion control of general AI agents.",
    "authors": [
      "Hanchao Liu",
      "Xiaohang Zhan",
      "Shaoli Huang",
      "Tai-Jiang Mu",
      "Ying Shan"
    ],
    "url": "http://arxiv.org/abs/2405.19283v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a54c7496-c6f0-48fa-b20a-6355cf208061": {
    "pk": "a54c7496-c6f0-48fa-b20a-6355cf208061",
    "title": "Causal Data Fusion with Quantum Confounders",
    "abstract": "From the modern perspective of causal inference, Bell's theorem -- a fundamental signature of quantum theory -- is a particular case where quantum correlations are incompatible with the classical theory of causality, and the generalization of Bell's theorem to quantum networks has led to several breakthrough results and novel applications. Here, we consider the problem of causal data fusion, where we piece together multiple datasets collected under heterogeneous conditions. In particular, we show quantum experiments can generate observational and interventional data with a non-classical signature when pieced together that cannot be reproduced classically. We prove this quantum non-classicality emerges from the fusion of the datasets and is present in a plethora of scenarios, even where standard Bell non-classicality is impossible. Furthermore, we show that non-classicality genuine to the fusion of multiple data tables is achievable with quantum resources. Our work shows incorporating interventions -- a central tool in causal inference -- can be a powerful tool to detect non-classicality beyond the violation of a standard Bell inequality. In a companion article \"Quantum Non-classicality from Causal Data Fusion\", we extend our investigation considering all latent exogenous causal structures with 3 observable variables.",
    "authors": [
      "Pedro Lauand",
      "Bereket Ngussie Bekele",
      "Elie Wolfe"
    ],
    "url": "http://arxiv.org/abs/2405.19278v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9f064d73-a32a-4a57-bfb1-5b832438ebd5": {
    "pk": "9f064d73-a32a-4a57-bfb1-5b832438ebd5",
    "title": "Deep Latent Variable Modeling of Physiological Signals",
    "abstract": "A deep latent variable model is a powerful method for capturing complex distributions. These models assume that underlying structures, but unobserved, are present within the data. In this dissertation, we explore high-dimensional problems related to physiological monitoring using latent variable models. First, we present a novel deep state-space model to generate electrical waveforms of the heart using optically obtained signals as inputs. This can bring about clinical diagnoses of heart disease via simple assessment through wearable devices. Second, we present a brain signal modeling scheme that combines the strengths of probabilistic graphical models and deep adversarial learning. The structured representations can provide interpretability and encode inductive biases to reduce the data complexity of neural oscillations. The efficacy of the learned representations is further studied in epilepsy seizure detection formulated as an unsupervised learning problem. Third, we propose a framework for the joint modeling of physiological measures and behavior. Existing methods to combine multiple sources of brain data provided are limited. Direct analysis of the relationship between different types of physiological measures usually does not involve behavioral data. Our method can identify the unique and shared contributions of brain regions to behavior and can be used to discover new functions of brain regions. The success of these innovative computational methods would allow the translation of biomarker findings across species and provide insight into neurocognitive analysis in numerous biological studies and clinical diagnoses, as well as emerging consumer applications.",
    "authors": [
      "Khuong Vo"
    ],
    "url": "http://arxiv.org/abs/2405.19277v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7f1ac308-c6ea-476d-9b69-e4878db82b51": {
    "pk": "7f1ac308-c6ea-476d-9b69-e4878db82b51",
    "title": "Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering",
    "abstract": "Federated Learning (FL) is a decentralized machine learning (ML) approach that keeps data localized and often incorporates Differential Privacy (DP) to enhance privacy guarantees. Similar to previous work on DP in ML, we observed that differentially private federated learning (DPFL) introduces performance disparities, particularly affecting minority groups. Recent work has attempted to address performance fairness in vanilla FL through clustering, but this method remains sensitive and prone to errors, which are further exacerbated by the DP noise in DPFL. To fill this gap, in this paper, we propose a novel clustered DPFL algorithm designed to effectively identify clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees. To this end, we propose to cluster clients based on both their model updates and training loss values. Our proposed approach also addresses the server's uncertainties in clustering clients' model updates by employing larger batch sizes along with Gaussian Mixture Model (GMM) to alleviate the impact of noise and potential clustering errors, especially in privacy-sensitive scenarios. We provide theoretical analysis of the effectiveness of our proposed approach. We also extensively evaluate our approach across diverse data distributions and privacy budgets and show its effectiveness in mitigating the disparate impact of DP in FL settings with a small computational cost.",
    "authors": [
      "Saber Malekmohammadi",
      "Afaf Taik",
      "Golnoosh Farnadi"
    ],
    "url": "http://arxiv.org/abs/2405.19272v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bde3a5a7-9bba-4aa8-b1cc-4f37db0a7ef2": {
    "pk": "bde3a5a7-9bba-4aa8-b1cc-4f37db0a7ef2",
    "title": "PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications",
    "abstract": "Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce. Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures. To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline. In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation. Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models. After that, we devise a direct following preference optimization to enhance the generation of pediatrician-like humanistic responses. In the parameter-efficient secondary SFT phase, a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery. Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct doctor downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs. Our model and dataset will be open-source for community development.",
    "authors": [
      "Dingkang Yang",
      "Jinjie Wei",
      "Dongling Xiao",
      "Shunli Wang",
      "Tong Wu",
      "Gang Li",
      "Mingcheng Li",
      "Shuaibing Wang",
      "Jiawei Chen",
      "Yue Jiang",
      "Qingyao Xu",
      "Ke Li",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19266v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5d0ba631-8976-4043-86a3-3d70df0ca4e0": {
    "pk": "5d0ba631-8976-4043-86a3-3d70df0ca4e0",
    "title": "AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data",
    "abstract": "Open-source Large Language Models (LLMs) and their specialized variants, particularly Code LLMs, have recently delivered impressive performance. However, previous Code LLMs are typically fine-tuned on single-source data with limited quality and diversity, which may insufficiently elicit the potential of pre-trained Code LLMs. In this paper, we present AlchemistCoder, a series of Code LLMs with enhanced code generation and generalization capabilities fine-tuned on multi-source data. To achieve this, we pioneer to unveil inherent conflicts among the various styles and qualities in multi-source code corpora and introduce data-specific prompts with hindsight relabeling, termed AlchemistPrompts, to harmonize different data sources and instruction-response pairs. Additionally, we propose incorporating the data construction process into the fine-tuning data as code comprehension tasks, including instruction evolution, data filtering, and code review. Extensive experiments demonstrate that AlchemistCoder holds a clear lead among all models of the same size (6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B), showcasing the efficacy of our method in refining instruction-following capabilities and advancing the boundaries of code intelligence.",
    "authors": [
      "Zifan Song",
      "Yudong Wang",
      "Wenwei Zhang",
      "Kuikun Liu",
      "Chengqi Lyu",
      "Demin Song",
      "Qipeng Guo",
      "Hang Yan",
      "Dahua Lin",
      "Kai Chen",
      "Cairong Zhao"
    ],
    "url": "http://arxiv.org/abs/2405.19265v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "85ea0687-87f6-47ac-8ac8-2048452f7e35": {
    "pk": "85ea0687-87f6-47ac-8ac8-2048452f7e35",
    "title": "Measurement of the presence of $\\mathrm{a}_1(1420)$ and $\u03c9(782)$ in $\u03c4^-\\to\u03c0^-\u03c0^-\u03c0^+\u03bd_\u03c4$ at Belle",
    "abstract": "We present preliminary results of a partial-wave analysis of $\\tau^-\\to\\pi^-\\pi^-\\pi^+\\nu_\\tau$ using data from the Belle experiment at the KEKB $\\mathrm{e}^+\\mathrm{e}^-$ collider. We validate our analysis with a model-independent one. We see an $\\mathrm{a}_1(1420)$ resonance and a G-parity violating $1^-[\\omega(782)\\pi]_\\mathrm{P}]$ wave in tauon decays. Our results will improve models used in simulation studies necessary for measuring the tauon electric and magnetic dipole moments and Michel parameters.",
    "authors": [
      "Andrei Rabusov",
      "Daniel Greenwald",
      "Stephan Paul"
    ],
    "url": "http://arxiv.org/abs/2405.19264v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ex",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5581677d-f870-4f3a-bd8d-1faf7e5756bb": {
    "pk": "5581677d-f870-4f3a-bd8d-1faf7e5756bb",
    "title": "A Privacy-Preserving Graph Encryption Scheme Based on Oblivious RAM",
    "abstract": "Graph encryption schemes play a crucial role in facilitating secure queries on encrypted graphs hosted on untrusted servers. With applications spanning navigation systems, network topology, and social networks, the need to safeguard sensitive data becomes paramount. Existing graph encryption methods, however, exhibit vulnerabilities by inadvertently revealing aspects of the graph structure and query patterns, posing threats to security and privacy. In response, we propose a novel graph encryption scheme designed to mitigate access pattern and query pattern leakage through the integration of oblivious RAM and trusted execution environment techniques, exemplified by a Trusted Execution Environment (TEE). Our solution establishes two key security objectives: (1) ensuring that adversaries, when presented with an encrypted graph, remain oblivious to any information regarding the underlying graph, and (2) achieving query indistinguishability by concealing access patterns. Additionally, we conducted experimentation to evaluate the efficiency of the proposed schemes when dealing with real-world location navigation services.",
    "authors": [
      "Seyni Kane",
      "Anis Bkakria"
    ],
    "url": "http://arxiv.org/abs/2405.19259v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c253b741-27c3-4122-832a-3b0a1620ea86": {
    "pk": "c253b741-27c3-4122-832a-3b0a1620ea86",
    "title": "Hybrid-Parallel: Achieving High Performance and Energy Efficient Distributed Inference on Robots",
    "abstract": "The rapid advancements in machine learning techniques have led to significant achievements in various real-world robotic tasks. These tasks heavily rely on fast and energy-efficient inference of deep neural network (DNN) models when deployed on robots. To enhance inference performance, distributed inference has emerged as a promising approach, parallelizing inference across multiple powerful GPU devices in modern data centers using techniques such as data parallelism, tensor parallelism, and pipeline parallelism. However, when deployed on real-world robots, existing parallel methods fail to provide low inference latency and meet the energy requirements due to the limited bandwidth of robotic IoT. We present Hybrid-Parallel, a high-performance distributed inference system optimized for robotic IoT. Hybrid-Parallel employs a fine-grained approach to parallelize inference at the granularity of local operators within DNN layers (i.e., operators that can be computed independently with the partial input, such as the convolution kernel in the convolution layer). By doing so, Hybrid-Parallel enables different operators of different layers to be computed and transmitted concurrently, and overlap the computation and transmission phases within the same inference task. The evaluation demonstrate that Hybrid-Parallel reduces inference time by 14.9% ~41.1% and energy consumption per inference by up to 35.3% compared to the state-of-the-art baselines.",
    "authors": [
      "Zekai Sun",
      "Xiuxian Guan",
      "Junming Wang",
      "Haoze Song",
      "Yuhao Qing",
      "Tianxiang Shen",
      "Dong Huang",
      "Fangming Liu",
      "Heming Cui"
    ],
    "url": "http://arxiv.org/abs/2405.19257v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a19de754-1547-473b-a48c-745ee3cdcbe3": {
    "pk": "a19de754-1547-473b-a48c-745ee3cdcbe3",
    "title": "Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation",
    "abstract": "Sampling invariant distributions from an Ito diffusion process presents a significant challenge in stochastic simulation. Traditional numerical solvers for stochastic differential equations require both a fine step size and a lengthy simulation period, resulting in both biased and correlated samples. Current deep learning-based method solves the stationary Fokker--Planck equation to determine the invariant probability density function in form of deep neural networks, but they generally do not directly address the problem of sampling from the computed density function. In this work, we introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker--Planck equation. Our proposed loss function is based on the weak form of the Fokker--Planck equation, integrating normalizing flows to characterize the invariant distribution and facilitate sample generation from the base distribution. Our randomized test function circumvents the need for mini-max optimization in the traditional weak formulation. Distinct from conventional generative models, our method neither necessitates the computationally intensive calculation of the Jacobian determinant nor the invertibility of the transformation map. A crucial component of our framework is the adaptively chosen family of test functions in the form of Gaussian kernel functions with centres selected from the generated data samples. Experimental results on several benchmark examples demonstrate the effectiveness of our method, which offers both low computational costs and excellent capability in exploring multiple metastable states.",
    "authors": [
      "Zhiqiang Cai",
      "Yu Cao",
      "Yuanfei Huang",
      "Xiang Zhou"
    ],
    "url": "http://arxiv.org/abs/2405.19256v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1a944190-6ff2-4d31-a150-c09f72dad8ea": {
    "pk": "1a944190-6ff2-4d31-a150-c09f72dad8ea",
    "title": "Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation",
    "abstract": "The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. Yet, addressing complex urban and environmental management problems normally requires in-depth domain science and informatics expertise. This expertise is essential for deriving data and simulation-driven for informed decision support. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated workflow that encompasses natural language processing, methontology-based prompt tuning, and transformers. This workflow automates the creation of scenario-based ontology using existing research articles and technical manuals of urban datasets and simulations. The outcomes of our methodology are knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL). These facilitate the development of urban decision support systems by enhancing the data and metadata modeling, the integration of complex datasets, the coupling of multi-domain simulation models, and the formulation of decision-making metrics and workflow. The feasibility of our methodology is evaluated through a comparative analysis that juxtaposes our AI-generated ontology with the well-known Pizza Ontology employed in tutorials for popular ontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of optimizing the complex urban system of multi-modal freight transportation by generating anthologies of various domain data and simulations to support informed decision-making.",
    "authors": [
      "Jose Tupayachi",
      "Haowen Xu",
      "Olufemi A. Omitaomu",
      "Mustafa Can Camur",
      "Aliza Sharmin",
      "Xueping Li"
    ],
    "url": "http://arxiv.org/abs/2405.19255v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1a044fd4-60ff-4b83-b45d-8ac49fc5dc62": {
    "pk": "1a044fd4-60ff-4b83-b45d-8ac49fc5dc62",
    "title": "Seasonal and longitudinal variability in Io's SO2 atmosphere from 22 years of IRTF/TEXES observations",
    "abstract": "Between 2001 and 2023, we obtained high spectral resolution mid-infrared observations of Io using the TEXES instrument at NASA's Infrared Telescope Facility. These observations were centered at 529.8 cm-1 (18.88 {\\mu}m) and include several SO2 absorption lines. By modeling the shapes and strengths of these absorption lines, we are able to determine how Io's SO2 atmospheric density varies over the 22-year time period, covering nearly two Jovian years. Previous analysis has shown that the density of Io's atmosphere on the anti-Jovian hemisphere exhibits clear seasonal temporal variability, which can be modeled as the sum of a seasonally-varying frost sublimation component and a constant component, assumed to be volcanic. The new data show that the seasonal pattern repeats during the second Jovian year, confirming the importance of sublimation support. The considerable longitudinal variability in Io's atmospheric density found in previous work is also stable over the second Jovian year with the SO2 column density on the Jupiter-facing hemisphere being 5--8 times lower than the anti-Jovian hemisphere. For the first time, we detect seasonal variability on the Jupiter-facing hemisphere as well. This can also be modeled as a combination of sublimation and a small constant source. The lower atmospheric density on the Jupiter-facing hemisphere can plausibly be explained by the daily Jupiter eclipses, which decrease the surface temperature and therefore reduce the sublimation-driven component of the atmosphere, combined with a lower level of volcanic activity directly emitting SO2 into the atmosphere.",
    "authors": [
      "Rohini S. Giles",
      "John R. Spencer",
      "Constantine C. C. Tsang",
      "Thomas K. Greathouse",
      "Emmanuel Lellouch",
      "Miguel A. L\u00f3pez-Valverde"
    ],
    "url": "http://arxiv.org/abs/2405.19253v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.EP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9029e4f0-c31c-494d-af00-b46684a762bc": {
    "pk": "9029e4f0-c31c-494d-af00-b46684a762bc",
    "title": "Quantum Non-classicality from Causal Data Fusion",
    "abstract": "Bell's theorem, a cornerstone of quantum theory, shows that quantum correlations are incompatible with a classical theory of cause and effect. Through the lens of causal inference, it can be understood as a particular case of causal compatibility, which delves into the alignment of observational data with a given causal structure. Here, we explore the problem of causal data fusion that aims to piece together data tables collected under heterogeneous conditions. We investigate the quantum non-classicality that emerges when integrating both passive observations and interventions within an experimental setup. Referred to as \"non-classicality from data fusion,\" this phenomenon is identified and scrutinized across all latent exogenous causal structures involving three observed variables. Notably, we demonstrate the existence of quantum non-classicality resulting from data fusion, even in scenarios where achieving standard Bell non-classicality is impossible. Furthermore, we showcase the potential for attaining non-classicality across multiple interventions using quantum resources. This work extends a more compact parallel letter on the same subject and provides all the required technical proofs.",
    "authors": [
      "Pedro Lauand",
      "Bereket Ngussie Bekele",
      "Elie Wolfe"
    ],
    "url": "http://arxiv.org/abs/2405.19252v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "00491d73-b1d4-468d-b53b-36f54b8f83cb": {
    "pk": "00491d73-b1d4-468d-b53b-36f54b8f83cb",
    "title": "Kotlin ML Pack: Technical Report",
    "abstract": "In this technical report, we present three novel datasets of Kotlin code: KStack, KStack-clean, and KExercises. We also describe the results of fine-tuning CodeLlama and DeepSeek models on this data. Additionally, we present a version of the HumanEval benchmark rewritten by human experts into Kotlin - both the solutions and the tests. Our results demonstrate that small, high-quality datasets (KStack-clean and KExercises) can significantly improve model performance on code generation tasks, achieving up to a 16-point increase in pass rate on the HumanEval benchmark. Lastly, we discuss potential future work in the field of improving language modeling for Kotlin, including the use of static analysis tools in the learning process and the introduction of more intricate and realistic benchmarks.",
    "authors": [
      "Sergey Titov",
      "Mikhail Evtikhiev",
      "Anton Shapkin",
      "Oleg Smirnov",
      "Sergei Boytsov",
      "Sergei Boytsov",
      "Dariia Karaeva",
      "Maksim Sheptyakov",
      "Mikhail Arkhipov",
      "Timofey Bryksin",
      "Egor Bogomolov"
    ],
    "url": "http://arxiv.org/abs/2405.19250v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "aad77a54-a941-4e7e-80a2-c9a971c52c89": {
    "pk": "aad77a54-a941-4e7e-80a2-c9a971c52c89",
    "title": "Bivariate phase-type distributions for experience rating",
    "abstract": "In this paper, we consider the problem of experience rating within the classic Markov chain life insurance framework. We begin by investigating various multivariate mixed Poisson models with mixing distributions encompassing independent Gamma, hierarchical Gamma, and multivariate phase-type. In particular, we demonstrate how maximum likelihood estimation for these proposed models can be performed using expectation-maximization algorithms, which might be of independent interest. Subsequently, we establish a link between mixed Poisson distributions and the problem of pricing group disability insurance contracts that exhibit heterogeneity. We focus on shrinkage estimation of disability and recovery rates, taking into account sampling effects such as right-censoring. Finally, we showcase the practicality of these shrinkage estimators through a numerical study based on simulated yet realistic insurance data. Our findings highlight that by allowing for dependency between latent group effects, estimates of recovery and disability rates mutually improve, leading to enhanced predictive performance.",
    "authors": [
      "Christian Furrer",
      "Jacob Juhl S\u00f8rensen",
      "Jorge Yslas"
    ],
    "url": "http://arxiv.org/abs/2405.19248v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.ST",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f3345993-1ac1-4302-afe1-9afcf1018436": {
    "pk": "f3345993-1ac1-4302-afe1-9afcf1018436",
    "title": "Bottomed mesons and baryons in pp collisions at $\\sqrt{s}=5 \\, TeV$ LHC energy within a Coalescence plus Fragmentation approach",
    "abstract": "Recent experimental data from $pp$ collisions have shown a significant increase in heavy baryon production leading to a baryon over meson ratio which is one order of magnitude higher than elementary collisions ($e^+e^-$, $ep$). From a theoretical point of view this large production of baryon can be explained with hadronization via quark coalescence assuming a QGP medium in $pp$ collisions. In this study, we extend this analysis to include hadrons containing bottom quarks. Employing a coalescence plus fragmentation approach, we present predictions for $p_T$ spectra and the heavy baryon/meson ratio of charmed hadrons with and without strangeness content, specifically: $\\bar{B^0}$, $B_s$, $\\Lambda_b$, $\\Xi_b^{0,-}$, $\\Omega_b$, and the $B_c$ meson. We have found that coalescence is the dominant mechanism in the B meson production, especially at low momenta, at variance with what found in the charm sector where the D meson were mainly produced via fragmentation. Our model predicts a $\\Lambda_b/\\bar{B^0}\\approx0.5\\!-\\!1$ and $\\Xi_b^0/\\bar{B^0}$ ratio around 0.3 at very low transverse momentum, which are about $1.5$ larger then those of the corresponding charmed hadron ratios at the same collision energy. Furthermore, we discuss the relative ratios between charmed and bottomed hadrons, emphasizing how these observables can provide information about the distribution of charm and bottom quarks and, if experimentally observed, would further support the idea of quark-gluon plasma formation even in small collision systems.",
    "authors": [
      "Vincenzo Minissale",
      "Vincenzo Greco",
      "Salvatore Plumari"
    ],
    "url": "http://arxiv.org/abs/2405.19244v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7a194541-342e-4943-ba36-0706463862a5": {
    "pk": "7a194541-342e-4943-ba36-0706463862a5",
    "title": "Challenge-Device-Synthesis: A multi-disciplinary approach for the development of social innovation competences for students of Artificial Intelligence",
    "abstract": "The advent of Artificial Intelligence is expected to imply profound changes in the short-term. It is therefore imperative for Academia, and particularly for the Computer Science scope, to develop cross-disciplinary tools that bond AI developments to their social dimension. To this aim, we introduce the Challenge-Device-Synthesis methodology (CDS), in which a specific challenge is presented to the students of AI, who are required to develop a device as a solution for the challenge. The device becomes the object of study for the different dimensions of social transformation, and the conclusions addressed by the students during the discussion around the device are presented in a synthesis piece in the shape of a 10-page scientific paper. The latter is evaluated taking into account both the depth of analysis and the level to which it genuinely reflects the social transformations associated with the proposed AI-based device. We provide data obtained during the pilot for the implementation phase of CDS within the subject of Social Innovation, a 6-ECTS subject from the 6th semester of the Degree of Artificial Intelligence, UAB-Barcelona. We provide details on temporalisation, task distribution, methodological tools used and assessment delivery procedure, as well as qualitative analysis of the results obtained.",
    "authors": [
      "Mat\u00edas Bilkis",
      "Joan Moya Kohler",
      "Fernando Vilari\u00f1o"
    ],
    "url": "http://arxiv.org/abs/2405.19243v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f6496ed6-36c9-4580-afb8-a972ea975d72": {
    "pk": "f6496ed6-36c9-4580-afb8-a972ea975d72",
    "title": "Intermediate-mass-ratio inspirals with general dynamical friction in dark matter minispikes",
    "abstract": "The intermediate-mass-ratio inspirals (IMRIs) may be surrounded by dark matter (DM) minispikes. The dynamical friction from these DM minispike structures can affect the dynamics and the gravitational wave (GW) emission of the IMRIs. We analyze the effects of general dynamical friction, with a particular contribution from DM particles moving faster than the stellar-mass black hole in an eccentric IMRI. The results show that the dynamical friction caused by these DM particles tends to eccentricify the orbit, and the general dynamical friction is able to increase the eccentricity. We also analyze the effects of general dynamical friction on the GW characteristic strain. The results indicate that the peak value of the characteristic strain occurs at higher frequencies as the power law index of DM minispike $\\gamma_\\mathrm{sp}$ increases. For the first time, a general analytical relation between the frequency peak value of characteristic strain of GWs and $\\gamma_\\mathrm{sp}$ is established. Using the analytical relation, the presence of DM and its halo density may be determined potentially from future GW data.",
    "authors": [
      "Yu-Chen Zhou",
      "Hong-Bo Jin",
      "Cong-Feng Qiao",
      "Yue-Liang Wu"
    ],
    "url": "http://arxiv.org/abs/2405.19240v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.HE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "df46f964-9cde-475d-9203-428b0ba221e7": {
    "pk": "df46f964-9cde-475d-9203-428b0ba221e7",
    "title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning",
    "abstract": "While large-scale text-to-image diffusion models have demonstrated impressive image-generation capabilities, there are significant concerns about their potential misuse for generating unsafe content, violating copyright, and perpetuating societal biases. Recently, the text-to-image generation community has begun addressing these concerns by editing or unlearning undesired concepts from pre-trained models. However, these methods often involve data-intensive and inefficient fine-tuning or utilize various forms of token remapping, rendering them susceptible to adversarial jailbreaks. In this paper, we present a simple and effective training-free approach, ConceptPrune, wherein we first identify critical regions within pre-trained models responsible for generating undesirable concepts, thereby facilitating straightforward concept unlearning via weight pruning. Experiments across a range of concepts including artistic styles, nudity, object erasure, and gender debiasing demonstrate that target concepts can be efficiently erased by pruning a tiny fraction, approximately 0.12% of total weights, enabling multi-concept erasure and robustness against various white-box and black-box adversarial attacks.",
    "authors": [
      "Ruchika Chavhan",
      "Da Li",
      "Timothy Hospedales"
    ],
    "url": "http://arxiv.org/abs/2405.19237v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0d36340c-a670-4ce7-84c6-e5aa07115d0b": {
    "pk": "0d36340c-a670-4ce7-84c6-e5aa07115d0b",
    "title": "Forward-Backward Knowledge Distillation for Continual Clustering",
    "abstract": "Unsupervised Continual Learning (UCL) is a burgeoning field in machine learning, focusing on enabling neural networks to sequentially learn tasks without explicit label information. Catastrophic Forgetting (CF), where models forget previously learned tasks upon learning new ones, poses a significant challenge in continual learning, especially in UCL, where labeled information of data is not accessible. CF mitigation strategies, such as knowledge distillation and replay buffers, often face memory inefficiency and privacy issues. Although current research in UCL has endeavored to refine data representations and address CF in streaming data contexts, there is a noticeable lack of algorithms specifically designed for unsupervised clustering. To fill this gap, in this paper, we introduce the concept of Unsupervised Continual Clustering (UCC). We propose Forward-Backward Knowledge Distillation for unsupervised Continual Clustering (FBCC) to counteract CF within the context of UCC. FBCC employs a single continual learner (the ``teacher'') with a cluster projector, along with multiple student models, to address the CF issue. The proposed method consists of two phases: Forward Knowledge Distillation, where the teacher learns new clusters while retaining knowledge from previous tasks with guidance from specialized student models, and Backward Knowledge Distillation, where a student model mimics the teacher's behavior to retain task-specific knowledge, aiding the teacher in subsequent tasks. FBCC marks a pioneering approach to UCC, demonstrating enhanced performance and memory efficiency in clustering across various tasks, outperforming the application of clustering algorithms to the latent space of state-of-the-art UCL algorithms.",
    "authors": [
      "Mohammadreza Sadeghi",
      "Zihan Wang",
      "Narges Armanfard"
    ],
    "url": "http://arxiv.org/abs/2405.19234v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "20a49c8e-7153-49bf-861d-173a010d9093": {
    "pk": "20a49c8e-7153-49bf-861d-173a010d9093",
    "title": "Covariate Shift Corrected Conditional Randomization Test",
    "abstract": "Conditional independence tests are crucial across various disciplines in determining the independence of an outcome variable $Y$ from a treatment variable $X$, conditioning on a set of confounders $Z$. The Conditional Randomization Test (CRT) offers a powerful framework for such testing by assuming known distributions of $X \\mid Z$; it controls the Type-I error exactly, allowing for the use of flexible, black-box test statistics. In practice, testing for conditional independence often involves using data from a source population to draw conclusions about a target population. This can be challenging due to covariate shift -- differences in the distribution of $X$, $Z$, and surrogate variables, which can affect the conditional distribution of $Y \\mid X, Z$ -- rendering traditional CRT approaches invalid. To address this issue, we propose a novel Covariate Shift Corrected Pearson Chi-squared Conditional Randomization (csPCR) test. This test adapts to covariate shifts by integrating importance weights and employing the control variates method to reduce variance in the test statistics and thus enhance power. Theoretically, we establish that the csPCR test controls the Type-I error asymptotically. Empirically, through simulation studies, we demonstrate that our method not only maintains control over Type-I errors but also exhibits superior power, confirming its efficacy and practical utility in real-world scenarios where covariate shifts are prevalent. Finally, we apply our methodology to a real-world dataset to assess the impact of a COVID-19 treatment on the 90-day mortality rate among patients.",
    "authors": [
      "Bowen Xu",
      "Yiwen Huang",
      "Chuan Hong",
      "Shuangning Li",
      "Molei Liu"
    ],
    "url": "http://arxiv.org/abs/2405.19231v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ME",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b76ca5c5-2d12-4c99-98bb-20181936ee2b": {
    "pk": "b76ca5c5-2d12-4c99-98bb-20181936ee2b",
    "title": "Synthetic Potential Outcomes for Mixtures of Treatment Effects",
    "abstract": "Modern data analysis frequently relies on the use of large datasets, often constructed as amalgamations of diverse populations or data-sources. Heterogeneity across these smaller datasets constitutes two major challenges for causal inference: (1) the source of each sample can introduce latent confounding between treatment and effect, and (2) diverse populations may respond differently to the same treatment, giving rise to heterogeneous treatment effects (HTEs). The issues of latent confounding and HTEs have been studied separately but not in conjunction. In particular, previous works only report the conditional average treatment effect (CATE) among similar individuals (with respect to the measured covariates). CATEs cannot resolve mixtures of potential treatment effects driven by latent heterogeneity, which we call mixtures of treatment effects (MTEs). Inspired by method of moment approaches to mixture models, we propose \"synthetic potential outcomes\" (SPOs). Our new approach deconfounds heterogeneity while also guaranteeing the identifiability of MTEs. This technique bypasses full recovery of a mixture, which significantly simplifies its requirements for identifiability. We demonstrate the efficacy of SPOs on synthetic data.",
    "authors": [
      "Bijan Mazaheri",
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "url": "http://arxiv.org/abs/2405.19225v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0fba4a13-ba70-467c-9313-77c66d36177a": {
    "pk": "0fba4a13-ba70-467c-9313-77c66d36177a",
    "title": "A study on the adequacy of common IQA measures for medical images",
    "abstract": "Image quality assessment (IQA) is standard practice in the development stage of novel machine learning algorithms that operate on images. The most commonly used IQA measures have been developed and tested for natural images, but not in the medical setting. Reported inconsistencies arising in medical images are not surprising, as they have different properties than natural images. In this study, we test the applicability of common IQA measures for medical image data by comparing their assessment to manually rated chest X-ray (5 experts) and photoacoustic image data (1 expert). Moreover, we include supplementary studies on grayscale natural images and accelerated brain MRI data. The results of all experiments show a similar outcome in line with previous findings for medical imaging: PSNR and SSIM in the default setting are in the lower range of the result list and HaarPSI outperforms the other tested measures in the overall performance. Also among the top performers in our medical experiments are the full reference measures DISTS, FSIM, LPIPS and MS-SSIM. Generally, the results on natural images yield considerably higher correlations, suggesting that the additional employment of tailored IQA measures for medical imaging algorithms is needed.",
    "authors": [
      "Anna Breger",
      "Clemens Karner",
      "Ian Selby",
      "Janek Gr\u00f6hl",
      "S\u00f6ren Dittmer",
      "Edward Lilley",
      "Judith Babar",
      "Jake Beckford",
      "Timothy J Sadler",
      "Shahab Shahipasand",
      "Arthikkaa Thavakumar",
      "Michael Roberts",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "url": "http://arxiv.org/abs/2405.19224v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d0a6b233-ec82-4513-8282-29956aa602a4": {
    "pk": "d0a6b233-ec82-4513-8282-29956aa602a4",
    "title": "Domain adaptation in small-scale and heterogeneous biological datasets",
    "abstract": "Machine learning techniques are steadily becoming more important in modern biology, and are used to build predictive models, discover patterns, and investigate biological problems. However, models trained on one dataset are often not generalizable to other datasets from different cohorts or laboratories, due to differences in the statistical properties of these datasets. These could stem from technical differences, such as the measurement technique used, or from relevant biological differences between the populations studied. Domain adaptation, a type of transfer learning, can alleviate this problem by aligning the statistical distributions of features and samples among different datasets so that similar models can be applied across them. However, a majority of state-of-the-art domain adaptation methods are designed to work with large-scale data, mostly text and images, while biological datasets often suffer from small sample sizes, and possess complexities such as heterogeneity of the feature space. This Review aims to synthetically discuss domain adaptation methods in the context of small-scale and highly heterogeneous biological data. We describe the benefits and challenges of domain adaptation in biological research and critically discuss some of its objectives, strengths, and weaknesses through key representative methodologies. We argue for the incorporation of domain adaptation techniques to the computational biologist's toolkit, with further development of customized approaches.",
    "authors": [
      "Seyedmehdi Orouji",
      "Martin C. Liu",
      "Tal Korem",
      "Megan A. K. Peters"
    ],
    "url": "http://arxiv.org/abs/2405.19221v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.QM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3b092d34-6731-4255-a89a-81403ce61352": {
    "pk": "3b092d34-6731-4255-a89a-81403ce61352",
    "title": "WRDScore: New Metric for Evaluation of Natural Language Generation Models",
    "abstract": "The problem of natural language generation, and, more specifically, method name prediction, faces significant difficulties when proposed models need to be evaluated on test data. Such a metric would need to consider the versatility with which a single method can be named, with respect to both semantics and syntax. Measuring the direct overlap between the predicted and reference (true) sequences will not be able to capture these subtleties. Other existing embedding based metrics either do not measure precision and recall or impose strict unrealistic assumptions on both sequences. To address these issues, we propose a new metric that, on the one hand, is very simple and lightweight, and, on the other hand, is able to calculate precision and recall without resorting to any assumptions while obtaining good performance with respect to the human judgement.",
    "authors": [
      "Ravil Mussabayev"
    ],
    "url": "http://arxiv.org/abs/2405.19220v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a5a5a72b-f385-414d-85de-1682092db9b6": {
    "pk": "a5a5a72b-f385-414d-85de-1682092db9b6",
    "title": "LoByITFL: Low Communication Secure and Private Federated Learning",
    "abstract": "Federated Learning (FL) faces several challenges, such as the privacy of the clients data and security against Byzantine clients. Existing works treating privacy and security jointly make sacrifices on the privacy guarantee. In this work, we introduce LoByITFL, the first communication-efficient Information-Theoretic (IT) private and secure FL scheme that makes no sacrifices on the privacy guarantees while ensuring security against Byzantine adversaries. The key ingredients are a small and representative dataset available to the federator, a careful transformation of the FLTrust algorithm and the use of a trusted third party only in a one-time preprocessing phase before the start of the learning algorithm. We provide theoretical guarantees on privacy and Byzantine-resilience, and provide convergence guarantee and experimental results validating our theoretical findings.",
    "authors": [
      "Yue Xia",
      "Christoph Hofmeister",
      "Maximilian Egger",
      "Rawad Bitar"
    ],
    "url": "http://arxiv.org/abs/2405.19217v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0f7752ab-c17b-4c15-9cf6-a53a75dc99da": {
    "pk": "0f7752ab-c17b-4c15-9cf6-a53a75dc99da",
    "title": "HawkVision: Low-Latency Modeless Edge AI Serving",
    "abstract": "The trend of modeless ML inference is increasingly growing in popularity as it hides the complexity of model inference from users and caters to diverse user and application accuracy requirements. Previous work mostly focuses on modeless inference in data centers. To provide low-latency inference, in this paper, we promote modeless inference at the edge. The edge environment introduces additional challenges related to low power consumption, limited device memory, and volatile network environments.   To address these challenges, we propose HawkVision, which provides low-latency modeless serving of vision DNNs. HawkVision leverages a two-layer edge-DC architecture that employs confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. It also supports lossy inference under volatile network environments. Our experimental results show that HawkVision outperforms current serving systems by up to 1.6X in P99 latency for providing modeless service. Our FPGA prototype demonstrates similar performance at certain accuracy levels with up to a 3.34X reduction in power consumption.",
    "authors": [
      "ChonLam Lao",
      "Jiaqi Gao",
      "Ganesh Ananthanarayanan",
      "Aditya Akella",
      "Minlan Yu"
    ],
    "url": "http://arxiv.org/abs/2405.19213v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "131d350c-048e-4609-9851-212b6dfb9f63": {
    "pk": "131d350c-048e-4609-9851-212b6dfb9f63",
    "title": "Partial Information Decomposition for Data Interpretability and Feature Selection",
    "abstract": "In this paper, we introduce Partial Information Decomposition of Features (PIDF), a new paradigm for simultaneous data interpretability and feature selection. Contrary to traditional methods that assign a single importance value, our approach is based on three metrics per feature: the mutual information shared with the target variable, the feature's contribution to synergistic information, and the amount of this information that is redundant. In particular, we develop a novel procedure based on these three metrics, which reveals not only how features are correlated with the target but also the additional and overlapping information provided by considering them in combination with other features. We extensively evaluate PIDF using both synthetic and real-world data, demonstrating its potential applications and effectiveness, by considering case studies from genetics and neuroscience.",
    "authors": [
      "Charles Westphal",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "url": "http://arxiv.org/abs/2405.19212v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b0da00b6-e319-4b4e-a1e4-a5cdec9487f1": {
    "pk": "b0da00b6-e319-4b4e-a1e4-a5cdec9487f1",
    "title": "Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning",
    "abstract": "Machine learning models are vulnerable to adversarial attacks, including attacks that leak information about the model's training data. There has recently been an increase in interest about how to best address privacy concerns, especially in the presence of data-removal requests. Machine unlearning algorithms aim to efficiently update trained models to comply with data deletion requests while maintaining performance and without having to resort to retraining the model from scratch, a costly endeavor. Several algorithms in the machine unlearning literature demonstrate some level of privacy gains, but they are often evaluated only on rudimentary membership inference attacks, which do not represent realistic threats. In this paper we describe and propose alternative evaluation methods for three key shortcomings in the current evaluation of unlearning algorithms. We show the utility of our alternative evaluations via a series of experiments of state-of-the-art unlearning algorithms on different computer vision datasets, presenting a more detailed picture of the state of the field.",
    "authors": [
      "Keltin Grimes",
      "Collin Abidi",
      "Cole Frank",
      "Shannon Gallagher"
    ],
    "url": "http://arxiv.org/abs/2405.19211v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a8270c27-4939-446c-9ad2-00bc960d124e": {
    "pk": "a8270c27-4939-446c-9ad2-00bc960d124e",
    "title": "Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes",
    "abstract": "Ensuring high-quality data is paramount for maximizing the performance of machine learning models and business intelligence systems. However, challenges in data quality, including noise in data capture, missing records, limited data production, and confounding variables, significantly constrain the potential performance of these systems. In this study, we propose an architecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to address these challenges. GGH analyses gradients from hypotheses as a proxy of distinct and possibly contradictory patterns in the data. This framework entails an additional step in machine learning training, where gradients can be included or excluded from backpropagation. In this manner, missing and noisy data are addressed through a unified solution that perceives both challenges as facets of the same overarching issue: the propagation of erroneous information. Experimental validation of GGH is conducted using real-world open-source datasets, where records with missing rates of up to 98.5% are simulated. Comparative analysis with state-of-the-art imputation methods demonstrates a substantial improvement in model performance achieved by GGH. Specifically in very high scarcity regimes, GGH was found to be the only viable solution. Additionally, GGH's noise detection capabilities are showcased by introducing simulated noise into the datasets and observing enhanced model performance after filtering out the noisy data. This study presents GGH as a promising solution for improving data quality and model performance in various applications.",
    "authors": [
      "Paulo Neves",
      "Joerg K. Wegner",
      "Philippe Schwaller"
    ],
    "url": "http://arxiv.org/abs/2405.19210v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bc05452f-4482-4bca-b462-ad610e2b79c4": {
    "pk": "bc05452f-4482-4bca-b462-ad610e2b79c4",
    "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
    "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study delves into the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is crucial for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.",
    "authors": [
      "Renato M. Silva",
      "Greg\u00f3rio F. Azevedo",
      "Matheus V. V. Berto",
      "Jean R. Rocha",
      "Eduardo C. Fidelis",
      "Matheus V. Nogueira",
      "Pedro H. Lisboa",
      "Tiago A. Almeida"
    ],
    "url": "http://arxiv.org/abs/2405.19202v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "99109efe-bc7e-4824-858c-f6e54dd01c28": {
    "pk": "99109efe-bc7e-4824-858c-f6e54dd01c28",
    "title": "Going beyond compositional generalization, DDPMs can produce zero-shot interpolation",
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable capabilities in image generation, with studies suggesting that they can generalize by composing latent factors learned from the training data. In this work, we go further and study DDPMs trained on strictly separate subsets of the data distribution with large gaps on the support of the latent factors. We show that such a model can effectively generate images in the unexplored, intermediate regions of the distribution. For instance, when trained on clearly smiling and non-smiling faces, we demonstrate a sampling procedure which can generate slightly smiling faces without reference images (zero-shot interpolation). We replicate these findings for other attributes as well as other datasets. $\\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\\text{Our code is available on GitHub.}}$",
    "authors": [
      "Justin Deschenaux",
      "Igor Krawczuk",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ],
    "url": "http://arxiv.org/abs/2405.19201v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d3e756c3-d16c-4744-bc60-782c0c92ec7e": {
    "pk": "d3e756c3-d16c-4744-bc60-782c0c92ec7e",
    "title": "A statistical analysis of drug seizures and opioid overdose deaths in Ohio from 2014 to 2018",
    "abstract": "This paper examines the association between police drug seizures and drug overdose deaths in Ohio from 2014 to 2018. We use linear regression, ARIMA models, and categorical data analysis to quantify the effect of drug seizure composition and weight on drug overdose deaths, to quantify the lag between drug seizures and overdose deaths, and to compare the weight distributions of drug seizures conducted by different types of law enforcement (national, local, and drug task forces). We find that drug seizure composition and weight have strong predictive value for drug overdose deaths (F = 27.14, p < 0.0001, R^2 = .7799). A time series analysis demonstrates no statistically significant lag between drug seizures and overdose deaths or weight. Histograms and Kolmogorov-Smirnov tests demonstrate stark differences between seizure weight distributions of different types of law enforcement (p < 0.0001 for each pairwise comparison). We include a discussion of what our conclusions mean for law enforcement and harm reduction efforts.",
    "authors": [
      "Lin Ma",
      "Lam Tran",
      "David White"
    ],
    "url": "http://arxiv.org/abs/2405.19199v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.soc-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7483dc49-f180-442b-962e-823757bf11c9": {
    "pk": "7483dc49-f180-442b-962e-823757bf11c9",
    "title": "Diffusion-based Dynamics Models for Long-Horizon Rollout in Offline Reinforcement Learning",
    "abstract": "With the great success of diffusion models (DMs) in generating realistic synthetic vision data, many researchers have investigated their potential in decision-making and control. Most of these works utilized DMs to sample directly from the trajectory space, where DMs can be viewed as a combination of dynamics models and policies. In this work, we explore how to decouple DMs' ability as dynamics models in fully offline settings, allowing the learning policy to roll out trajectories. As DMs learn the data distribution from the dataset, their intrinsic policy is actually the behavior policy induced from the dataset, which results in a mismatch between the behavior policy and the learning policy. We propose Dynamics Diffusion, short as DyDiff, which can inject information from the learning policy to DMs iteratively. DyDiff ensures long-horizon rollout accuracy while maintaining policy consistency and can be easily deployed on model-free algorithms. We provide theoretical analysis to show the advantage of DMs on long-horizon rollout over models and demonstrate the effectiveness of DyDiff in the context of offline reinforcement learning, where the rollout dataset is provided but no online environment for interaction. Our code is at https://github.com/FineArtz/DyDiff.",
    "authors": [
      "Hanye Zhao",
      "Xiaoshen Han",
      "Zhengbang Zhu",
      "Minghuan Liu",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19189v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "be89b956-3c32-4b7b-ba61-0c63017e068b": {
    "pk": "be89b956-3c32-4b7b-ba61-0c63017e068b",
    "title": "Personalized Interiors at Scale: Leveraging AI for Efficient and Customizable Design Solutions",
    "abstract": "In this paper, we introduce an innovative application of artificial intelligence in the realm of interior design through the integration of Stable Diffusion and Dreambooth models. This paper explores the potential of these advanced generative models to streamline and democratize the process of room interior generation, offering a significant departure from conventional, labor-intensive techniques. Our approach leverages the capabilities of Stable Diffusion for generating high-quality images and Dreambooth for rapid customization with minimal training data, addressing the need for efficiency and personalization in the design industry. We detail a comprehensive methodology that combines these models, providing a robust framework for the creation of tailored room interiors that reflect individual tastes and functional requirements. We presents an extensive evaluation of our method, supported by experimental results that demonstrate its effectiveness and a series of case studies that illustrate its practical application in interior design projects. Our study contributes to the ongoing discourse on the role of AI in creative fields, highlighting the benefits of leveraging generative models to enhance creativity and reshape the future of interior design.",
    "authors": [
      "Kaiwen Zhou",
      "Tianyu Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19188v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.HC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4c728f62-77ce-4893-9c50-ae768c2dc460": {
    "pk": "4c728f62-77ce-4893-9c50-ae768c2dc460",
    "title": "MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification",
    "abstract": "Large Vision Language Models (LVLMs) have shown remarkable capabilities in multimodal tasks like visual question answering or image captioning. However, inconsistencies between the visual information and the generated text, a phenomenon referred to as hallucinations, remain an unsolved problem with regard to the trustworthiness of LVLMs. To address this problem, recent works proposed to incorporate computationally costly Large (Vision) Language Models in order to detect hallucinations on a sentence- or subsentence-level. In this work, we introduce MetaToken, a lightweight binary classifier to detect hallucinations on the token-level at negligible cost. Based on a statistical analysis, we reveal key factors of hallucinations in LVLMs which have been overseen in previous works. MetaToken can be applied to any open-source LVLM without any knowledge about ground truth data providing a reliable detection of hallucinations. We evaluate our method on four state-of-the-art LVLMs demonstrating the effectiveness of our approach.",
    "authors": [
      "Laura Fieback",
      "Jakob Spiegelberg",
      "Hanno Gottschalk"
    ],
    "url": "http://arxiv.org/abs/2405.19186v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1d41c974-b315-4526-a660-119d760c65cf": {
    "pk": "1d41c974-b315-4526-a660-119d760c65cf",
    "title": "Benford's law in atomic spectra and opacity databases",
    "abstract": "The intriguing law of anomalous numbers, also named Benford's law, states that the significant digits of data follow a logarithmic distribution favoring the smallest values. In this work, we test the compliance with this law of the atomic databases developed at the National Institute of Standards and Technology (NIST) focusing on line energies, oscillator strengths, Einstein coefficients and radiative opacities. The considered databases are the Atomic Spectra Database (ASD) and the NIST-LANL (Los Alamos National Laboratory) Lanthanide/Actinide Opacity Database. The present study is not limited to the first digit and the case of multipole lines is also considered. The fact that the law is verified with a high accuracy means that the occurrence of digits reflects the constraints induced, in a given angular-momentum coupling, by the selection rules for atomic processes. As a consequence, Benford's law may be of great interest to detect inconsistencies in atomic databases.",
    "authors": [
      "Jean-Christophe Pain",
      "Yuri Ralchenko"
    ],
    "url": "http://arxiv.org/abs/2405.19185v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.atom-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "97d88628-2adc-4631-9729-2b0230f1d8d3": {
    "pk": "97d88628-2adc-4631-9729-2b0230f1d8d3",
    "title": "Post-Minkowskian Theory Meets the Spinning Effective-One-Body Approach for Bound-Orbit Waveforms",
    "abstract": "Driven by advances in scattering amplitudes and worldline-based methods, recent years have seen significant progress in our ability to calculate gravitational two-body scattering observables. These observables effectively encapsulate the gravitational two-body problem in the weak-field and high-velocity regime (post-Minkowskian, PM), with applications to the bound two-body problem and gravitational-wave modeling. We leverage PM data to construct a complete inspiral-merger-ringdown waveform model for non-precessing spinning black holes within the effective-one-body (EOB) formalism: SEOBNR-PM. This model is closely based on the highly successful SEOBNRv5 model, used by the LIGO-Virgo-KAGRA Collaboration, with its key new feature being an EOB Hamiltonian derived by matching the two-body scattering angle in a perturbative PM expansion. The model performs remarkably well, showing a median mismatch against 441 numerical-relativity (NR) simulations that is somewhat lower than a similarly calibrated version of SEOBNRv5. Comparisons of the binding energy with NR also demonstrate better agreement than SEOBNRv5, despite the latter containing additional calibration to NR simulations.",
    "authors": [
      "Alessandra Buonanno",
      "Gustav Mogull",
      "Raj Patil",
      "Lorenzo Pompili"
    ],
    "url": "http://arxiv.org/abs/2405.19181v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "gr-qc",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5b0de076-d1ae-4396-bae7-01a03e7ea87b": {
    "pk": "5b0de076-d1ae-4396-bae7-01a03e7ea87b",
    "title": "Observation of Significant Photosynthesis in Garden Cress and Cyanobacteria under Simulated Illumination from a K Dwarf Star",
    "abstract": "Stars with about 45 to 80% the mass of the Sun, so-called K dwarf stars, have previously been proposed as optimal host stars in the search for habitable extrasolar worlds. These stars are abundant, have stable luminosities over billions of years longer than Sun-like stars, and offer favorable space environmental conditions. So far, the theoretical and experimental focus on exoplanet habitability has been on even less massive, though potentially less hospitable red dwarf stars. Here we present the first experimental data on the responses of photosynthetic organisms to a simulated K dwarf spectrum. We find that garden cress Lepidium sativum under K-dwarf radiation exhibits comparable growth and photosynthetic efficiency as under solar illumination on Earth. The cyanobacterium Chroococcidiopsis sp. CCMEE 029 exhibits significantly higher photosynthetic efficiency and culture growth under K dwarf radiation compared to solar conditions. Our findings of the affirmative responses of these two photosynthetic organisms to K dwarf radiation suggest that exoplanets in the habitable zones around such stars deserve high priority in the search for extrasolar life.",
    "authors": [
      "Iva Vilovi\u0107",
      "Dirk Schulze-Makuch",
      "Ren\u00e9 Heller"
    ],
    "url": "http://arxiv.org/abs/2405.19180v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.EP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9c6ff7f7-92ab-4d89-8da5-e28549496cb1": {
    "pk": "9c6ff7f7-92ab-4d89-8da5-e28549496cb1",
    "title": "Model-independent cosmological inference post DESI DR1 BAO measurements",
    "abstract": "In this work, we implement Gaussian process regression to reconstruct the expansion history of the universe in a model-agnostic manner, using the Pantheon-Plus SN-Ia compilation in combination with two different BAO measurements (SDSS-IV and DESI DR1). In both the reconstructions, the $\\Lambda$CDM model is always included in the 95\\% confidence intervals. We find evidence that the DESI LRG data at $z_{\\text{eff}} = 0.51$ is not an outlier within our model-independent framework. We study the $\\mathcal{O}m$-diagnostics and the evolution of the total equation of state (EoS) of our universe, which hint towards the possibility of a quintessence-like dark energy scenario with a very slowly varying EoS, and a phantom-crossing in higher $z$. The entire exercise is later complemented by considering two more SN-Ia compilations - DES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI BAO + DES-5YR SN data sets predicts that the $\\Lambda$CDM model lies outside the 3$\\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the $\\Lambda$CDM model is always included within 1$\\sigma$. We also report constraints on $H_0 r_d$ from our model-agnostic analysis, independent of the pre-recombination physics. Our results point towards an $\\approx$ 2$\\sigma$ discrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets, which calls for further investigation.",
    "authors": [
      "Purba Mukherjee",
      "Anjan Ananda Sen"
    ],
    "url": "http://arxiv.org/abs/2405.19178v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "80197656-df8a-4c4d-a946-ca09aa81952b": {
    "pk": "80197656-df8a-4c4d-a946-ca09aa81952b",
    "title": "Exoplanet Aeronomy: A Case Study of WASP-69b's Variable Thermosphere",
    "abstract": "Aeronomy, the study of Earth's upper atmosphere and its interaction with the local space environment, has long traced changes in the thermospheres of Earth and other solar system planets to solar variability in the X-ray and extreme ultraviolet (collectively, \"XUV\") bands. Extending comparative aeronomy to the short-period extrasolar planets may illuminate whether stellar XUV irradiation powers atmospheric outflows that change planetary radii on astronomical timescales. In recent years, near-infrared transit spectroscopy of metastable HeI has been a prolific tracer of high-altitude planetary gas. We present a case study of exoplanet aeronomy using metastable HeI transit observations from Palomar/WIRC and follow-up high-energy data from the Neil Gehrels Swift Observatory that were taken within one month of the WASP-69 system, a K-type main sequence star with a well-studied hot Jupiter companion. Supplemented by archival data, we find that WASP-69's X-ray flux in 2023 was less than 50% of what was recorded in 2016 and that the metastable HeI absorption from WASP-69b was lower in 2023 versus past epochs from 2017-2019. Via atmospheric modeling, we show that this time-variable metastable HeI signal is in the expected direction given the observed change in stellar XUV, possibly stemming from WASP-69's magnetic activity cycle. Our results underscore the ability of multi-epoch, multi-wavelength observations to paint a cohesive picture of the interaction between an exoplanet's atmosphere and its host star.",
    "authors": [
      "W. Garrett Levine",
      "Shreyas Vissapragada",
      "Adina D. Feinstein",
      "George W. King",
      "Aleck Hernandez",
      "Lia Corrales",
      "Michael Greklek-McKeon",
      "Heather A. Knutson"
    ],
    "url": "http://arxiv.org/abs/2405.19177v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.EP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "06931d34-5ac4-4c49-9cab-bfaa1f636e08": {
    "pk": "06931d34-5ac4-4c49-9cab-bfaa1f636e08",
    "title": "Strong solution of the three-dimensional $(3D)$ incompressible magneto-hydrodynamic $(MHD)$ equationss with a modified damping",
    "abstract": "This study delves into a comprehensive examination of the three-dimensional $(3D)$ incompressible magneto-hydrodynamic $(MHD)$ equations in $H^{1}(\\R^{3})$. The modification involves incorporating a power term in the nonlinear convection component, a particularly relevant adjustment in porous media scenarios, especially when the fluid adheres to the Darcy-Forchheimer law instead of the conventional Darcy law. Our main contributions include establishing global existence over time and demonstrating the uniqueness of solutions. It is important to note that these achievements are obtained with smallness conditions on the initial data, but under the condition that $\\beta >3$ and $\\alpha>0$. However, when $\\beta=3$, the problem is limited to the case $0<\\alpha<\\frac{1}{2}$ as the above inequality is unsolvable for these values of $\\alpha$ using our method. To support our statement, we will add a \"slight disturbance\" of the function f of the type $f(z)=log(e+z^{2})$ or $\\log(\\log(e^{e}+z^{2}))$ or even $\\log(\\log(\\log((e^{e})^{e}+z^{2})))$.",
    "authors": [
      "Maroua Ltifi"
    ],
    "url": "http://arxiv.org/abs/2405.19174v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.AP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f39a7ce9-0a60-426a-b380-4ac76a5e155e": {
    "pk": "f39a7ce9-0a60-426a-b380-4ac76a5e155e",
    "title": "Exploring AI-based Anonymization of Industrial Image and Video Data in the Context of Feature Preservation",
    "abstract": "With rising technologies, the protection of privacy-sensitive information is becoming increasingly important. In industry and production facilities, image or video recordings are beneficial for documentation, tracing production errors or coordinating workflows. Individuals in images or videos need to be anonymized. However, the anonymized data should be reusable for further applications. In this work, we apply the Deep Learning-based full-body anonymization framework DeepPrivacy2, which generates artificial identities, to industrial image and video data. We compare its performance with conventional anonymization techniques. Therefore, we consider the quality of identity generation, temporal consistency, and the applicability of pose estimation and action recognition.",
    "authors": [
      "Sabrina Cynthia Triess",
      "Timo Leitritz",
      "Christian Jauch"
    ],
    "url": "http://arxiv.org/abs/2405.19173v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0ceaddc3-43db-4c1b-ab69-8007c618af3f": {
    "pk": "0ceaddc3-43db-4c1b-ab69-8007c618af3f",
    "title": "Greedy Kernel Methods for Approximating Breakthrough Curves for Reactive Flow from 3D Porous Geometry Data",
    "abstract": "We address the challenging application of 3D pore scale reactive flow under varying geometry parameters. The task is to predict time-dependent integral quantities, i.e., breakthrough curves, from the given geometries. As the 3D reactive flow simulation is highly complex and computationally expensive, we are interested in data-based surrogates that can give a rapid prediction of the target quantities of interest. This setting is an example of an application with scarce data, i.e., only having available few data samples, while the input and output dimensions are high. In this scarce data setting, standard machine learning methods are likely to ail. Therefore, we resort to greedy kernel approximation schemes that have shown to be efficient meshless approximation techniques for multivariate functions. We demonstrate that such methods can efficiently be used in the high-dimensional input/output case under scarce data. Especially, we show that the vectorial kernel orthogonal greedy approximation (VKOGA) procedure with a data-adapted two-layer kernel yields excellent predictors for learning from 3D geometry voxel data via both morphological descriptors or principal component analysis.",
    "authors": [
      "Robin Herkert",
      "Patrick Buchfink",
      "Tizian Wenzel",
      "Bernard Haasdonk",
      "Pavel Toktaliev",
      "Oleg Iliev"
    ],
    "url": "http://arxiv.org/abs/2405.19170v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.NA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "26db8923-43ed-401d-8ed5-edae24b900b5": {
    "pk": "26db8923-43ed-401d-8ed5-edae24b900b5",
    "title": "Measuring differential particle correlations in relativistic nuclear collisions",
    "abstract": "This study explores the transverse momentum ($p_T$) dependencies of Symmetric and Asymmetric Correlations (SC and ASC) with one and two particles of interest in Au+Au collisions at 200 GeV. Leveraging the AMPT model, the investigation delves into the sensitivity of these correlations to the final state effects, providing valuable insights into their potential for constraining the final state effects' $p_T$ dependencies. The HIJING model is employed as a benchmark for non-flow correlations, shedding light on their impact on interpreting SC and ASC data. Moreover, the study points out that differential SC and ASC with one and two particles of interest (POIs) typically incorporate contributions from event-plane angle fluctuations. Consequently, this work highlights the significance of SC and ASC with one and two POIs as valuable tools for investigating the $p_T$ nature of the final state effects and advocates for comprehensive experimental measurements across various beam energies and system sizes to enhance our understanding and provide additional constraints for theoretical models.",
    "authors": [
      "Niseem Magdy"
    ],
    "url": "http://arxiv.org/abs/2405.19169v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "1b45b9aa-0da4-4b05-abb4-5316fed29b7f": {
    "pk": "1b45b9aa-0da4-4b05-abb4-5316fed29b7f",
    "title": "Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity",
    "abstract": "Neural operator learning models have emerged as very effective surrogates in data-driven methods for partial differential equations (PDEs) across different applications from computational science and engineering. Such operator learning models not only predict particular instances of a physical or biological system in real-time but also forecast classes of solutions corresponding to a distribution of initial and boundary conditions or forcing terms. % DeepONet is the first neural operator model and has been tested extensively for a broad class of solutions, including Riemann problems. Transformers have not been used in that capacity, and specifically, they have not been tested for solutions of PDEs with low regularity. %   In this work, we first establish the theoretical groundwork that transformers possess the universal approximation property as operator learning models.   We then apply transformers to forecast solutions of diverse dynamical systems with solutions of finite regularity for a plurality of initial conditions and forcing terms. In particular, we consider three examples: the Izhikevich neuron model, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and the one-dimensional Euler equation Riemann problem. For the latter problem, we also compare with variants of DeepONet, and we find that transformers outperform DeepONet in accuracy but they are computationally more expensive.",
    "authors": [
      "Benjamin Shih",
      "Ahmad Peyvan",
      "Zhongqiang Zhang",
      "George Em Karniadakis"
    ],
    "url": "http://arxiv.org/abs/2405.19166v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9e07cd27-0d51-4e9a-8509-3331972f006b": {
    "pk": "9e07cd27-0d51-4e9a-8509-3331972f006b",
    "title": "Does learning the right latent variables necessarily improve in-context learning?",
    "abstract": "Large autoregressive models like Transformers can solve tasks through in-context learning (ICL) without learning new weights, suggesting avenues for efficiently solving new tasks. For many tasks, e.g., linear regression, the data factorizes: examples are independent given a task latent that generates the data, e.g., linear coefficients. While an optimal predictor leverages this factorization by inferring task latents, it is unclear if Transformers implicitly do so or if they instead exploit heuristics and statistical shortcuts enabled by attention layers. Both scenarios have inspired active ongoing work. In this paper, we systematically investigate the effect of explicitly inferring task latents. We minimally modify the Transformer architecture with a bottleneck designed to prevent shortcuts in favor of more structured solutions, and then compare performance against standard Transformers across various ICL tasks. Contrary to intuition and some recent works, we find little discernible difference between the two; biasing towards task-relevant latent variables does not lead to better out-of-distribution performance, in general. Curiously, we find that while the bottleneck effectively learns to extract latent task variables from context, downstream processing struggles to utilize them for robust prediction. Our study highlights the intrinsic limitations of Transformers in achieving structured ICL solutions that generalize, and shows that while inferring the right latents aids interpretability, it is not sufficient to alleviate this problem.",
    "authors": [
      "Sarthak Mittal",
      "Eric Elmoznino",
      "Leo Gagnon",
      "Sangnie Bhardwaj",
      "Dhanya Sridhar",
      "Guillaume Lajoie"
    ],
    "url": "http://arxiv.org/abs/2405.19162v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "34d9398d-9d3c-47c8-9284-e57c7db54acf": {
    "pk": "34d9398d-9d3c-47c8-9284-e57c7db54acf",
    "title": "Beyond Discrepancy: A Closer Look at the Theory of Distribution Shift",
    "abstract": "Many machine learning models appear to deploy effortlessly under distribution shift, and perform well on a target distribution that is considerably different from the training distribution. Yet, learning theory of distribution shift bounds performance on the target distribution as a function of the discrepancy between the source and target, rarely guaranteeing high target accuracy. Motivated by this gap, this work takes a closer look at the theory of distribution shift for a classifier from a source to a target distribution. Instead of relying on the discrepancy, we adopt an Invariant-Risk-Minimization (IRM)-like assumption connecting the distributions, and characterize conditions under which data from a source distribution is sufficient for accurate classification of the target. When these conditions are not met, we show when only unlabeled data from the target is sufficient, and when labeled target data is needed. In all cases, we provide rigorous theoretical guarantees in the large sample regime.",
    "authors": [
      "Robi Bhattacharjee",
      "Nick Rittler",
      "Kamalika Chaudhuri"
    ],
    "url": "http://arxiv.org/abs/2405.19156v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "efd820eb-945d-4419-b013-eb1651be32e6": {
    "pk": "efd820eb-945d-4419-b013-eb1651be32e6",
    "title": "L-Estimation in Instrumental Variables Regression for Censored Data in Presence of Endogeneity and Dependent Errors",
    "abstract": "In this article, we propose L-estimators of the unknown parameters in the instrumental variables regression in the presence of censored data under endogeneity. We allow the random errors involved in the model to be dependent. The proposed estimation procedure is a two-stage procedure, and the large sample properties of the proposed estimators are established. The utility of the proposed methodology is demonstrated for various simulated data and a benchmark real data set.",
    "authors": [
      "Swati Shukla",
      "Subhra Sankar Dhar",
      "Shalabh"
    ],
    "url": "http://arxiv.org/abs/2405.19145v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ME",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6f29062f-9a61-48a2-b2b1-48bfbb9b0867": {
    "pk": "6f29062f-9a61-48a2-b2b1-48bfbb9b0867",
    "title": "Resilience of mobility network to dynamic population response across COVID-19 interventions: evidences from Chile",
    "abstract": "The COVID19 pandemic highlighted the importance of non-traditional data sources, such as mobile phone data, to inform effective public health interventions and monitor adherence to such measures. Previous studies showed how socioeconomic characteristics shaped population response during restrictions and how repeated interventions eroded adherence over time. Less is known about how different population strata changed their response to repeated interventions and how this impacted the resulting mobility network. We study population response during the first and second infection waves of the COVID-19 pandemic in Chile and Spain. Via spatial lag and regression models, we investigate the adherence to mobility interventions at the municipality level in Chile, highlighting the significant role of wealth, labor structure, COVID-19 incidence, and network metrics characterizing business-as-usual municipality connectivity in shaping mobility changes during the two waves. We assess network structural similarities in the two periods by defining mobility hotspots and traveling probabilities in the two countries. As a proof of concept, we simulate and compare outcomes of an epidemic diffusion occurring in the two waves. Our analysis reveals the resilience of the mobility network across waves. We test the robustness of our findings recovering similar results for Spain. Finally, epidemic modeling suggests that historical mobility data from past waves can be leveraged to inform future disease spatial invasion models in repeated interventions. This study highlights the value of historical mobile phone data for building pandemic preparedness and lessens the need for real-time data streams for risk assessment and outbreak response. Our work provides valuable insights into the complex interplay of factors driving mobility across repeated interventions, aiding in developing targeted mitigation strategies.",
    "authors": [
      "Pasquale Casaburi",
      "Lorenzo Dall'Amico",
      "Nicol\u00f2 Gozzi",
      "Kyriaki Kalimeri",
      "Anna Sapienza",
      "Rossano Schifanella",
      "T. Di Matteo",
      "Leo Ferres",
      "Mattia Mazzoli"
    ],
    "url": "http://arxiv.org/abs/2405.19141v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.soc-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b2cc0450-2ed7-4024-8605-de6dcc2d2b4b": {
    "pk": "b2cc0450-2ed7-4024-8605-de6dcc2d2b4b",
    "title": "Multi-Channel Multi-Step Spectrum Prediction Using Transformer and Stacked Bi-LSTM",
    "abstract": "Spectrum prediction is considered as a key technology to assist spectrum decision. Despite the great efforts that have been put on the construction of spectrum prediction, achieving accurate spectrum prediction emphasizes the need for more advanced solutions. In this paper, we propose a new multichannel multi-step spectrum prediction method using Transformer and stacked bidirectional LSTM (Bi- LSTM), named TSB. Specifically, we use multi-head attention and stacked Bi-LSTM to build a new Transformer based on encoder-decoder architecture. The self-attention mechanism composed of multiple layers of multi-head attention can continuously attend to all positions of the multichannel spectrum sequences. The stacked Bi-LSTM can learn these focused coding features by multi-head attention layer by layer. The advantage of this fusion mode is that it can deeply capture the long-term dependence of multichannel spectrum data. We have conducted extensive experiments on a dataset generated by a real simulation platform. The results show that the proposed algorithm performs better than the baselines.",
    "authors": [
      "Guangliang Pan",
      "Jie Li",
      "Minglei Li"
    ],
    "url": "http://arxiv.org/abs/2405.19138v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "70d225c1-a8fb-4a31-8f38-a56fe60f79d2": {
    "pk": "70d225c1-a8fb-4a31-8f38-a56fe60f79d2",
    "title": "Multi-Source Coflow Scheduling in Collaborative Edge Computing with Multihop Network",
    "abstract": "Collaborative edge computing has become a popular paradigm where edge devices collaborate by sharing resources. Data dissemination is a fundamental problem in CEC to decide what data is transmitted from which device and how. Existing works on data dissemination have not focused on coflow scheduling in CEC, which involves deciding the order of flows within and across coflows at network links. Coflow implies a set of parallel flows with a shared objective. The existing works on coflow scheduling in data centers usually assume a non-blocking switch and do not consider congestion at different links in the multi-hop path in CEC, leading to increased coflow completion time (CCT). Furthermore, existing works do not consider multiple flow sources that cannot be ignored, as data can have duplicate copies at different edge devices. This work formulates the multi-source coflow scheduling problem in CEC, which includes jointly deciding the source and flow ordering for multiple coflows to minimize the sum of CCT. This problem is shown to be NP-hard and challenging as each flow can have multiple dependent conflicts at multiple links. We propose a source and coflow-aware search and adjust (SCASA) heuristic that first provides an initial solution considering the coflow characteristics. SCASA further improves the initial solution using the source search and adjust heuristic by leveraging the knowledge of both coflows and network congestion at links. Evaluation done using simulation experiments shows that SCASA leads to up to 83% reduction in the sum of CCT compared to benchmarks without a joint solution.",
    "authors": [
      "Yuvraj Sahni",
      "Jiannong Cao",
      "Lei Yang",
      "Shengwei Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19136v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.NI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d20e55dd-0b4b-4aec-bd73-102dd3c782bd": {
    "pk": "d20e55dd-0b4b-4aec-bd73-102dd3c782bd",
    "title": "Photometric Completeness Modelled With Neural Networks",
    "abstract": "In almost any study involving optical/NIR photometry, understanding the completeness of detection and recovery is an essential part of the work. The recovery fraction is, in general, a function of several variables including magnitude, color, background sky noise, and crowding. We explore how completeness can be modelled, {with the use of artificial-star tests,} in a way that includes all of these parameters \\emph{simultaneously} within a neural network (NN) framework. The method is able to manage common issues including asymmetric completeness functions and the bilinear dependence of the detection limit on color index. We test the method with two sample HST (Hubble Space Telescope) datasets: the first involves photometry of the star cluster population around the giant Perseus galaxy NGC 1275, and the second involves the halo-star population in the nearby elliptical galaxy NGC 3377. The NN-based method achieves a classification accuracy of $>$\\,94\\%, and produces results entirely consistent with more traditional techniques for determining completeness. Additional advantages of the method are that none of the issues arising from binning of the data are present, and that a recovery probability can be assigned to every individual star in the real photometry. Our data, models, and code (called COINTOSS) can be found online on Zenodo at the following link: https://doi.org/10.5281/zenodo.8306488.",
    "authors": [
      "William E. Harris",
      "Joshua S. Speagle"
    ],
    "url": "http://arxiv.org/abs/2405.19135v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.IM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b4201b51-8c23-4af4-83ad-88f7d2c54fca": {
    "pk": "b4201b51-8c23-4af4-83ad-88f7d2c54fca",
    "title": "Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT",
    "abstract": "Large Language Models (LLMs) have taken the world by storm, and students are assumed to use related tools at a great scale. In this research paper we aim to gain an understanding of how introductory programming students chat with LLMs and related tools, e.g., ChatGPT-3.5. To address this goal, computing students at a large German university were motivated to solve programming exercises with the assistance of ChatGPT as part of their weekly introductory course exercises. Then students (n=213) submitted their chat protocols (with 2335 prompts in sum) as data basis for this analysis. The data was analyzed w.r.t. the prompts, frequencies, the chats' progress, contents, and other use pattern, which revealed a great variety of interactions, both potentially supportive and concerning. Learning about students' interactions with ChatGPT will help inform and align teaching practices and instructions for future introductory programming courses in higher education.",
    "authors": [
      "Andreas Scholl",
      "Daniel Schiffner",
      "Natalie Kiesler"
    ],
    "url": "http://arxiv.org/abs/2405.19132v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4b4caa6f-d257-4e2d-b391-52329a25d18a": {
    "pk": "4b4caa6f-d257-4e2d-b391-52329a25d18a",
    "title": "Learning Interpretable Scheduling Algorithms for Data Processing Clusters",
    "abstract": "Workloads in data processing clusters are often represented in the form of DAG (Directed Acyclic Graph) jobs. Scheduling DAG jobs is challenging. Simple heuristic scheduling algorithms are often adopted in practice in production data centres. There is much room for scheduling performance optimisation for cost saving. Recently, reinforcement learning approaches (like decima) have been attempted to optimise DAG job scheduling and demonstrate clear performance gain in comparison to traditional algorithms. However, reinforcement learning (RL) approaches face their own problems in real-world deployment. In particular, their black-box decision making processes and generalizability in unseen workloads may add a non-trivial burden to the cluster administrators. Moreover, adapting RL models on unseen workloads often requires significant amount of training data, which leaves edge cases run in a sub-optimal mode. To fill the gap, we propose a new method to distill a simple scheduling policy based on observations of the behaviours of a complex deep learning model. The simple model not only provides interpretability of scheduling decisions, but also adaptive to edge cases easily through tuning. We show that our method achieves high fidelity to the decisions made by deep learning models and outperforms these models when additional heuristics are taken into account.",
    "authors": [
      "Zhibo Hu",
      "Chen Wang",
      "Helen",
      "Paik",
      "Yanfeng Shu",
      "Liming Zhu"
    ],
    "url": "http://arxiv.org/abs/2405.19131v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "35f6377d-6a3c-4b71-a77a-c8ac07d605de": {
    "pk": "35f6377d-6a3c-4b71-a77a-c8ac07d605de",
    "title": "Transport model study of transverse momentum distributions of Pion, kaon, and (anti-)proton production in U+U collisions at $\\sqrt{s_{NN}}$ = 193 GeV",
    "abstract": "The transverse momentum spectra of $\\pi ^{\\pm }$, $k ^{\\pm }$ and $p(\\bar{p})$ in midrapidity ($\\left | y \\right | < 0.1$) for nine centrality classes : $0-5\\%$, $5-10\\%$, $10-20\\%$, $20-30\\%$, $30-40\\%$, $40-50\\%$, $50-60\\%$, $60-70\\%$ and $70-80\\%$ in $^{238} U$+$^{238} U$ collisions at $\\sqrt{s_{NN}}$=193 GeV are studied within the framework of the cascade and soft momentum dependent equation of state (SM-EoS) mode of the UrQMD model. Other extracted observables from $p_{T}$ spectra such as average transverse momentum ($\\left \\langle p_{T} \\right \\rangle$), particle yields ($dN/dy$) and particle ratios are also shown as functions of collision centrality. It is found that the U+U collision process is segmented. Before the collision centrality is $50-60\\%$, the experimental data are described well using cascade mode when the $p_{T} < 1.2 GeV/c$. The results are in good agreement with the experimental data using the SM-EoS mode at $p_{T} > 1.2 GeV/c$. For the case of $60-80\\%$ centrality, the SM-EoS mode describes the data better. Anti-particle to particle yield ratios indicating pair production is the dominant mechanism of particle production at RHIC energy.",
    "authors": [
      "Ying Yuan"
    ],
    "url": "http://arxiv.org/abs/2405.19130v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "17cd007b-8833-4696-aadb-5d73791bdee5": {
    "pk": "17cd007b-8833-4696-aadb-5d73791bdee5",
    "title": "Early Detection of Critical Urban Events using Mobile Phone Network Data",
    "abstract": "Network Signalling Data (NSD) have the potential to provide continuous spatio-temporal information about the presence, mobility, and usage patterns of cell phone services by individuals. Such information is invaluable for monitoring large urban areas and supporting the implementation of decision-making services. When analyzed in real time, NSD can enable the early detection of critical urban events, including fires, large accidents, stampedes, terrorist attacks, and sports and leisure gatherings, especially if these events significantly impact mobile phone network activity in the affected areas. This paper presents empirical evidence that advanced NSD can detect anomalies in mobile traffic service consumption, attributable to critical urban events, with fine spatial and temporal resolutions. We introduce two methodologies for real-time anomaly detection from multivariate time series extracted from large-scale NSD, utilizing a range of algorithms adapted from the state-of-the-art in unsupervised machine learning techniques for anomaly detection. Our research includes a comprehensive quantitative evaluation of these algorithms on a large-scale dataset of NSD service consumption for the Paris region. The evaluation uses an original dataset of documented critical or unusual urban events. This dataset has been built as a ground truth basis for assessing the algorithms performance. The obtained results demonstrate that our framework can detect unusual events almost instantaneously and locate the affected areas with high precision, largely outperforming random classifiers. This efficiency and effectiveness underline the potential of NSD-based anomaly detection in significantly enhancing emergency response strategies and urban planning.",
    "authors": [
      "Pierre Lemaire",
      "Angelo Furno",
      "Stefania Rubrichi",
      "Alexis Bondu",
      "Zbigniew Smoreda",
      "Cezary Ziemlicki",
      "Nour-Eddin El Faouzi",
      "Eric Gaume"
    ],
    "url": "http://arxiv.org/abs/2405.19125v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "52c075cb-435c-4cb4-9b1d-64b2a2fbb467": {
    "pk": "52c075cb-435c-4cb4-9b1d-64b2a2fbb467",
    "title": "Apparent horizon tracking in supercritical solutions of the Einstein-scalar field equations in spherical symmetry in affine-null coordinates",
    "abstract": "Choptuik's critical phenomena in general relativity is revisited in the affine-null metric formulation of Einstein's equations for a massless scalar field in spherical symmetry. Numerical solutions are obtained by evolution of initial data using pseudo-spectral methods. The underlying system consists of differential equations along the outgoing null rays which can be solved in sequential form. A new two-parameter family of initial data is presented for which these equations can be integrated analytically. Specific choices of the initial data parameters correspond to either an asymptotically flat null cone, a black hole event horizon or the singular interior of a black hole. Our main focus is on the interior features of a black hole, for which the affine-null system is especially well adapted. We present both analytic and numerical results describing the geometric properties of the apparent horizon and final singularity. Using a re-gridding technique for the affine parameter, numerical evolution of initially asymptotically flat supercritical data can be continued inside the event horizon and track the apparent horizon up to the formation of the final singularity.",
    "authors": [
      "Thomas M\u00e4dler",
      "Olaf Baake",
      "Hamideh Hosseini",
      "Jeffrey Winicour"
    ],
    "url": "http://arxiv.org/abs/2405.19122v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "gr-qc",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f96d9bb5-407d-4065-ac0f-cc82a3c3b131": {
    "pk": "f96d9bb5-407d-4065-ac0f-cc82a3c3b131",
    "title": "Spatio-Spectral Graph Neural Networks",
    "abstract": "Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for learning on graph-structured data. However, key limitations of l-step MPGNNs are that their \"receptive field\" is typically limited to the l-hop neighborhood of a node and that information exchange between distant nodes is limited by over-squashing. Motivated by these limitations, we propose Spatio-Spectral Graph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural Networks (GNNs) that synergistically combines spatially and spectrally parametrized graph filters. Parameterizing filters partially in the frequency domain enables global yet efficient information propagation. We show that S$^2$GNNs vanquish over-squashing and yield strictly tighter approximation-theoretic error bounds than MPGNNs. Further, rethinking graph convolutions at a fundamental level unlocks new design spaces. For example, S$^2$GNNs allow for free positional encodings that make them strictly more expressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain general-purpose S$^2$GNNs, we propose spectrally parametrized filters for directed graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and graph rewirings, e.g., on the peptide long-range benchmark tasks, and are competitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs scale to millions of nodes.",
    "authors": [
      "Simon Geisler",
      "Arthur Kosmala",
      "Daniel Herbst",
      "Stephan G\u00fcnnemann"
    ],
    "url": "http://arxiv.org/abs/2405.19121v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c955781f-3335-4ffd-a7e0-26caacf22676": {
    "pk": "c955781f-3335-4ffd-a7e0-26caacf22676",
    "title": "ChartFormer: A Large Vision Language Model for Converting Chart Images into Tactile Accessible SVGs",
    "abstract": "Visualizations, such as charts, are crucial for interpreting complex data. However, they are often provided as raster images, which are not compatible with assistive technologies for people with blindness and visual impairments, such as embossed papers or tactile displays. At the same time, creating accessible vector graphics requires a skilled sighted person and is time-intensive. In this work, we leverage advancements in the field of chart analysis to generate tactile charts in an end-to-end manner. Our three key contributions are as follows: (1) introducing the ChartFormer model trained to convert raster chart images into tactile-accessible SVGs, (2) training this model on the Chart2Tactile dataset, a synthetic chart dataset we created following accessibility standards, and (3) evaluating the effectiveness of our SVGs through a pilot user study with an refreshable two-dimensional tactile display. Our work is publicly available at https://github.com/nsothman/ChartFormer .",
    "authors": [
      "Omar Moured",
      "Sara Alzalabny",
      "Anas Osman",
      "Thorsten Schwarz",
      "Karin Muller",
      "Rainer Stiefelhagen"
    ],
    "url": "http://arxiv.org/abs/2405.19117v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "84f27c23-9572-4aa6-a43e-6aca649b9651": {
    "pk": "84f27c23-9572-4aa6-a43e-6aca649b9651",
    "title": "Full Asymptotic Expansion of Monodromy Data for the First Painlev\u00e9 Transcendent: Applications to Connection Problems",
    "abstract": "We study the full asymptotic expansion of the monodromy data ({\\it i.e.}, Stokes multipliers) for the first Painlev\\'{e} transcendent (PI) with large initial data or large pole parameters. Our primary approach involves refining the complex WKB method, also known as the method of uniform asymptotics, to approximate the second-order ODEs derived from PI's Lax pair with higher-order accuracy. As an application, we provide a rigorous proof of the full asymptotic expansion of the nonlinear eigenvalues proposed numerically by Bender, Komijani, and Wang. Additionally, we present the full asymptotic expansion for the pole parameters $(p_{n}, H_{n})$ corresponding to the $n$-th pole of the real tritronqu\\'{e}e solution of the PI equation as $n \\to +\\infty$.",
    "authors": [
      "Yun-Jiang Jiang",
      "Yu-Tian Li",
      "Wen-Gao Long"
    ],
    "url": "http://arxiv.org/abs/2405.19115v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "nlin.SI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "14c9bde5-9ab2-4d1b-a641-5dda0e0312a0": {
    "pk": "14c9bde5-9ab2-4d1b-a641-5dda0e0312a0",
    "title": "PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering",
    "abstract": "Logical reasoning task has attracted great interest since it was proposed. Faced with such a task, current competitive models, even large language models (e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs struggle in logical consistency modeling and logical structure perception. To this end, we model the logical reasoning task by transforming each logical sample into reasoning paths and propose an architecture \\textbf{PathReasoner}. It addresses the task from the views of both data and model. To expand the diversity of the logical samples, we propose an atom extension strategy supported by equivalent logical formulas, to form new reasoning paths. From the model perspective, we design a stack of transformer-style blocks. In particular, we propose a path-attention module to joint model in-atom and cross-atom relations with the high-order diffusion strategy. Experiments show that PathReasoner achieves competitive performances on two logical reasoning benchmarks and great generalization abilities.",
    "authors": [
      "Fangzhi Xu",
      "Qika Lin",
      "Tianzhe Zhao",
      "Jiawei Han",
      "Jun Liu"
    ],
    "url": "http://arxiv.org/abs/2405.19109v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d45fa208-8fc0-4a2f-8bff-c2d430ab903e": {
    "pk": "d45fa208-8fc0-4a2f-8bff-c2d430ab903e",
    "title": "Offline Regularised Reinforcement Learning for Large Language Models Alignment",
    "abstract": "The dominant framework for alignment of large language models (LLM), whether through reinforcement learning from human feedback or direct preference optimisation, is to learn from preference data. This involves building datasets where each element is a quadruplet composed of a prompt, two independent responses (completions of the prompt) and a human preference between the two independent responses, yielding a preferred and a dis-preferred response. Such data is typically scarce and expensive to collect. On the other hand, \\emph{single-trajectory} datasets where each element is a triplet composed of a prompt, a response and a human feedback is naturally more abundant. The canonical element of such datasets is for instance an LLM's response to a user's prompt followed by a user's feedback such as a thumbs-up/down. Consequently, in this work, we propose DRO, or \\emph{Direct Reward Optimisation}, as a framework and associated algorithms that do not require pairwise preferences. DRO uses a simple mean-squared objective that can be implemented in various ways. We validate our findings empirically, using T5 encoder-decoder language models, and show DRO's performance over selected baselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that DRO is a simple and empirically compelling method for single-trajectory policy optimisation.",
    "authors": [
      "Pierre Harvey Richemond",
      "Yunhao Tang",
      "Daniel Guo",
      "Daniele Calandriello",
      "Mohammad Gheshlaghi Azar",
      "Rafael Rafailov",
      "Bernardo Avila Pires",
      "Eugene Tarassov",
      "Lucas Spangher",
      "Will Ellsworth",
      "Aliaksei Severyn",
      "Jonathan Mallinson",
      "Lior Shani",
      "Gil Shamir",
      "Rishabh Joshi",
      "Tianqi Liu",
      "Remi Munos",
      "Bilal Piot"
    ],
    "url": "http://arxiv.org/abs/2405.19107v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b0cbe335-fd36-4186-b212-270539bd8711": {
    "pk": "b0cbe335-fd36-4186-b212-270539bd8711",
    "title": "Reflections to set-theoretic solutions of the Yang-Baxter equation",
    "abstract": "The main aim of this paper is to determine reflections to bijective and non-degenerate solutions of the Yang-Baxter equation, by exploring their connections with their derived solutions. This is motivated by a recent description of left non-degenerate solutions in terms of a family of automorphisms of their associated left rack. In some cases, we show that the study of reflections for bijective and non-degenerate solutions can be reduced to those of derived type. Moreover, we extend some results obtained in the literature for reflections of involutive non-degenerate solutions to more arbitrary solutions. Besides, we provide ways for defining reflections for solutions obtained by employing some classical construction techniques of solutions. Finally, we gather some numerical data on reflections for bijective non-degenerate solutions associated with skew braces of small order.",
    "authors": [
      "Andrea Albano",
      "Marzia Mazzotta",
      "Paola Stefanelli"
    ],
    "url": "http://arxiv.org/abs/2405.19105v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.QA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "84376da5-ffe3-49e2-a1ab-66364911c5ff": {
    "pk": "84376da5-ffe3-49e2-a1ab-66364911c5ff",
    "title": "Poseidon: Efficient Foundation Models for PDEs",
    "abstract": "We introduce Poseidon, a foundation model for learning the solution operators of PDEs. It is based on a multiscale operator transformer, with time-conditioned layer norms that enable continuous-in-time evaluations. A novel training strategy leveraging the semi-group property of time-dependent PDEs to allow for significant scaling-up of the training data is also proposed. Poseidon is pretrained on a diverse, large scale dataset for the governing equations of fluid dynamics. It is then evaluated on a suite of 15 challenging downstream tasks that include a wide variety of PDE types and operators. We show that Poseidon exhibits excellent performance across the board by outperforming baselines significantly, both in terms of sample efficiency and accuracy. Poseidon also generalizes very well to new physics that is not seen during pretraining. Moreover, Poseidon scales with respect to model and data size, both for pretraining and for downstream tasks. Taken together, our results showcase the surprising ability of Poseidon to learn effective representations from a very small set of PDEs during pretraining in order to generalize well to unseen and unrelated PDEs downstream, demonstrating its potential as an effective, general purpose PDE foundation model. Finally, the Poseidon model as well as underlying pretraining and downstream datasets are open sourced, with code being available at https://github.com/camlab-ethz/poseidon and pretrained models and datasets at https://huggingface.co/camlab-ethz.",
    "authors": [
      "Maximilian Herde",
      "Bogdan Raoni\u0107",
      "Tobias Rohner",
      "Roger K\u00e4ppeli",
      "Roberto Molinaro",
      "Emmanuel de B\u00e9zenac",
      "Siddhartha Mishra"
    ],
    "url": "http://arxiv.org/abs/2405.19101v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c63fc9e4-4723-4c47-b060-b39bacf04573": {
    "pk": "c63fc9e4-4723-4c47-b060-b39bacf04573",
    "title": "Enhancing Zero-Shot Facial Expression Recognition by LLM Knowledge Transfer",
    "abstract": "Current facial expression recognition (FER) models are often designed in a supervised learning manner thus are constrained by the lack of large-scale facial expression images with high-quality annotations. Consequently, these models often fail to generalize well, performing poorly on unseen images in training. Vision-language-based zero-shot models demonstrate a promising potential for addressing such challenges. However, these models lack task-specific knowledge therefore are not optimized for the nuances of recognizing facial expressions. To bridge this gap, this work proposes a novel method, Exp-CLIP, to enhance zero-shot FER by transferring the task knowledge from large language models (LLMs). Specifically, based on the pre-trained vision-language encoders, we incorporate a projection head designed to map the initial joint vision-language space into a space that captures representations of facial actions. To train this projection head for subsequent zero-shot predictions, we propose to align the projected visual representations with task-specific semantic meanings derived from the LLM encoder, and the text instruction-based strategy is employed to customize the LLM knowledge. Given unlabelled facial data and efficient training of the projection head, Exp-CLIP achieves superior zero-shot results to the CLIP models and several other large vision-language models (LVLMs) on seven in-the-wild FER datasets. The code and pre-trained models are available at \\url{https://github.com/zengqunzhao/Exp-CLIP}.",
    "authors": [
      "Zengqun Zhao",
      "Yu Cao",
      "Shaogang Gong",
      "Ioannis Patras"
    ],
    "url": "http://arxiv.org/abs/2405.19100v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "46226e8a-e8ff-4229-b9e7-4b67d3ced242": {
    "pk": "46226e8a-e8ff-4229-b9e7-4b67d3ced242",
    "title": "A study of why we need to reassess full reference image quality assessment with medical images",
    "abstract": "Image quality assessment (IQA) is not just indispensable in clinical practice to ensure high standards, but also in the development stage of novel algorithms that operate on medical images with reference data. This paper provides a structured and comprehensive collection of examples where the two most common full reference (FR) image quality measures prove to be unsuitable for the assessment of novel algorithms using different kinds of medical images, including real-world MRI, CT, OCT, X-Ray, digital pathology and photoacoustic imaging data. In particular, the FR-IQA measures PSNR and SSIM are known and tested for working successfully in many natural imaging tasks, but discrepancies in medical scenarios have been noted in the literature. Inconsistencies arising in medical images are not surprising, as they have very different properties than natural images which have not been targeted nor tested in the development of the mentioned measures, and therefore might imply wrong judgement of novel methods for medical images. Therefore, improvement is urgently needed in particular in this era of AI to increase explainability, reproducibility and generalizability in machine learning for medical imaging and beyond. On top of the pitfalls we will provide ideas for future research as well as suggesting guidelines for the usage of FR-IQA measures applied to medical images.",
    "authors": [
      "Anna Breger",
      "Ander Biguri",
      "Malena Sabat\u00e9 Landman",
      "Ian Selby",
      "Nicole Amberg",
      "Elisabeth Brunner",
      "Janek Gr\u00f6hl",
      "Sepideh Hatamikia",
      "Clemens Karner",
      "Lipeng Ning",
      "S\u00f6ren Dittmer",
      "Michael Roberts",
      "AIX-COVNET Collaboration",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "url": "http://arxiv.org/abs/2405.19097v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5b0ce9ae-f49c-4643-96c5-35a06fc411e9": {
    "pk": "5b0ce9ae-f49c-4643-96c5-35a06fc411e9",
    "title": "Faithful Chart Summarization with ChaTS-Pi",
    "abstract": "Chart-to-summary generation can help explore data, communicate insights, and help the visually impaired people. Multi-modal generative models have been used to produce fluent summaries, but they can suffer from factual and perceptual errors. In this work we present CHATS-CRITIC, a reference-free chart summarization metric for scoring faithfulness. CHATS-CRITIC is composed of an image-to-text model to recover the table from a chart, and a tabular entailment model applied to score the summary sentence by sentence. We find that CHATS-CRITIC evaluates the summary quality according to human ratings better than reference-based metrics, either learned or n-gram based, and can be further used to fix candidate summaries by removing not supported sentences. We then introduce CHATS-PI, a chart-to-summary pipeline that leverages CHATS-CRITIC during inference to fix and rank sampled candidates from any chart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human raters, establishing state-of-the-art results on two popular chart-to-summary datasets.",
    "authors": [
      "Syrine Krichene",
      "Francesco Piccinno",
      "Fangyu Liu",
      "Julian Martin Eisenschlos"
    ],
    "url": "http://arxiv.org/abs/2405.19094v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "95c2c68c-58fc-4f98-8228-fa7b15e54ec7": {
    "pk": "95c2c68c-58fc-4f98-8228-fa7b15e54ec7",
    "title": "Benchmarking and Improving Detail Image Caption",
    "abstract": "Image captioning has long been regarded as a fundamental task in visual understanding. Recently, however, few large vision-language model (LVLM) research discusses model's image captioning performance because of the outdated short-caption benchmarks and unreliable evaluation metrics. In this work, we propose to benchmark detail image caption task by curating high-quality evaluation datasets annotated by human experts, GPT-4V and Gemini-1.5-Pro. We also design a more reliable caption evaluation metric called CAPTURE (CAPtion evaluation by exTracting and coUpling coRE information). CAPTURE extracts visual elements, e.g., objects, attributes and relations from captions, and then matches these elements through three stages, achieving the highest consistency with expert judgements over other rule-based or model-based caption metrics. The proposed benchmark and metric provide reliable evaluation for LVLM's detailed image captioning ability. Guided by this evaluation, we further explore to unleash LVLM's detail caption capabilities by synthesizing high-quality data through a five-stage data construction pipeline. Our pipeline only uses a given LVLM itself and other open-source tools, without any human or GPT-4V annotation in the loop. Experiments show that the proposed data construction strategy significantly improves model-generated detail caption data quality for LVLMs with leading performance, and the data quality can be further improved in a self-looping paradigm. All code and dataset will be publicly available at https://github.com/foundation-multimodal-models/CAPTURE.",
    "authors": [
      "Hongyuan Dong",
      "Jiawen Li",
      "Bohong Wu",
      "Jiacong Wang",
      "Yuan Zhang",
      "Haoyuan Guo"
    ],
    "url": "http://arxiv.org/abs/2405.19092v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f17f295d-cb75-470d-bd79-16b189a58c51": {
    "pk": "f17f295d-cb75-470d-bd79-16b189a58c51",
    "title": "Probing the strength of radial migration via churning by using metal-rich red giant stars from APOGEE",
    "abstract": "Making use of the APOGEE DR17 catalogue with high quality data for 143,509 red giant branch stars we explore the strength of different mechanisms that causes a star to radially migrate in the Milky Way stellar disk. At any position in the disk we find stars that are more metal-rich than the local interstellar medium. This is surprising and normally attributed to the migration of these stars after their formation inside their current Galactocentric-radius. Such stars are prime candidates for studying the strength of different migratory processes. We specifically select two types of metal-rich stars: i) super metal-rich stars ([Fe/H] > 0.2) and ii) stars that are more metal-rich than their local environment. For both, we explore the distribution of orbital parameters and ages as evidence of their migration history. We find that most super metal-rich stars have experienced some amount of churning as they have orbits with Rg >= 5 kpc. Furthermore, about half of the super metal-rich stars are on non-circular orbits (ecc > 0.15) and therefore also have experienced blurring. The metallicity of young stars in our sample is generally the same as the metallicity of the interstellar medium, suggesting they have not radially migrated yet. Stars with lower metallicity than the local environment have intermediate to old ages. We further find that super metal-rich stars have approximately the same age distribution at all Galactocentric-radii, which suggests that radial migration is a key mechanism responsible for the chemical compositions of stellar populations in the Milky Way.",
    "authors": [
      "Christian Lehmann",
      "Sofia Feltzing",
      "Diane Feuillet",
      "Georges Kordopatis"
    ],
    "url": "http://arxiv.org/abs/2405.19089v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.GA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f7c59f87-85df-4e38-b4fc-8df32cbebb28": {
    "pk": "f7c59f87-85df-4e38-b4fc-8df32cbebb28",
    "title": "Impacts of ALP on the Constraints of Dark Photon",
    "abstract": "Dark sector may exist and interact with Standard Model (SM) through the $U(1)$ kinetic mixing. Through this portal-type interaction, dark photon from dark sector couples to SM fermions, and may explain the discrepancy between experimental data and SM calculations on muon anomalous magnetic moment, muon $g-2$. However, current searches for dark photon impose stringent constraints on the mixing parameter $\\varepsilon$ for various dark photon masses, excluding the favorite parameter space for muon $g-2$. In this paper, we study the case where a global $U(1)$ in dark sector is spontaneously broken, resulting a light pseudo-Goldstone, axion-like particle (ALP) $a$, which couples to dark photon and SM photon, $g_{a\\gamma\\gamma'}$. Through this interaction, dark photon may decay into photon and ALP when this channel is kinematically allowed. As a result, the experimental constraints on dark photon change significantly, and dark photon is able to explain the muon $g-2$ anomaly when its mass is heavier than $10$ GeV.",
    "authors": [
      "Chuan-Ren Chen",
      "Yuan-Feng Hsieh",
      "Chrisna Setyo Nugroho"
    ],
    "url": "http://arxiv.org/abs/2405.19087v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a36edc1b-d58c-40a2-b261-02ec6ac616a5": {
    "pk": "a36edc1b-d58c-40a2-b261-02ec6ac616a5",
    "title": "OMPO: A Unified Framework for RL under Policy and Dynamics Shifts",
    "abstract": "Training reinforcement learning policies using environment interaction data collected from varying policies or dynamics presents a fundamental challenge. Existing works often overlook the distribution discrepancies induced by policy or dynamics shifts, or rely on specialized algorithms with task priors, thus often resulting in suboptimal policy performances and high learning variances. In this paper, we identify a unified strategy for online RL policy learning under diverse settings of policy and dynamics shifts: transition occupancy matching. In light of this, we introduce a surrogate policy learning objective by considering the transition occupancy discrepancies and then cast it into a tractable min-max optimization problem through dual reformulation. Our method, dubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized actor-critic structure equipped with a distribution discriminator and a small-size local buffer. We conduct extensive experiments based on the OpenAI Gym, Meta-World, and Panda Robots environments, encompassing policy shifts under stationary and nonstationary dynamics, as well as domain adaption. The results demonstrate that OMPO outperforms the specialized baselines from different categories in all settings. We also find that OMPO exhibits particularly strong performance when combined with domain randomization, highlighting its potential in RL-based robotics applications",
    "authors": [
      "Yu Luo",
      "Tianying Ji",
      "Fuchun Sun",
      "Jianwei Zhang",
      "Huazhe Xu",
      "Xianyuan Zhan"
    ],
    "url": "http://arxiv.org/abs/2405.19080v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bcefc6d9-1402-44fe-82f5-af29631ffc28": {
    "pk": "bcefc6d9-1402-44fe-82f5-af29631ffc28",
    "title": "Diagrammatic Representations of Higher-Dimensional Topological Orders",
    "abstract": "In 3D spacetime, topologically ordered phases of matter feature emergent particles called anyons, whose properties like fusion rules and braiding statistics are schematically represented by diagrams. Important consistency conditions, such as pentagon and hexagon relations, are encoded in diagrams. In 4D and higher spacetimes, topological orders support not only point-like particles but also spatially extended excitations, such as loops and membranes, allowing for diverse topological data about braiding, fusion, and shrinking processes. Recently, these topological data have been explored through the path-integral formalism of topological quantum field theory. Analogous to the counterpart in 3D, in this work, we construct diagrammatic representations of higher-dimensional (4D and 5D) topological orders. We introduce basic fusion and shrinking diagrams and treat them as vectors in corresponding spaces, then build complex diagrams by stacking these basic diagrams. Within the same vector spaces, we use $F$-, $\\Delta$-, and $\\Delta^2$-symbols to transform between different bases. From these transformations, we derive consistency conditions like \\textit{pentagon equations} and \\textit{(hierarchical) shrinking-fusion hexagon equations}, which describe the consistent coexistence of fusion and shrinking data. We conjecture that all anomaly-free higher-dimensional topological orders must satisfy these conditions, with violations indicating a quantum anomaly. This work opens several promising avenues for future research such as the exploration of diagrammatic representations of braiding processes in higher dimensions as well as implications for noninvertible symmetries and Symmetry Topological Field Theory (SymTFT).",
    "authors": [
      "Yizhou Huang",
      "Zhi-Feng Zhang",
      "Peng Ye"
    ],
    "url": "http://arxiv.org/abs/2405.19077v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-th",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9c081fa4-b71c-408a-a790-d7cc497e06b2": {
    "pk": "9c081fa4-b71c-408a-a790-d7cc497e06b2",
    "title": "Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design",
    "abstract": "We present Cephalo, a series of multimodal vision large language models (V-LLMs) designed for materials science applications, integrating visual and linguistic data for enhanced understanding and interaction within human-AI and multi-agent AI frameworks. A key innovation of Cephalo is its advanced dataset generation method, which employs a sophisticated algorithm to accurately detect and separate images and their corresponding textual descriptions from PDF documents, such as scientific papers. The method includes a careful refinement of image-text pairs through integrated vision and language processing, ensuring high-quality, contextually relevant, and well reasoned training data. Cephalo is trained on integrated image and text data extracted from thousands of scientific papers and science-focused Wikipedia pages demonstrates can interpret complex visual scenes, generate precise language descriptions, and answer queries about images effectively. The combination of a vision encoder with an autoregressive transformer supports complex natural language understanding in an integrated model, which can be coupled with other generative methods to create an image-to-text-to-image or image-to-text-to-3D pipeline. To explore the development of larger models from smaller ones, we merge sets of layers that originate from different pre-trained source models. This hybrid approach allows us to leverage the domain-specific expertise and general conversational capabilities to harness the strengths of multiple models. We examine the models in diverse use cases that incorporate biological materials, fracture and engineering analysis, protein biophysics, and bio-inspired design based on insect behavior. Generative applications include bio-inspired designs, including pollen-inspired architected materials, as well as the synthesis of bio-inspired material microstructures from a photograph of a solar eclipse.",
    "authors": [
      "Markus J. Buehler"
    ],
    "url": "http://arxiv.org/abs/2405.19076v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9de103bd-6fd8-4ea0-8778-832ff1efe4c8": {
    "pk": "9de103bd-6fd8-4ea0-8778-832ff1efe4c8",
    "title": "Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning",
    "abstract": "Continual learning methods are known to suffer from catastrophic forgetting, a phenomenon that is particularly hard to counter for methods that do not store exemplars of previous tasks. Therefore, to reduce potential drift in the feature extractor, existing exemplar-free methods are typically evaluated in settings where the first task is significantly larger than subsequent tasks. Their performance drops drastically in more challenging settings starting with a smaller first task. To address this problem of feature drift estimation for exemplar-free methods, we propose to adversarially perturb the current samples such that their embeddings are close to the old class prototypes in the old model embedding space. We then estimate the drift in the embedding space from the old to the new model using the perturbed images and compensate the prototypes accordingly. We exploit the fact that adversarial samples are transferable from the old to the new feature space in a continual learning setting. The generation of these images is simple and computationally cheap. We demonstrate in our experiments that the proposed approach better tracks the movement of prototypes in embedding space and outperforms existing methods on several standard continual learning benchmarks as well as on fine-grained datasets. Code is available at https://github.com/dipamgoswami/ADC.",
    "authors": [
      "Dipam Goswami",
      "Albin Soutif--Cormerais",
      "Yuyang Liu",
      "Sandesh Kamath",
      "Bart\u0142omiej Twardowski",
      "Joost van de Weijer"
    ],
    "url": "http://arxiv.org/abs/2405.19074v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4cdd76b7-7d84-4962-aa8f-dd5c4080ae74": {
    "pk": "4cdd76b7-7d84-4962-aa8f-dd5c4080ae74",
    "title": "UPC physics with ALICE in Run 3",
    "abstract": "The ALICE experiment has undergone a major detector upgrade for Run 3, expanding its detection capabilities for a wide variety of studies. The new continuous readout has significantly enhanced the physics potential for ultra-peripheral collision analyses. In this talk, we discussed some of the physics analyses that can be carried out in ultra-peripheral collisions using the Run 3 data and presented some of the first physics performance plots in both proton-proton and heavy-ion collisions.",
    "authors": [
      "Anisa Khatun"
    ],
    "url": "http://arxiv.org/abs/2405.19069v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ex",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "61df2803-9f0a-402f-a7e7-fffa3aeda675": {
    "pk": "61df2803-9f0a-402f-a7e7-fffa3aeda675",
    "title": "SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs",
    "abstract": "While dynamic graph neural networks have shown promise in various applications, explaining their predictions on continuous-time dynamic graphs (CTDGs) is difficult. This paper investigates a new research task: self-interpretable GNNs for CTDGs. We aim to predict future links within the dynamic graph while simultaneously providing causal explanations for these predictions. There are two key challenges: (1) capturing the underlying structural and temporal information that remains consistent across both independent and identically distributed (IID) and out-of-distribution (OOD) data, and (2) efficiently generating high-quality link prediction results and explanations. To tackle these challenges, we propose a novel causal inference model, namely the Independent and Confounded Causal Model (ICCM). ICCM is then integrated into a deep learning architecture that considers both effectiveness and efficiency. Extensive experiments demonstrate that our proposed model significantly outperforms existing methods across link prediction accuracy, explanation quality, and robustness to shortcut features. Our code and datasets are anonymously released at https://github.com/2024SIG/SIG.",
    "authors": [
      "Lanting Fang",
      "Yulian Yang",
      "Kai Wang",
      "Shanshan Feng",
      "Kaiyu Feng",
      "Jie Gui",
      "Shuliang Wang",
      "Yew-Soon Ong"
    ],
    "url": "http://arxiv.org/abs/2405.19062v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c4dd5e36-72af-486d-b3d7-6cd7be31385d": {
    "pk": "c4dd5e36-72af-486d-b3d7-6cd7be31385d",
    "title": "Robust Entropy Search for Safe Efficient Bayesian Optimization",
    "abstract": "The practical use of Bayesian Optimization (BO) in engineering applications imposes special requirements: high sampling efficiency on the one hand and finding a robust solution on the other hand. We address the case of adversarial robustness, where all parameters are controllable during the optimization process, but a subset of them is uncontrollable or even adversely perturbed at the time of application. To this end, we develop an efficient information-based acquisition function that we call Robust Entropy Search (RES). We empirically demonstrate its benefits in experiments on synthetic and real-life data. The results showthat RES reliably finds robust optima, outperforming state-of-the-art algorithms.",
    "authors": [
      "Dorina Weichert",
      "Alexander Kister",
      "Patrick Link",
      "Sebastian Houben",
      "Gunar Ernis"
    ],
    "url": "http://arxiv.org/abs/2405.19059v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  }
}

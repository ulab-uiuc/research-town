{
  "e0b31013-faef-4b7e-b7b1-87584af30b7c": {
    "pk": "e0b31013-faef-4b7e-b7b1-87584af30b7c",
    "name": "Jack W. Rae",
    "bio": " I am a researcher with a focus on developing and improving machine learning models, particularly in the areas of natural language processing, reinforcement learning, and sparse neural networks. I have worked on a variety of projects aimed at advancing the state-of-the-art in these fields.\n\nIn the area of natural language processing, I have explored the use of Transformer models for language modeling, and have found that incorporating a long-range memory of past activations, as in the Transformer-XL, can improve performance on a variety of benchmarks. However, I have also discovered that it may be possible to achieve comparable performance with fewer long-range memories, and that limiting the range of attention in lower layers of the network can actually improve performance.\n\nI have also developed the Compressive Transformer, an attentive sequence model that compresses past memories for long-range sequence learning. This model has achieved state-of-the-art language modeling results on the WikiText-103 and Enwik8 benchmarks, and has been shown to be effective at modeling high-frequency speech and as a memory mechanism for reinforcement learning.\n\nIn the area of reinforcement learning, I have worked on the development of the V-MPO algorithm, an on-policy adaptation of Maximum a Posteriori Policy Optimization that performs policy iteration based on a learned state-value function. This algorithm has surpassed previously reported scores on the Atari-57 and DMLab-30 benchmark suites in the multi-task setting, and has achieved substantially higher scores on individual DMLab and Atari levels.\n\nI have also explored the use of sparse neural networks, and have developed the Top-KAST method, which preserves constant sparsity throughout training in both the forward and backward passes. This method has been shown to perform comparably to or better than previous works when training models on the ImageNet benchmark, and can be used to train massive models with significantly fewer resources, making them more widely accessible and applicable.\n\nIn addition to these projects, I have also worked on the development of the Memory-based Parameter Adaptation method, which stores examples in memory and uses a context-based lookup to directly modify the weights of a neural network. This method has been shown to alleviate several shortcomings of neural networks, such as catastrophic forgetting and fast, stable acquisition of new",
    "collaborators": [
      "Siddhant M. Jayakumar",
      "Ali Razavi",
      "Anna Potapenko",
      "Timothy P. Lillicrap",
      "Razvan Pascanu"
    ],
    "institute": null
  },
  "9da76794-a0b6-4804-bb4c-fbb66354a210": {
    "pk": "9da76794-a0b6-4804-bb4c-fbb66354a210",
    "name": "Andrew Moore",
    "bio": " I am a researcher with a focus on developing efficient data structures and algorithms for high-dimensional data and statistical learning tasks. I have recently been working on the Anchors Hierarchy, a fast data structure and algorithm for localizing data based on a triangle-inequality-obeying distance metric. This allows for the creation of a well-balanced structure similar to a Ball-Tree or a metric tree, which can be used to accelerate a wide variety of statistical learning algorithms in high-dimensional spaces.\n\nIn addition to this, I have also been investigating a new approach to searching the combinatorial space of contingency tables during the inner loop of a nonlinear statistical optimization, called RADSEARCH. This approach finds the global optimum and has been shown to outperform other recent successful search algorithms such as CN2, PRIM, APriori, OPUS and DenseMiner. I have also used RADSEARCH to develop a new regression algorithm for learning real-valued outputs, called RADREG.\n\nI am also interested in the field of Bayesian networks, specifically in developing techniques for quickly learning probability density functions from data in low-dimensional continuous space. I have proposed a kind of Bayesian networks in which low-dimensional mixtures of Gaussians over different subsets of the domain's variables are combined into a coherent joint probability model over the entire domain. I have presented efficient heuristic algorithms for automatically learning these networks from data and have performed comparative experiments that illustrate their effectiveness in modeling real scientific data and synthetic data.\n\nIn the field of Natural Language Processing, I have been working on the problem of replication and reproduction, specifically taking Target Dependent Sentiment Analysis as a case study. I have shown how recent work in the field has not consistently released code, or described settings for learning methods in enough detail, and lacks comparability and generalisability in train, test or validation data. To investigate generalisability and to enable state of the art comparative evaluations, I have carried out the first reproduction studies of three groups of complementary methods and performed the first large-scale mass evaluation on six different English datasets.\n\nI am also interested in developing algorithms for large graphs, specifically for accelerating random walk approaches to compute proximity measures. I have introduced a truncated variation on a well-known measure, namely commute times arising from random walks on graphs, and have",
    "collaborators": [
      "Jeff Schneider",
      "Scott Davies"
    ],
    "institute": null
  },
  "2b098fbc-3e7c-4deb-820f-a197c2d929ee": {
    "pk": "2b098fbc-3e7c-4deb-820f-a197c2d929ee",
    "name": "Yoshua Bengio",
    "bio": " I am a researcher focused on deep learning, with a particular interest in the practical aspects of training and debugging deep neural networks. I enjoy providing practical recommendations for hyper-parameter tuning, especially in the context of back-propagated gradient and gradient-based optimization. I am aware of the challenges that come with adjusting many hyper-parameters and the potential for more interesting results in deeper architectures.\n\nIn my research, I explore forward-looking directions for deep learning, such as scaling algorithms to larger models and datasets, reducing optimization difficulties, designing efficient inference and sampling procedures, and learning to disentangle factors of variation in observed data. I am also interested in the biological plausibility of deep learning algorithms and have shown that a particular form of target propagation, based on learned inverses of each layer, can give rise to an update rule that corresponds to an approximate Gauss-Newton gradient-based optimization.\n\nI have proposed a theory that relates the difficulty of learning in deep architectures to culture and language, emphasizing the importance of human culture and the evolution of ideas in countering optimization difficulties. I am also interested in the problem of estimating or propagating gradients through stochastic neurons and have presented two novel families of solutions for this challenge.\n\nI believe that auto-encoders can provide credit assignment in deep networks via target propagation, reducing the reliance on derivatives for credit assignment across many levels of non-linearities. I have also proposed a new prior for learning representations of high-level concepts, inspired by cognitive neuroscience theories of consciousness, and have shown that early inference in energy-based models with latent variables corresponds to propagating error gradients into internal layers, similarly to back-propagation.\n\nIn summary, I am a researcher dedicated to advancing the field of deep learning through practical recommendations, theoretical insights, and a focus on both biological plausibility and the challenges of optimization in deep architectures.",
    "collaborators": [
      "Asja Fischer",
      "Jonathan Binas",
      "Guillaume Alain"
    ],
    "institute": null
  },
  "bb51288f-8c26-474e-9da7-cb4eaf3c9963": {
    "pk": "bb51288f-8c26-474e-9da7-cb4eaf3c9963",
    "name": "Quanquan Gu",
    "bio": " I am a researcher specializing in machine learning, with a focus on developing computationally efficient and statistically optimal algorithms for high-dimensional data analysis. My work includes proposing a nonconvex estimator for joint multivariate regression and precision matrix estimation in the high-dimensional regime, which attains a linear rate of convergence to the true regression coefficients and precision matrix simultaneously, up to the statistical error. This algorithm not only outperforms existing methods in terms of computational efficiency and convergence guarantees but also achieves the optimal finite sample statistical rate up to a logarithmic factor.\n\nI have also developed a differentially private high-dimensional sparse learning framework using the idea of knowledge transfer. This framework distills the knowledge from a \"teacher\" estimator trained on a private dataset and creates a new dataset from auxiliary features to train a differentially private \"student\" estimator. This method achieves improved utility guarantees compared with the best known results for sparse linear and logistic regression.\n\nIn addition, I have presented a unified framework for low-rank matrix estimation with nonconvex penalties, which attains a faster statistical rate than traditional low-rank matrix estimators with nuclear norm penalties. I have also proven that under a certain condition on the magnitude of the nonzero singular values, the proposed estimator enjoys oracle property, i.e., exactly recovers the true rank of the matrix.\n\nMy work on the training and generalization of deep neural networks in the over-parameterized regime shows that the expected 0-1 loss of a wide enough ReLU network trained with stochastic gradient descent (SGD) and random initialization can be bounded by the training loss of a random feature model induced by the network gradient at initialization. This result yields a generalization error bound in the order of ~O(n^(-1/2)) that is independent of the network width.\n\nI have proposed a unified non-convex optimization framework for the analysis of neural network training, introducing the notions of proxy convexity and proxy Polyak-Lojasiewicz (PL) inequalities. These notions allow for efficient guarantees for proxy objective functions when using gradient methods.\n\nFurthermore, I have studied the lower bounds for smooth nonconvex finite-sum optimization, proving tight lower bounds for the complexity of finding epsilon-suboptimal point and",
    "collaborators": [
      "Yuan Cao",
      "Jinghui Chen",
      "Lingxiao Wang",
      "Huan Gui",
      "Spencer Frei"
    ],
    "institute": null
  },
  "0aa7af2f-b9d1-441d-914e-3550e284a12a": {
    "pk": "0aa7af2f-b9d1-441d-914e-3550e284a12a",
    "name": "Yuan Cao",
    "bio": " I am a researcher with a strong background in algebra, coding theory, and optical networks. My work is focused on the classification and enumeration of various types of cyclic codes over different rings and fields, as well as the study of their structures and dual codes. I have also contributed to the development of a flexible training framework for conditional random fields using natural gradient descent and Bregman divergences.\n\nIn my recent work, I have presented an explicit representation and enumeration for all distinct $(\\delta+\u03b1u^2)$-constacyclic codes of length $2n$ over $R=F_{2^m}[u]/\\langle u^4\\rangle$, where $2^m$ is a finite field of cardinality $2^m$, and $n$ is an odd positive integer. I have also studied the structure of $(1+pw)$-constacyclic codes of arbitrary length over the non-principal ideal ring $Z_{p^s} +uZ_{p^s}$, where $p$ is a prime, $w$ is a unit in $Z_{p^s}$, and $s$ is an integer satisfying $sgeq 2$. I have given enumerations for the number of all codes and the number of codewords in each code, and the structure of dual codes for these codes.\n\nIn addition, I have investigated self-dual $(1+2w)$-constacyclic codes over $Z_{2^s} +uZ_{2^s}$, where $w=2^{s-2}-1$ or $2^{s-1}-1$ if $sgeq 3$, and $w=1$ if $s=2$. I have also presented a canonical form decomposition and the structure for any negacyclic code over $R=Z_{4}[v]/\\langle v^2+2v\\rangle$ of length $2n$, where $n$ is an odd positive integer. From this decomposition, I have obtained a complete classification of all these codes, and given the cardinality and the dual code for each of these codes. I have also presented self-dual negacyclic codes over $R$ of length $2n$.\n\nFurthermore, I have constructed some optimal constacyclic codes over $F_{3}$ and $F_{5}$ using the Gray image of linear $\\lambda$-constacyclic codes",
    "collaborators": [
      "Yonglin Cao",
      "Qingguo Li"
    ],
    "institute": null
  },
  "85619cf9-5be6-411b-8d85-fbe5d6d35e1a": {
    "pk": "85619cf9-5be6-411b-8d85-fbe5d6d35e1a",
    "name": "Pieter Abbeel",
    "bio": " I am a researcher with a focus on machine learning, specifically in the areas of deep reinforcement learning, multi-GPU computations, and policy parameterization. I have developed several tools and techniques to advance the field and improve the efficiency and effectiveness of deep reinforcement learning algorithms.\n\nOne of my most notable contributions is Synkhronos, a Multi-GPU Theano Extension for Data Parallelism. This tool allows users to write serial programs without risk of race conditions, while the framework automatically handles execution and synchronization across devices. By using the NVIDIA Collective Communication Library for high-bandwidth inter-GPU communication, Synkhronos achieves a near-linear speedup of 7.5x on an NVIDIA DGX-1 using 8 GPUs.\n\nI have also developed rlpyt, a Research Code Base for Deep Reinforcement Learning in PyTorch. This code base implements all three major families of deep reinforcement learning algorithms - deep Q-learning, policy gradients, and Q-value policy gradients - on top of a shared, optimized infrastructure. It contains modular implementations of many common deep RL algorithms in Python using PyTorch, and is designed as a high-throughput code base for small- to medium-scale research in deep RL.\n\nIn addition, I have explored the connection between contrastive learning and supervised learning through the perspective of hybrid discriminative-generative training of energy-based models. I have shown that this unified view leads to improved performance on classification accuracy of WideResNet on CIFAR-10 and CIFAR-100, as well as improved performance on robustness, out-of-distribution detection, and calibration.\n\nI have also proposed a new policy parameterization for representing 3D rotations during reinforcement learning, called Bingham Policy Parameterization (BPP). This parameterization models the Bingham distribution and allows for better rotation (quaternion) prediction over a Gaussian policy parameterization in a range of reinforcement learning tasks.\n\nMost recently, I have investigated the emergence of grounded compositional language in multi-agent populations, and proposed a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined",
    "collaborators": [
      "Adam Stooke",
      "Hao Liu",
      "Stephen James",
      "Igor Mordatch"
    ],
    "institute": null
  },
  "eaad3f05-c23e-4560-bc7b-0713c39e9c4e": {
    "pk": "eaad3f05-c23e-4560-bc7b-0713c39e9c4e",
    "name": "Chelsea Finn",
    "bio": " I am a researcher focused on machine learning, with a particular interest in meta-learning, deep learning, and reinforcement learning. My work aims to enable models to learn from data more effectively and efficiently, and to develop methods that allow for unsupervised or self-supervised learning.\n\nIn my research on meta-learning, I have explored the use of recurrent models and deep representations to approximate any learning algorithm. I have found that deep representation combined with standard gradient descent has sufficient capacity to approximate any learning algorithm, and that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.\n\nI have also applied meta-learning to the problem of one-shot learning, allowing the model to decide which examples are worth labeling during classification. I have demonstrated that this approach can achieve a higher prediction accuracy than a similar model on a purely supervised task, or trade prediction accuracy for fewer label requests.\n\nIn the area of reinforcement learning, I have developed a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data. This approach enables a real robot to perform nonprehensile manipulation, such as pushing objects, and can handle novel objects not seen during training.\n\nI am also interested in the problem of planning over long horizons to reach distant goals. To that end, I have proposed a framework for subgoal generation and planning, hierarchical visual foresight (HVF), which generates subgoal images conditioned on a goal image and uses them for planning. The subgoal images are directly optimized to decompose the task into easy to plan segments, and as a result, the method naturally identifies semantically meaningful states as subgoals.\n\nIn addition, I have studied a practical sequential multi-task RL problem that is motivated by the constraints of physical robotic systems, and derived an approach that effectively leverages the data and policies learned for previous tasks to cumulatively grow the robot's skill-set.\n\nI am also interested in the development of more stable and scalable algorithms in the field of generative modeling, and have shown that certain IRL methods are mathematically equivalent to GANs. I have also explored the use of probabilistic meta-learning algorithms for few-shot learning, which can sample models for a new task from a model distribution, and have",
    "collaborators": [
      "Sergey Levine",
      "Pieter Abbeel",
      "Mark Woodward",
      "Suraj Nair",
      "Annie Xie"
    ],
    "institute": null
  },
  "eec6f526-dd1a-4cb9-82ab-495ade152d20": {
    "pk": "eec6f526-dd1a-4cb9-82ab-495ade152d20",
    "name": "Sergey Levine",
    "bio": " I am a researcher focused on the intersection of machine learning, reinforcement learning, and control theory. My work involves exploring the application of deep and recurrent neural networks to complex control tasks, such as locomotion, where the network is used to represent a control policy that maps the state of the system directly to the torques at each joint. I have used guided policy search, a recent reinforcement learning algorithm, to successfully train neural network controllers with thousands of parameters, allowing for the comparison of various architectures.\n\nMy research has also focused on understanding the connection between reinforcement learning and inference in probabilistic models. I have shown that a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. This connection has considerable value when it comes to algorithm design, as it allows for the use of a wide array of approximate inference tools and the ability to reason about compositionality and partial observability.\n\nI am also interested in the use of unlabeled data in machine learning and have argued that a general, principled, and powerful framework for utilizing unlabeled data can be derived from reinforcement learning, using general purpose unsupervised or self-supervised reinforcement learning objectives in concert with offline reinforcement learning methods that can leverage large datasets.\n\nIn the field of robotics, I have presented a general toolkit for experiential learning of robotic navigation skills that unifies several recent approaches, described the underlying design principles, and discussed open problems and directions for future work. I have also developed a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data, enabling a real robot to perform nonprehensile manipulation.\n\nAdditionally, I have explored the connection between MaxEnt RL, robust control, and POMDPs, and have shown that MaxEnt RL can be used to solve certain classes of control problems with variability in the reward function. I have also proposed the amortized conditional normalized maximum likelihood (ACNML) method as a scalable general-purpose approach for uncertainty estimation, calibration, and out-of-distribution robustness with deep networks.\n\nIn summary, my research focuses on the application of deep learning and reinforce",
    "collaborators": [
      "Dhruv Shah",
      "William Montgomery",
      "Chelsea Finn",
      "Aurick Zhou"
    ],
    "institute": null
  },
  "c8f75198-a05b-46f8-8363-ecb6d36571a7": {
    "pk": "c8f75198-a05b-46f8-8363-ecb6d36571a7",
    "name": "Timothy P. Lillicrap",
    "bio": " I am a researcher with a strong interest in understanding the workings of neural networks and how they can be applied to various fields, such as language modeling, deep learning, and reinforcement learning. I am particularly intrigued by the idea that rules for development and learning in brains may be far easier to understand than their resulting properties, and I believe that focusing on learning and development is key to making progress in neuroscience.\n\nIn my work, I have presented the Compressive Transformer, an attentive sequence model that compresses past memories for long-range sequence learning. This model has achieved state-of-the-art language modeling results in the WikiText-103 and Enwik8 benchmarks, and has also been used as a memory mechanism for reinforcement learning. I have also proposed a new open-vocabulary language modeling benchmark derived from books, PG-19, to promote the domain of long-range sequence learning.\n\nIn addition to my work on sequence learning, I have also explored the use of random feedback weights in deep neural networks as a way to assign blame and facilitate learning. I have shown that this simple algorithm can perform as quickly and accurately as backpropagation on a variety of problems, and provides a plausible basis for how a neuron can be adapted using error signals generated at distal locations in the brain.\n\nI am also interested in the idea of using multi-compartment neurons in deep learning algorithms as a way to understand how the brain optimizes cost functions. I have shown that a deep learning algorithm that utilizes segregated dendrites can help to explain the dendritic morphology of neocortical pyramidal neurons and improve the performance of image categorization tasks.\n\nIn the area of continual learning, I have examined the issue of catastrophic forgetting and proposed the use of experience replay buffers with a mixture of on- and off-policy learning as a solution. I have shown that this strategy can substantially reduce catastrophic forgetting in both Atari and DMLab domains, and can still learn new tasks quickly.\n\nOverall, my research is focused on developing and applying neural networks and deep learning algorithms to various tasks, with a particular focus on understanding the underlying mechanisms and principles that make these approaches successful.",
    "collaborators": [
      "Konrad P. Kording",
      "Jack W. Rae",
      "Anna Potapenko",
      "Siddhant M. Jayakumar",
      "Daniel Cownden"
    ],
    "institute": null
  },
  "6e5ab67c-4b8f-4876-a6a4-d71037dd6f42": {
    "pk": "6e5ab67c-4b8f-4876-a6a4-d71037dd6f42",
    "name": "Caglar Gulcehre",
    "bio": " I am a researcher with a focus on machine learning, particularly in the optimization of deep neural networks and large-scale learning problems. I have worked on developing a robust adaptive secant method for stochastic gradient (ADASECANT) that utilizes curvature information for automatically tuning learning rates, which has led to better performance in deep neural networks compared to popular stochastic gradient algorithms.\n\nI have also extended the Neural Turing Machine (NTM) model into a dynamic neural Turing machine (D-NTM) by introducing a trainable memory addressing scheme, which allows the D-NTM to learn a wide variety of location-based addressing strategies including both linear and nonlinear ones. I have implemented the D-NTM with both continuous, differentiable and discrete, non-differentiable read/write mechanisms and evaluated it on Facebook bAbI tasks, showing that it outperforms NTM and LSTM baselines.\n\nIn addition, I have proposed mollifying networks, which attack the problem of optimization of highly non-convex neural networks by starting with a smoothed objective function that gradually has a more non-convex energy landscape during the training. I have shown improvements on various difficult optimization tasks and established a relationship with recent works on continuation methods for neural networks and mollifiers.\n\nI have also investigated the integration of a planning mechanism into an encoder-decoder architecture with an explicit alignment for character-level machine translation and developed a model that plans ahead when it computes alignments between the source and target sequences. I have shown that it outperforms a strong baseline on three character-level decoder neural machine translation on WMT'15 corpus.\n\nFurthermore, I have proposed a planning mechanism for sequence-to-sequence models using attention, which can plan ahead in the future when it computes its alignments between input and output sequences. I have shown that it outperforms a strong baseline on character-level translation tasks from WMT'15, the algorithmic task of finding Eulerian circuits of graphs, and question generation from the text.\n\nI am also interested in the study of recurrent neural networks (RNNs) and have compared different types of recurrent units in RNNs, especially focusing on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recur",
    "collaborators": [
      "Yoshua Bengio",
      "Marcin Moczulski",
      "Sarath Chandar",
      "Kyunghyun Cho",
      "Francis Dutil"
    ],
    "institute": null
  }
}

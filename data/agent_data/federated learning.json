{
  "9f8e6810-9736-4f7c-a4d9-d99124415bdb": {
    "pk": "9f8e6810-9736-4f7c-a4d9-d99124415bdb",
    "name": "Song Guo",
    "bio": " I am a researcher with a focus on developing automatic models for computer-aided diagnosis, particularly in the field of ophthalmology and cardiovascular diseases. I have proposed the Detail-Preserving Network (DPN), a high-resolution representation model for retinal vessel segmentation. This model breaks away from the traditional encoder-decoder architecture, which often results in the loss of detailed information. The DPN maintains a high/full resolution during processing, avoiding the loss of detailed information and resulting in competitive/better performance in terms of segmentation accuracy, speed, and model size compared to state-of-the-art methods.\n\nIn the area of zero-shot recognition, I have proposed a novel learning framework that adaptively adjusts the semantic feature space, handling domain shift and hubness problems. This is achieved by formulating the solution to a more efficient framework that significantly boosts training. My work in this area has shown remarkable performance improvement compared to other existing methods.\n\nI have also proposed an Exclusivity Enhanced unsupervised feature learning approach for the autoencoder (AE), which improves the conventional AE by utilizing the exclusivity concept to cooperate with feature extraction. This approach has shown remarkable performance compared with other related methods.\n\nFurthermore, I have worked on zero-shot learning, proposing a novel model called AMS-SFE, which considers the alignment of manifold structures by semantic feature expansion. This model builds upon an autoencoder-based model to expand the semantic features from the visual inputs and aligns both feature spaces by expanding semantic features, deriving benefits such as enhancing the semantic feature space and implicitly aligning the manifold structures between the visual and semantic feature spaces.\n\nIn addition to my work in computer-aided diagnosis and zero-shot recognition, I have also contributed to the field of recurrence relations for rooted forests and position-aware neural networks for traffic prediction. My research interests are diverse, and I am committed to exploring new methods and techniques for improving the field of machine learning and image processing.",
    "collaborators": [
      "Jingcai Guo"
    ],
    "institute": null
  },
  "96460ec5-cf29-426f-bca3-c095a5b24342": {
    "pk": "96460ec5-cf29-426f-bca3-c095a5b24342",
    "name": "Ismar Volic",
    "bio": " I am a researcher with a focus on the topology of knot and link spaces, particularly the use of configuration space integrals to study these spaces. My work involves filling in the gaps in the literature regarding Bott and Taubes' important discovery that certain combinations of configuration space integrals produce cohomology classes of spaces of knots. I have also studied the cohomology of spaces of string links and braids in $\\mathbb{R}^n$ using configuration space integrals, which give a chain map from certain diagram complexes to the deRham algebra of differential forms on these spaces for $n>3$. For $n=3$, these integrals produce all finite type invariants of string links and braids.\n\nIn addition to my work on configuration space integrals, I have also explored the use of calculus of the embedding functor in the study of long knots. I have associated a Taylor tower supplied by calculus of the embedding functor to the space of long knots and studied its cohomology spectral sequence. I have shown that the spectral sequence collapses along the line of total degree zero and that the Taylor tower represents a universal finite type knot invariant. I have also given an overview of how calculus of the embedding functor can be used for the study of long knots and summarized various results connecting the calculus approach to the rational homotopy type of spaces of long knots, collapse of the Vassiliev spectral sequence, Hochschild homology of the Poisson operad, and finite type knot invariants.\n\nI have also written about the formality of the little N-disks operad over the field of real numbers, which holds in the category of operads of chain complexes and also in some sense in the category of commutative differential graded algebras. I have developed the details of Kontsevich's proof of this formality and proved a relative version of the formality for the inclusion of the little m-disks operad in the little N-disks operad for $N>=2m+1$.\n\nMore recently, I have extended the modeling of political structures from simplicial complexes to hypergraphs, which allows for the analysis of more complex political dynamics. I have extended topological constructions such as wedge, cone, and collapse from simplicial complexes to hypergraphs and used them to study mergers, mediators",
    "collaborators": [
      "Pascal Lambrechts",
      "Zixu Wang",
      "Franjo Sarcevic",
      "Yiran Chen"
    ],
    "institute": null
  },
  "a5bad962-f528-4a87-9985-58fd2c514802": {
    "pk": "a5bad962-f528-4a87-9985-58fd2c514802",
    "name": "H. Brendan McMahan",
    "bio": " I am a researcher specializing in online convex optimization, with a focus on unconstrained optimization problems. I have developed algorithms that achieve near-optimal regret bounds in unconstrained settings, without requiring prior knowledge of constraints on the comparator point. I have also shown lower bounds demonstrating the near-optimality of these guarantees.\n\nIn addition to unconstrained optimization, I have also worked on reducing the memory footprint of popular large-scale online learning methods. I have done this by projecting the weight vector onto a coarse discrete set using randomized rounding, which reduces RAM usage during training and prediction with minimal loss in accuracy. I have also shown that randomized counting can be used to implement per-coordinate learning rates, improving model quality with little additional RAM.\n\nI have also introduced an online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This algorithm's regret bounds are worst-case optimal, and for certain realistic classes of loss functions, they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance without requiring prior knowledge of this structure.\n\nIn the area of prediction systems, I have focused on calibration for auction selection mechanisms, specifically for click-through-rate (CTR) prediction in search ad auctions. I have shown that certain natural notions of calibration can be impossible to achieve, depending on the details of the auction. I have also shown that it can be impossible to maximize auction efficiency while using calibrated predictions. However, I have given conditions under which calibration is achievable and simultaneously maximizes auction efficiency.\n\nI have also studied algorithms for online linear optimization in Hilbert spaces, focusing on the case where the player is unconstrained. I have developed a novel characterization of a large class of minimax algorithms, recovering and even improving several previous results as immediate corollaries. I have also derived an algorithm that provides a regret bound of $\\mathcal{O}\\Big(U \\sqrt{T \\log(U \\sqrt{T} \\log^2 T +1)}\\Big)$, where $U$ is the $L_2$ norm of an arbitrary comparator and both $T$ and $U$ are unknown to the player. This bound is optimal up to $\\sqrt{\\log \\log T}$ terms.\n\nI have also",
    "collaborators": [
      "Matthew Streeter",
      "Daniel Golovin",
      "D. Sculley",
      "Michael Young",
      "Omkar Muralidharan"
    ],
    "institute": null
  },
  "fbac425b-927e-4ca7-bce7-91203c5ffc34": {
    "pk": "fbac425b-927e-4ca7-bce7-91203c5ffc34",
    "name": "Yiran Chen",
    "bio": " I am a researcher with a focus on developing and applying advanced mathematical and computational techniques to address important real-world problems. In particular, I have been working on the application of topological data analysis to the spread of the COVID-19 pandemic, using the Mapper algorithm to create visualizations that encode a variety of geometric features of the data cloud and reflect the development of the pandemic across time and space. These Mapper graphs have the potential to become a useful predictive tool for the spread of the coronavirus.\n\nIn addition to my work on the pandemic, I am also interested in the development of neural architectures that are capable of logical reasoning, which I believe is important for a wide range of applications such as natural language processing. Towards this goal, I have proposed a symbolic reasoning architecture that chains many join operators together to model output logical expressions, and have shown that such an ensemble of join-chains can express a broad subset of first-order logical expressions that is particularly useful for modeling natural languages.\n\nI am also concerned about the privacy implications of machine learning models, and have studied the privacy leakage of adversarial training models in federated learning systems. Using a novel privacy attack that I designed, I have shown that attackers can exploit adversarial training models in federated learning systems to accurately reconstruct users' private training images, even when the training batch size is large.\n\nTo enhance the privacy of collaborative inference, I have introduced a defense strategy called PrivaScissors, which is designed to reduce the mutual information between a model's intermediate outcomes and the device's data and predictions. I have evaluated PrivaScissors's performance on several datasets in the context of diverse attacks and have offered a theoretical robustness guarantee.\n\nI am also interested in the security vulnerabilities of deep learning models, and have developed a powerful untargeted adversarial attack for action recognition systems in both white-box and black-box settings. I have shown that these attacks can significantly degrade a model's performance with sparsely and imperceptibly perturbed examples, and have demonstrated the transferability of the attacks to black-box action recognition systems.\n\nIn the area of reinforcement learning, I have proposed a new class of threat models, called snooping threat models, that are unique to reinforcement learning. In these snooping threat models, the adversary does not have the ability to interact with the target agent",
    "collaborators": [
      "Hai Li",
      "Matthew Inkawhich",
      "Ismar Volic",
      "Jianyi Zhang",
      "Jianshu Chen"
    ],
    "institute": null
  },
  "942346b6-9f4a-480d-9621-f8a4fe19b69a": {
    "pk": "942346b6-9f4a-480d-9621-f8a4fe19b69a",
    "name": "Nicholas Lane",
    "bio": " I am a researcher with a focus on developing and improving machine learning models and techniques for various applications. In the realm of Automatic Speech Recognition (ASR), I have explored the use of knowledge distillation from ensembles of acoustic models to increase recognition performance. I have proposed an extension of multi-teacher distillation methods to joint CTC-attention end-to-end ASR systems and introduced three novel distillation strategies that integrate the error rate metric to the teacher selection process. These strategies have been shown to directly distill and optimize the student model towards the relevant metric for speech recognition, resulting in state-of-the-art error rates on several datasets and languages.\n\nIn the field of distant ASR, I have proposed the use of quaternion neural networks to capture internal relations between multi-channel audio recordings. By replacing the standard dot product with the Hamilton one, quaternion algebra offers a simple and elegant way to model dependencies between elements. I have shown that a quaternion long-short term memory neural network (QLSTM), trained on the concatenated multi-channel speech signals, outperforms equivalent real-valued LSTM on two different tasks of multi-channel distant speech recognition.\n\nI have also worked on predicting patient outcomes in the Intensive Care Unit (ICU) using Graph Representation Learning. I proposed a strategy to exploit diagnoses as relational information by connecting similar patients in a graph and introduced LSTM-GNN for patient outcome prediction tasks, a hybrid model combining Long Short-Term Memory networks (LSTMs) for extracting temporal features and Graph Neural Networks (GNNs) for extracting the patient neighborhood information. I have demonstrated that LSTM-GNNs outperform the LSTM-only baseline on length of stay prediction tasks on the eICU database.\n\nAdditionally, I have developed a method to speed up training and inference in deep neural networks using structured pruning applied before training. Unlike previous works on pruning before training which prune individual weights, my work develops a methodology to remove entire channels and hidden units with the explicit aim of speeding up training and inference. I have also introduced a compute-aware scoring mechanism which enables pruning in units of sensitivity per FLOP removed, allowing even greater speed ups.\n\nI am also interested in unsupervised domain adaptation (uDA) in distributed settings.",
    "collaborators": [
      "Yan Gao",
      "Titouan Parcollet"
    ],
    "institute": null
  },
  "25ab3876-eee5-48d5-8f57-f7c527486c27": {
    "pk": "25ab3876-eee5-48d5-8f57-f7c527486c27",
    "name": "Daniel Ramage",
    "bio": " I am a researcher with a focus on developing and analyzing methods for preserving privacy in data analysis and machine learning. I have worked on various projects involving local privacy, federated learning, and differential privacy.\n\nIn my research on discrete distribution estimation under local privacy, I developed new mechanisms, such as hashed K-ary Randomized Response (KRR), that allow service providers to learn the distribution of a categorical statistic of interest without collecting the underlying data. These mechanisms have been shown to empirically meet or exceed the utility of existing mechanisms at all privacy levels, and are theoretically order-optimal at different privacy regimes.\n\nI have also researched the flow of language across fields in academia by analyzing the text of dissertation abstracts from 1980 to 2010. My statistical model revealed the directional flow of ideas, methods, and vocabulary in science, and identified methodological fields that export broadly, emerging topical fields that borrow heavily and expand, and old topical fields that grow insular and retract.\n\nIn the area of federated learning, I have worked on methods for evaluating strategies for personalization of global models without exporting sensitive user data to servers. I have also applied federated learning in a commercial, global-scale setting to train, evaluate and deploy a model to improve virtual keyboard search suggestion quality without direct access to the underlying user data.\n\nI have demonstrated that it is possible to train large recurrent language models with user-level differential privacy guarantees with only a negligible cost in predictive accuracy. I have also proposed a context-aware framework of local differential privacy that allows a privacy designer to incorporate the application's context into the privacy definition.\n\nIn addition, I have investigated how large language models trained on public data can improve the quality of pre-training data for the on-device language models trained with DP and FL. I have carefully designed LLM prompts to filter and transform existing public data, and generate new data to resemble the real user data distribution.\n\nI have also introduced the setting of Federated Optimization, a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are distributed (unevenly) over an extremely large number of nodes, but the goal remains to train a high-quality centralized model. In this setting, communication efficiency is of utmost importance.\n\nI am currently",
    "collaborators": [
      "Peter Kairouz",
      "Keith Bonawitz",
      "Hubert Eichner",
      "Fran\u00e7oise Beaufays",
      "H. Brendan McMahan"
    ],
    "institute": null
  },
  "4a468475-f11a-4a61-9fa4-927c86605c86": {
    "pk": "4a468475-f11a-4a61-9fa4-927c86605c86",
    "name": "Peter Kairouz",
    "bio": " I am a researcher with a focus on privacy and communication in the context of data analysis and communication systems. I have worked on a variety of topics within this field, including discrete distribution estimation under local privacy, MIMO communications over multi-mode optical fibers, and extremal mechanisms for local differential privacy.\n\nIn my work on discrete distribution estimation under local privacy, I developed new mechanisms for estimating the distribution of a categorical statistic of interest without collecting the underlying data. These mechanisms, including hashed K-ary Randomized Response (KRR), have been shown to empirically meet or exceed the utility of existing mechanisms at all privacy levels. I also provided new theoretical results demonstrating the order-optimality of KRR and the existing RAPPOR mechanism at different privacy regimes.\n\nIn my research on MIMO communications over multi-mode optical fibers, I presented input-output coupling schemes that allow users to couple and extract a reasonable number of signals from a fiber with many modes. This approach is attractive because it is scalable, meaning that the fibers do not have to be replaced every time the number of transmitters or receivers is increased. I also presented a statistical channel model that incorporates various factors affecting the communication, such as intermodal dispersion, chromatic dispersion, mode dependent losses, mode coupling, and input-output coupling. I showed that the statistics of the fiber's frequency response are independent of frequency, which simplifies the computation of the average Shannon capacity of the fiber. I also provided an input-output coupling strategy that leads to an increase in the overall capacity, and presented a statistical input-output coupling model to quantify the loss in capacity when channel state information is not available at the transmitter.\n\nIn my work on extremal mechanisms for local differential privacy, I studied the fundamental trade-off between local differential privacy and utility. I introduced a combinatorial family of extremal privatization mechanisms, which I called staircase mechanisms, and showed that it contains the optimal privatization mechanisms for a broad class of information theoretic utilities such as mutual information and $f$-divergences. I also proved that for any utility function and any privacy level, solving the privacy-utility maximization problem is equivalent to solving a finite-dimensional linear program, the outcome of which is the optimal staircase mechanism.\n\nI am also interested in private federated learning, where I proposed techniques for reducing communication without the need",
    "collaborators": [
      "Sewoong Oh",
      "Pramod Viswanath",
      "Mario Diaz",
      "Lalitha Sankar",
      "Keith Bonawitz"
    ],
    "institute": null
  },
  "01ef4b15-4c49-4916-b072-2370f749e5ef": {
    "pk": "01ef4b15-4c49-4916-b072-2370f749e5ef",
    "name": "Baochun Li",
    "bio": " I am a researcher with a focus on addressing various problems in data centers, cloud computing systems, and federated learning. My work involves developing practical and effective solutions that improve the performance, efficiency, and security of these systems.\n\nIn the context of data centers, I have worked on minimizing flow completion times (FCT) for short TCP flows that are critical for many interactive applications. I proposed RepFlow, a simple yet effective approach that replicates each short flow to reduce completion times without requiring any changes to switches or host kernels. RepFlow provides a 50%-70% speedup in both mean and 99-th percentile FCT for all loads, and offers near-optimal FCT when used with DCTCP.\n\nIn the area of cloud computing systems, I designed a multi-resource allocation mechanism called DRFH that generalizes the notion of Dominant Resource Fairness (DRF) from a single server to multiple heterogeneous servers. DRFH provides desirable properties such as envy-freeness, individual rationality, and truthfulness. I also developed a simple heuristic that implements DRFH in real-world systems, which significantly outperforms the traditional slot-based scheduler, leading to higher resource utilization and shorter job completion times.\n\nRegarding federated learning, I proposed FedReview, a review mechanism that identifies and declines potential poisoned updates in federated learning. FedReview uses a review mechanism where the server randomly assigns a subset of clients as reviewers to evaluate the model updates on their training datasets in each round. The reviewers rank the model updates based on the evaluation results, and the server employs a majority voting mechanism to integrate the rankings and remove the potential poisoned updates in the model aggregation process.\n\nI have also worked on reducing electricity demand charge for data centers with partial execution. I found that demand charge per kW for the maximum power used is a major component of the total cost. I proposed a simple idea of using partial execution to reduce the peak power demand and energy cost of data centers. I systematically studied the problem of scheduling partial execution with stringent SLAs on response quality and developed a distributed optimization algorithm to solve the large-scale request routing problem.\n\nIn addition, I presented Pisces, an asynchronous FL system with intelligent participant selection and model aggregation for accelerated training. Pisces uses",
    "collaborators": [
      "Hong Xu",
      "Wei Wang",
      "Ben Liang",
      "Sijia Chen",
      "Tianhang Zheng"
    ],
    "institute": null
  },
  "54729e54-517a-46d5-a10f-0bbffd6c8712": {
    "pk": "54729e54-517a-46d5-a10f-0bbffd6c8712",
    "name": "Ben Liang",
    "bio": " I am a researcher with a focus on wireless networks and stochastic geometry. I have contributed to the field by developing comprehensive analytical frameworks to compare different access modes in two-tier femtocell networks, taking into account interference at both the macrocell and femtocell levels. I have derived sufficient conditions for open access and closed access to outperform each other in terms of outage probability, leading to closed-form expressions to upper and lower bound the difference in the targeted received power between the two access modes.\n\nIn addition to my work on femtocell networks, I have also studied the benefits of node cooperation in conjunction with multi-hopping on the network capacity. I have proposed a multi-phase communication scheme, combining distributed MIMO transmission with multi-hop forwarding among clusters of nodes, and determined the optimal cluster size. This has provided a constructive lower bound on the network capacity.\n\nI have also researched the insensitivity of user distribution in multicell networks under general mobility and session patterns. I have shown that the user distribution is insensitive to user movement patterns, general and dependently distributed channel holding times, and depends only on the average arrival rate and average channel holding time at each cell. This result is completely characterized by an open network with M/M/infinity queues.\n\nFurthermore, I have presented an optimal frame transmission scheme for streaming scalable video over a link with limited capacity. I have solved the problem for two general classes of hierarchical prediction structures and developed a jointly optimal frame selection and scheduling algorithm with computational complexity that is quadratic in the number of frames.\n\nI have also studied joint spectrum allocation and user association in heterogeneous cellular networks with multiple tiers of base stations. I have applied a stochastic geometric approach to derive the average downlink user data rate in a closed-form expression and employed it as the objective function in jointly optimizing spectrum allocation and user association. I have proposed a computationally efficient Structured Spectrum Allocation and User Association (SSAUA) approach, solving the optimization problem optimally when the density of users is low, and near-optimally with a guaranteed performance bound when the density of users is high.\n\nRecently, I have considered the problem of distributed online optimization, with a group of learners connected via a dynamic communication graph. I have proposed a novel algorithm, termed Distributed Online Mir",
    "collaborators": [
      "Wei Bao",
      "Sam Vakil",
      "Saied Mehdian",
      "Nima Eshraghi",
      "Jingrong Wang"
    ],
    "institute": null
  },
  "94457e10-15cd-4a52-9c16-302cdc7a3d9b": {
    "pk": "94457e10-15cd-4a52-9c16-302cdc7a3d9b",
    "name": "Daniel Golovin",
    "bio": " I am a researcher with a focus on developing algorithms and data structures for various optimization problems. In the past, I have worked on the B-skip-list, a uniquely represented alternative to B-trees that is simpler and easier to implement while maintaining strong performance guarantees. This work built upon my previous introduction of the B-treap, which has complex invariants and is more difficult to implement.\n\nI have also explored adaptive submodular optimization under matroid constraints, extending classic results to adaptive optimization problems under partial observability. This work resulted in a natural adaptive greedy algorithm that provides a $1/(p+1)$ approximation for the problem of maximizing an adaptive monotone submodular function subject to $p$ matroid constraints.\n\nIn addition to my work on optimization problems, I have also developed algorithms for online learning of assignments that maximize submodular functions. These algorithms have been applied to problems such as ad allocation with submodular utilities and dynamically ranking blogs to detect information cascades.\n\nI have also tackled the problem of Bayesian active learning with noise, developing a novel, greedy active learning algorithm called EC2 that is competitive with the optimal policy. This work resulted in the first competitiveness guarantees for Bayesian active learning with noisy observations.\n\nMost recently, I have worked on algorithms for online submodular maximization under a matroid constraint, as well as the use of random hypervolume scalarizations for provable multi-objective black box optimization. I have also explored methods for reducing the memory footprint of popular large-scale online learning methods through randomized rounding and randomized counting.\n\nI am passionate about using my expertise in algorithms and optimization to solve real-world problems and improve the efficiency and effectiveness of various systems and applications.",
    "collaborators": [
      "Andreas Krause",
      "Matthew Streeter",
      "Debajyoti Ray",
      "Qiuyi Zhang",
      "D. Sculley"
    ],
    "institute": null
  }
}

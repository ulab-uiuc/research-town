{
  "32a6f3ad-5771-4915-b8b6-9678adbb64e3": {
    "pk": "32a6f3ad-5771-4915-b8b6-9678adbb64e3",
    "title": "X-VILA: Cross-Modality Alignment for Large Language Model",
    "abstract": "We introduce X-VILA, an omni-modality model designed to extend the capabilities of large language models (LLMs) by incorporating image, video, and audio modalities. By aligning modality-specific encoders with LLM inputs and diffusion decoders with LLM outputs, X-VILA achieves cross-modality understanding, reasoning, and generation. To facilitate this cross-modality alignment, we curate an effective interleaved any-to-any modality instruction-following dataset. Furthermore, we identify a significant problem with the current cross-modality alignment method, which results in visual information loss. To address the issue, we propose a visual alignment mechanism with a visual embedding highway module. We then introduce a resource-efficient recipe for training X-VILA, that exhibits proficiency in any-to-any modality conversation, surpassing previous approaches by large margins. X-VILA also showcases emergent properties across modalities even in the absence of similar training data. The project will be made open-source.",
    "authors": [
      "Hanrong Ye",
      "De-An Huang",
      "Yao Lu",
      "Zhiding Yu",
      "Wei Ping",
      "Andrew Tao",
      "Jan Kautz",
      "Song Han",
      "Dan Xu",
      "Pavlo Molchanov",
      "Hongxu Yin"
    ],
    "url": "http://arxiv.org/abs/2405.19335v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d95aac5b-9b97-4e9b-b5b5-d06c7320a7c7": {
    "pk": "d95aac5b-9b97-4e9b-b5b5-d06c7320a7c7",
    "title": "LLMs Meet Multimodal Generation and Editing: A Survey",
    "abstract": "With the recent advancement in large language models (LLMs), there is a growing interest in combining LLMs with multimodal learning. Previous surveys of multimodal large language models (MLLMs) mainly focus on understanding. This survey elaborates on multimodal generation across different domains, including image, video, 3D, and audio, where we highlight the notable advancements with milestone works in these fields. Specifically, we exhaustively investigate the key technical components behind methods and multimodal datasets utilized in these studies. Moreover, we dig into tool-augmented multimodal agents that can use existing generative models for human-computer interaction. Lastly, we also comprehensively discuss the advancement in AI safety and investigate emerging applications as well as future prospects. Our work provides a systematic and insightful overview of multimodal generation, which is expected to advance the development of Artificial Intelligence for Generative Content (AIGC) and world models. A curated list of all related papers can be found at https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
    "authors": [
      "Yingqing He",
      "Zhaoyang Liu",
      "Jingye Chen",
      "Zeyue Tian",
      "Hongyu Liu",
      "Xiaowei Chi",
      "Runtao Liu",
      "Ruibin Yuan",
      "Yazhou Xing",
      "Wenhai Wang",
      "Jifeng Dai",
      "Yong Zhang",
      "Wei Xue",
      "Qifeng Liu",
      "Yike Guo",
      "Qifeng Chen"
    ],
    "url": "http://arxiv.org/abs/2405.19334v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4ecdd5c7-77b4-424e-b058-3e6d05d05e2c": {
    "pk": "4ecdd5c7-77b4-424e-b058-3e6d05d05e2c",
    "title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment",
    "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process. However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language. Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement. To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions. By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective. Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency. Our experimental results demonstrate that when finetuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings. Our code and models are available at https://github.com/shenao-zhang/SELM.",
    "authors": [
      "Shenao Zhang",
      "Donghan Yu",
      "Hiteshi Sharma",
      "Ziyi Yang",
      "Shuohang Wang",
      "Hany Hassan",
      "Zhaoran Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19332v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2d4f6c9e-e20b-4175-8c7a-82daf411d073": {
    "pk": "2d4f6c9e-e20b-4175-8c7a-82daf411d073",
    "title": "NPGA: Neural Parametric Gaussian Avatars",
    "abstract": "The creation of high-fidelity, digital versions of human heads is an important stepping stone in the process of further integrating virtual components into our everyday lives. Constructing such avatars is a challenging research problem, due to a high demand for photo-realism and real-time rendering performance. In this work, we propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings. We build our method around 3D Gaussian Splatting for its highly efficient rendering and to inherit the topological flexibility of point clouds. In contrast to previous work, we condition our avatars' dynamics on the rich expression space of neural parametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we distill the backward deformation field of our underlying NPHM into forward deformations which are compatible with rasterization-based rendering. All remaining fine-scale, expression-dependent details are learned from the multi-view videos. To increase the representational capacity of our avatars, we augment the canonical Gaussian point cloud using per-primitive latent features which govern its dynamic behavior. To regularize this increased dynamic expressivity, we propose Laplacian terms on the latent features and predicted dynamics. We evaluate our method on the public NeRSemble dataset, demonstrating that NPGA significantly outperforms the previous state-of-the-art avatars on the self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from real-world monocular videos.",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Martin R\u00fcnz",
      "Lourdes Agapito",
      "Matthias Nie\u00dfner"
    ],
    "url": "http://arxiv.org/abs/2405.19331v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "69ac0d6b-9eb4-487a-96f6-24da659b3b4e": {
    "pk": "69ac0d6b-9eb4-487a-96f6-24da659b3b4e",
    "title": "Barium stars as tracers of s-process nucleosynthesis in AGB stars III. Systematic deviations from the AGB models",
    "abstract": "Barium (Ba) stars help to verify asymptotic giant branch (AGB) star nucleosynthesis models since they experienced pollution from an AGB binary companion and thus their spectra carry the signatures of the slow neutron capture process (s process). For 180 Ba stars, we searched for AGB stellar models that match the observed abundance patterns. We employed three machine learning algorithms as classifiers: a Random Forest method, developed for this work, and the two classifiers used in our previous study. We studied the statistical behaviour of the s-process elements in the observational sample to investigate if the AGB models systematically under- or overpredict the abundances observed in the Ba stars and show the results in the form of violin plots of the residuals between spectroscopic abundances and model predictions. We find a significant trend in the residuals that implies an underproduction of the elements Nb, Mo, and Ru in the models relative to the observations. This may originate from a process (e.g. the intermediate neutron-capture process, i process) at the metallicity of the Ba stars not yet included in the AGB models. Correlations are found between the residuals of these elements, suggesting a common origin for the deviations. In addition, there is a weak metallicity dependence of their residuals. The s-process temperatures derived with the [Zr/Fe] - [Nb/Fe] thermometer have an unrealistic value for the majority of our stars. The most likely explanation is that at least a fraction of these elements are not produced in a steady-state s process, and instead may be due to processes not included in the AGB models. The mass distribution of the identified models confirms that our sample of Ba stars was polluted by low-mass AGB stars. Most of the matching AGB models require low accreted mass, but a few systems with high accreted mass are needed to explain the observations. (abridged)",
    "authors": [
      "B. Vil\u00e1gos",
      "B. Cseh",
      "A. Yag\u00fce L\u00f3pez",
      "M. Joyce",
      "A. Karakas",
      "G. Tagliente",
      "M. Lugaro"
    ],
    "url": "http://arxiv.org/abs/2405.19330v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.SR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3e0ddf58-a94e-4abb-b3a8-6b1858ceef6a": {
    "pk": "3e0ddf58-a94e-4abb-b3a8-6b1858ceef6a",
    "title": "Normative Modules: A Generative Agent Architecture for Learning Norms that Supports Multi-Agent Cooperation",
    "abstract": "Generative agents, which implement behaviors using a large language model (LLM) to interpret and evaluate an environment, has demonstrated the capacity to solve complex tasks across many social and technological domains. However, when these agents interact with other agents and humans in presence of social structures such as existing norms, fostering cooperation between them is a fundamental challenge. In this paper, we develop the framework of a 'Normative Module': an architecture designed to enhance cooperation by enabling agents to recognize and adapt to the normative infrastructure of a given environment. We focus on the equilibrium selection aspect of the cooperation problem and inform our agent design based on the existence of classification institutions that implement correlated equilibrium to provide effective resolution of the equilibrium selection problem. Specifically, the normative module enables agents to learn through peer interactions which of multiple candidate institutions in the environment, does a group treat as authoritative. By enabling normative competence in this sense, agents gain ability to coordinate their sanctioning behaviour; coordinated sanctioning behaviour in turn shapes primary behaviour within a social environment, leading to higher average welfare. We design a new environment that supports institutions and evaluate the proposed framework based on two key criteria derived from agent interactions with peers and institutions: (i) the agent's ability to disregard non-authoritative institutions and (ii) the agent's ability to identify authoritative institutions among several options. We show that these capabilities allow the agent to achieve more stable cooperative outcomes compared to baseline agents without the normative module, paving the way for research in a new avenue of designing environments and agents that account for normative infrastructure.",
    "authors": [
      "Atrisha Sarkar",
      "Andrei Ioan Muresanu",
      "Carter Blair",
      "Aaryam Sharma",
      "Rakshit S Trivedi",
      "Gillian K Hadfield"
    ],
    "url": "http://arxiv.org/abs/2405.19328v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.MA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "afcdd450-a109-4605-af22-8e31a7efe049": {
    "pk": "afcdd450-a109-4605-af22-8e31a7efe049",
    "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series",
    "abstract": "Large Language Models (LLMs) have made great strides in recent years to achieve unprecedented performance across different tasks. However, due to commercial interest, the most competitive models like GPT, Gemini, and Claude have been gated behind proprietary interfaces without disclosing the training details. Recently, many institutions have open-sourced several strong LLMs like LLaMA-3, comparable to existing closed-source LLMs. However, only the model's weights are provided with most details (e.g., intermediate checkpoints, pre-training corpus, and training code, etc.) being undisclosed. To improve the transparency of LLMs, the research community has formed to open-source truly open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training corpus and training code) are being provided. These models have greatly advanced the scientific study of these large models including their strengths, weaknesses, biases and risks. However, we observe that the existing truly open LLMs on reasoning, knowledge, and coding tasks are still inferior to existing state-of-the-art LLMs with similar model sizes. To this end, we open-source MAP-Neo, a highly capable and transparent bilingual language model with 7B parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs. Moreover, we open-source all details to reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning pipeline, checkpoints, and well-optimized training/evaluation framework are provided. Finally, we hope our MAP-Neo will enhance and strengthen the open research community and inspire more innovations and creativities to facilitate the further improvements of LLMs.",
    "authors": [
      "Ge Zhang",
      "Scott Qu",
      "Jiaheng Liu",
      "Chenchen Zhang",
      "Chenghua Lin",
      "Chou Leuang Yu",
      "Danny Pan",
      "Esther Cheng",
      "Jie Liu",
      "Qunshu Lin",
      "Raven Yuan",
      "Tuney Zheng",
      "Wei Pang",
      "Xinrun Du",
      "Yiming Liang",
      "Yinghao Ma",
      "Yizhi Li",
      "Ziyang Ma",
      "Bill Lin",
      "Emmanouil Benetos",
      "Huan Yang",
      "Junting Zhou",
      "Kaijing Ma",
      "Minghao Liu",
      "Morry Niu",
      "Noah Wang",
      "Quehry Que",
      "Ruibo Liu",
      "Sine Liu",
      "Shawn Guo",
      "Soren Gao",
      "Wangchunshu Zhou",
      "Xinyue Zhang",
      "Yizhi Zhou",
      "Yubo Wang",
      "Yuelin Bai",
      "Yuhan Zhang",
      "Yuxiang Zhang",
      "Zenith Wang",
      "Zhenzhu Yang",
      "Zijian Zhao",
      "Jiajun Zhang",
      "Wanli Ouyang",
      "Wenhao Huang",
      "Wenhu Chen"
    ],
    "url": "http://arxiv.org/abs/2405.19327v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9ad0d66b-4e91-4c1e-b048-0a49c8b3dfd6": {
    "pk": "9ad0d66b-4e91-4c1e-b048-0a49c8b3dfd6",
    "title": "Are Large Language Models Chameleons?",
    "abstract": "Do large language models (LLMs) have their own worldviews and personality tendencies? Simulations in which an LLM was asked to answer subjective questions were conducted more than 1 million times. Comparison of the responses from different LLMs with real data from the European Social Survey (ESS) suggests that the effect of prompts on bias and variability is fundamental, highlighting major cultural, age, and gender biases. Methods for measuring the difference between LLMs and survey data are discussed, such as calculating weighted means and a new proposed measure inspired by Jaccard similarity. We conclude that it is important to analyze the robustness and variability of prompts before using LLMs to model individual decisions or collective behavior, as their imitation abilities are approximate at best.",
    "authors": [
      "Mingmeng Geng",
      "Sihong He",
      "Roberto Trotta"
    ],
    "url": "http://arxiv.org/abs/2405.19323v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d5523b21-08bc-4064-af9e-c3db47e0654e": {
    "pk": "d5523b21-08bc-4064-af9e-c3db47e0654e",
    "title": "DGD: Dynamic 3D Gaussians Distillation",
    "abstract": "We tackle the task of learning dynamic 3D semantic radiance fields given a single monocular video as input. Our learned semantic radiance field captures per-point semantics as well as color and geometric properties for a dynamic 3D scene, enabling the generation of novel views and their corresponding semantics. This enables the segmentation and tracking of a diverse set of 3D semantic entities, specified using a simple and intuitive interface that includes a user click or a text prompt. To this end, we present DGD, a unified 3D representation for both the appearance and semantics of a dynamic 3D scene, building upon the recently proposed dynamic 3D Gaussians representation. Our representation is optimized over time with both color and semantic information. Key to our method is the joint optimization of the appearance and semantic attributes, which jointly affect the geometric properties of the scene. We evaluate our approach in its ability to enable dense semantic 3D object tracking and demonstrate high-quality results that are fast to render, for a diverse set of scenes. Our project webpage is available on https://isaaclabe.github.io/DGD-Website/",
    "authors": [
      "Isaac Labe",
      "Noam Issachar",
      "Itai Lang",
      "Sagie Benaim"
    ],
    "url": "http://arxiv.org/abs/2405.19321v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f694399d-1b6a-44c5-83fc-41114cea9892": {
    "pk": "f694399d-1b6a-44c5-83fc-41114cea9892",
    "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF",
    "abstract": "Reinforcement learning from human feedback (RLHF) has demonstrated great promise in aligning large language models (LLMs) with human preference. Depending on the availability of preference data, both online and offline RLHF are active areas of investigation. A key bottleneck is understanding how to incorporate uncertainty estimation in the reward function learned from the preference data for RLHF, regardless of how the preference data is collected. While the principles of optimism or pessimism under uncertainty are well-established in standard reinforcement learning (RL), a practically-implementable and theoretically-grounded form amenable to large language models is not yet available, as standard techniques for constructing confidence intervals become intractable under arbitrary policy parameterizations.   In this paper, we introduce a unified approach to online and offline RLHF -- value-incentivized preference optimization (VPO) -- which regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, modulated by a $\\textit{sign}$ to indicate whether the optimism or pessimism is chosen. VPO also directly optimizes the policy with implicit reward modeling, and therefore shares a simpler RLHF pipeline similar to direct preference optimization. Theoretical guarantees of VPO are provided for both online and offline settings, matching the rates of their standard RL counterparts. Moreover, experiments on text summarization and dialog verify the practicality and effectiveness of VPO.",
    "authors": [
      "Shicong Cen",
      "Jincheng Mei",
      "Katayoon Goshvadi",
      "Hanjun Dai",
      "Tong Yang",
      "Sherry Yang",
      "Dale Schuurmans",
      "Yuejie Chi",
      "Bo Dai"
    ],
    "url": "http://arxiv.org/abs/2405.19320v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "08faf26b-3c1b-4f85-ae61-e2b620919dc4": {
    "pk": "08faf26b-3c1b-4f85-ae61-e2b620919dc4",
    "title": "ACE: A general-purpose non-Markovian open quantum systems simulation toolkit based on process tensors",
    "abstract": "We describe a general-purpose computational toolkit for simulating open quantum systems, which provides numerically exact solutions for composites of zero-dimensional quantum systems that may be strongly coupled to multiple, quite general non-Markovian environments. It is based on process tensor matrix product operators (PT-MPOs), which efficiently encapsulate environment influences. The code features implementations of several PT-MPO algorithms, in particular, Automated Compression of Environments (ACE) for general environments comprised of independent modes as well as schemes for generalized spin boson models. The latter includes a divide-and-conquer scheme for periodic PT-MPOs, which enable million time step simulations for realistic models. PT-MPOs can be precalculated and reused for efficiently probing different time-dependent system Hamiltonians. They can also be stacked together and combined to provide numerically complete solutions of small networks of open quantum systems. The code is written in C++ and is fully controllable by configuration files, for which we have developed a versatile and compact human-readable format.",
    "authors": [
      "Moritz Cygorek",
      "Erik M. Gauger"
    ],
    "url": "http://arxiv.org/abs/2405.19319v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6546472f-beee-4111-a963-83b095e7bf73": {
    "pk": "6546472f-beee-4111-a963-83b095e7bf73",
    "title": "Adaptive Generalized Neyman Allocation: Local Asymptotic Minimax Optimal Best Arm Identification",
    "abstract": "This study investigates a local asymptotic minimax optimal strategy for fixed-budget best arm identification (BAI). We propose the Adaptive Generalized Neyman Allocation (AGNA) strategy and show that its worst-case upper bound of the probability of misidentifying the best arm aligns with the worst-case lower bound under the small-gap regime, where the gap between the expected outcomes of the best and suboptimal arms is small. Our strategy corresponds to a generalization of the Neyman allocation for two-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and a refinement of existing strategies such as the ones proposed by Glynn & Juneja (2004) and Shin et al. (2018). Compared to Komiyama et al. (2022), which proposes a minimax rate-optimal strategy, our proposed strategy has a tighter upper bound that exactly matches the lower bound, including the constant terms, by restricting the class of distributions to the class of small-gap distributions. Our result contributes to the longstanding open issue about the existence of asymptotically optimal strategies in fixed-budget BAI, by presenting the local asymptotic minimax optimal strategy.",
    "authors": [
      "Masahiro Kato"
    ],
    "url": "http://arxiv.org/abs/2405.19317v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "87ecfa35-95cb-4329-9d99-c25ce28508e0": {
    "pk": "87ecfa35-95cb-4329-9d99-c25ce28508e0",
    "title": "Robust Preference Optimization through Reward Model Distillation",
    "abstract": "Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning. However, typical preference datasets have only a single, or at most a few, annotation per preference pair, which causes DPO to overconfidently assign rewards that trend towards infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero. In this work, we analyze this phenomenon and propose distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM to produce probabilities that match the distribution induced by a reward model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution. Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO.",
    "authors": [
      "Adam Fisch",
      "Jacob Eisenstein",
      "Vicky Zayats",
      "Alekh Agarwal",
      "Ahmad Beirami",
      "Chirag Nagpal",
      "Pete Shaw",
      "Jonathan Berant"
    ],
    "url": "http://arxiv.org/abs/2405.19316v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f4c24af6-2123-4de0-8db2-406bb5bd4d37": {
    "pk": "f4c24af6-2123-4de0-8db2-406bb5bd4d37",
    "title": "Matryoshka Query Transformer for Large Vision-Language Models",
    "abstract": "Large Vision-Language Models (LVLMs) typically encode an image into a fixed number of visual tokens (e.g., 576) and process these tokens with a language model. Despite their strong performance, LVLMs face challenges in adapting to varying computational constraints. This raises the question: can we achieve flexibility in the number of visual tokens to suit different tasks and computational resources? We answer this with an emphatic yes. Inspired by Matryoshka Representation Learning, we introduce the Matryoshka Query Transformer (MQT), capable of encoding an image into m visual tokens during inference, where m can be any number up to a predefined maximum. This is achieved by employing a query transformer with M latent query tokens to compress the visual embeddings. During each training step, we randomly select m <= M latent query tokens and train the model using only these first m tokens, discarding the rest. Combining MQT with LLaVA, we train a single model once, and flexibly and drastically reduce the number of inference-time visual tokens while maintaining similar or better performance compared to training independent models for each number of tokens. Our model, MQT-LLAVA, matches LLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens instead of LLaVA's fixed 576. Reducing to 16 tokens (8x less TFLOPs) only sacrifices the performance by 2.4 points on MMBench. On certain tasks such as ScienceQA and MMMU, we can even go down to only 2 visual tokens with performance drops of just 3% and 6% each. Our exploration of the trade-off between the accuracy and computational cost brought about by the number of visual tokens facilitates future research to achieve the best of both worlds.",
    "authors": [
      "Wenbo Hu",
      "Zi-Yi Dou",
      "Liunian Harold Li",
      "Amita Kamath",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ],
    "url": "http://arxiv.org/abs/2405.19315v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "aa70e970-1fe4-48f8-9bc9-bbc909cd8d35": {
    "pk": "aa70e970-1fe4-48f8-9bc9-bbc909cd8d35",
    "title": "SDPRLayers: Certifiable Backpropagation Through Polynomial Optimization Problems in Robotics",
    "abstract": "Differentiable optimization is a powerful new paradigm capable of reconciling model-based and learning-based approaches in robotics. However, the majority of robotics optimization problems are non-convex and current differentiable optimization techniques are therefore prone to convergence to local minima. When this occurs, the gradients provided by these existing solvers can be wildly inaccurate and will ultimately corrupt the training process. On the other hand, any non-convex robotics problems can be framed as polynomial optimization problems and, in turn, admit convex relaxations that can be used to recover a global solution via so-called certifiably correct methods. We present SDPRLayers, an approach that leverages these methods as well as state-of-the-art convex implicit differentiation techniques to provide certifiably correct gradients throughout the training process. We introduce this approach and showcase theoretical results that provide conditions under which correctness of the gradients is guaranteed. We demonstrate our approach on two simple-but-demonstrative simulated examples, which expose the potential pitfalls of existing, state-of-the-art, differentiable optimization methods. We apply our method in a real-world application: we train a deep neural network to detect image keypoints for robot localization in challenging lighting conditions. An open-source, PyTorch implementation of SDPRLayers will be made available upon paper acceptance.",
    "authors": [
      "Connor Holmes",
      "Frederike D\u00fcmbgen",
      "Timothy D. Barfoot"
    ],
    "url": "http://arxiv.org/abs/2405.19309v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "867915f4-2abe-430d-86bd-cc9d0137ac02": {
    "pk": "867915f4-2abe-430d-86bd-cc9d0137ac02",
    "title": "Data Efficient Behavior Cloning for Fine Manipulation via Continuity-based Corrective Labels",
    "abstract": "We consider imitation learning with access only to expert demonstrations, whose real-world application is often limited by covariate shift due to compounding errors during execution. We investigate the effectiveness of the Continuity-based Corrective Labels for Imitation Learning (CCIL) framework in mitigating this issue for real-world fine manipulation tasks. CCIL generates corrective labels by learning a locally continuous dynamics model from demonstrations to guide the agent back toward expert states. Through extensive experiments on peg insertion and fine grasping, we provide the first empirical validation that CCIL can significantly improve imitation learning performance despite discontinuities present in contact-rich manipulation. We find that: (1) real-world manipulation exhibits sufficient local smoothness to apply CCIL, (2) generated corrective labels are most beneficial in low-data regimes, and (3) label filtering based on estimated dynamics model error enables performance gains. To effectively apply CCIL to robotic domains, we offer a practical instantiation of the framework and insights into design choices and hyperparameter selection. Our work demonstrates CCIL's practicality for alleviating compounding errors in imitation learning on physical robots.",
    "authors": [
      "Abhay Deshpande",
      "Liyiming Ke",
      "Quinn Pfeifer",
      "Abhishek Gupta",
      "Siddhartha S. Srinivasa"
    ],
    "url": "http://arxiv.org/abs/2405.19307v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d9475f70-c53a-4f35-9a91-8c9237260d64": {
    "pk": "d9475f70-c53a-4f35-9a91-8c9237260d64",
    "title": "Uniform-in-time estimates on the size of chaos for interacting Brownian particles",
    "abstract": "We consider a system of classical Brownian particles interacting via a smooth long-range potential in the mean-field regime, and we analyze the propagation of chaos in form of sharp, uniform-in-time estimates on many-particle correlation functions. Our results cover both the kinetic Langevin setting and the corresponding overdamped Brownian dynamics. The approach is mainly based on so-called Lions expansions, which we combine with new diagrammatic tools to capture many-particle cancellations, as well as with fine ergodic estimates on the linearized mean-field equation, and with discrete stochastic calculus with respect to initial data. In the process, we derive some new ergodic estimates for the linearized Vlasov-Fokker-Planck kinetic equation that are of independent interest. Our analysis also leads to uniform-in-time concentration estimates and to a uniform-in-time quantitative central limit theorem for the empirical measure associated with the particle dynamics.",
    "authors": [
      "Armand Bernou",
      "Mitia Duerinckx"
    ],
    "url": "http://arxiv.org/abs/2405.19306v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.AP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2bb2712e-cccc-4b91-bbc5-fef00a725e50": {
    "pk": "2bb2712e-cccc-4b91-bbc5-fef00a725e50",
    "title": "Real-Time Environment Condition Classification for Autonomous Vehicles",
    "abstract": "Current autonomous driving technologies are being rolled out in geo-fenced areas with well-defined operation conditions such as time of operation, area, weather conditions and road conditions. In this way, challenging conditions as adverse weather, slippery road or densely-populated city centers can be excluded. In order to lift the geo-fenced restriction and allow a more dynamic availability of autonomous driving functions, it is necessary for the vehicle to autonomously perform an environment condition assessment in real time to identify when the system cannot operate safely and either stop operation or require the resting passenger to take control. In particular, adverse-weather challenges are a fundamental limitation as sensor performance degenerates quickly, prohibiting the use of sensors such as cameras to locate and monitor road signs, pedestrians or other vehicles. To address this issue, we train a deep learning model to identify outdoor weather and dangerous road conditions, enabling a quick reaction to new situations and environments. We achieve this by introducing an improved taxonomy and label hierarchy for a state-of-the-art adverse-weather dataset, relabelling it with a novel semi-automated labeling pipeline. Using the novel proposed dataset and hierarchy, we train RECNet, a deep learning model for the classification of environment conditions from a single RGB frame. We outperform baseline models by relative 16% in F1- Score, while maintaining a real-time capable performance of 20 Hz.",
    "authors": [
      "Marco Introvigne",
      "Andrea Ramazzina",
      "Stefanie Walz",
      "Dominik Scheuble",
      "Mario Bijelic"
    ],
    "url": "http://arxiv.org/abs/2405.19305v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bf46615d-20b1-487e-8a71-03cba1d28bb1": {
    "pk": "bf46615d-20b1-487e-8a71-03cba1d28bb1",
    "title": "Set Descriptive Complexity of Solvable Functions",
    "abstract": "In a recent article, we introduced and studied a precise class of dynamical systems called solvable systems. These systems present a dynamic ruled by discontinuous ordinary differential equations with solvable right-hand terms and unique evolution. They correspond to a class of systems for which a transfinite method exist to compute the solution. We also presented several examples including a nontrivial one whose solution yields, at an integer time, a real encoding of the halting set for Turing machines; therefore showcasing that the behavior of solvable systems might describe ordinal Turing computations. In the current article, we study in more depth solvable systems, using tools from descriptive set theory. By establishing a correspondence with the class of well-founded trees, we construct a coanalytic ranking over the set of solvable functions and discuss its relation with other existing rankings for differentiable functions, in particular with the Kechris-Woodin, Denjoy and Zalcwasser ranking. We prove that our ranking is unbounded below the first uncountable ordinal.",
    "authors": [
      "Gozzi Riccardo",
      "Bournez Olivier"
    ],
    "url": "http://arxiv.org/abs/2405.19304v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "12c51c2a-bf4f-4e5e-81ae-65e2a457328b": {
    "pk": "12c51c2a-bf4f-4e5e-81ae-65e2a457328b",
    "title": "Safe and Efficient Estimation for Robotics through the Optimal Use of Resources",
    "abstract": "In order to operate in and interact with the physical world, robots need to have estimates of the current and future state of the environment. We thus equip robots with sensors and build models and algorithms that, given some measurements, produce estimates of the current or future states. Environments can be unpredictable and sensors are not perfect. Therefore, it is important to both use all information available, and to do so optimally: making sure that we get the best possible answer from the amount of information we have. However, in prevalent research, uncommon sensors, such as sound or radio-frequency signals, are commonly ignored for state estimation; and the most popular solvers employed to produce state estimates are only of local nature, meaning they may produce suboptimal estimates for the typically non-convex estimation problems. My research aims to use resources more optimally, by building on 1) multi-modality: using ubiquitous RF transceivers and microphones to support state estimation, 2) building certifiably optimal solvers and 3) learning and improving adequate models from data.",
    "authors": [
      "Frederike D\u00fcmbgen"
    ],
    "url": "http://arxiv.org/abs/2405.19301v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "04a0d10c-cb0e-4001-a924-3acb57ee7b60": {
    "pk": "04a0d10c-cb0e-4001-a924-3acb57ee7b60",
    "title": "Measuring and Mitigating Bias for Tabular Datasets with Multiple Protected Attributes",
    "abstract": "Motivated by the recital (67) of the current corrigendum of the AI Act in the European Union, we propose and present measures and mitigation strategies for discrimination in tabular datasets. We specifically focus on datasets that contain multiple protected attributes, such as nationality, age, and sex. This makes measuring and mitigating bias more challenging, as many existing methods are designed for a single protected attribute. This paper comes with a twofold contribution: Firstly, new discrimination measures are introduced. These measures are categorized in our framework along with existing ones, guiding researchers and practitioners in choosing the right measure to assess the fairness of the underlying dataset. Secondly, a novel application of an existing bias mitigation method, FairDo, is presented. We show that this strategy can mitigate any type of discrimination, including intersectional discrimination, by transforming the dataset. By conducting experiments on real-world datasets (Adult, Bank, Compas), we demonstrate that de-biasing datasets with multiple protected attributes is achievable. Further, the transformed fair datasets do not compromise any of the tested machine learning models' performances significantly when trained on these datasets compared to the original datasets. Discrimination was reduced by up to 83% in our experimentation. For most experiments, the disparity between protected groups was reduced by at least 7% and 27% on average. Generally, the findings show that the mitigation strategy used is effective, and this study contributes to the ongoing discussion on the implementation of the European Union's AI Act.",
    "authors": [
      "Manh Khoi Duong",
      "Stefan Conrad"
    ],
    "url": "http://arxiv.org/abs/2405.19300v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f96ef0be-7d10-402a-a99a-1eb2dd5de185": {
    "pk": "f96ef0be-7d10-402a-a99a-1eb2dd5de185",
    "title": "Neural Isometries: Taming Transformations for Equivariant ML",
    "abstract": "Real-world geometry and 3D vision tasks are replete with challenging symmetries that defy tractable analytical expression. In this paper, we introduce Neural Isometries, an autoencoder framework which learns to map the observation space to a general-purpose latent space wherein encodings are related by isometries whenever their corresponding observations are geometrically related in world space. Specifically, we regularize the latent space such that maps between encodings preserve a learned inner product and commute with a learned functional operator, in the same manner as rigid-body transformations commute with the Laplacian. This approach forms an effective backbone for self-supervised representation learning, and we demonstrate that a simple off-the-shelf equivariant network operating in the pre-trained latent space can achieve results on par with meticulously-engineered, handcrafted networks designed to handle complex, nonlinear symmetries. Furthermore, isometric maps capture information about the respective transformations in world space, and we show that this allows us to regress camera poses directly from the coefficients of the maps between encodings of adjacent views of a scene.",
    "authors": [
      "Thomas W. Mitchel",
      "Michael Taylor",
      "Vincent Sitzmann"
    ],
    "url": "http://arxiv.org/abs/2405.19296v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bca7c17b-79fd-414d-97ca-d60e8142cdf7": {
    "pk": "bca7c17b-79fd-414d-97ca-d60e8142cdf7",
    "title": "3D Neural Edge Reconstruction",
    "abstract": "Real-world objects and environments are predominantly composed of edge features, including straight lines and curves. Such edges are crucial elements for various applications, such as CAD modeling, surface meshing, lane mapping, etc. However, existing traditional methods only prioritize lines over curves for simplicity in geometric modeling. To this end, we introduce EMAP, a new method for learning 3D edge representations with a focus on both lines and curves. Our method implicitly encodes 3D edge distance and direction in Unsigned Distance Functions (UDF) from multi-view edge maps. On top of this neural representation, we propose an edge extraction algorithm that robustly abstracts parametric 3D edges from the inferred edge points and their directions. Comprehensive evaluations demonstrate that our method achieves better 3D edge reconstruction on multiple challenging datasets. We further show that our learned UDF field enhances neural surface reconstruction by capturing more details.",
    "authors": [
      "Lei Li",
      "Songyou Peng",
      "Zehao Yu",
      "Shaohui Liu",
      "R\u00e9mi Pautrat",
      "Xiaochuan Yin",
      "Marc Pollefeys"
    ],
    "url": "http://arxiv.org/abs/2405.19295v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "0a8dd4c7-37b6-42c8-98c2-396c514835dc": {
    "pk": "0a8dd4c7-37b6-42c8-98c2-396c514835dc",
    "title": "GPU-accelerated Higher Representations of Wilson Fermions with HiRep",
    "abstract": "We are improving one of the available lattice software packages HiRep by adding GPU acceleration supporting highly-optimized simulations on both NVIDIA and AMD GPUs. HiRep allows lattice simulations of theories with fermions in higher representations and a variable number of colors in the gauge group. The development is accompanied by an overall software quality improvement in the build system, testing, and documentation, adding features for both CPUs and GPUs. The software is available under https://github.com/claudiopica/HiRep",
    "authors": [
      "Sofie Martins",
      "Erik Kjellgren",
      "Emiliano Molinaro",
      "Claudio Pica",
      "Antonio Rago"
    ],
    "url": "http://arxiv.org/abs/2405.19294v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-lat",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "363b440e-b386-42ad-a803-a9b59d7b4d37": {
    "pk": "363b440e-b386-42ad-a803-a9b59d7b4d37",
    "title": "Act Natural! Projecting Autonomous System Trajectories Into Naturalistic Behavior Sets",
    "abstract": "Autonomous agents operating around human actors must consider how their behaviors might affect those humans, even when not directly interacting with them. To this end, it is often beneficial to be predictable and appear naturalistic. Existing methods to address this problem use human actor intent modeling or imitation learning techniques, but these approaches rarely capture all possible motivations for human behavior or require significant amounts of data. In contrast, we propose a technique for modeling naturalistic behavior as a set of convex hulls computed over a relatively small dataset of human behavior. Given this set, we design an optimization-based filter which projects arbitrary trajectories into it to make them more naturalistic for autonomous agents to execute while also satisfying dynamics constraints. We demonstrate our methods on real-world human driving data from the inD intersection dataset (Bock et al., 2020).",
    "authors": [
      "Hamzah I. Khan",
      "Adam J. Thorpe",
      "David Fridovich-Keil"
    ],
    "url": "http://arxiv.org/abs/2405.19292v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.MA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "51016411-43cc-4442-8900-375efe9176b7": {
    "pk": "51016411-43cc-4442-8900-375efe9176b7",
    "title": "Grasp as You Say: Language-guided Dexterous Grasp Generation",
    "abstract": "This paper explores a novel task \"\"Dexterous Grasp as You Say\"\" (DexGYS), enabling robots to perform dexterous grasping based on human commands expressed in natural language. However, the development of this field is hindered by the lack of datasets with natural human guidance; thus, we propose a language-guided dexterous grasp dataset, named DexGYSNet, offering high-quality dexterous grasp annotations along with flexible and fine-grained human language guidance. Our dataset construction is cost-efficient, with the carefully-design hand-object interaction retargeting strategy, and the LLM-assisted language guidance annotation system. Equipped with this dataset, we introduce the DexGYSGrasp framework for generating dexterous grasps based on human language instructions, with the capability of producing grasps that are intent-aligned, high quality and diversity. To achieve this capability, our framework decomposes the complex learning process into two manageable progressive objectives and introduce two components to realize them. The first component learns the grasp distribution focusing on intention alignment and generation diversity. And the second component refines the grasp quality while maintaining intention consistency. Extensive experiments are conducted on DexGYSNet and real world environment for validation.",
    "authors": [
      "Yi-Lin Wei",
      "Jian-Jian Jiang",
      "Chengyi Xing",
      "Xiantuo Tan",
      "Xiao-Ming Wu",
      "Hao Li",
      "Mark Cutkosky",
      "Wei-Shi Zheng"
    ],
    "url": "http://arxiv.org/abs/2405.19291v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "07a6dcf4-c6c9-43f5-8eb3-a6dac9879a0a": {
    "pk": "07a6dcf4-c6c9-43f5-8eb3-a6dac9879a0a",
    "title": "Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation",
    "abstract": "Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual translation, the imbalance in data volumes across different languages spreads to the vocabulary, exacerbating translations involving low-resource languages. While byte-based tokenization addresses these issues, byte-based models struggle with the low information density inherent in UTF-8 byte sequences. Previous works enhance token semantics through local contextualization but fail to select an appropriate contextualizing scope based on the input. Consequently, we propose the Multi-Scale Contextualization (MSC) method, which learns contextualized information of varying scales across different hidden state dimensions. It then leverages the attention module to dynamically integrate the multi-scale contextualized information. Experiments show that MSC significantly outperforms subword-based and other byte-based methods in both multilingual and out-of-domain scenarios. Code can be found in https://github.com/ictnlp/Multiscale-Contextualization.",
    "authors": [
      "Langlin Huang",
      "Yang Feng"
    ],
    "url": "http://arxiv.org/abs/2405.19290v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3fb6ce27-2952-4458-8238-41c533713777": {
    "pk": "3fb6ce27-2952-4458-8238-41c533713777",
    "title": "Genuine topological Anderson insulator from impurity induced chirality reversal",
    "abstract": "We investigate a model of Dirac fermions with Haldane type mass impurities which open a global topological gap even in the dilute limit. Surprisingly, we find that the chirality of this mass term, i.e., the sign of the Chern number, can be reversed by tuning the magnitude of the single-impurity scattering. Consequently, the disorder induces a phase disconnected from the clean topological phase, i.e., a genuine topological Anderson insulator. In seeming contradiction to the expectation that mass disorder is an irrelevant perturbation to the clean integer quantum Hall transition, the tri-critical point separating these two Chern insulating phases and a thermal metal phase is located at zero impurity density and connected to the appearance of a zero energy bound state in the continuum corresponding to a divergent Haldane mass impurity. Our conclusions based on the T-matrix expansion are substantiated by large scale Chebyshev-Polynomial-Green-Function numerics. We discuss possible experimental platforms.",
    "authors": [
      "Avedis Neehus",
      "Frank Pollmann",
      "Johannes Knolle"
    ],
    "url": "http://arxiv.org/abs/2405.19289v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mes-hall",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "13db438c-d917-42e5-9372-6082e47c95a1": {
    "pk": "13db438c-d917-42e5-9372-6082e47c95a1",
    "title": "EDGE: A new model for Nuclear Star Cluster formation in dwarf galaxies",
    "abstract": "Nuclear Star Clusters (NSCs) are amongst the densest stellar systems in the Universe and are found at the centres of many bright spiral and elliptical galaxies, and up to ${\\sim}$40% of dwarf galaxies. However, their formation mechanisms, and possible links to globular clusters (GCs), remain debated. This paper uses the EDGE simulations - a collection of zoom-in, cosmological simulations of isolated dwarf galaxies -- to present a new formation mechanism for NSCs. We find that, at a gas spatial and mass resolution of ${\\sim}3\\,$pc and ${\\sim}161$ M$_\\odot$, respectively, NSCs naturally emerge in a subset of our EDGE dwarfs with redshift-zero halo masses of $\\rm{M}_{\\rm{r}200\\rm{c}} \\sim 5 \\times 10^9$ M$_\\odot$. These dwarfs are quenched by reionisation, but retain a significant reservoir of gas that is unable to cool and form stars. Sometime after reionisation, the dwarfs then undergo a major (${\\sim}$1:1) merger that excites rapid gas cooling, leading to a significant starburst. An NSC forms in this starburst that then quenches star formation thereafter. The result is a nucleated dwarf that has two stellar populations with distinct age: one pre-reionisation and one post-reionisation. Our mechanism is unique for two key reasons. Firstly, the low mass of the host dwarf means that NSCs, formed in this way, can accrete onto galaxies of almost all masses, potentially seeding the formation of NSCs everywhere. Secondly, our model predicts that NSCs should have at least two stellar populations with a large ($\\gtrsim$1 billion year) age separation. This yields a predicted colour magnitude diagram for our nucleated dwarfs that has two distinct main sequence turnoffs. Several GCs orbiting the Milky Way, including Omega Centauri and M54, show exactly this behaviour, suggesting that they may, in fact, be accreted NSCs.",
    "authors": [
      "Emily I. Gray",
      "Justin I. Read",
      "Ethan Taylor",
      "Matthew D. A. Orkney",
      "Martin P. Rey",
      "Robert M. Yates",
      "Stacy Y. Kim",
      "Noelia E. D. No\u00ebl",
      "Oscar Agertz",
      "Eric Andersson",
      "Andrew Pontzen"
    ],
    "url": "http://arxiv.org/abs/2405.19286v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.GA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a40a7f8d-8d4e-464a-bac4-6405e8bb90be": {
    "pk": "a40a7f8d-8d4e-464a-bac4-6405e8bb90be",
    "title": "Optimizing Foundation Model Inference on a Many-tiny-core Open-source RISC-V Platform",
    "abstract": "Transformer-based foundation models have become crucial for various domains, most notably natural language processing (NLP) or computer vision (CV). These models are predominantly deployed on high-performance GPUs or hardwired accelerators with highly customized, proprietary instruction sets. Until now, limited attention has been given to RISC-V-based general-purpose platforms. In our work, we present the first end-to-end inference results of transformer models on an open-source many-tiny-core RISC-V platform implementing distributed Softmax primitives and leveraging ISA extensions for SIMD floating-point operand streaming and instruction repetition, as well as specialized DMA engines to minimize costly main memory accesses and to tolerate their latency. We focus on two foundational transformer topologies, encoder-only and decoder-only models. For encoder-only models, we demonstrate a speedup of up to 12.8x between the most optimized implementation and the baseline version. We reach over 79% FPU utilization and 294 GFLOPS/W, outperforming State-of-the-Art (SoA) accelerators by more than 2x utilizing the HW platform while achieving comparable throughput per computational unit. For decoder-only topologies, we achieve 16.1x speedup in the Non-Autoregressive (NAR) mode and up to 35.6x speedup in the Autoregressive (AR) mode compared to the baseline implementation. Compared to the best SoA dedicated accelerator, we achieve 2.04x higher FPU utilization.",
    "authors": [
      "Viviane Potocnik",
      "Luca Colagrande",
      "Tim Fischer",
      "Luca Bertaccini",
      "Daniele Jahier Pagliari",
      "Alessio Burrello",
      "Luca Benini"
    ],
    "url": "http://arxiv.org/abs/2405.19284v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.DC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b2d5ba90-c11a-46cf-bff4-df7d1de4fc00": {
    "pk": "b2d5ba90-c11a-46cf-bff4-df7d1de4fc00",
    "title": "Understanding and Minimising Outlier Features in Neural Network Training",
    "abstract": "Outlier Features (OF) are neurons whose activation magnitudes significantly exceed the average over a neural network's (NN) width. They are well known to emerge during standard transformer training and have the undesirable effect of hindering quantisation in afflicted models. Despite their practical importance, little is known behind why OFs emerge during training, nor how one can minimise them.   Our work focuses on the above questions, first identifying several quantitative metrics, such as the kurtosis over neuron activation norms, to measure OFs. With these metrics, we study how architectural and optimisation choices influence OFs, and provide practical insights to minimise OFs during training. As highlights, we emphasise the importance of controlling signal propagation throughout training, and propose the Outlier Protected transformer block, which removes standard Pre-Norm layers to mitigate OFs, without loss of convergence speed or training stability. Overall, our findings shed new light on our understanding of, our ability to prevent, and the complexity of this important facet in NN training dynamics.",
    "authors": [
      "Bobby He",
      "Lorenzo Noci",
      "Daniele Paliotta",
      "Imanol Schlag",
      "Thomas Hofmann"
    ],
    "url": "http://arxiv.org/abs/2405.19279v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "07b49bf5-58ee-416c-b75c-30adca8d54d2": {
    "pk": "07b49bf5-58ee-416c-b75c-30adca8d54d2",
    "title": "Deep Latent Variable Modeling of Physiological Signals",
    "abstract": "A deep latent variable model is a powerful method for capturing complex distributions. These models assume that underlying structures, but unobserved, are present within the data. In this dissertation, we explore high-dimensional problems related to physiological monitoring using latent variable models. First, we present a novel deep state-space model to generate electrical waveforms of the heart using optically obtained signals as inputs. This can bring about clinical diagnoses of heart disease via simple assessment through wearable devices. Second, we present a brain signal modeling scheme that combines the strengths of probabilistic graphical models and deep adversarial learning. The structured representations can provide interpretability and encode inductive biases to reduce the data complexity of neural oscillations. The efficacy of the learned representations is further studied in epilepsy seizure detection formulated as an unsupervised learning problem. Third, we propose a framework for the joint modeling of physiological measures and behavior. Existing methods to combine multiple sources of brain data provided are limited. Direct analysis of the relationship between different types of physiological measures usually does not involve behavioral data. Our method can identify the unique and shared contributions of brain regions to behavior and can be used to discover new functions of brain regions. The success of these innovative computational methods would allow the translation of biomarker findings across species and provide insight into neurocognitive analysis in numerous biological studies and clinical diagnoses, as well as emerging consumer applications.",
    "authors": [
      "Khuong Vo"
    ],
    "url": "http://arxiv.org/abs/2405.19277v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e5c2c0e1-1605-4ee9-b53e-5dd9843cab32": {
    "pk": "e5c2c0e1-1605-4ee9-b53e-5dd9843cab32",
    "title": "A Recipe for Charge Density Prediction",
    "abstract": "In density functional theory, charge density is the core attribute of atomic systems from which all chemical properties can be derived. Machine learning methods are promising in significantly accelerating charge density prediction, yet existing approaches either lack accuracy or scalability. We propose a recipe that can achieve both. In particular, we identify three key ingredients: (1) representing the charge density with atomic and virtual orbitals (spherical fields centered at atom/virtual coordinates); (2) using expressive and learnable orbital basis sets (basis function for the spherical fields); and (3) using high-capacity equivariant neural network architecture. Our method achieves state-of-the-art accuracy while being more than an order of magnitude faster than existing methods. Furthermore, our method enables flexible efficiency-accuracy trade-offs by adjusting the model/basis sizes.",
    "authors": [
      "Xiang Fu",
      "Andrew Rosen",
      "Kyle Bystrom",
      "Rui Wang",
      "Albert Musaelian",
      "Boris Kozinsky",
      "Tess Smidt",
      "Tommi Jaakkola"
    ],
    "url": "http://arxiv.org/abs/2405.19276v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.comp-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6ef8aadf-1b8f-4339-aaa0-b540d5375460": {
    "pk": "6ef8aadf-1b8f-4339-aaa0-b540d5375460",
    "title": "The Future of Child Development in the AI Era. Cross-Disciplinary Perspectives Between AI and Child Development Experts",
    "abstract": "This report explores the potential implications of rapidly integrating Artificial Intelligence (AI) applications into children's environments. The introduction of AI in our daily lives necessitates scrutiny considering the significant role of the environment in shaping cognition, socio-emotional skills, and behaviors, especially during the first 25 years of cerebral development. As AI becomes prevalent in educational and leisure activities, it will significantly modify the experiences of children and adolescents, presenting both challenges and opportunities for their developmental trajectories. This analysis was informed by consulting with 15 experts from pertinent disciplines (AI, product development, child development, and neurosciences), along with a comprehensive review of scientific literature on children development and child-technology interactions. Overall, AI experts anticipate that AI will transform leisure activities, revolutionize education, and redefine human-machine interactions. While AI offers substantial benefits in fostering interactive engagement, it also poses risks that require careful considerations, especially during sensitive developmental periods. The report advocates for proactive international collaboration across multiple disciplines and increased research into how technological innovations affect child development. Such efforts are crucial for designing a sustainable and ethical future for the next generation through specific child-centered regulations, and helping to educate all potential stakeholders (regulators, developers, parents and educators, children) about responsible AI use and its potential impacts on child development.",
    "authors": [
      "Mathilde Neugnot-Cerioli",
      "Olga Muss Laurenty"
    ],
    "url": "http://arxiv.org/abs/2405.19275v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.HC",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "7ce8ad74-0fd7-464a-bc3c-b4ff2e8b6bcf": {
    "pk": "7ce8ad74-0fd7-464a-bc3c-b4ff2e8b6bcf",
    "title": "Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering",
    "abstract": "Federated Learning (FL) is a decentralized machine learning (ML) approach that keeps data localized and often incorporates Differential Privacy (DP) to enhance privacy guarantees. Similar to previous work on DP in ML, we observed that differentially private federated learning (DPFL) introduces performance disparities, particularly affecting minority groups. Recent work has attempted to address performance fairness in vanilla FL through clustering, but this method remains sensitive and prone to errors, which are further exacerbated by the DP noise in DPFL. To fill this gap, in this paper, we propose a novel clustered DPFL algorithm designed to effectively identify clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees. To this end, we propose to cluster clients based on both their model updates and training loss values. Our proposed approach also addresses the server's uncertainties in clustering clients' model updates by employing larger batch sizes along with Gaussian Mixture Model (GMM) to alleviate the impact of noise and potential clustering errors, especially in privacy-sensitive scenarios. We provide theoretical analysis of the effectiveness of our proposed approach. We also extensively evaluate our approach across diverse data distributions and privacy budgets and show its effectiveness in mitigating the disparate impact of DP in FL settings with a small computational cost.",
    "authors": [
      "Saber Malekmohammadi",
      "Afaf Taik",
      "Golnoosh Farnadi"
    ],
    "url": "http://arxiv.org/abs/2405.19272v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9bb22db4-1688-4d34-bd53-0ee0b62486d6": {
    "pk": "9bb22db4-1688-4d34-bd53-0ee0b62486d6",
    "title": "Rich-Observation Reinforcement Learning with Continuous Latent Dynamics",
    "abstract": "Sample-efficiency and reliability remain major bottlenecks toward wide adoption of reinforcement learning algorithms in continuous settings with high-dimensional perceptual inputs. Toward addressing these challenges, we introduce a new theoretical framework, RichCLD (Rich-Observation RL with Continuous Latent Dynamics), in which the agent performs control based on high-dimensional observations, but the environment is governed by low-dimensional latent states and Lipschitz continuous dynamics. Our main contribution is a new algorithm for this setting that is provably statistically and computationally efficient. The core of our algorithm is a new representation learning objective; we show that prior representation learning schemes tailored to discrete dynamics do not naturally extend to the continuous setting. Our new objective is amenable to practical implementation, and empirically, we find that it compares favorably to prior schemes in a standard evaluation protocol. We further provide several insights into the statistical complexity of the RichCLD framework, in particular proving that certain notions of Lipschitzness that admit sample-efficient learning in the absence of rich observations are insufficient in the rich-observation setting.",
    "authors": [
      "Yuda Song",
      "Lili Wu",
      "Dylan J. Foster",
      "Akshay Krishnamurthy"
    ],
    "url": "http://arxiv.org/abs/2405.19269v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "60fe3f59-c607-4bf6-880a-98a75c53edb1": {
    "pk": "60fe3f59-c607-4bf6-880a-98a75c53edb1",
    "title": "Photonic bilayer Chern insulator with corner states",
    "abstract": "Photonic Chern insulators can be implemented in gyromagnetic photonic crystals with broken time-reversal (TR) symmetry. They exhibit gapless chiral edge states (CESs), enabling unidirectional propagation and demonstrating exceptional resilience to localization even in the presence of defects or disorders. However, when two Chern insulators with opposite Chern numbers are stacked together, this one-way nature can be nullified, causing the originally gapless CESs to become gapped. Recent theoretical works have proposed achieving such a topological phase transition in condensed matter systems using antiferromagnetic thin films such as MnBi2Te4 or by coupling two quantum spin/anomalous Hall insulators, but these approaches have yet to be realized experimentally. In a bilayer gyromagnetic photonic crystal arranged in an antiferromagnetic layer configuration, our experimental observations reveal that interlayer coupling initiates a transition from a Chern insulating phase to a higher-order topological phase. This transition results in the gapping of CESs and triggers the emergence of corner states within the bandgap. The corner mode energy within the gap can be attributed to CESs interaction, forming a Jackiw-Rebbi topological domain wall mode at the corner. These states exhibit heightened resilience against defects, setting them apart from their time-reversal symmetric counterparts.",
    "authors": [
      "Subhaskar Mandal",
      "Ziyao Wang",
      "Rimi Banerjee",
      "Hau Tian Teo",
      "Peiheng Zhou",
      "Xiang Xi",
      "Zhen Gao",
      "Gui-Geng Liu",
      "Baile Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19267v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.mes-hall",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "48b9d10d-7548-41dd-b9df-a2cb5789deec": {
    "pk": "48b9d10d-7548-41dd-b9df-a2cb5789deec",
    "title": "PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications",
    "abstract": "Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce. Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures. To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline. In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation. Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models. After that, we devise a direct following preference optimization to enhance the generation of pediatrician-like humanistic responses. In the parameter-efficient secondary SFT phase, a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery. Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct doctor downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs. Our model and dataset will be open-source for community development.",
    "authors": [
      "Dingkang Yang",
      "Jinjie Wei",
      "Dongling Xiao",
      "Shunli Wang",
      "Tong Wu",
      "Gang Li",
      "Mingcheng Li",
      "Shuaibing Wang",
      "Jiawei Chen",
      "Yue Jiang",
      "Qingyao Xu",
      "Ke Li",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19266v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "440658a1-57d1-4105-8eaf-54e0f3d0eb6b": {
    "pk": "440658a1-57d1-4105-8eaf-54e0f3d0eb6b",
    "title": "Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models",
    "abstract": "Large language models are usually fine-tuned to align with human preferences. However, fine-tuning a large language model can be challenging. In this work, we introduce $\\textit{weak-to-strong search}$, framing the alignment of a large language model as a test-time greedy search to maximize the log-likelihood difference between small tuned and untuned models while sampling from the frozen large model. This method serves both as (i) a compute-efficient model up-scaling strategy that avoids directly tuning the large model and as (ii) an instance of weak-to-strong generalization that enhances a strong model with weak test-time guidance. Empirically, we demonstrate the flexibility of weak-to-strong search across different tasks. In controlled-sentiment generation and summarization, we use tuned and untuned $\\texttt{gpt2}$s to effectively improve the alignment of large models without additional training. Crucially, in a more difficult instruction-following benchmark, AlpacaEval 2.0, we show that reusing off-the-shelf small model pairs (e.g., $\\texttt{zephyr-7b-beta}$ and its untuned version) can significantly improve the length-controlled win rates of both white-box and black-box large models against $\\texttt{gpt-4-turbo}$ (e.g., $34.4 \\rightarrow 37.9$ for $\\texttt{Llama-3-70B-Instruct}$ and $16.0 \\rightarrow 20.1$ for $\\texttt{gpt-3.5-turbo-instruct}$), despite the small models' low win rates $\\approx 10.0$.",
    "authors": [
      "Zhanhui Zhou",
      "Zhixuan Liu",
      "Jie Liu",
      "Zhichen Dong",
      "Chao Yang",
      "Yu Qiao"
    ],
    "url": "http://arxiv.org/abs/2405.19262v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bb153b53-91ed-4eef-9b88-eb52f18e2e03": {
    "pk": "bb153b53-91ed-4eef-9b88-eb52f18e2e03",
    "title": "Faster Cascades via Speculative Decoding",
    "abstract": "Cascades and speculative decoding are two common approaches to improving language models' inference efficiency. Both approaches involve interleaving models of different sizes, but via fundamentally distinct mechanisms: cascades employ a deferral rule that invokes the larger model only for \"hard\" inputs, while speculative decoding uses speculative execution to primarily invoke the larger model in parallel verification mode. These mechanisms offer different benefits: empirically, cascades are often capable of yielding better quality than even the larger model, while theoretically, speculative decoding offers a guarantee of quality-neutrality. In this paper, we leverage the best of both these approaches by designing new speculative cascading techniques that implement their deferral rule through speculative execution. We characterize the optimal deferral rule for our speculative cascades, and employ a plug-in approximation to the optimal rule. Through experiments with T5 models on benchmark language tasks, we show that the proposed approach yields better cost-quality trade-offs than cascading and speculative decoding baselines.",
    "authors": [
      "Harikrishna Narasimhan",
      "Wittawat Jitkrittum",
      "Ankit Singh Rawat",
      "Seungyeon Kim",
      "Neha Gupta",
      "Aditya Krishna Menon",
      "Sanjiv Kumar"
    ],
    "url": "http://arxiv.org/abs/2405.19261v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5a8a44a8-cddd-46df-a264-0fdde51f691f": {
    "pk": "5a8a44a8-cddd-46df-a264-0fdde51f691f",
    "title": "Hilbert Space Diffusion in Systems with Approximate Symmetries",
    "abstract": "Random matrix theory (RMT) universality is the defining property of quantum mechanical chaotic systems, and can be probed by observables like the spectral form factor (SFF). In this paper, we describe systematic deviations from RMT behaviour at intermediate time scales in systems with approximate symmetries. At early times, the symmetries allow us to organize the Hilbert space into approximately decoupled sectors, each of which contributes independently to the SFF. At late times, the SFF transitions into the final ramp of the fully mixed chaotic Hamiltonian. For approximate continuous symmetries, the transitional behaviour is governed by a universal process that we call Hilbert space diffusion. The diffusion constant corresponding to this process is related to the relaxation rate of the associated nearly conserved charge. By implementing a chaotic sigma model for Hilbert-space diffusion, we formulate an analytic theory of this process which agrees quantitatively with our numerical results for different examples.",
    "authors": [
      "Rahel L. Baumgartner",
      "Luca V. Delacr\u00e9taz",
      "Pranjal Nayak",
      "Julian Sonner"
    ],
    "url": "http://arxiv.org/abs/2405.19260v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.stat-mech",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e5a959bd-a608-4035-ae36-e8af6274a286": {
    "pk": "e5a959bd-a608-4035-ae36-e8af6274a286",
    "title": "A Privacy-Preserving Graph Encryption Scheme Based on Oblivious RAM",
    "abstract": "Graph encryption schemes play a crucial role in facilitating secure queries on encrypted graphs hosted on untrusted servers. With applications spanning navigation systems, network topology, and social networks, the need to safeguard sensitive data becomes paramount. Existing graph encryption methods, however, exhibit vulnerabilities by inadvertently revealing aspects of the graph structure and query patterns, posing threats to security and privacy. In response, we propose a novel graph encryption scheme designed to mitigate access pattern and query pattern leakage through the integration of oblivious RAM and trusted execution environment techniques, exemplified by a Trusted Execution Environment (TEE). Our solution establishes two key security objectives: (1) ensuring that adversaries, when presented with an encrypted graph, remain oblivious to any information regarding the underlying graph, and (2) achieving query indistinguishability by concealing access patterns. Additionally, we conducted experimentation to evaluate the efficiency of the proposed schemes when dealing with real-world location navigation services.",
    "authors": [
      "Seyni Kane",
      "Anis Bkakria"
    ],
    "url": "http://arxiv.org/abs/2405.19259v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "55024ad5-cef9-4de7-9231-68aaa782f356": {
    "pk": "55024ad5-cef9-4de7-9231-68aaa782f356",
    "title": "Hybrid-Parallel: Achieving High Performance and Energy Efficient Distributed Inference on Robots",
    "abstract": "The rapid advancements in machine learning techniques have led to significant achievements in various real-world robotic tasks. These tasks heavily rely on fast and energy-efficient inference of deep neural network (DNN) models when deployed on robots. To enhance inference performance, distributed inference has emerged as a promising approach, parallelizing inference across multiple powerful GPU devices in modern data centers using techniques such as data parallelism, tensor parallelism, and pipeline parallelism. However, when deployed on real-world robots, existing parallel methods fail to provide low inference latency and meet the energy requirements due to the limited bandwidth of robotic IoT. We present Hybrid-Parallel, a high-performance distributed inference system optimized for robotic IoT. Hybrid-Parallel employs a fine-grained approach to parallelize inference at the granularity of local operators within DNN layers (i.e., operators that can be computed independently with the partial input, such as the convolution kernel in the convolution layer). By doing so, Hybrid-Parallel enables different operators of different layers to be computed and transmitted concurrently, and overlap the computation and transmission phases within the same inference task. The evaluation demonstrate that Hybrid-Parallel reduces inference time by 14.9% ~41.1% and energy consumption per inference by up to 35.3% compared to the state-of-the-art baselines.",
    "authors": [
      "Zekai Sun",
      "Xiuxian Guan",
      "Junming Wang",
      "Haoze Song",
      "Yuhao Qing",
      "Tianxiang Shen",
      "Dong Huang",
      "Fangming Liu",
      "Heming Cui"
    ],
    "url": "http://arxiv.org/abs/2405.19257v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "dff3f429-a510-45c6-8606-b036f49898e0": {
    "pk": "dff3f429-a510-45c6-8606-b036f49898e0",
    "title": "Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation",
    "abstract": "Sampling invariant distributions from an Ito diffusion process presents a significant challenge in stochastic simulation. Traditional numerical solvers for stochastic differential equations require both a fine step size and a lengthy simulation period, resulting in both biased and correlated samples. Current deep learning-based method solves the stationary Fokker--Planck equation to determine the invariant probability density function in form of deep neural networks, but they generally do not directly address the problem of sampling from the computed density function. In this work, we introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker--Planck equation. Our proposed loss function is based on the weak form of the Fokker--Planck equation, integrating normalizing flows to characterize the invariant distribution and facilitate sample generation from the base distribution. Our randomized test function circumvents the need for mini-max optimization in the traditional weak formulation. Distinct from conventional generative models, our method neither necessitates the computationally intensive calculation of the Jacobian determinant nor the invertibility of the transformation map. A crucial component of our framework is the adaptively chosen family of test functions in the form of Gaussian kernel functions with centres selected from the generated data samples. Experimental results on several benchmark examples demonstrate the effectiveness of our method, which offers both low computational costs and excellent capability in exploring multiple metastable states.",
    "authors": [
      "Zhiqiang Cai",
      "Yu Cao",
      "Yuanfei Huang",
      "Xiang Zhou"
    ],
    "url": "http://arxiv.org/abs/2405.19256v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "45ae6f19-2dc8-4c16-b641-507be2b8a5ec": {
    "pk": "45ae6f19-2dc8-4c16-b641-507be2b8a5ec",
    "title": "Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation",
    "abstract": "The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. Yet, addressing complex urban and environmental management problems normally requires in-depth domain science and informatics expertise. This expertise is essential for deriving data and simulation-driven for informed decision support. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated workflow that encompasses natural language processing, methontology-based prompt tuning, and transformers. This workflow automates the creation of scenario-based ontology using existing research articles and technical manuals of urban datasets and simulations. The outcomes of our methodology are knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL). These facilitate the development of urban decision support systems by enhancing the data and metadata modeling, the integration of complex datasets, the coupling of multi-domain simulation models, and the formulation of decision-making metrics and workflow. The feasibility of our methodology is evaluated through a comparative analysis that juxtaposes our AI-generated ontology with the well-known Pizza Ontology employed in tutorials for popular ontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of optimizing the complex urban system of multi-modal freight transportation by generating anthologies of various domain data and simulations to support informed decision-making.",
    "authors": [
      "Jose Tupayachi",
      "Haowen Xu",
      "Olufemi A. Omitaomu",
      "Mustafa Can Camur",
      "Aliza Sharmin",
      "Xueping Li"
    ],
    "url": "http://arxiv.org/abs/2405.19255v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "2108b4af-241b-4414-862b-93feb3a25bc2": {
    "pk": "2108b4af-241b-4414-862b-93feb3a25bc2",
    "title": "Causal Fermion Systems as an Effective Collapse Theory",
    "abstract": "It is shown that, in the non-relativistic limit, causal fermion systems give rise to an effective collapse theory. The nonlinear and stochastic correction terms to the Schr\\\"odinger equation are derived from the causal action principle. The dynamics of the statistical operator is described by a deterministic equation of Kossakowski-Lindblad form. Moreover, the quantum state undergoes a dynamical collapse compatible with Born's rule. The effective model has similarities with the continuous spontaneous localization model, but differs from it by a conservation law for the probability integral as well as a non-locality in time on a microscopic length scale $\\ell_{\\min}$.",
    "authors": [
      "Felix Finster",
      "Johannes Kleiner",
      "Claudio F. Paganini"
    ],
    "url": "http://arxiv.org/abs/2405.19254v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "003bf7c1-b4b5-4ef2-926e-6b2e408fdbb7": {
    "pk": "003bf7c1-b4b5-4ef2-926e-6b2e408fdbb7",
    "title": "Dark matter admixed neutron stars with a realistic nuclear equation of state from chiral nuclear interactions",
    "abstract": "We study the effects of dark matter on the structural properties of neutron stars. In particular we investigate how the presence of a dark matter component influences the mass-radius relation, the value of the maximum mass of a neutron star and others stellar properties. To model ordinary matter we use a state-of-the-art equation of state of $\\beta$-stable nuclear matter obtained using the Brueckner-Hartree-Fock quantum many-body approach starting from two-body and three-body nuclear interactions derived from chiral effective field theory. The dark matter component of the star is modeled as a non-self-annihilating system of spin $1/2$ fermions and its equation of state as an ideal relativistic Fermi gas. The equilibrium configurations of these dark matter admixed neutron stars (DANS) are calculated by solving a generalization of the Tolman-Oppenheimer-Volkoff equations to the case where the system consists of two perfect fluids interacting solely through gravity. We find that, depending on the dark matter particle mass $m_\\chi$, one can have somehow opposite effects on the stellar properties. In the case $m_\\chi = 1\\, \\mathrm{GeV}$, the stellar gravitational maximum mass $M_{max}$ decreases, whereas in the case $m_\\chi = 0.1\\, \\mathrm{GeV}$, $M_{max}$ increases with respect to the maximum mass of ordinary neutron stars. We also show that the presence of dark matter has indirect sizeable effect on the proton fraction in the ordinary matter fluid and, in the case $m_\\chi = 1\\, \\mathrm{GeV}$, results in a decrease of the threshold gravitational mass $M_{tot}^{durca}$ for having direct URCA processes and fast stellar cooling. Finally we study the stability of dark matter admixed neutron stars with respect to radial perturbations.",
    "authors": [
      "Domenico Scordino",
      "Ignazio Bombaci"
    ],
    "url": "http://arxiv.org/abs/2405.19251v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.HE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "bbfbbdd3-ff0a-458c-9d66-9b738fb8dcd5": {
    "pk": "bbfbbdd3-ff0a-458c-9d66-9b738fb8dcd5",
    "title": "Kotlin ML Pack: Technical Report",
    "abstract": "In this technical report, we present three novel datasets of Kotlin code: KStack, KStack-clean, and KExercises. We also describe the results of fine-tuning CodeLlama and DeepSeek models on this data. Additionally, we present a version of the HumanEval benchmark rewritten by human experts into Kotlin - both the solutions and the tests. Our results demonstrate that small, high-quality datasets (KStack-clean and KExercises) can significantly improve model performance on code generation tasks, achieving up to a 16-point increase in pass rate on the HumanEval benchmark. Lastly, we discuss potential future work in the field of improving language modeling for Kotlin, including the use of static analysis tools in the learning process and the introduction of more intricate and realistic benchmarks.",
    "authors": [
      "Sergey Titov",
      "Mikhail Evtikhiev",
      "Anton Shapkin",
      "Oleg Smirnov",
      "Sergei Boytsov",
      "Sergei Boytsov",
      "Dariia Karaeva",
      "Maksim Sheptyakov",
      "Mikhail Arkhipov",
      "Timofey Bryksin",
      "Egor Bogomolov"
    ],
    "url": "http://arxiv.org/abs/2405.19250v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SE",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fa9883e4-9901-4898-92d3-d4d96b8f08d3": {
    "pk": "fa9883e4-9901-4898-92d3-d4d96b8f08d3",
    "title": "Comparative Study of Neighbor-based Methods for Local Outlier Detection",
    "abstract": "The neighbor-based method has become a powerful tool to handle the outlier detection problem, which aims to infer the abnormal degree of the sample based on the compactness of the sample and its neighbors. However, the existing methods commonly focus on designing different processes to locate outliers in the dataset, while the contributions of different types neighbors to outlier detection has not been well discussed. To this end, this paper studies the neighbor in the existing outlier detection algorithms and a taxonomy is introduced, which uses the three-level components of information, neighbor and methodology to define hybrid methods. This taxonomy can serve as a paradigm where a novel neighbor-based outlier detection method can be proposed by combining different components in this taxonomy. A large number of comparative experiments were conducted on synthetic and real-world datasets in terms of performance comparison and case study, and the results show that reverse K-nearest neighbor based methods achieve promising performance and dynamic selection method is suitable for working in high-dimensional space. Notably, it is verified that rationally selecting components from this taxonomy may create an algorithms superior to existing methods.",
    "authors": [
      "Zhuang Qi",
      "Junlin Zhang",
      "Xiaming Chen",
      "Xin Qi"
    ],
    "url": "http://arxiv.org/abs/2405.19247v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "86de8d46-afc9-40cc-8ddf-09511281c89c": {
    "pk": "86de8d46-afc9-40cc-8ddf-09511281c89c",
    "title": "Efficient Optimal Control of Open Quantum Systems",
    "abstract": "The optimal control problem for open quantum systems can be formulated as a time-dependent Lindbladian that is parameterized by a number of time-dependent control variables. Given an observable and an initial state, the goal is to tune the control variables so that the expected value of some observable with respect to the final state is maximized. In this paper, we present algorithms for solving this optimal control problem efficiently, i.e., having a poly-logarithmic dependency on the system dimension, which is exponentially faster than best-known classical algorithms. Our algorithms are hybrid, consisting of both quantum and classical components. The quantum procedure simulates time-dependent Lindblad evolution that drives the initial state to the final state, and it also provides access to the gradients of the objective function via quantum gradient estimation. The classical procedure uses the gradient information to update the control variables.   At the technical level, we provide the first (to the best of our knowledge) simulation algorithm for time-dependent Lindbladians with an $\\ell_1$-norm dependence. As an alternative, we also present a simulation algorithm in the interaction picture to improve the algorithm for the cases where the time-independent component of a Lindbladian dominates the time-dependent part. On the classical side, we heavily adapt the state-of-the-art classical optimization analysis to interface with the quantum part of our algorithms. Both the quantum simulation techniques and the classical optimization analyses might be of independent interest.",
    "authors": [
      "Wenhao He",
      "Tongyang Li",
      "Xiantao Li",
      "Zecheng Li",
      "Chunhao Wang",
      "Ke Wang"
    ],
    "url": "http://arxiv.org/abs/2405.19245v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5562fce9-55d0-4762-8ac8-423ba704d294": {
    "pk": "5562fce9-55d0-4762-8ac8-423ba704d294",
    "title": "Bottomed mesons and baryons in pp collisions at $\\sqrt{s}=5 \\, TeV$ LHC energy within a Coalescence plus Fragmentation approach",
    "abstract": "Recent experimental data from $pp$ collisions have shown a significant increase in heavy baryon production leading to a baryon over meson ratio which is one order of magnitude higher than elementary collisions ($e^+e^-$, $ep$). From a theoretical point of view this large production of baryon can be explained with hadronization via quark coalescence assuming a QGP medium in $pp$ collisions. In this study, we extend this analysis to include hadrons containing bottom quarks. Employing a coalescence plus fragmentation approach, we present predictions for $p_T$ spectra and the heavy baryon/meson ratio of charmed hadrons with and without strangeness content, specifically: $\\bar{B^0}$, $B_s$, $\\Lambda_b$, $\\Xi_b^{0,-}$, $\\Omega_b$, and the $B_c$ meson. We have found that coalescence is the dominant mechanism in the B meson production, especially at low momenta, at variance with what found in the charm sector where the D meson were mainly produced via fragmentation. Our model predicts a $\\Lambda_b/\\bar{B^0}\\approx0.5\\!-\\!1$ and $\\Xi_b^0/\\bar{B^0}$ ratio around 0.3 at very low transverse momentum, which are about $1.5$ larger then those of the corresponding charmed hadron ratios at the same collision energy. Furthermore, we discuss the relative ratios between charmed and bottomed hadrons, emphasizing how these observables can provide information about the distribution of charm and bottom quarks and, if experimentally observed, would further support the idea of quark-gluon plasma formation even in small collision systems.",
    "authors": [
      "Vincenzo Minissale",
      "Vincenzo Greco",
      "Salvatore Plumari"
    ],
    "url": "http://arxiv.org/abs/2405.19244v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "18d900fb-9618-4735-8e2c-b9d4fb31eea4": {
    "pk": "18d900fb-9618-4735-8e2c-b9d4fb31eea4",
    "title": "Challenge-Device-Synthesis: A multi-disciplinary approach for the development of social innovation competences for students of Artificial Intelligence",
    "abstract": "The advent of Artificial Intelligence is expected to imply profound changes in the short-term. It is therefore imperative for Academia, and particularly for the Computer Science scope, to develop cross-disciplinary tools that bond AI developments to their social dimension. To this aim, we introduce the Challenge-Device-Synthesis methodology (CDS), in which a specific challenge is presented to the students of AI, who are required to develop a device as a solution for the challenge. The device becomes the object of study for the different dimensions of social transformation, and the conclusions addressed by the students during the discussion around the device are presented in a synthesis piece in the shape of a 10-page scientific paper. The latter is evaluated taking into account both the depth of analysis and the level to which it genuinely reflects the social transformations associated with the proposed AI-based device. We provide data obtained during the pilot for the implementation phase of CDS within the subject of Social Innovation, a 6-ECTS subject from the 6th semester of the Degree of Artificial Intelligence, UAB-Barcelona. We provide details on temporalisation, task distribution, methodological tools used and assessment delivery procedure, as well as qualitative analysis of the results obtained.",
    "authors": [
      "Mat\u00edas Bilkis",
      "Joan Moya Kohler",
      "Fernando Vilari\u00f1o"
    ],
    "url": "http://arxiv.org/abs/2405.19243v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "822b0462-a5dd-4797-8776-0dd07548e632": {
    "pk": "822b0462-a5dd-4797-8776-0dd07548e632",
    "title": "Modeling public opinion control by a charismatic leader",
    "abstract": "We study the average long-time behavior of the binary opinions of a social group with peer-to-peer interactions under the influence of an external bias and a persuadable leader, a strongly-biased agent with a dynamic opinion with the intention of spreading it across the system. We use a generalized, fully-connected Ising model, with each spin representing the binary opinion of an agent at a given time and a single, super spin representing the opinion of the leader. External fields and interaction constants model the opinion bias and peer-to-peer interactions, respectively, while the temperature $T$ models an idealized social climate, representing an authoritarian regime if $T$ is low or a liberal one if $T$ is high. We derive a mean-field solution for the average magnetization $m$, the \"social mood\", and investigate how $m$ and the super spin magnetization vary as a function of $T$. We find that, depending on the initial conditions, due to the presence of metastable states, the sign of the average magnetization depends on the temperature. Finally, we verify that this effect is also present even if we consider only nearest-neighbor interactions within the social group.",
    "authors": [
      "Tiago S. A. N. Sim\u00f5es",
      "Antonio Coniglio",
      "Hans J. Herrmann",
      "Lucilla de Arcangelis"
    ],
    "url": "http://arxiv.org/abs/2405.19242v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cond-mat.stat-mech",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "562353a2-3212-4b21-a03b-b4381c32d69e": {
    "pk": "562353a2-3212-4b21-a03b-b4381c32d69e",
    "title": "A remark on rapid mixing for hyperbolic flows",
    "abstract": "In this short paper, we introduce a new criterion based on the temporal distance function that guarantees rapid mixing for a hyperbolic flow with respect to Gibbs measures. This criterion is probabilistically satisfied almost surely but lacks robustness. Moreover, it enables us to establish rapid mixing for a class of hyperbolic flows that do not meet the existing rapid mixing criteria. Furthermore, beyond uniform hyperbolicity, our proof also works for a significant category of non-uniformly hyperbolic flows that can be modeled by Young towers.",
    "authors": [
      "Daofei Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19241v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.DS",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "920b4776-36bb-4788-b66b-00240f03f668": {
    "pk": "920b4776-36bb-4788-b66b-00240f03f668",
    "title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning",
    "abstract": "While large-scale text-to-image diffusion models have demonstrated impressive image-generation capabilities, there are significant concerns about their potential misuse for generating unsafe content, violating copyright, and perpetuating societal biases. Recently, the text-to-image generation community has begun addressing these concerns by editing or unlearning undesired concepts from pre-trained models. However, these methods often involve data-intensive and inefficient fine-tuning or utilize various forms of token remapping, rendering them susceptible to adversarial jailbreaks. In this paper, we present a simple and effective training-free approach, ConceptPrune, wherein we first identify critical regions within pre-trained models responsible for generating undesirable concepts, thereby facilitating straightforward concept unlearning via weight pruning. Experiments across a range of concepts including artistic styles, nudity, object erasure, and gender debiasing demonstrate that target concepts can be efficiently erased by pruning a tiny fraction, approximately 0.12% of total weights, enabling multi-concept erasure and robustness against various white-box and black-box adversarial attacks.",
    "authors": [
      "Ruchika Chavhan",
      "Da Li",
      "Timothy Hospedales"
    ],
    "url": "http://arxiv.org/abs/2405.19237v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "f52ac9d3-65c5-4b8a-a24f-95f84aca9a13": {
    "pk": "f52ac9d3-65c5-4b8a-a24f-95f84aca9a13",
    "title": "Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach",
    "abstract": "In transportation networks, intersections pose significant risks of collisions due to conflicting movements of vehicles approaching from different directions. To address this issue, various tools can exert influence on traffic safety both directly and indirectly. This study focuses on investigating the impact of adaptive signal control and connected and automated vehicles (CAVs) on intersection safety using a deep reinforcement learning approach. The objective is to assess the individual and combined effects of CAVs and adaptive traffic signal control on traffic safety, considering rear-end and crossing conflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals and driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses Time To Collision (TTC) metric to evaluate safety. The findings demonstrate a significant reduction in rear-end and crossing conflicts through the combined implementation of CAVs and DQNs-based traffic signal control. Additionally, the long-term positive effects of CAVs on safety are similar to the short-term effects of combined CAVs and DQNs-based traffic signal control. Overall, the study emphasizes the potential benefits of integrating CAVs and adaptive traffic signal control approaches in order to enhance traffic safety. The findings of this study could provide valuable insights for city officials and transportation authorities in developing effective strategies to improve safety at signalized intersections.",
    "authors": [
      "Amir Hossein Karbasi",
      "Hao Yang",
      "Saiedeh Razavi"
    ],
    "url": "http://arxiv.org/abs/2405.19236v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "9cb114cc-49d0-42fd-814b-57d820cda5f2": {
    "pk": "9cb114cc-49d0-42fd-814b-57d820cda5f2",
    "title": "Forward-Backward Knowledge Distillation for Continual Clustering",
    "abstract": "Unsupervised Continual Learning (UCL) is a burgeoning field in machine learning, focusing on enabling neural networks to sequentially learn tasks without explicit label information. Catastrophic Forgetting (CF), where models forget previously learned tasks upon learning new ones, poses a significant challenge in continual learning, especially in UCL, where labeled information of data is not accessible. CF mitigation strategies, such as knowledge distillation and replay buffers, often face memory inefficiency and privacy issues. Although current research in UCL has endeavored to refine data representations and address CF in streaming data contexts, there is a noticeable lack of algorithms specifically designed for unsupervised clustering. To fill this gap, in this paper, we introduce the concept of Unsupervised Continual Clustering (UCC). We propose Forward-Backward Knowledge Distillation for unsupervised Continual Clustering (FBCC) to counteract CF within the context of UCC. FBCC employs a single continual learner (the ``teacher'') with a cluster projector, along with multiple student models, to address the CF issue. The proposed method consists of two phases: Forward Knowledge Distillation, where the teacher learns new clusters while retaining knowledge from previous tasks with guidance from specialized student models, and Backward Knowledge Distillation, where a student model mimics the teacher's behavior to retain task-specific knowledge, aiding the teacher in subsequent tasks. FBCC marks a pioneering approach to UCC, demonstrating enhanced performance and memory efficiency in clustering across various tasks, outperforming the application of clustering algorithms to the latent space of state-of-the-art UCL algorithms.",
    "authors": [
      "Mohammadreza Sadeghi",
      "Zihan Wang",
      "Narges Armanfard"
    ],
    "url": "http://arxiv.org/abs/2405.19234v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "92e55f3b-de06-4034-b2e0-5e469c8cde54": {
    "pk": "92e55f3b-de06-4034-b2e0-5e469c8cde54",
    "title": "DiPPeST: Diffusion-based Path Planner for Synthesizing Trajectories Applied on Quadruped Robots",
    "abstract": "We present DiPPeST, a novel image and goal conditioned diffusion-based trajectory generator for quadrupedal robot path planning. DiPPeST is a zero-shot adaptation of our previously introduced diffusion-based 2D global trajectory generator (DiPPeR). The introduced system incorporates a novel strategy for local real-time path refinements, that is reactive to camera input, without requiring any further training, image processing, or environment interpretation techniques. DiPPeST achieves 92% success rate in obstacle avoidance for nominal environments and an average of 88% success rate when tested in environments that are up to 3.5 times more complex in pixel variation than DiPPeR. A visual-servoing framework is developed to allow for real-world execution, tested on the quadruped robot, achieving 80% success rate in different environments and showcasing improved behavior than complex state-of-the-art local planners, in narrow environments.",
    "authors": [
      "Maria Stamatopoulou",
      "Jianwei Liu",
      "Dimitrios Kanoulas"
    ],
    "url": "http://arxiv.org/abs/2405.19232v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "91ff3caa-4a3d-4ee7-8b8f-9496baf79365": {
    "pk": "91ff3caa-4a3d-4ee7-8b8f-9496baf79365",
    "title": "Valid Conformal Prediction for Dynamic GNNs",
    "abstract": "Graph neural networks (GNNs) are powerful black-box models which have shown impressive empirical performance. However, without any form of uncertainty quantification, it can be difficult to trust such models in high-risk scenarios. Conformal prediction aims to address this problem, however, an assumption of exchangeability is required for its validity which has limited its applicability to static graphs and transductive regimes. We propose to use unfolding, which allows any existing static GNN to output a dynamic graph embedding with exchangeability properties. Using this, we extend the validity of conformal prediction to dynamic GNNs in both transductive and semi-inductive regimes. We provide a theoretical guarantee of valid conformal prediction in these cases and demonstrate the empirical validity, as well as the performance gains, of unfolded GNNs against standard GNN architectures on both simulated and real datasets.",
    "authors": [
      "Ed Davis",
      "Ian Gallagher",
      "Daniel John Lawson",
      "Patrick Rubin-Delanchy"
    ],
    "url": "http://arxiv.org/abs/2405.19230v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c013823a-665e-4087-ab2a-dff05a757d0f": {
    "pk": "c013823a-665e-4087-ab2a-dff05a757d0f",
    "title": "On Generating Monolithic and Model Reconciling Explanations in Probabilistic Scenarios",
    "abstract": "Explanation generation frameworks aim to make AI systems' decisions transparent and understandable to human users. However, generating explanations in uncertain environments characterized by incomplete information and probabilistic models remains a significant challenge. In this paper, we propose a novel framework for generating probabilistic monolithic explanations and model reconciling explanations. Monolithic explanations provide self-contained reasons for an explanandum without considering the agent receiving the explanation, while model reconciling explanations account for the knowledge of the agent receiving the explanation. For monolithic explanations, our approach integrates uncertainty by utilizing probabilistic logic to increase the probability of the explanandum. For model reconciling explanations, we propose a framework that extends the logic-based variant of the model reconciliation problem to account for probabilistic human models, where the goal is to find explanations that increase the probability of the explanandum while minimizing conflicts between the explanation and the probabilistic human model. We introduce explanatory gain and explanatory power as quantitative metrics to assess the quality of these explanations. Further, we present algorithms that exploit the duality between minimal correction sets and minimal unsatisfiable sets to efficiently compute both types of explanations in probabilistic contexts. Extensive experimental evaluations on various benchmarks demonstrate the effectiveness and scalability of our approach in generating explanations under uncertainty.",
    "authors": [
      "Stylianos Loukas Vasileiou",
      "William Yeoh",
      "Alessandro Previti",
      "Tran Cao Son"
    ],
    "url": "http://arxiv.org/abs/2405.19229v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "a5f4e9a2-6f7e-44f1-954a-f80bd6a0610e": {
    "pk": "a5f4e9a2-6f7e-44f1-954a-f80bd6a0610e",
    "title": "ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions",
    "abstract": "Image retrieval from contextual descriptions (IRCD) aims to identify an image within a set of minimally contrastive candidates based on linguistically complex text. Despite the success of VLMs, they still significantly lag behind human performance in IRCD. The main challenges lie in aligning key contextual cues in two modalities, where these subtle cues are concealed in tiny areas of multiple contrastive images and within the complex linguistics of textual descriptions. This motivates us to propose ContextBLIP, a simple yet effective method that relies on a doubly contextual alignment scheme for challenging IRCD. Specifically, 1) our model comprises a multi-scale adapter, a matching loss, and a text-guided masking loss. The adapter learns to capture fine-grained visual cues. The two losses enable iterative supervision for the adapter, gradually highlighting the focal patches of a single image to the key textual cues. We term such a way as intra-contextual alignment. 2) Then, ContextBLIP further employs an inter-context encoder to learn dependencies among candidates, facilitating alignment between the text to multiple images. We term this step as inter-contextual alignment. Consequently, the nuanced cues concealed in each modality can be effectively aligned. Experiments on two benchmarks show the superiority of our method. We observe that ContextBLIP can yield comparable results with GPT-4V, despite involving about 7,500 times fewer parameters.",
    "authors": [
      "Honglin Lin",
      "Siyu Li",
      "Guoshun Nan",
      "Chaoyue Tang",
      "Xueting Wang",
      "Jingxin Xu",
      "Rong Yankai",
      "Zhili Zhou",
      "Yutong Gao",
      "Qimei Cui",
      "Xiaofeng Tao"
    ],
    "url": "http://arxiv.org/abs/2405.19226v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "02115052-65eb-4d3d-a494-39d4641e885c": {
    "pk": "02115052-65eb-4d3d-a494-39d4641e885c",
    "title": "Synthetic Potential Outcomes for Mixtures of Treatment Effects",
    "abstract": "Modern data analysis frequently relies on the use of large datasets, often constructed as amalgamations of diverse populations or data-sources. Heterogeneity across these smaller datasets constitutes two major challenges for causal inference: (1) the source of each sample can introduce latent confounding between treatment and effect, and (2) diverse populations may respond differently to the same treatment, giving rise to heterogeneous treatment effects (HTEs). The issues of latent confounding and HTEs have been studied separately but not in conjunction. In particular, previous works only report the conditional average treatment effect (CATE) among similar individuals (with respect to the measured covariates). CATEs cannot resolve mixtures of potential treatment effects driven by latent heterogeneity, which we call mixtures of treatment effects (MTEs). Inspired by method of moment approaches to mixture models, we propose \"synthetic potential outcomes\" (SPOs). Our new approach deconfounds heterogeneity while also guaranteeing the identifiability of MTEs. This technique bypasses full recovery of a mixture, which significantly simplifies its requirements for identifiability. We demonstrate the efficacy of SPOs on synthetic data.",
    "authors": [
      "Bijan Mazaheri",
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "url": "http://arxiv.org/abs/2405.19225v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4f2d7cc3-afbc-4934-9657-f05267641ccd": {
    "pk": "4f2d7cc3-afbc-4934-9657-f05267641ccd",
    "title": "A study on the adequacy of common IQA measures for medical images",
    "abstract": "Image quality assessment (IQA) is standard practice in the development stage of novel machine learning algorithms that operate on images. The most commonly used IQA measures have been developed and tested for natural images, but not in the medical setting. Reported inconsistencies arising in medical images are not surprising, as they have different properties than natural images. In this study, we test the applicability of common IQA measures for medical image data by comparing their assessment to manually rated chest X-ray (5 experts) and photoacoustic image data (1 expert). Moreover, we include supplementary studies on grayscale natural images and accelerated brain MRI data. The results of all experiments show a similar outcome in line with previous findings for medical imaging: PSNR and SSIM in the default setting are in the lower range of the result list and HaarPSI outperforms the other tested measures in the overall performance. Also among the top performers in our medical experiments are the full reference measures DISTS, FSIM, LPIPS and MS-SSIM. Generally, the results on natural images yield considerably higher correlations, suggesting that the additional employment of tailored IQA measures for medical imaging algorithms is needed.",
    "authors": [
      "Anna Breger",
      "Clemens Karner",
      "Ian Selby",
      "Janek Gr\u00f6hl",
      "S\u00f6ren Dittmer",
      "Edward Lilley",
      "Judith Babar",
      "Jake Beckford",
      "Timothy J Sadler",
      "Shahab Shahipasand",
      "Arthikkaa Thavakumar",
      "Michael Roberts",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "url": "http://arxiv.org/abs/2405.19224v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c9d09989-b09f-466b-aba1-33fdac2fb1ae": {
    "pk": "c9d09989-b09f-466b-aba1-33fdac2fb1ae",
    "title": "Domain adaptation in small-scale and heterogeneous biological datasets",
    "abstract": "Machine learning techniques are steadily becoming more important in modern biology, and are used to build predictive models, discover patterns, and investigate biological problems. However, models trained on one dataset are often not generalizable to other datasets from different cohorts or laboratories, due to differences in the statistical properties of these datasets. These could stem from technical differences, such as the measurement technique used, or from relevant biological differences between the populations studied. Domain adaptation, a type of transfer learning, can alleviate this problem by aligning the statistical distributions of features and samples among different datasets so that similar models can be applied across them. However, a majority of state-of-the-art domain adaptation methods are designed to work with large-scale data, mostly text and images, while biological datasets often suffer from small sample sizes, and possess complexities such as heterogeneity of the feature space. This Review aims to synthetically discuss domain adaptation methods in the context of small-scale and highly heterogeneous biological data. We describe the benefits and challenges of domain adaptation in biological research and critically discuss some of its objectives, strengths, and weaknesses through key representative methodologies. We argue for the incorporation of domain adaptation techniques to the computational biologist's toolkit, with further development of customized approaches.",
    "authors": [
      "Seyedmehdi Orouji",
      "Martin C. Liu",
      "Tal Korem",
      "Megan A. K. Peters"
    ],
    "url": "http://arxiv.org/abs/2405.19221v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "q-bio.QM",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "40bdd956-3dc6-4601-87ae-aefa1e9f3f99": {
    "pk": "40bdd956-3dc6-4601-87ae-aefa1e9f3f99",
    "title": "LoByITFL: Low Communication Secure and Private Federated Learning",
    "abstract": "Federated Learning (FL) faces several challenges, such as the privacy of the clients data and security against Byzantine clients. Existing works treating privacy and security jointly make sacrifices on the privacy guarantee. In this work, we introduce LoByITFL, the first communication-efficient Information-Theoretic (IT) private and secure FL scheme that makes no sacrifices on the privacy guarantees while ensuring security against Byzantine adversaries. The key ingredients are a small and representative dataset available to the federator, a careful transformation of the FLTrust algorithm and the use of a trusted third party only in a one-time preprocessing phase before the start of the learning algorithm. We provide theoretical guarantees on privacy and Byzantine-resilience, and provide convergence guarantee and experimental results validating our theoretical findings.",
    "authors": [
      "Yue Xia",
      "Christoph Hofmeister",
      "Maximilian Egger",
      "Rawad Bitar"
    ],
    "url": "http://arxiv.org/abs/2405.19217v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IT",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "959a157b-d342-4d08-bea0-ab7fbb61051b": {
    "pk": "959a157b-d342-4d08-bea0-ab7fbb61051b",
    "title": "Two dimensional potential theory with a view towards vortex motion: Energy, capacity and Green functions",
    "abstract": "The paper reviews some parts of classical potential theory with applications to two dimensional fluid dynamics, in particular vortex motion. Energy and forces within a system of point vortices are similar to those for point charges when the vortices are kept fixed, but the dynamics is different in the case of free vortices. Starting from Bernoulli's equation we derive these laws. Letting the number of vortices tend to infinity leads in the limit to considerations of capacity, harmonic measure and many other notions in potential theory. In particular various kinds of Green functions have a central role in the paper, where we make a difference between electrostatic and hydrodynamic Green function.   We also consider the corresponding concepts in the case of closed Riemann surfaces provided with a metric. From a canonically defined monopole Green function we rederive much of the classical theory of harmonic and analytic forms. In the final section of the paper we return to the planar case, then reappearing in form of a symmetric Riemann surface, the Schottky double. Bergman kernels, electrostatic and hydrodynamic, come up naturally, and associated to the Green function the is a certain Robin function which is important for vortex motion and which also relates to capacity functions in classical potential theory.",
    "authors": [
      "Bj\u00f6rn Gustafsson"
    ],
    "url": "http://arxiv.org/abs/2405.19215v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "3acd9ff7-26db-48e1-80f6-03eb6770844d": {
    "pk": "3acd9ff7-26db-48e1-80f6-03eb6770844d",
    "title": "HawkVision: Low-Latency Modeless Edge AI Serving",
    "abstract": "The trend of modeless ML inference is increasingly growing in popularity as it hides the complexity of model inference from users and caters to diverse user and application accuracy requirements. Previous work mostly focuses on modeless inference in data centers. To provide low-latency inference, in this paper, we promote modeless inference at the edge. The edge environment introduces additional challenges related to low power consumption, limited device memory, and volatile network environments.   To address these challenges, we propose HawkVision, which provides low-latency modeless serving of vision DNNs. HawkVision leverages a two-layer edge-DC architecture that employs confidence scaling to reduce the number of model options while meeting diverse accuracy requirements. It also supports lossy inference under volatile network environments. Our experimental results show that HawkVision outperforms current serving systems by up to 1.6X in P99 latency for providing modeless service. Our FPGA prototype demonstrates similar performance at certain accuracy levels with up to a 3.34X reduction in power consumption.",
    "authors": [
      "ChonLam Lao",
      "Jiaqi Gao",
      "Ganesh Ananthanarayanan",
      "Aditya Akella",
      "Minlan Yu"
    ],
    "url": "http://arxiv.org/abs/2405.19213v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5328f807-196d-4b85-b876-55ef5c50f905": {
    "pk": "5328f807-196d-4b85-b876-55ef5c50f905",
    "title": "Partial Information Decomposition for Data Interpretability and Feature Selection",
    "abstract": "In this paper, we introduce Partial Information Decomposition of Features (PIDF), a new paradigm for simultaneous data interpretability and feature selection. Contrary to traditional methods that assign a single importance value, our approach is based on three metrics per feature: the mutual information shared with the target variable, the feature's contribution to synergistic information, and the amount of this information that is redundant. In particular, we develop a novel procedure based on these three metrics, which reveals not only how features are correlated with the target but also the additional and overlapping information provided by considering them in combination with other features. We extensively evaluate PIDF using both synthetic and real-world data, demonstrating its potential applications and effectiveness, by considering case studies from genetics and neuroscience.",
    "authors": [
      "Charles Westphal",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "url": "http://arxiv.org/abs/2405.19212v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4e815645-34d3-4103-aeba-f5f338a25386": {
    "pk": "4e815645-34d3-4103-aeba-f5f338a25386",
    "title": "Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning",
    "abstract": "Machine learning models are vulnerable to adversarial attacks, including attacks that leak information about the model's training data. There has recently been an increase in interest about how to best address privacy concerns, especially in the presence of data-removal requests. Machine unlearning algorithms aim to efficiently update trained models to comply with data deletion requests while maintaining performance and without having to resort to retraining the model from scratch, a costly endeavor. Several algorithms in the machine unlearning literature demonstrate some level of privacy gains, but they are often evaluated only on rudimentary membership inference attacks, which do not represent realistic threats. In this paper we describe and propose alternative evaluation methods for three key shortcomings in the current evaluation of unlearning algorithms. We show the utility of our alternative evaluations via a series of experiments of state-of-the-art unlearning algorithms on different computer vision datasets, presenting a more detailed picture of the state of the field.",
    "authors": [
      "Keltin Grimes",
      "Collin Abidi",
      "Cole Frank",
      "Shannon Gallagher"
    ],
    "url": "http://arxiv.org/abs/2405.19211v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c2742356-233c-47e9-9762-30f3a16b59cb": {
    "pk": "c2742356-233c-47e9-9762-30f3a16b59cb",
    "title": "Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes",
    "abstract": "Ensuring high-quality data is paramount for maximizing the performance of machine learning models and business intelligence systems. However, challenges in data quality, including noise in data capture, missing records, limited data production, and confounding variables, significantly constrain the potential performance of these systems. In this study, we propose an architecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to address these challenges. GGH analyses gradients from hypotheses as a proxy of distinct and possibly contradictory patterns in the data. This framework entails an additional step in machine learning training, where gradients can be included or excluded from backpropagation. In this manner, missing and noisy data are addressed through a unified solution that perceives both challenges as facets of the same overarching issue: the propagation of erroneous information. Experimental validation of GGH is conducted using real-world open-source datasets, where records with missing rates of up to 98.5% are simulated. Comparative analysis with state-of-the-art imputation methods demonstrates a substantial improvement in model performance achieved by GGH. Specifically in very high scarcity regimes, GGH was found to be the only viable solution. Additionally, GGH's noise detection capabilities are showcased by introducing simulated noise into the datasets and observing enhanced model performance after filtering out the noisy data. This study presents GGH as a promising solution for improving data quality and model performance in various applications.",
    "authors": [
      "Paulo Neves",
      "Joerg K. Wegner",
      "Philippe Schwaller"
    ],
    "url": "http://arxiv.org/abs/2405.19210v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "c34c16da-7d58-440a-bc60-13f1841e9c7c": {
    "pk": "c34c16da-7d58-440a-bc60-13f1841e9c7c",
    "title": "A Multi-Source Retrieval Question Answering Framework Based on RAG",
    "abstract": "With the rapid development of large-scale language models, Retrieval-Augmented Generation (RAG) has been widely adopted. However, existing RAG paradigms are inevitably influenced by erroneous retrieval information, thereby reducing the reliability and correctness of generated results. Therefore, to improve the relevance of retrieval information, this study proposes a method that replaces traditional retrievers with GPT-3.5, leveraging its vast corpus knowledge to generate retrieval information. We also propose a web retrieval based method to implement fine-grained knowledge retrieval, Utilizing the powerful reasoning capability of GPT-3.5 to realize semantic partitioning of problem.In order to mitigate the illusion of GPT retrieval and reduce noise in Web retrieval,we proposes a multi-source retrieval framework, named MSRAG, which combines GPT retrieval with web retrieval. Experiments on multiple knowledge-intensive QA datasets demonstrate that the proposed framework in this study performs better than existing RAG framework in enhancing the overall efficiency and accuracy of QA systems.",
    "authors": [
      "Ridong Wu",
      "Shuhong Chen",
      "Xiangbiao Su",
      "Yuankai Zhu",
      "Yifei Liao",
      "Jianming Wu"
    ],
    "url": "http://arxiv.org/abs/2405.19207v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IR",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "abd60eec-68c6-4ad2-9880-c86da2016a11": {
    "pk": "abd60eec-68c6-4ad2-9880-c86da2016a11",
    "title": "Matrix Manifold Neural Networks++",
    "abstract": "Deep neural networks (DNNs) on Riemannian manifolds have garnered increasing interest in various applied areas. For instance, DNNs on spherical and hyperbolic manifolds have been designed to solve a wide range of computer vision and nature language processing tasks. One of the key factors that contribute to the success of these networks is that spherical and hyperbolic manifolds have the rich algebraic structures of gyrogroups and gyrovector spaces. This enables principled and effective generalizations of the most successful DNNs to these manifolds. Recently, some works have shown that many concepts in the theory of gyrogroups and gyrovector spaces can also be generalized to matrix manifolds such as Symmetric Positive Definite (SPD) and Grassmann manifolds. As a result, some building blocks for SPD and Grassmann neural networks, e.g., isometric models and multinomial logistic regression (MLR) can be derived in a way that is fully analogous to their spherical and hyperbolic counterparts. Building upon these works, we design fully-connected (FC) and convolutional layers for SPD neural networks. We also develop MLR on Symmetric Positive Semi-definite (SPSD) manifolds, and propose a method for performing backpropagation with the Grassmann logarithmic map in the projector perspective. We demonstrate the effectiveness of the proposed approach in the human action recognition and node classification tasks.",
    "authors": [
      "Xuan Son Nguyen",
      "Shuo Yang",
      "Aymeric Histace"
    ],
    "url": "http://arxiv.org/abs/2405.19206v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5e2222fb-aa49-4161-9ef6-58b98c5afccd": {
    "pk": "5e2222fb-aa49-4161-9ef6-58b98c5afccd",
    "title": "Detection of entanglement by harnessing extracted work in an opto-magno-mechanics",
    "abstract": "The connections between thermodynamics and quantum information processing are of paramount importance. Here, we address a bipartite entanglement via extracted work in a cavity magnomechanical system contained inside an yttrium iron garnet (YIG) sphere. The photons and magnons interact through an interaction between magnetic dipoles. A magnetostrictive interaction, analogous to radiation pressure, couple's phonons and magnons. The extracted work was obtained through a device similar to the Szil\\'ard engine. This engine operates by manipulating the photon-magnon as a bipartite quantum state. We employ logarithmic negativity to measure the amount of entanglement between photon and magnon modes in steady and dynamical states. We explore the extracted work, separable work, and maximum work for squeezed thermal states. We investigate the amount of work extracted from a bipartite quantum state, which can potentially determine the degree of entanglement present in that state. Numerical studies show that entanglement, as detected by the extracted work and quantified by logarithmic negativity, is in good agreement. We show the reduction of extracted work by a second measurement compared to a single measurement. Also, the efficiency of the Szilard engine in steady and dynamical states is investigated. We hope this work is of paramount importance in quantum information processing.",
    "authors": [
      "M'bark Amghar",
      "Mohamed Amazioug"
    ],
    "url": "http://arxiv.org/abs/2405.19205v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "05bf5aae-311e-4290-9d45-666319d4e83d": {
    "pk": "05bf5aae-311e-4290-9d45-666319d4e83d",
    "title": "Contrastive-Adversarial and Diffusion: Exploring pre-training and fine-tuning strategies for sulcal identification",
    "abstract": "In the last decade, computer vision has witnessed the establishment of various training and learning approaches. Techniques like adversarial learning, contrastive learning, diffusion denoising learning, and ordinary reconstruction learning have become standard, representing state-of-the-art methods extensively employed for fully training or pre-training networks across various vision tasks. The exploration of fine-tuning approaches has emerged as a current focal point, addressing the need for efficient model tuning with reduced GPU memory usage and time costs while enhancing overall performance, as exemplified by methodologies like low-rank adaptation (LoRA). Key questions arise: which pre-training technique yields optimal results - adversarial, contrastive, reconstruction, or diffusion denoising? How does the performance of these approaches vary as the complexity of fine-tuning is adjusted? This study aims to elucidate the advantages of pre-training techniques and fine-tuning strategies to enhance the learning process of neural networks in independent identical distribution (IID) cohorts. We underscore the significance of fine-tuning by examining various cases, including full tuning, decoder tuning, top-level tuning, and fine-tuning of linear parameters using LoRA. Systematic summaries of model performance and efficiency are presented, leveraging metrics such as accuracy, time cost, and memory efficiency. To empirically demonstrate our findings, we focus on a multi-task segmentation-classification challenge involving the paracingulate sulcus (PCS) using different 3D Convolutional Neural Network (CNN) architectures by using the TOP-OSLO cohort comprising 596 subjects.",
    "authors": [
      "Michail Mamalakis",
      "H\u00e9lo\u00efse de Vareilles",
      "Shun-Chin Jim Wu",
      "Ingrid Agartz",
      "Lynn Egeland M\u00f8rch-Johnsen",
      "Jane Garrison",
      "Jon Simons",
      "Pietro Lio",
      "John Suckling",
      "Graham Murray"
    ],
    "url": "http://arxiv.org/abs/2405.19204v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.IV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "94a8db96-b549-4ea0-a057-c3a8aacf8b58": {
    "pk": "94a8db96-b549-4ea0-a057-c3a8aacf8b58",
    "title": "$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation",
    "abstract": "This paper aims to introduce 3D Gaussian for efficient, expressive, and editable digital avatar generation. This task faces two major challenges: (1) The unstructured nature of 3D Gaussian makes it incompatible with current generation pipelines; (2) the expressive animation of 3D Gaussian in a generative setting that involves training with multiple subjects remains unexplored. In this paper, we propose a novel avatar generation method named $E^3$Gen, to effectively address these challenges. First, we propose a novel generative UV features plane representation that encodes unstructured 3D Gaussian onto a structured 2D UV space defined by the SMPL-X parametric model. This novel representation not only preserves the representation ability of the original 3D Gaussian but also introduces a shared structure among subjects to enable generative learning of the diffusion model. To tackle the second challenge, we propose a part-aware deformation module to achieve robust and accurate full-body expressive pose control. Extensive experiments demonstrate that our method achieves superior performance in avatar generation and enables expressive full-body pose control and editing.",
    "authors": [
      "Weitian Zhang",
      "Yichao Yan",
      "Yunhui Liu",
      "Xingdong Sheng",
      "Xiaokang Yang"
    ],
    "url": "http://arxiv.org/abs/2405.19203v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "5084bb9a-d7b6-4cef-b49c-02cfe797eb8d": {
    "pk": "5084bb9a-d7b6-4cef-b49c-02cfe797eb8d",
    "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
    "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study delves into the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is crucial for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.",
    "authors": [
      "Renato M. Silva",
      "Greg\u00f3rio F. Azevedo",
      "Matheus V. V. Berto",
      "Jean R. Rocha",
      "Eduardo C. Fidelis",
      "Matheus V. Nogueira",
      "Pedro H. Lisboa",
      "Tiago A. Almeida"
    ],
    "url": "http://arxiv.org/abs/2405.19202v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "b6a0cce3-5ee5-49ac-946f-4fa5080d5c61": {
    "pk": "b6a0cce3-5ee5-49ac-946f-4fa5080d5c61",
    "title": "Going beyond compositional generalization, DDPMs can produce zero-shot interpolation",
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable capabilities in image generation, with studies suggesting that they can generalize by composing latent factors learned from the training data. In this work, we go further and study DDPMs trained on strictly separate subsets of the data distribution with large gaps on the support of the latent factors. We show that such a model can effectively generate images in the unexplored, intermediate regions of the distribution. For instance, when trained on clearly smiling and non-smiling faces, we demonstrate a sampling procedure which can generate slightly smiling faces without reference images (zero-shot interpolation). We replicate these findings for other attributes as well as other datasets. $\\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\\text{Our code is available on GitHub.}}$",
    "authors": [
      "Justin Deschenaux",
      "Igor Krawczuk",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ],
    "url": "http://arxiv.org/abs/2405.19201v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "59c4ac20-10e4-46ed-8007-6293903bdc7e": {
    "pk": "59c4ac20-10e4-46ed-8007-6293903bdc7e",
    "title": "Diffusion-based Dynamics Models for Long-Horizon Rollout in Offline Reinforcement Learning",
    "abstract": "With the great success of diffusion models (DMs) in generating realistic synthetic vision data, many researchers have investigated their potential in decision-making and control. Most of these works utilized DMs to sample directly from the trajectory space, where DMs can be viewed as a combination of dynamics models and policies. In this work, we explore how to decouple DMs' ability as dynamics models in fully offline settings, allowing the learning policy to roll out trajectories. As DMs learn the data distribution from the dataset, their intrinsic policy is actually the behavior policy induced from the dataset, which results in a mismatch between the behavior policy and the learning policy. We propose Dynamics Diffusion, short as DyDiff, which can inject information from the learning policy to DMs iteratively. DyDiff ensures long-horizon rollout accuracy while maintaining policy consistency and can be easily deployed on model-free algorithms. We provide theoretical analysis to show the advantage of DMs on long-horizon rollout over models and demonstrate the effectiveness of DyDiff in the context of offline reinforcement learning, where the rollout dataset is provided but no online environment for interaction. Our code is at https://github.com/FineArtz/DyDiff.",
    "authors": [
      "Hanye Zhao",
      "Xiaoshen Han",
      "Zhengbang Zhu",
      "Minghuan Liu",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "url": "http://arxiv.org/abs/2405.19189v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "13e616de-8e50-40aa-8848-ccd6eca2b9c4": {
    "pk": "13e616de-8e50-40aa-8848-ccd6eca2b9c4",
    "title": "Algorithmic Transparency and Participation through the Handoff Lens: Lessons Learned from the U.S. Census Bureau's Adoption of Differential Privacy",
    "abstract": "Emerging discussions on the responsible government use of algorithmic technologies propose transparency and public participation as key mechanisms for preserving accountability and trust. But in practice, the adoption and use of any technology shifts the social, organizational, and political context in which it is embedded. Therefore translating transparency and participation efforts into meaningful, effective accountability must take into account these shifts. We adopt two theoretical frames, Mulligan and Nissenbaum's handoff model and Star and Griesemer's boundary objects, to reveal such shifts during the U.S. Census Bureau's adoption of differential privacy (DP) in its updated disclosure avoidance system (DAS) for the 2020 census. This update preserved (and arguably strengthened) the confidentiality protections that the Bureau is mandated to uphold, and the Bureau engaged in a range of activities to facilitate public understanding of and participation in the system design process. Using publicly available documents concerning the Census' implementation of DP, this case study seeks to expand our understanding of how technical shifts implicate values, how such shifts can afford (or fail to afford) greater transparency and participation in system design, and the importance of localized expertise throughout. We present three lessons from this case study toward grounding understandings of algorithmic transparency and participation: (1) efforts towards transparency and participation in algorithmic governance must center values and policy decisions, not just technical design decisions; (2) the handoff model is a useful tool for revealing how such values may be cloaked beneath technical decisions; and (3) boundary objects alone cannot bridge distant communities without trusted experts traveling alongside to broker their adoption.",
    "authors": [
      "Amina A. Abdu",
      "Lauren M. Chambers",
      "Deirdre K. Mulligan",
      "Abigail Z. Jacobs"
    ],
    "url": "http://arxiv.org/abs/2405.19187v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "db5c1050-93d5-4202-88ba-4ce508a61083": {
    "pk": "db5c1050-93d5-4202-88ba-4ce508a61083",
    "title": "MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification",
    "abstract": "Large Vision Language Models (LVLMs) have shown remarkable capabilities in multimodal tasks like visual question answering or image captioning. However, inconsistencies between the visual information and the generated text, a phenomenon referred to as hallucinations, remain an unsolved problem with regard to the trustworthiness of LVLMs. To address this problem, recent works proposed to incorporate computationally costly Large (Vision) Language Models in order to detect hallucinations on a sentence- or subsentence-level. In this work, we introduce MetaToken, a lightweight binary classifier to detect hallucinations on the token-level at negligible cost. Based on a statistical analysis, we reveal key factors of hallucinations in LVLMs which have been overseen in previous works. MetaToken can be applied to any open-source LVLM without any knowledge about ground truth data providing a reliable detection of hallucinations. We evaluate our method on four state-of-the-art LVLMs demonstrating the effectiveness of our approach.",
    "authors": [
      "Laura Fieback",
      "Jakob Spiegelberg",
      "Hanno Gottschalk"
    ],
    "url": "http://arxiv.org/abs/2405.19186v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8035099d-7b83-4c10-8b1c-5826fb12f3fc": {
    "pk": "8035099d-7b83-4c10-8b1c-5826fb12f3fc",
    "title": "Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem",
    "abstract": "Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic Vehicle Routing Problem (VRP), which is a fundamental problem in logistics and transportation. Typically, DVRPs involve two stakeholders: service providers that deliver services to customers and customers who raise requests from different locations. Many real-world applications can be formulated as DVRP such as ridesharing and non-compliance capture. Apart from original objectives like optimising total utility or efficiency, DVRP should also consider fairness for all parties. Unfairness can induce service providers and customers to give up on the systems, leading to negative financial and social impacts. However, most existing DVRP-related applications focus on improving fairness from a single side, and there have been few works considering two-sided fairness and utility optimisation concurrently. To this end, we propose a novel framework, a Two-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the genetic algorithm from the original objective solely focusing on utility to multi-objectives that incorporate two-sided fairness. Subsequently, the impact of injecting two fairness definitions into the utility-focused model and the correlation between any pair of the three objectives are explored. Extensive experiments demonstrate the superiority of our proposed framework compared to the state-of-the-art.",
    "authors": [
      "Yufan Kang",
      "Rongsheng Zhang",
      "Wei Shao",
      "Flora D. Salim",
      "Jeffrey Chan"
    ],
    "url": "http://arxiv.org/abs/2405.19184v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "6b46e32f-f93e-4ad2-b798-132f4e36bc67": {
    "pk": "6b46e32f-f93e-4ad2-b798-132f4e36bc67",
    "title": "Conditional Latent ODEs for Motion Prediction in Autonomous Driving",
    "abstract": "This paper addresses imitation learning for motion prediction problem in autonomous driving, especially in multi-agent setting. Different from previous methods based on GAN, we present the conditional latent ordinary differential equation (cLODE) to leverage both the generative strength of conditional VAE and the continuous representation of neural ODE. Our network architecture is inspired from the Latent-ODE model. The experiment shows that our method outperform the baseline methods in the simulation of multi-agent driving and is very efficient in term of GPU memory consumption. Our code and docker image are publicly available: https://github.com/TruongKhang/cLODE; https://hub.docker.com/r/kim4375731/clode.",
    "authors": [
      "Khang Truong Giang",
      "Yongjae Kim",
      "Andrea Finazzi"
    ],
    "url": "http://arxiv.org/abs/2405.19183v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.RO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "014b3a9b-31f2-4206-b60c-e4a2df4b7434": {
    "pk": "014b3a9b-31f2-4206-b60c-e4a2df4b7434",
    "title": "Delay-Doppler Domain Pulse Design for OTFS-NOMA",
    "abstract": "We address the challenge of developing an orthogonal time-frequency space (OTFS)-based non-orthogonal multiple access (NOMA) system where each user is modulated using orthogonal pulses in the delay Doppler domain. Building upon the concept of the sufficient (bi)orthogonality train-pulse [1], we extend this idea by introducing Hermite functions, known for their orthogonality properties. Simulation results demonstrate that our proposed Hermite functions outperform the traditional OTFS-NOMA schemes, including power-domain (PDM) NOMA and code-domain (CDM) NOMA, in terms of bit error rate (BER) over a high-mobility channel. The algorithm's complexity is minimal, primarily involving the demodulation of OTFS. The spectrum efficiency of Hermite-based OTFS-NOMA is K times that of OTFS-CDM-NOMA scheme, where K is the spreading length of the NOMA waveform.",
    "authors": [
      "Michel Kulhandjian",
      "Hovannes Kulhandjian",
      "Gunes Karabulut Kurt",
      "Halim Yanikomeroglu"
    ],
    "url": "http://arxiv.org/abs/2405.19182v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "909aa99a-f68c-476e-9322-144c16484af9": {
    "pk": "909aa99a-f68c-476e-9322-144c16484af9",
    "title": "Model-independent cosmological inference post DESI DR1 BAO measurements",
    "abstract": "In this work, we implement Gaussian process regression to reconstruct the expansion history of the universe in a model-agnostic manner, using the Pantheon-Plus SN-Ia compilation in combination with two different BAO measurements (SDSS-IV and DESI DR1). In both the reconstructions, the $\\Lambda$CDM model is always included in the 95\\% confidence intervals. We find evidence that the DESI LRG data at $z_{\\text{eff}} = 0.51$ is not an outlier within our model-independent framework. We study the $\\mathcal{O}m$-diagnostics and the evolution of the total equation of state (EoS) of our universe, which hint towards the possibility of a quintessence-like dark energy scenario with a very slowly varying EoS, and a phantom-crossing in higher $z$. The entire exercise is later complemented by considering two more SN-Ia compilations - DES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI BAO + DES-5YR SN data sets predicts that the $\\Lambda$CDM model lies outside the 3$\\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the $\\Lambda$CDM model is always included within 1$\\sigma$. We also report constraints on $H_0 r_d$ from our model-agnostic analysis, independent of the pre-recombination physics. Our results point towards an $\\approx$ 2$\\sigma$ discrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets, which calls for further investigation.",
    "authors": [
      "Purba Mukherjee",
      "Anjan Ananda Sen"
    ],
    "url": "http://arxiv.org/abs/2405.19178v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.CO",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "488b55fa-1619-4211-90b5-aaa79402810c": {
    "pk": "488b55fa-1619-4211-90b5-aaa79402810c",
    "title": "Exoplanet Aeronomy: A Case Study of WASP-69b's Variable Thermosphere",
    "abstract": "Aeronomy, the study of Earth's upper atmosphere and its interaction with the local space environment, has long traced changes in the thermospheres of Earth and other solar system planets to solar variability in the X-ray and extreme ultraviolet (collectively, \"XUV\") bands. Extending comparative aeronomy to the short-period extrasolar planets may illuminate whether stellar XUV irradiation powers atmospheric outflows that change planetary radii on astronomical timescales. In recent years, near-infrared transit spectroscopy of metastable HeI has been a prolific tracer of high-altitude planetary gas. We present a case study of exoplanet aeronomy using metastable HeI transit observations from Palomar/WIRC and follow-up high-energy data from the Neil Gehrels Swift Observatory that were taken within one month of the WASP-69 system, a K-type main sequence star with a well-studied hot Jupiter companion. Supplemented by archival data, we find that WASP-69's X-ray flux in 2023 was less than 50% of what was recorded in 2016 and that the metastable HeI absorption from WASP-69b was lower in 2023 versus past epochs from 2017-2019. Via atmospheric modeling, we show that this time-variable metastable HeI signal is in the expected direction given the observed change in stellar XUV, possibly stemming from WASP-69's magnetic activity cycle. Our results underscore the ability of multi-epoch, multi-wavelength observations to paint a cohesive picture of the interaction between an exoplanet's atmosphere and its host star.",
    "authors": [
      "W. Garrett Levine",
      "Shreyas Vissapragada",
      "Adina D. Feinstein",
      "George W. King",
      "Aleck Hernandez",
      "Lia Corrales",
      "Michael Greklek-McKeon",
      "Heather A. Knutson"
    ],
    "url": "http://arxiv.org/abs/2405.19177v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "astro-ph.EP",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "d314968e-c73e-4a8b-9ccd-d8d281197caa": {
    "pk": "d314968e-c73e-4a8b-9ccd-d8d281197caa",
    "title": "The ethical situation of DALL-E 2",
    "abstract": "A hot topic of Artificial Intelligence right now is image generation from prompts. DALL-E 2 is one of the biggest names in this domain, as it allows people to create images from simple text inputs, to even more complicated ones. The company that made this possible, OpenAI, has assured everyone that visited their website that their mission is to ensure that artificial general intelligence benefits all humanity. A noble idea in our opinion, that also stood as the motive behind us choosing this subject. This paper analyzes the ethical implications of an AI image generative system, with an emphasis on how society is responding to it, how it probably will and how it should if all the right measures are taken.",
    "authors": [
      "Eduard Hogea",
      "Josem Rocafortf"
    ],
    "url": "http://arxiv.org/abs/2405.19176v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CY",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "512cc629-8eeb-4ee5-80d4-772d033cb760": {
    "pk": "512cc629-8eeb-4ee5-80d4-772d033cb760",
    "title": "Online Linear Regression in Dynamic Environments via Discounting",
    "abstract": "We develop algorithms for online linear regression which achieve optimal static and dynamic regret guarantees \\emph{even in the complete absence of prior knowledge}. We present a novel analysis showing that a discounted variant of the Vovk-Azoury-Warmuth forecaster achieves dynamic regret of the form $R_{T}(\\vec{u})\\le O\\left(d\\log(T)\\vee \\sqrt{dP_{T}^{\\gamma}(\\vec{u})T}\\right)$, where $P_{T}^{\\gamma}(\\vec{u})$ is a measure of variability of the comparator sequence, and show that the discount factor achieving this result can be learned on-the-fly. We show that this result is optimal by providing a matching lower bound. We also extend our results to \\emph{strongly-adaptive} guarantees which hold over every sub-interval $[a,b]\\subseteq[1,T]$ simultaneously.",
    "authors": [
      "Andrew Jacobsen",
      "Ashok Cutkosky"
    ],
    "url": "http://arxiv.org/abs/2405.19175v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ebe0068a-b031-48cc-9f36-6c868de3ecff": {
    "pk": "ebe0068a-b031-48cc-9f36-6c868de3ecff",
    "title": "Exploring AI-based Anonymization of Industrial Image and Video Data in the Context of Feature Preservation",
    "abstract": "With rising technologies, the protection of privacy-sensitive information is becoming increasingly important. In industry and production facilities, image or video recordings are beneficial for documentation, tracing production errors or coordinating workflows. Individuals in images or videos need to be anonymized. However, the anonymized data should be reusable for further applications. In this work, we apply the Deep Learning-based full-body anonymization framework DeepPrivacy2, which generates artificial identities, to industrial image and video data. We compare its performance with conventional anonymization techniques. Therefore, we consider the quality of identity generation, temporal consistency, and the applicability of pose estimation and action recognition.",
    "authors": [
      "Sabrina Cynthia Triess",
      "Timo Leitritz",
      "Christian Jauch"
    ],
    "url": "http://arxiv.org/abs/2405.19173v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "e631a8cf-a1e0-4798-9b37-2bcc35d66471": {
    "pk": "e631a8cf-a1e0-4798-9b37-2bcc35d66471",
    "title": "Greedy Kernel Methods for Approximating Breakthrough Curves for Reactive Flow from 3D Porous Geometry Data",
    "abstract": "We address the challenging application of 3D pore scale reactive flow under varying geometry parameters. The task is to predict time-dependent integral quantities, i.e., breakthrough curves, from the given geometries. As the 3D reactive flow simulation is highly complex and computationally expensive, we are interested in data-based surrogates that can give a rapid prediction of the target quantities of interest. This setting is an example of an application with scarce data, i.e., only having available few data samples, while the input and output dimensions are high. In this scarce data setting, standard machine learning methods are likely to ail. Therefore, we resort to greedy kernel approximation schemes that have shown to be efficient meshless approximation techniques for multivariate functions. We demonstrate that such methods can efficiently be used in the high-dimensional input/output case under scarce data. Especially, we show that the vectorial kernel orthogonal greedy approximation (VKOGA) procedure with a data-adapted two-layer kernel yields excellent predictors for learning from 3D geometry voxel data via both morphological descriptors or principal component analysis.",
    "authors": [
      "Robin Herkert",
      "Patrick Buchfink",
      "Tizian Wenzel",
      "Bernard Haasdonk",
      "Pavel Toktaliev",
      "Oleg Iliev"
    ],
    "url": "http://arxiv.org/abs/2405.19170v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "math.NA",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4611e20e-ae50-43c8-b843-2339137a44e4": {
    "pk": "4611e20e-ae50-43c8-b843-2339137a44e4",
    "title": "Measuring differential particle correlations in relativistic nuclear collisions",
    "abstract": "This study explores the transverse momentum ($p_T$) dependencies of Symmetric and Asymmetric Correlations (SC and ASC) with one and two particles of interest in Au+Au collisions at 200 GeV. Leveraging the AMPT model, the investigation delves into the sensitivity of these correlations to the final state effects, providing valuable insights into their potential for constraining the final state effects' $p_T$ dependencies. The HIJING model is employed as a benchmark for non-flow correlations, shedding light on their impact on interpreting SC and ASC data. Moreover, the study points out that differential SC and ASC with one and two particles of interest (POIs) typically incorporate contributions from event-plane angle fluctuations. Consequently, this work highlights the significance of SC and ASC with one and two POIs as valuable tools for investigating the $p_T$ nature of the final state effects and advocates for comprehensive experimental measurements across various beam energies and system sizes to enhance our understanding and provide additional constraints for theoretical models.",
    "authors": [
      "Niseem Magdy"
    ],
    "url": "http://arxiv.org/abs/2405.19169v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "hep-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8b436c34-8b7e-4404-b68e-d44210dcca07": {
    "pk": "8b436c34-8b7e-4404-b68e-d44210dcca07",
    "title": "Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity",
    "abstract": "Neural operator learning models have emerged as very effective surrogates in data-driven methods for partial differential equations (PDEs) across different applications from computational science and engineering. Such operator learning models not only predict particular instances of a physical or biological system in real-time but also forecast classes of solutions corresponding to a distribution of initial and boundary conditions or forcing terms. % DeepONet is the first neural operator model and has been tested extensively for a broad class of solutions, including Riemann problems. Transformers have not been used in that capacity, and specifically, they have not been tested for solutions of PDEs with low regularity. %   In this work, we first establish the theoretical groundwork that transformers possess the universal approximation property as operator learning models.   We then apply transformers to forecast solutions of diverse dynamical systems with solutions of finite regularity for a plurality of initial conditions and forcing terms. In particular, we consider three examples: the Izhikevich neuron model, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and the one-dimensional Euler equation Riemann problem. For the latter problem, we also compare with variants of DeepONet, and we find that transformers outperform DeepONet in accuracy but they are computationally more expensive.",
    "authors": [
      "Benjamin Shih",
      "Ahmad Peyvan",
      "Zhongqiang Zhang",
      "George Em Karniadakis"
    ],
    "url": "http://arxiv.org/abs/2405.19166v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "fb6bd84f-83e2-45ba-911a-29c5c74403cf": {
    "pk": "fb6bd84f-83e2-45ba-911a-29c5c74403cf",
    "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery",
    "abstract": "Electronic Discovery (eDiscovery) involves identifying relevant documents from a vast collection based on legal production requests. The integration of artificial intelligence (AI) and natural language processing (NLP) has transformed this process, helping document review and enhance efficiency and cost-effectiveness. Although traditional approaches like BM25 or fine-tuned pre-trained models are common in eDiscovery, they face performance, computational, and interpretability challenges. In contrast, Large Language Model (LLM)-based methods prioritize interpretability but sacrifice performance and throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid approach that combines the strengths of two worlds: a heterogeneous graph-based method for accurate document relevance prediction and subsequent LLM-driven approach for reasoning. Graph representational learning generates embeddings and predicts links, ranking the corpus for a given request, and the LLMs provide reasoning for document relevance. Our approach handles datasets with balanced and imbalanced distributions, outperforming baselines in F1-score, precision, and recall by an average of 12%, 3%, and 16%, respectively. In an enterprise context, our approach drastically reduces document review costs by 99.9% compared to manual processes and by 95% compared to LLM-based classification methods",
    "authors": [
      "Sounak Lahiri",
      "Sumit Pai",
      "Tim Weninger",
      "Sanmitra Bhattacharya"
    ],
    "url": "http://arxiv.org/abs/2405.19164v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.AI",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "384e5fd5-6856-4a49-8167-0c848bdc43f0": {
    "pk": "384e5fd5-6856-4a49-8167-0c848bdc43f0",
    "title": "Does learning the right latent variables necessarily improve in-context learning?",
    "abstract": "Large autoregressive models like Transformers can solve tasks through in-context learning (ICL) without learning new weights, suggesting avenues for efficiently solving new tasks. For many tasks, e.g., linear regression, the data factorizes: examples are independent given a task latent that generates the data, e.g., linear coefficients. While an optimal predictor leverages this factorization by inferring task latents, it is unclear if Transformers implicitly do so or if they instead exploit heuristics and statistical shortcuts enabled by attention layers. Both scenarios have inspired active ongoing work. In this paper, we systematically investigate the effect of explicitly inferring task latents. We minimally modify the Transformer architecture with a bottleneck designed to prevent shortcuts in favor of more structured solutions, and then compare performance against standard Transformers across various ICL tasks. Contrary to intuition and some recent works, we find little discernible difference between the two; biasing towards task-relevant latent variables does not lead to better out-of-distribution performance, in general. Curiously, we find that while the bottleneck effectively learns to extract latent task variables from context, downstream processing struggles to utilize them for robust prediction. Our study highlights the intrinsic limitations of Transformers in achieving structured ICL solutions that generalize, and shows that while inferring the right latents aids interpretability, it is not sufficient to alleviate this problem.",
    "authors": [
      "Sarthak Mittal",
      "Eric Elmoznino",
      "Leo Gagnon",
      "Sangnie Bhardwaj",
      "Dhanya Sridhar",
      "Guillaume Lajoie"
    ],
    "url": "http://arxiv.org/abs/2405.19162v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "8ad4f635-5bb3-42d1-86f9-f5c6d88562f2": {
    "pk": "8ad4f635-5bb3-42d1-86f9-f5c6d88562f2",
    "title": "Beyond Discrepancy: A Closer Look at the Theory of Distribution Shift",
    "abstract": "Many machine learning models appear to deploy effortlessly under distribution shift, and perform well on a target distribution that is considerably different from the training distribution. Yet, learning theory of distribution shift bounds performance on the target distribution as a function of the discrepancy between the source and target, rarely guaranteeing high target accuracy. Motivated by this gap, this work takes a closer look at the theory of distribution shift for a classifier from a source to a target distribution. Instead of relying on the discrepancy, we adopt an Invariant-Risk-Minimization (IRM)-like assumption connecting the distributions, and characterize conditions under which data from a source distribution is sufficient for accurate classification of the target. When these conditions are not met, we show when only unlabeled data from the target is sufficient, and when labeled target data is needed. In all cases, we provide rigorous theoretical guarantees in the large sample regime.",
    "authors": [
      "Robi Bhattacharjee",
      "Nick Rittler",
      "Kamalika Chaudhuri"
    ],
    "url": "http://arxiv.org/abs/2405.19156v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "88a3b9b4-7ed6-490e-b9ed-a97ea360ae52": {
    "pk": "88a3b9b4-7ed6-490e-b9ed-a97ea360ae52",
    "title": "Fate of non-Hermitian free fermions with Wannier-Stark ladder",
    "abstract": "The Wannier-Stark ladder (WSL) dynamically alters the entanglement behavior of non-Hermitian free fermions. Using the single-particle correlation matrix, we studied the effective Hamiltonian of these fermions with WSL. By examining the half-chain entanglement entropy (EE) under open boundary conditions (OBCs), we identified two different area law regions and an algebraic scaling region. Finite-size scaling revealed the critical scaling behavior of the half-chain EE. This system also shows distinct entanglement behavior under periodic boundary conditions (PBCs), differing from (1+1)D conformal field theory (CFT) under Anderson localizations scenarios. Our work paves the way for exploring the intriguing entanglement phases arising from the interplay between the non-Hermitian Skin effect (NHSE) and Wannier-Stark localization.",
    "authors": [
      "Han-Ze Li",
      "Jian-Xin Zhong"
    ],
    "url": "http://arxiv.org/abs/2405.19155v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "17915d2f-ead2-49e3-8a50-8ab7cc572ece": {
    "pk": "17915d2f-ead2-49e3-8a50-8ab7cc572ece",
    "title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning",
    "abstract": "Continual learning with deep neural networks presents challenges distinct from both the fixed-dataset and convex continual learning regimes. One such challenge is plasticity loss, wherein a neural network trained in an online fashion displays a degraded ability to fit new tasks. This problem has been extensively studied in both supervised learning and off-policy reinforcement learning (RL), where a number of remedies have been proposed. Still, plasticity loss has received less attention in the on-policy deep RL setting. Here we perform an extensive set of experiments examining plasticity loss and a variety of mitigation methods in on-policy deep RL. We demonstrate that plasticity loss is pervasive under domain shift in this regime, and that a number of methods developed to resolve it in other settings fail, sometimes even resulting in performance that is worse than performing no intervention at all. In contrast, we find that a class of ``regenerative'' methods are able to consistently mitigate plasticity loss in a variety of contexts, including in gridworld tasks and more challenging environments like Montezuma's Revenge and ProcGen.",
    "authors": [
      "Arthur Juliani",
      "Jordan T. Ash"
    ],
    "url": "http://arxiv.org/abs/2405.19153v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "05137ef7-e9f4-4614-97c6-ae02201bb8e5": {
    "pk": "05137ef7-e9f4-4614-97c6-ae02201bb8e5",
    "title": "CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval",
    "abstract": "Composed Image Retrieval (CIR) involves searching for target images based on an image-text pair query. While current methods treat this as a query-target matching problem, we argue that CIR triplets contain additional associations beyond this primary relation. In our paper, we identify two new relations within triplets, treating each triplet as a graph node. Firstly, we introduce the concept of text-bridged image alignment, where the query text serves as a bridge between the query image and the target image. We propose a hinge-based cross-attention mechanism to incorporate this relation into network learning. Secondly, we explore complementary text reasoning, considering CIR as a form of cross-modal retrieval where two images compose to reason about complementary text. To integrate these perspectives effectively, we design a twin attention-based compositor. By combining these complementary associations with the explicit query pair-target image relation, we establish a comprehensive set of constraints for CIR. Our framework, CaLa (Complementary Association Learning for Augmenting Composed Image Retrieval), leverages these insights. We evaluate CaLa on CIRR and FashionIQ benchmarks with multiple backbones, demonstrating its superiority in composed image retrieval.",
    "authors": [
      "Xintong Jiang",
      "Yaxiong Wang",
      "Mengjian Li",
      "Yujiao Wu",
      "Bingwen Hu",
      "Xueming Qian"
    ],
    "url": "http://arxiv.org/abs/2405.19149v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "4010bca4-9e10-4f4a-b202-c1e337addfff": {
    "pk": "4010bca4-9e10-4f4a-b202-c1e337addfff",
    "title": "I Bet You Did Not Mean That: Testing Semantic Importance via Betting",
    "abstract": "Recent works have extended notions of feature importance to \\emph{semantic concepts} that are inherently interpretable to the users interacting with a black-box predictive model. Yet, precise statistical guarantees, such as false positive rate control, are needed to communicate findings transparently and to avoid unintended consequences in real-world scenarios. In this paper, we formalize the global (i.e., over a population) and local (i.e., for a sample) statistical importance of semantic concepts for the predictions of opaque models, by means of conditional independence, which allows for rigorous testing. We use recent ideas of sequential kernelized testing (SKIT) to induce a rank of importance across concepts, and showcase the effectiveness and flexibility of our framework on synthetic datasets as well as on image classification tasks using vision-language models such as CLIP.",
    "authors": [
      "Jacopo Teneggi",
      "Jeremias Sulam"
    ],
    "url": "http://arxiv.org/abs/2405.19146v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "stat.ML",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "90125257-01da-4f56-ac1b-f59a799131cd": {
    "pk": "90125257-01da-4f56-ac1b-f59a799131cd",
    "title": "DGRC: An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension",
    "abstract": "When evaluating a learner's knowledge proficiency, the multiple-choice question is an efficient and widely used format in standardized tests. Nevertheless, generating these questions, particularly plausible distractors (incorrect options), poses a considerable challenge. Generally, the distractor generation can be classified into cloze-style distractor generation (CDG) and natural questions distractor generation (NQDG). In contrast to the CDG, utilizing pre-trained language models (PLMs) for NQDG presents three primary challenges: (1) PLMs are typically trained to generate ``correct'' content, like answers, while rarely trained to generate ``plausible\" content, like distractors; (2) PLMs often struggle to produce content that aligns well with specific knowledge and the style of exams; (3) NQDG necessitates the model to produce longer, context-sensitive, and question-relevant distractors. In this study, we introduce a fine-tuning framework named DGRC for NQDG in Chinese multi-choice reading comprehension from authentic examinations. DGRC comprises three major components: hard chain-of-thought, multi-task learning, and generation mask patterns. The experiment results demonstrate that DGRC significantly enhances generation performance, achieving a more than 2.5-fold improvement in BLEU scores.",
    "authors": [
      "Runfeng Lin",
      "Dacheng Xu",
      "Huijiang Wang",
      "Zebiao Chen",
      "Yating Wang",
      "Shouqiang Liu"
    ],
    "url": "http://arxiv.org/abs/2405.19139v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CL",
    "references": null,
    "citation_count": 0,
    "award": null
  },
  "ebc219cd-2f97-4d19-9cf9-e9f550ce6364": {
    "pk": "ebc219cd-2f97-4d19-9cf9-e9f550ce6364",
    "title": "Multi-Channel Multi-Step Spectrum Prediction Using Transformer and Stacked Bi-LSTM",
    "abstract": "Spectrum prediction is considered as a key technology to assist spectrum decision. Despite the great efforts that have been put on the construction of spectrum prediction, achieving accurate spectrum prediction emphasizes the need for more advanced solutions. In this paper, we propose a new multichannel multi-step spectrum prediction method using Transformer and stacked bidirectional LSTM (Bi- LSTM), named TSB. Specifically, we use multi-head attention and stacked Bi-LSTM to build a new Transformer based on encoder-decoder architecture. The self-attention mechanism composed of multiple layers of multi-head attention can continuously attend to all positions of the multichannel spectrum sequences. The stacked Bi-LSTM can learn these focused coding features by multi-head attention layer by layer. The advantage of this fusion mode is that it can deeply capture the long-term dependence of multichannel spectrum data. We have conducted extensive experiments on a dataset generated by a real simulation platform. The results show that the proposed algorithm performs better than the baselines.",
    "authors": [
      "Guangliang Pan",
      "Jie Li",
      "Minglei Li"
    ],
    "url": "http://arxiv.org/abs/2405.19138v1",
    "timestamp": 1716912000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null
  }
}

{
  "db0f4874-66c8-449f-9c59-cf0b266be54f": {
    "pk": "db0f4874-66c8-449f-9c59-cf0b266be54f",
    "name": "Chao Zhang",
    "bio": " I am a researcher with a focus on mathematics, particularly in the areas of algebra, geometry, and number theory. My work involves investigating various mathematical structures and proving results related to them.\n\nIn one of my projects, I studied the Ekedahl-Oort stratifications for Shimura varieties of Hodge type, building on my Ph.D. thesis. I proved that the stratification is independent of the choice of symplectic embeddings and established functoriality under certain assumptions.\n\nIn another project, I explored the representation theory of finite-dimensional algebras over algebraically closed fields. I proved that an algebra is a strongly derived unbounded algebra if and only if the category of minimal projective complexes with degree concentrated in a certain range is of strongly unbounded type. This result has implications for the representation theory of these algebras.\n\nI have also worked on the derived category of gentle algebras, specifically on the \"no gaps\" theorem for the sequence of lengths of indecomposable objects. I showed that if there is an indecomposable object in the derived category with cohomological length greater than 1, then there exists an indecomposable with cohomological length one less.\n\nIn addition, I have studied the characterizations of Lipschitz spaces and homogeneous Lipschitz spaces associated with the biharmonic operator. I proved the boundedness of various operators on these spaces, including Bessel potentials, fractional integrals, Riesz transforms, and multipliers of Laplace transforms type.\n\nMost recently, I have been working on the compatibility of certain integral models of Shimura varieties of abelian type. I showed that the parahoric integral models are independent of the choice of auxiliary data in Kisin and Pappas's constructions. I also obtained partial results on extending morphisms of Shimura varieties to those of parahoric integral models.\n\nI am also interested in the intersection of mathematics and computer science, and have worked on a Trusted Computing enhanced blockchain called Truxen. This blockchain uses Proof of Integrity protocol as the consensus, which is derived from Trusted Computing and associated Remote Attestations. Truxen presents a Single Execution Model, which enables remote calls to off-chain applications and performs indeterministic tasks.\n\nIn my work, I",
    "collaborators": [],
    "institute": null
  },
  "2a27fbd3-e7ed-466f-a060-b3599aa25306": {
    "pk": "2a27fbd3-e7ed-466f-a060-b3599aa25306",
    "name": "Tim Althoff",
    "bio": " I am a researcher with a focus on using large-scale data analysis and natural language processing to understand and improve various aspects of society and technology. I have conducted studies on a variety of topics, including donor retention in online crowdfunding communities, multimedia event recognition, mental health counseling conversations, trending topics in online media streams, and the impact of gamification on physical activity.\n\nIn my study on donor retention in online crowdfunding communities, I used data from DonorsChoose.org to explore the factors that impact donor return rates. I found that donors are more likely to return if they had a positive interaction with the recipient of their donation, including appropriate and timely recognition of their support and detailed communication of their impact.\n\nIn my work on multimedia event recognition, I proposed a new image representation called Detection Bank that is based on the detection images from a large number of windowed object detectors. This representation is extended to video by aggregating the key frame level image representations through mean and max pooling. I showed that this representation captures complementary information to state-of-the-art representations and significantly outperforms them on TRECVID MED 2011 data.\n\nIn my study on mental health counseling conversations, I developed a set of novel computational discourse analysis methods to measure how various linguistic aspects of conversations are correlated with conversation outcomes. I discovered actionable conversation strategies that are associated with better conversation outcomes.\n\nIn my work on trending topics in online media streams, I presented the first comprehensive study across three major online and social media streams, covering thousands of trending topics during an entire year. I also presented a novel approach for forecasting the life cycle of trending topics in the very moment they emerge.\n\nIn my study on the impact of gamification on physical activity, I analyzed nearly 2,500 physical activity competitions over a period of one year, capturing more than 800,000 person days of activity tracking. I found that during walking competitions, the average user increases physical activity by 23%, and that the composition of participants greatly affects the dynamics of the game.\n\nIn my work on timeline generation for knowledge-base entities, I presented a method called TIMEMACHINE to generate a timeline of events and relations for entities in a knowledge base. I developed three orthogonal timeline",
    "collaborators": [
      "Ross Girshick",
      "Dan Klein",
      "Yangqing Jia",
      "Stefanie Jegelka",
      "Damian Borth",
      "Yeonwoo Jeong",
      "Kevin Clark",
      "Gaon An",
      "Eric Horvitz",
      "Jonathan Long",
      "Myunghwan Kim",
      "Trevor Darrell",
      "Ning Zhang",
      "Hyun Oh Song",
      "Jure Leskovec",
      "Julian McAuley",
      "Hongwei Wang",
      "Seungyong Moon"
    ],
    "institute": null
  },
  "aa04512f-2e7d-4198-9bcc-4d9bff936f55": {
    "pk": "aa04512f-2e7d-4198-9bcc-4d9bff936f55",
    "name": "Liwen Sun",
    "bio": " I am a researcher with a focus on natural language processing and artificial intelligence, specifically in the application of language models to solve real-world problems. In my most recent work, I have explored few-shot text classification, where only a few annotated examples are given for each class. This is a challenging scenario as traditional methods of fine-tuning language models with cross-entropy loss can lead to overfitting and sub-optimal generalization. To address this, I have proposed the use of supervised contrastive learning on limited labeled data and consistency-regularization on vast unlabeled data. Additionally, I have introduced a novel contrastive consistency method to further improve model performance and refine sentence representation. Through extensive experiments on four datasets, I have demonstrated that my model, FTCC, outperforms state-of-the-art methods and has better robustness.\n\nIn another project, I have worked on reducing emergency department (ED) wait times by developing a cost-effective diagnostic assistance system that utilizes artificial intelligence. In collaboration with ED clinicians, I have curated MIMIC-ED-Assist, a benchmark for AI systems to suggest laboratory tests that minimize wait time while accurately predicting critical outcomes such as death. Based on this benchmark, I have developed ED-Copilot, a system that sequentially suggests patient-specific laboratory tests and makes diagnostic predictions. ED-Copilot employs a pre-trained bio-medical language model to encode patient information and uses reinforcement learning to minimize ED wait time and maximize prediction accuracy. The system has been shown to improve prediction accuracy over baselines while halving average wait time from four hours to two hours. Furthermore, ED-Copilot can effectively personalize treatment recommendations based on patient severity.\n\nIn summary, my research interests lie in the intersection of natural language processing and artificial intelligence, with a focus on developing practical solutions to real-world problems. My recent work includes few-shot text classification and reducing ED wait times through diagnostic assistance. I am passionate about using language models to improve healthcare and other industries, and I am committed to making my code and research available to the broader community.",
    "collaborators": [
      "Zhenhui Li",
      "Jiawei Han",
      "Bin Yu",
      "Anish Agarwal",
      "R. Myrzakulov",
      "Aaron Kornblith",
      "Sabit Bekov",
      "Keyan Nasseri",
      "Yu Meng",
      "Quanquan Gu",
      "Chenyan Xiong",
      "James Duncan",
      "Naveen K. Singh",
      "M. Shahalam",
      "Chi Wang",
      "Abhineet Agarwal",
      "Chandan Singh"
    ],
    "institute": null
  },
  "60bf3f95-57ce-415a-a3cd-831bd9ae851d": {
    "pk": "60bf3f95-57ce-415a-a3cd-831bd9ae851d",
    "name": "Joydeep Ghosh",
    "bio": " I am a researcher with a focus on machine learning, particularly in the areas of data synthesis, multi-object tracking, and constrained Bayesian inference. My work involves developing and improving algorithms to handle complex data and real-world challenges.\n\nIn my research on data synthesis, I have proposed a categorical data synthesizer called Perturbed Gibbs Sampler, which can handle high-dimensional categorical data with a quantifiable disclosure risk. This algorithm extends multiple imputation strategies for fully synthetic data by utilizing feature hashing and non-parametric distribution approximations. I have demonstrated its effectiveness using the California Patient Discharge data, comparing statistical properties such as marginal and conditional distributions, as well as regression model coefficients. I have also evaluated the disclosure risks of the synthesized data through intruder scenario simulations.\n\nIn the field of multi-object tracking, I have worked on scaling data association for hypothesis-oriented MHT, addressing the challenge of poor scalability with the number of tracked objects. I have proposed enhancements including handling undetected objects and false measurements, early stopping during solution calculation, and sparse or gated input. These changes significantly improve the computational time and space requirements, allowing for the consideration of hundreds or thousands of hypotheses over hundreds of objects in real-time. I have demonstrated the value of scaling up the hypothesis count through multi-sensor simulations.\n\nMy research on vehicular multi-object tracking with persistent detector failures focuses on autonomous vehicles, where I modify probabilistic models of multi-object trackers to account for undetected objects and false detections that persist in certain conditions. I have tested these modifications on a vehicle tracking dataset using state-of-the-art lidar-based detectors, a novel lightweight detector, and a fusion of camera and lidar detectors, showing improvements in performance for each detector.\n\nIn the area of constrained Bayesian inference, I have presented a novel approach that does not require convexity of the constraint set, reducing the problem to a parametric optimization over the feasible set of densities. I have applied this approach to multitask learning subject to rank constraints on the weight matrix and constrained parameter estimation for recovering the sparse conditional independence structure encoded by prior precision matrices. This work is motivated by reverse inference for high-dimensional functional neuroimaging, where constraints are necessary to ensure meaningful and",
    "collaborators": [
      "Yongsoo Hwang",
      "Dany Haddad",
      "Yubin Park",
      "Taewan Kim",
      "Behcet Acikmese",
      "Joyce Ho",
      "Oluwasanmi Koyejo",
      "Joyce C. Ho",
      "Purnanand Elango",
      "Michael Motro",
      "Chandra Bhat",
      "Daniel Mihalko",
      "Beh\u00e7et A\u00e7\u0131kme\u015fe",
      "Rajiv Khanna"
    ],
    "institute": null
  },
  "c15bd036-6001-43b1-a5c7-1820c00d187d": {
    "pk": "c15bd036-6001-43b1-a5c7-1820c00d187d",
    "name": "Jie Tang",
    "bio": " I am a researcher with a focus on machine learning, particularly in the areas of graph-based learning, image super-resolution, and visual tracking. I have made significant contributions to these fields through the development of novel approaches and models that address key challenges and improve performance.\n\nIn my work on \"Semi-supervised Learning on Graphs with Generative Adversarial Nets,\" I investigated how generative adversarial nets (GANs) can be used to help semi-supervised learning on graphs. I introduced GraphSGAN, a novel approach that uses a competitive game between generator and classifier networks to improve traditional normalized graph Laplacian regularization. This method has been shown to significantly outperform several state-of-the-art methods on several different genres of datasets.\n\nIn the field of image super-resolution, I have proposed solutions to address the challenges of normalization and quantization errors. In \"AdaDM: Enabling Normalization for Image Super-Resolution,\" I studied the phenomenon of performance degradation caused by normalization layers and proposed an Adaptive Deviation Modulator (AdaDM) to amplify the pixel deviation. This method has been shown to result in substantial performance improvements in benchmark datasets. In \"Residual Feature Distillation Network for Lightweight Image Super-Resolution,\" I proposed a feature distillation connection (FDC) that is more lightweight and flexible than existing methods, and used it to develop a lightweight and accurate SISR model called residual feature distillation network (RFDN). This model has been shown to achieve a better trade-off against state-of-the-art methods in terms of performance and model complexity.\n\nIn the area of visual tracking, I have proposed a robust object modeling framework called ROMTrack that simultaneously models the inherent template and hybrid template features. This framework has been shown to suppress harmful distractors and extract target-related features, resulting in a more robust object modeling framework. I have also presented novel variation tokens that are adaptable to object deformation and appearance variations, which can boost overall performance with negligible computation.\n\nOverall, my research is focused on developing novel and effective approaches to address key challenges in machine learning, with a particular focus on graph-based learning, image super-resolution, and visual tracking. I am committed to pushing the boundaries of what is possible in these fields and making meaningful",
    "collaborators": [
      "Gangshan Wu",
      "Jie Liu",
      "Fan Xu",
      "Zhiqi Chen",
      "Bincheng Yang",
      "David Lopez-Perez",
      "Yidong Cai",
      "Ming Ding",
      "Limin Wang",
      "Jie Sheng",
      "Ziteng Gao",
      "Jie Zhang"
    ],
    "institute": null
  },
  "e5a591f0-bf96-4265-8504-11ebe7b4d47d": {
    "pk": "e5a591f0-bf96-4265-8504-11ebe7b4d47d",
    "name": "Quanquan Gu",
    "bio": " I am a researcher specializing in high-dimensional statistics, machine learning, and optimization. My work focuses on developing provably efficient algorithms for various statistical and machine learning problems, particularly in the high-dimensional regime. I am passionate about bridging the gap between theory and practice, ensuring that the algorithms I develop are not only mathematically sound but also computationally efficient and practically relevant.\n\nIn my research, I have made significant contributions to the fields of nonconvex optimization, differentially private sparse learning, distributed estimation, and deep neural networks. For instance, I have proposed a nonconvex estimator for joint multivariate regression and precision matrix estimation, which attains a linear rate of convergence to the true regression coefficients and precision matrix simultaneously. This work provides a more efficient and theoretically grounded alternative to existing methods, which often lack convergence guarantees.\n\nI have also developed a differentially private high-dimensional sparse learning framework using the idea of knowledge transfer. This framework achieves improved utility guarantees compared with the best known results for sparse linear and logistic regression, demonstrating the superiority of the approach through both synthetic and real-world data experiments.\n\nIn addition, I have proposed a communication-efficient distributed estimation method for sparse linear discriminant analysis (LDA) in the high dimensional regime. This method attains the same statistical rate as the centralized estimation method, as long as the number of machines is chosen appropriately. I have also established a sharper characterization of the trajectory length of the algorithm, leading to an improved analysis of the global convergence of (stochastic) gradient descent for training deep neural networks.\n\nMy work on low-rank matrix estimation with nonconvex penalties has provided a unified framework for low-rank matrix estimation, attaining a faster statistical rate than the traditional low-rank matrix estimator with nuclear norm penalty. I have also shown that under a certain condition on the magnitude of the nonzero singular values, the proposed estimator enjoys oracle property, i.e., exactly recovers the true rank of the matrix.\n\nI am committed to pushing the boundaries of knowledge in my field and continuously strive to improve the state-of-the-art in machine learning and optimization research.",
    "collaborators": [
      "Huan Gui",
      "Zhaoran Wang",
      "Yuan Cao",
      "Masahito Kobayashi",
      "Lingxiao Wang",
      "Zhuoran Yang",
      "Jinghui Chen",
      "Lu Tian",
      "Pei Fang",
      "Weiqi Peng",
      "Qingguo Li",
      "Huaidian Hou",
      "Yin Jiang",
      "Yonglin Cao",
      "Shuwen Chai"
    ],
    "institute": null
  },
  "6dbe2b7a-d545-428a-82b7-4269df1ddce8": {
    "pk": "6dbe2b7a-d545-428a-82b7-4269df1ddce8",
    "name": "Tianyi Zhou",
    "bio": " I am a researcher focused on developing efficient and scalable algorithms for machine learning and data mining problems. I have made contributions to various areas, including optimal transport distances, submodular maximization, low-rank approximation, compressed sensing, and matrix decomposition.\n\nIn the area of optimal transport distances, I proposed a faster Sinkhorn's Algorithm to approximate the OT distance when the matrix has small treewidth. This algorithm improves the state-of-the-art results from O(\u03f5^(-2)n^2) time to O(\ufffdepsilon^{-2} n \u03c4) time.\n\nIn the context of submodular maximization, I developed a streaming algorithm called Stream Clipper that performs as well as the offline greedy algorithm in practice. Stream Clipper adds elements from a stream either to a solution set or to an extra buffer based on two adaptive thresholds and improves the solution set by a final greedy step. This algorithm has a worst-case approximation factor of 1/2, but there are data-dependent conditions where the bound falls within the range [1/2, 1-1/e].\n\nIn the area of low-rank approximation, I showed that a dense matrix's low-rank approximation can be rapidly built from its left and right random projections, or bilateral random projection (BRP). I proved deterministic, average, and deviation bounds for the proposed method and its power scheme modification. The effectiveness and efficiency of BRP-based low-rank approximation are empirically verified on both artificial and real datasets.\n\nIn the context of compressed sensing, I introduced Hamming compressed sensing (HCS) that directly recovers a k-bit quantized signal of dimensional n from its 1-bit measurements via invoking n times of Kullback-Leibler divergence-based nearest neighbor search. HCS allows the signal to be dense, takes considerably less (linear) recovery time, and requires substantially less measurements (O(log n)). Moreover, HCS recovery can accelerate the subsequent 1-bit CS dequantizer.\n\nIn the area of matrix decomposition, I studied more adaptive models and efficient algorithms that decompose a data matrix as the sum of semantic components with incoherent structures. I introduced GO decomposition (GoDec), an alternating projection method estimating the low-rank part and the sp",
    "collaborators": [
      "Andrew Guillory",
      "Carlos Guestrin",
      "Josh Alman",
      "Rishabh Iyer",
      "Kainan Peng",
      "Jeff Bilmes",
      "Tongliang Liu",
      "Changxing Ding",
      "Mingquan Ye",
      "Wei Bian",
      "Dacheng Tao",
      "Xin Yang",
      "Aviad Rubinstein",
      "Zhao Song",
      "Andrew Ng",
      "Ruxin Wang"
    ],
    "institute": null
  },
  "e97b4151-366a-4f6f-93db-c690c0453d27": {
    "pk": "e97b4151-366a-4f6f-93db-c690c0453d27",
    "name": "Jure Leskovec",
    "bio": " I am a researcher focused on the analysis and modeling of large-scale networks, with a particular interest in networks with node attribute information. I have developed and worked with several models to understand the structure and behavior of these networks.\n\nIn my research, I have constructed and analyzed the largest social network to date, using anonymized data from the Microsoft Messenger instant-messaging system. I found that the network is well-connected and robust to node removal, and that people tend to communicate more with others who have similar age, language, and location. I also investigated the \"six degrees of separation\" phenomenon and found that the average path length among Messenger users is 6.6.\n\nI have also developed the Multiplicative Attribute Graph (MAG) model, which considers nodes with categorical attributes and models the probability of an edge as the product of individual attribute link formation affinities. This model allows for the reliable capture of network connectivity and provides insights into how different attributes shape the network structure.\n\nIn addition, I have developed the Latent Multi-group Membership Graph (LMMG) model, which allows each node to belong to multiple groups and models the occurrence of links as well as the node feature structure. This model can be used to summarize the network structure, predict links between nodes, and predict missing features of a node.\n\nI have also analyzed the Multiplicative Attribute Graphs (MAG) model in the context of large scale real-world networks, such as social and information networks. This model naturally captures the interactions between the network structure and the node attributes, and yields itself to mathematical analysis.\n\nIn the field of image classification, I have studied the use of social-network metadata for image classification, using structured learning techniques to learn model parameters. I have found that social-network metadata are useful in a variety of classification tasks, in many cases outperforming methods based on image content.\n\nMost recently, I have worked on the task of automatically identifying users' social circles in personal social networks, by posing it as a multi-membership node clustering problem on a user's ego-network. I have developed a model that combines network structure as well as user profile information, and have shown that it accurately identifies circles on a diverse set of data from Facebook, Google+, and Twitter.\n\nI am currently working on a nonparametric multi-group membership model for dynamic networks, which extracts",
    "collaborators": [
      "Julian McAuley",
      "Hongwei Wang",
      "David F. Gleich",
      "Canwen Xu",
      "Anthony Bonato",
      "John Breese",
      "Dieter Mitsche",
      "Finn Jensen",
      "Ruining He",
      "Eric Horvitz",
      "Tim Althoff",
      "Alex Yang",
      "Myunghwan Kim",
      "Pawe\u0142 Pra\u0142at"
    ],
    "institute": null
  },
  "dc93247a-297d-472c-b758-86fb13525e4e": {
    "pk": "dc93247a-297d-472c-b758-86fb13525e4e",
    "name": "Jiaming Shen",
    "bio": " I am a researcher with a focus on natural language processing, machine learning, and artificial intelligence. My recent work has been centered around developing and improving methods for linguistic steganography, corpus-based open-domain event type induction, and weakly-supervised neural text classification.\n\nIn the area of linguistic steganography, I have studied how to encode secret messages using self-adjusting arithmetic coding based on a neural language model. This method has been shown to outperform previous state-of-the-art methods in terms of statistical imperceptibility and has been empirically proven to fool eavesdroppers in human evaluations.\n\nIn the field of corpus-based open-domain event type induction, I have presented a method that automatically discovers a set of event types from a given corpus. This is done by representing each event type as a cluster of <predicate sense, object head> pairs and using a combination of salient predicate and object head selection, predicate sense disambiguation, and joint embedding and clustering in a latent spherical space. This method has been shown to discover salient and high-quality event types in experiments on three datasets from different domains.\n\nAdditionally, I have worked on developing a weakly-supervised method for neural text classification that addresses the lack of training data in many real-world applications. This method consists of a pseudo-document generator that leverages seed information to generate pseudo-labeled documents for model pre-training, and a self-training module that bootstraps on real unlabeled data for model refinement. This method is flexible and can handle different types of weak supervision, making it easily integrable into existing deep neural models for text classification.\n\nI am also interested in Hierarchical text classification, which aims to classify text documents into a given hierarchy. I have proposed a weakly-supervised neural method for this task that does not require a large amount of training data but requires only easy-to-provide weak supervision signals such as a few class-related documents or keywords. This method effectively leverages such weak supervision signals to generate pseudo documents for model pre-training, and then performs self-training on real unlabeled data to iteratively refine the model.\n\nIn my recent work, I have also been focusing on 3D reconstruction from images, where I have proposed a novel way of",
    "collaborators": [
      "Zhenhui Li",
      "Liwen Sun",
      "Jiawei Han",
      "Carl Edwards",
      "Xinya Du",
      "Tongtao Zhang",
      "Yanzhen Shen",
      "Yunyi Zhang",
      "Payam Karisani",
      "Dimitris N. Politis",
      "Zhenhailong Wang",
      "Tingting Wang",
      "Yu Meng",
      "Heng Ji",
      "Quanquan Gu",
      "Chi Wang",
      "Chao Zhang"
    ],
    "institute": null
  },
  "6cbddf37-3074-417b-b60f-5496ca5fd3b6": {
    "pk": "6cbddf37-3074-417b-b60f-5496ca5fd3b6",
    "name": "Trevor Hastie",
    "bio": " I am a researcher with a strong focus on developing and improving algorithms for machine learning and data science. I have spent the past 40 years working in applied statistics and have a deep understanding of essential concepts such as ridge regularization. I am particularly interested in exploring the use of regularization methods to improve model fitting and prediction, as well as to uncover interactions between variables.\n\nIn my work, I have developed and applied a variety of methods for regularization, including ridge regression, the elastic net, and group-lasso regularization. I have also worked on methods for learning interactions between variables, such as hierarchical group-lasso regularization, which allows for the estimation of pairwise interactions while ensuring that main effects are also included in the model.\n\nI am also interested in the problem of selecting a small subset of representative variables from a large dataset, which I have approached from both a computer science and statistical perspective. I have shown that these two approaches are equivalent and can be viewed as maximum likelihood estimation within a certain semi-parametric model. This has allowed me to develop efficient methods for performing column subset selection using only summary statistics from the original dataset, as well as in the presence of missing or censored data.\n\nIn addition to my work on regularization and variable selection, I have also developed methods for conditional density estimation, generalized additive model selection, and sparse quadratic discriminant analysis. I am always looking for new and interesting problems to work on in the field of machine learning and data science.",
    "collaborators": [
      "Ji Zhu",
      "Saharon Rosset",
      "Mudhakar Srivatsa",
      "Bruce Hajek",
      "Balasubramanian Narasimhan",
      "Michael Lim",
      "Max G'Sell",
      "Riccardo Fogliato",
      "Alexandra Chouldechova",
      "Aaron Roth",
      "Lingwei Cheng",
      "J. Kenneth Tay",
      "Nengfeng Zhou"
    ],
    "institute": null
  },
  "f7fa3dde-6bcb-466e-8b2d-0187bad70417": {
    "pk": "f7fa3dde-6bcb-466e-8b2d-0187bad70417",
    "name": "Ruxin Wang",
    "bio": " I am a researcher with a focus on image processing, machine learning, and graph neural networks. My recent work in image processing includes a comprehensive review of recent developments in image deblurring techniques. These techniques aim to infer a latent sharp image from one or multiple blurry images, with blind deblurring methods also required to derive an accurate blur kernel. I have analyzed various methods for handling the ill-posedness in deblurring tasks and grouped them into five categories: Bayesian inference framework, variational methods, sparse representation-based methods, homography-based modeling, and region-based methods.\n\nIn the field of machine learning, I have worked on fingerprint classification using a depth neural network. By using only the orientation field as the input feature and adopting a new method based on stacked sparse autoencoders, I achieved a classification accuracy of 93.1% for the four-class problem in the NIST-DB4 database. I also proposed a novel fuzzy classification method using two classification probabilities, which effectively enhances the accuracy of classification.\n\nMy research in graph neural networks involves proposing a post-hoc framework, TraP2, for understanding the behaviors of GNNs. TraP2 generates high-fidelity explanations by probing and monitoring the local predictive behavior of GNNs and fitting the local decision boundary. I have evaluated TraP2 on six benchmark datasets based on five desired attributions and achieved higher explanation accuracy than state-of-the-art methods.\n\nIn digital forensics, I proposed a color image splicing detection approach based on Markov transition probability of quaternion component separation in quaternion discrete cosine transform (QDCT) domain and quaternion wavelet transform (QWT) domain. The proposed approach outperforms some state-of-the-art methods in detecting spliced and authentic color images.\n\nI am also interested in semi-supervised multi-view nonnegative matrix factorization (MVNMF) algorithms for multi-view clustering. I proposed a novel Discriminatively Constrained Semi-Supervised Multi-View Nonnegative Matrix Factorization (DCS^2MVNMF) that enhances inter-class distinction and aligns multiple views using a new graph regularization and feature scale normalization strategy.\n\nIn radiology report generation,",
    "collaborators": [
      "Long Huang",
      "Huayong Han",
      "Ye Li",
      "Sibo Zheng",
      "Chiranjeevi Kanike",
      "Chen Wang",
      "Yunpeng Cai",
      "Hongyan Wu",
      "Tongliang Liu",
      "Changxing Ding",
      "Shuyuan Chen",
      "Tianyi Zhou",
      "Wei Bian",
      "Dacheng Tao",
      "Jie Zhang",
      "Pengfei Zhou",
      "Chaojie Ji"
    ],
    "institute": null
  },
  "f2eabe92-42de-4817-af01-acde8d7ec150": {
    "pk": "f2eabe92-42de-4817-af01-acde8d7ec150",
    "name": "Philip S. Yu",
    "bio": " I am a researcher with a focus on data science, artificial intelligence, and multi-view data analysis. My work involves developing and improving algorithms for various applications, such as social network analysis, financial technology, and natural language processing.\n\nIn the field of social network analysis, I have studied the problem of predicting dynamic trends and proposed a Dynamic Activeness (DA) model based on the concept of activeness. This model is able to capture the intensity, coverage, and duration of trends, and has been shown to be more accurate than existing approaches.\n\nIn the area of financial technology, I have presented an overview of the role of data science and AI in FinTech, including the use of DSAI techniques such as complex system methods, data analytics, and deep learning. I have also discussed the challenges and research directions in this field.\n\nI have also worked on developing algorithms for multi-view data analysis. In one project, I proposed a method for unsupervised feature selection for multi-view data called CDMA-FS. This method performs alignment on a cross diffused matrix and has been shown to be more effective than existing methods in the multi-view setting.\n\nIn addition to these projects, I have experience with sequence labeling and have developed a Knowledge-based CRF model for the task of Complementary Entity Recognition (CER). This model is able to expand domain knowledge as key-value pairs from unlabeled reviews and has been shown to improve the performance of the supervised CER task.\n\nI have also worked on developing a NoSQL store called dConssandra, which enables users to specify latency bounds for data access operations and dynamically bounds data access latency by trading off replica consistency. This store has been shown to effectively bound latency and improve the consistency of data access.\n\nOverall, my research is focused on developing and improving algorithms for various applications, with a particular focus on data science, artificial intelligence, and multi-view data analysis. I am always looking for new and challenging problems to tackle in these areas.",
    "collaborators": [],
    "institute": null
  },
  "1816a575-da42-4de6-85b3-aa7d0eae4e30": {
    "pk": "1816a575-da42-4de6-85b3-aa7d0eae4e30",
    "name": "Julian McAuley",
    "bio": " I am a researcher with a focus on developing and improving recommender systems and natural language processing models. My work involves using various types of data, such as social network metadata, user reviews, and visual features, to improve the accuracy and relevance of recommendations.\n\nIn my research on image classification and retrieval, I have found that social network metadata, such as the groups an image belongs to and the user who uploaded it, can be useful for improving image classification tasks. I have proposed a model that explicitly accounts for the interdependencies between images sharing common properties and have found that it outperforms methods based on image content in many cases.\n\nI have also studied the task of automatically identifying users' social circles in personal social networks. I have posed this task as a multi-membership node clustering problem on a user's ego-network and have developed a model that combines network structure and user profile information to detect circles. My model is able to accurately identify circles on a diverse set of data from Facebook, Google+, and Twitter, and is able to detect overlapping and hierarchically nested circles.\n\nIn addition to my work on recommender systems, I have also researched the use of reviews for recommendation. I have found that while reviews can be useful for inferring the underlying dimensions that predict ratings or purchases, there are discrepancies in reported results and a lack of robust empirical evaluation in this area. Through a wide range of experiments, I have observed several cases where state-of-the-art methods fail to outperform existing baselines, and have provided hypotheses for under what conditions reviews are likely to be helpful.\n\nI am also interested in the use of dynamic neural networks for natural language processing. I have summarized progress in this area and highlighted current challenges and directions for future research. I believe that dynamic neural networks, which are capable of scaling up neural networks with sub-linear increases in computation and time, could be a promising solution to the growing parameter numbers of pretrained language models and could allow for both model pretraining with trillions of parameters and faster inference on mobile devices.",
    "collaborators": [
      "Tim Althoff",
      "Canwen Xu",
      "Hongwei Wang",
      "Jianguo Wang",
      "Zhaowen Wang",
      "Chunbin Lin",
      "Chenliang Li",
      "Zhankui He",
      "Ruining He",
      "Chen Fang",
      "Zexue He",
      "Eric Horvitz",
      "Jure Leskovec",
      "Alex Yang",
      "Myunghwan Kim",
      "Wangchunshu Zhou"
    ],
    "institute": null
  },
  "753e8200-745d-480f-a67d-f192496d2ad0": {
    "pk": "753e8200-745d-480f-a67d-f192496d2ad0",
    "name": "Dacheng Tao",
    "bio": " I am a researcher with a focus on data mining, machine learning, and statistical pattern recognition. I have contributed to various areas within these fields, including bilateral random projections, Hamming compressed sensing, and asymptotic generalization bounds.\n\nIn the area of bilateral random projections, I have shown that a dense matrix's low-rank approximation can be rapidly built from its left and right random projections. I have also proved the deterministic, average, and deviation bounds of this method and its power scheme modification. My work has empirically verified the effectiveness and efficiency of this approach on both artificial and real datasets.\n\nIn Hamming compressed sensing, I have introduced a method that directly recovers a k-bit quantized signal from its 1-bit measurements via Kullback-Leibler divergence based nearest neighbor search. This method allows the signal to be dense, takes linear recovery time, and requires substantially less measurements. I have also studied a quantized recovery error bound of HCS for general signals and \"HCS+dequantizer\" recovery error bound for sparse signals.\n\nIn the area of statistical pattern recognition, I have presented an asymptotic generalization analysis of FLDA based on random matrix theory. This analysis overcomes the limitations of the classical result, which holds only for a fixed dimensionality, and provides a quantitative description of the generalization ability of FLDA in terms of the ratio of dimensionality and training sample size.\n\nI have also worked on more adaptive models and efficient algorithms for decomposing a data matrix as the sum of semantic components with incoherent structures. I have proposed \"GO decomposition (GoDec)\", an alternating projection method estimating the low-rank part and the sparse part from data matrix. I have also proposed two acceleration strategies, bilateral random projection (BRP) and greedy bilateral (GreB) paradigm, to obtain scalable unmixing algorithm on big data.\n\nAdditionally, I have reviewed the recent development of image deblurring, including non-blind/blind, spatially invariant/variant deblurring techniques. I have provided a holistic understanding and deep insight into image deblurring in this review, including an analysis of the empirical evidence for representative methods, practical issues, and promising future directions.\n\nI have also discussed the inherent difficulties in pose-invariant face recognition",
    "collaborators": [
      "Carlos Guestrin",
      "Zhao Song",
      "Zeyu Jiang",
      "Shengcong Chen",
      "Zefeng Ding",
      "Xiaojun Chen",
      "Wenjing Li",
      "Tongliang Liu",
      "Jeff Bilmes",
      "Changxing Ding",
      "Junyang Huang",
      "Tianyi Zhou",
      "Wei Bian",
      "Xin Yang",
      "Xin Qu",
      "Ruxin Wang",
      "Fan Wu"
    ],
    "institute": null
  },
  "45e2008c-1260-4844-96c2-f14b46d91d5c": {
    "pk": "45e2008c-1260-4844-96c2-f14b46d91d5c",
    "name": "Changxing Ding",
    "bio": " I am a researcher specializing in computer vision, with a focus on face recognition, text-to-image re-identification, and medical image analysis. My work has been published in various reports and papers, highlighting my contributions to these fields.\n\nIn the EPIC-Kitchens Action Anticipation Challenge 2022, I led a team to develop a method that achieves state-of-the-art results. Our approach includes Anticipation Time Knowledge Distillation and a Verb-Noun Relation Module, which helped us achieve top results on the testing set.\n\nIn the domain of face recognition, I have published papers on cross-pose face recognition, pose-invariant face recognition, and robust face recognition via multimodal deep face representation. My work on cross-pose face recognition presents a method for progressively transforming profile face representations to the canonical pose with an attentive pair-wise loss. This method has been shown to outperform existing approaches on the CFP and CPLFW datasets.\n\nIn the field of text-to-image re-identification, I proposed a Semantically Self-Aligned Network (SSAN) that handles the significant modality gap and large intra-class variance in textual descriptions. SSAN outperforms state-of-the-art approaches by significant margins, as demonstrated in extensive experiments.\n\nIn medical image analysis, I developed a Boundary-assisted Region Proposal Network (BRP-Net) for nucleus segmentation. BRP-Net achieves robust instance-level nucleus segmentation by proposing a novel Task-aware Feature Encoding (TAFE) network and generating coarse nucleus proposals based on the predictions of the above two tasks. BRP-Net has been shown to outperform existing approaches on the Kumar and CPM17 datasets.\n\nOverall, my research is focused on developing innovative and effective computer vision techniques to solve complex problems in various domains. I am committed to pushing the boundaries of what is possible in these fields and making meaningful contributions to the research community.",
    "collaborators": [
      "Zeyu Jiang",
      "Shengcong Chen",
      "Zefeng Ding",
      "Hao Chen",
      "Wenqi Li",
      "Shengbai Zhang",
      "Tongliang Liu",
      "Junyang Huang",
      "Damien West",
      "Tianyi Zhou",
      "Wei Bian",
      "Dacheng Tao",
      "Ruxin Wang",
      "Guotai Wang"
    ],
    "institute": null
  },
  "25c20a8f-2ed9-4115-b6ee-d09bf38014b4": {
    "pk": "25c20a8f-2ed9-4115-b6ee-d09bf38014b4",
    "name": "Yu Meng",
    "bio": " I am a researcher with a focus on theoretical physics, particularly in the field of lattice quantum chromodynamics (QCD). In my work, I have developed a new method for calculating the decay width of a hadron decaying to two photons, which provides a simple way to examine finite-volume effects. I have applied this method to the process of $\\eta_c \to 2\\gamma$ and have obtained the decay width of $\\Gamma_{\\eta_c\\gamma\\gamma} = 6.57(15)_{\\textrm{stat}}(8)_{\\textrm{syst}}$ keV. I have also presented the first lattice QCD study on the invisible decay $J/\to \\gamma\\nu\\bar{\\nu}$, and have obtained the branching fraction as $\\operatorname{Br}[J/\\psi \to \\gamma\\nu\\bar{\\nu}]=1.00(9)(7)\times 10^{-10}}$.\n\nIn addition to my work in lattice QCD, I have also explored the use of pretrained language models (PLMs) for natural language processing tasks. I have presented a simple approach that uses both unidirectional and bidirectional PLMs for fully zero-shot learning of NLU tasks without requiring any task-specific data. I have demonstrated the strong performance of this approach across seven classification tasks of the GLUE benchmark.\n\nI am also interested in the application of deep learning models for image and video reconstruction, specifically in the context of through-wall human pose imaging using radio frequency (RF) signals. I have established a deep-learning model that can be trained to reconstruct continuous video of a 15-point human skeleton even through visual occlusion, using a student/teacher learning procedure inspired by the Feynman learning technique.\n\nIn the field of document categorization, I have studied the integration of label hierarchy, metadata, and text signals for document categorization under weak supervision. I have developed HiMeCat, an embedding-based generative framework for this task, and have demonstrated its consistent improvement over competitive baselines.\n\nI have also proposed Edgeformers, a framework built upon graph-enhanced Transformers, to perform edge and node representation learning by modeling texts on edges in a contextualized way. On five public datasets from three different domains, Edgeformers have consistently outperformed state-of-the-art bas",
    "collaborators": [
      "Zhenhui Li",
      "Liwen Sun",
      "Jiawei Han",
      "Yu Zhang",
      "Quanquan Gu",
      "Jiaxin Huang",
      "Chi Wang"
    ],
    "institute": null
  },
  "e2b1cb57-7850-4d77-bf2e-66ca440a02e6": {
    "pk": "e2b1cb57-7850-4d77-bf2e-66ca440a02e6",
    "name": "Eric Horvitz",
    "bio": " I am a researcher with a focus on artificial intelligence and its implications on society. In recent years, my work has explored the rise of deepfakes and their potential malicious uses. I believe that as deepfake technology becomes more sophisticated, it will be used to create interactive and compositional deepfakes that can impersonate people and manipulate events. These deepfakes have the potential to move us closer to a \"post-epistemic world\" where fact and fiction are indistinguishable.\n\nIn addition to my work on deepfakes, I have also explored the metareasoning-partition problem, which deals with determining the ideal portion of resources to allocate to metareasoning and control versus to the execution of a solution plan. I have also considered the key considerations for the responsible development and fielding of AI technologies, with a focus on critical challenges and recommendations for priority consideration, implementation, and policy-making.\n\nI am interested in the potential of AI to transform decision-making and enable evidence-based approaches in various fields, from healthcare to government. I believe that the convergence of advances in computer and mathematical sciences has the potential to unleash unprecedented capabilities for enabling true evidence-based decision-making. However, I also recognize the need for responsible development and deployment of AI technologies, with a focus on addressing ethical concerns and potential negative impacts on work.\n\nIn my work on the public perception of AI, I have analyzed text corpora over time to reveal trends in beliefs, interest, and sentiment about AI. I have found that discussions of AI have increased sharply since 2009 and have been consistently more optimistic than pessimistic. However, I have also identified growing concerns about loss of control of AI, ethical issues, and the negative impact of AI on work. I believe that it is important to address these concerns and work towards the responsible development and deployment of AI technologies.",
    "collaborators": [
      "M. Pawan Kumar",
      "Urszula Chajewska",
      "John Breese",
      "Ron Parr",
      "Daphne Koller",
      "Finn Jensen",
      "Avi Pfeffer"
    ],
    "institute": null
  },
  "26ebd576-ba00-4371-b3ff-036f05d94947": {
    "pk": "26ebd576-ba00-4371-b3ff-036f05d94947",
    "name": "Wei Wang",
    "bio": " I am a researcher with a focus on algebraic graph theory, particularly in the area of spectral graph theory. I am interested in characterizing graphs by their spectra and have contributed to the field by proposing an algorithm to find all possible generalized cospectral mates for a given graph, assuming that the graph is controllable or almost controllable. The experimental results of this algorithm have given strong evidence for Haemers' conjecture, which states that almost all graphs are determined by their spectra.\n\nIn addition to my work on Haemers' conjecture, I have also revisited the generalized spectral characterization of graphs and presented new methods for determining whether a family of graphs are determined by their generalized spectra. I have also proven the Smith normal form of the walk matrix of the Dynkin graph $D_n$ when $n$ is a multiple of 4.\n\nI have also explored other areas of mathematics such as dynamical systems, where I have proven the existence of at least two strictly elliptic closed characteristics on a compact convex hypersurface that is pinched and carries at least two non-hyperbolic closed characteristics. I have also proven the existence of at least two geometrically distinct symmetric closed trajectories on a compact convex Hamiltonian energy surface that is symmetric with respect to the origin.\n\nFurthermore, I have worked on the stability of closed characteristics on symmetric compact convex hypersurfaces in $\\R^{2n}$, and have proven that if a hypersurface carries finitely many geometrically distinct closed characteristics, then at least $n-1$ of them must be non-hyperbolic.\n\nIn the field of algebraic geometry, I have constructed the reduced genus-two Gromov-Witten invariants for certain almost K\u00e4hler manifolds and have proven a conjecture of Anosov regarding the existence of prime closed geodesics on a bumpy Finsler $n$-sphere.\n\nI am passionate about exploring and contributing to various areas of mathematics, and I am committed to furthering my research in spectral graph theory and other related fields.",
    "collaborators": [],
    "institute": null
  },
  "b51ab215-bd5a-4b6f-a506-31bb22557b1c": {
    "pk": "b51ab215-bd5a-4b6f-a506-31bb22557b1c",
    "name": "Wei Bian",
    "bio": " I am a researcher with a focus on developing and analyzing numerical methods for solving various optimization problems. I have worked on a number of projects involving nonsmooth optimization, including the design and analysis of accelerated methods for finding minimizers of decomposable nonsmooth convex functions, as well as the study of the convergence rate of these methods. I have also explored the use of smoothing techniques to approximate nonsmooth functions and improve the convergence of iterative methods.\n\nIn addition to my work on nonsmooth optimization, I have also studied the asymptotic behavior of dynamic algorithms for solving convex optimization problems. I have proven convergence results and established convergence rates for these algorithms under certain conditions on the smoothing parameters.\n\nI have a strong background in random matrix theory and have used this knowledge to analyze the generalization ability of Fisher's linear discriminant analysis (FLDA) in a setting where both the dimensionality and training sample size are large. I have derived an asymptotic generalization bound for FLDA that overcomes the limitations of classical results and provides a quantitative description of its generalization ability in terms of the ratio of the dimensionality to the training sample size and the population discrimination power.\n\nI am also interested in the application of optimization methods to machine learning problems, and have developed a projected neural network and correction method for solving a class of sparse regression problems with cardinality penalties. I have proven theoretical results on the convergence and optimality of the proposed method, and have demonstrated its effectiveness through numerical experiments.\n\nOverall, my research combines elements of optimization theory, numerical analysis, and machine learning to develop and analyze effective methods for solving a wide range of optimization problems.",
    "collaborators": [
      "Farkhod Eshmatov",
      "Jan Egger",
      "Noel Cressie",
      "Chung G. Kang",
      "Carl Kelley",
      "Kevin Bowman",
      "Xiaojun Chen",
      "Alex Hall",
      "Jie Jiang",
      "Tongliang Liu",
      "Changxing Ding",
      "Tianyi Zhou",
      "Dacheng Tao",
      "Xin Qu",
      "Wenjing Li",
      "Ruxin Wang",
      "Fan Wu"
    ],
    "institute": null
  },
  "04951337-2c9d-4348-b463-57bda667a351": {
    "pk": "04951337-2c9d-4348-b463-57bda667a351",
    "name": "Jiawei Han",
    "bio": " I am a researcher with a focus on mathematical analysis of Teichm\u00fcller space and developing machine learning models for natural language processing.\n\nIn my Teichm\u00fcller space research, I have built upon the work of Athreya, Bufetov, Eskin, and Mirzakhani to study the growth rate of pseudo-Anosov mapping class conjugacy classes and Dehn twist lattice points. I have proven that for any pseudo-Anosov mapping class $f$, there exists a power $n$ such that the number of lattice points of the $f^n$ conjugacy class intersecting a closed ball of radius $R$ is coarsely asymptotic to $e^{\\frac{h}{2}R}$. In contrast, the number of Dehn twist lattice points intersecting a closed ball of radius $R$ is coarsely asymptotic to $e^{\\frac{h}{2}R}$, and the number of multi-twist lattice points grows coarsely at least at the rate of $R \to e^{\\frac{h}{2}R}$.\n\nIn the field of natural language processing, I have worked on few-shot text classification, where only a few annotated examples are given for each class. I have addressed the issue of overfitting and suboptimal generalization caused by traditional cross-entropy loss by adopting supervised contrastive learning on few labeled data and consistency-regularization on vast unlabeled data. I have also proposed a novel contrastive consistency to further boost model performance and refine sentence representation.\n\nAdditionally, I have developed a generalized Fisher score for feature selection, which aims at finding an subset of features that maximize the lower bound of traditional Fisher score. This is achieved by solving a mixed integer programming problem, which can be reformulated as a quadratically constrained linear programming (QCLP) and solved by a cutting plane algorithm.\n\nI have also proposed a scalable and robust algorithm for constructing a hierarchy of topics from a text collection, which reduces the time of construction by several orders of magnitude and renders it possible for users to interactively revise the hierarchy.\n\nFurthermore, I have presented a novel research problem on joint discovery of commonalities and differences between two individual documents or document sets, called Comparative Document Analysis (CDA). I have developed an iterative algorithm to integrate the maximization of phrase",
    "collaborators": [
      "Zhenhui Li",
      "Liwen Sun",
      "Yu Zhang",
      "Bin Yu",
      "Yuan Cao",
      "Aaron Kornblith",
      "Lingxiao Wang",
      "Jinghui Chen",
      "Huan Gui",
      "Lu Tian",
      "Quanquan Gu",
      "Yu Meng",
      "Chenyan Xiong",
      "Jiaxin Huang",
      "Chi Wang",
      "Abhineet Agarwal"
    ],
    "institute": null
  },
  "e1f11d69-2a01-4fb4-bd7a-6f5fcfd63a64": {
    "pk": "e1f11d69-2a01-4fb4-bd7a-6f5fcfd63a64",
    "name": "Hongwei Wang",
    "bio": " I am a researcher with a focus on condensed matter physics, particularly in the study of hyperbolic plasmonic media in transition metal ditellurides. My work in this area has involved elucidating the physical origin of the strong infrared hyperbolic response in WTe2, which I have attributed to band-nested anisotropic interband transitions. I have also demonstrated the possibility of inducing such a phenomenon through proper electronic band nesting, and have illustrated this principle by showing a topological elliptic-to-hyperbolic transition in MoTe2 via strain engineering.\n\nIn addition to my work in condensed matter physics, I have also contributed to the field of graph neural networks. I have studied the relationship between Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN), both of which are message passing algorithms on graphs that solve the task of node classification. I have analyzed the feature/label smoothing and influence of these two algorithms, and have proposed a unified model that combines GCN and LPA for node classification. This model has shown superiority over state-of-the-art GCN-based methods in terms of node classification accuracy.\n\nI have also explored the action of the Kauffman bracket skein algebra of the torus on the Kauffman bracket skein module of the complement of the 3-twist knot, as well as the robust filtering problem for a nonlinear state-space model with outliers in measurements. I have proposed two robust filters based on mixture correntropy, specifically the double-Gaussian mixture correntropy and Laplace-Gaussian mixture correntropy, and have shown that these methods can achieve a performance improvement over existing robust solutions.\n\nIn the field of natural language processing, I have presented a comprehensive and empirical analysis of the dimensionality of sentence embeddings. I have demonstrated that the optimal dimension of sentence embeddings is usually smaller than the default value, and have proposed a two-step training method for sentence representation learning models to compress the dimension of sentence embeddings with minimum performance degradation.\n\nI am also interested in millimeter wave/Terahertz (mmWave/THz) communication with extremely large-scale antenna arrays (ELAAs) and have considered the problem of hybrid near/far-field channel estimation by taking spherical wave propagation",
    "collaborators": [
      "Julian McAuley",
      "Tim Althoff",
      "Razvan Gelca",
      "Davood Ansari",
      "Joerg Appenzeller",
      "Eric Horvitz",
      "Tony Low",
      "Phaedon Avouris",
      "Jure Leskovec",
      "Myunghwan Kim"
    ],
    "institute": null
  },
  "d3757512-7845-42e0-8b2a-55354ab86e41": {
    "pk": "d3757512-7845-42e0-8b2a-55354ab86e41",
    "name": "Tongliang Liu",
    "bio": " I am a researcher with a strong focus on machine learning, specifically in the areas of classification with noisy labels, crowd counting, learning with noisy labels, and multi-task learning. My work in classification with noisy labels involves studying the problem of random corruption in sample labels and addressing the challenge of using surrogate loss functions in this scenario. I have proven that any surrogate loss function can be used for classification with noisy labels, and I have shown that the noise rate can be estimated using the upper bound of the conditional probability of the noisy sample.\n\nIn the field of crowd counting, I have introduced a decomposable structure called the point-query quadtree and a new counting model called Point quEry Transformer (PET). PET implements decomposable point querying via data-dependent quadtree splitting, enabling dynamic processing of sparse and dense regions. I have demonstrated the applications of PET on a number of crowd-related tasks and reported state-of-the-art performance.\n\nWhen it comes to learning with noisy labels, I have introduced channel-wise contrastive learning (CWCL) to distinguish authentic label information from noise. CWCL tends to yield more nuanced and resilient features aligned with the authentic labels, and I have shown that it is effective in extracting pertinent features to identify cleanly labeled samples.\n\nIn the area of multi-task learning, I have proposed a new strategy to measure the relatedness between tasks by jointly learning shared parameters and shared feature representations. This approach transforms the features from different tasks into a common feature space, allowing for better optimization of the shared parameters.\n\nOverall, my research is focused on developing and improving machine learning algorithms and techniques to address real-world challenges and improve the performance of machine learning models.",
    "collaborators": [
      "Tianyi Zhou",
      "Chengxin Liu",
      "Hui Kang",
      "Chunhua Shen",
      "Liang Liu",
      "Zhiguo Cao",
      "Mengdi Wang",
      "Haipeng Xiong",
      "Changxing Ding",
      "Hao Lu",
      "Wei Bian",
      "Dacheng Tao",
      "Ruxin Wang"
    ],
    "institute": null
  },
  "8672ea26-3248-482e-a783-5a6e1b577103": {
    "pk": "8672ea26-3248-482e-a783-5a6e1b577103",
    "name": "Myunghwan Kim",
    "bio": " I am a researcher focused on developing and analyzing models for networks with rich attribute and feature structures. I have worked on the Multiplicative Attribute Graph (MAG) model, which considers nodes with categorical attributes and models the probability of an edge as the product of individual attribute link formation affinities. This model can reliably capture network connectivity and provide insights into how different attributes shape the network structure.\n\nI have also developed the Latent Multi-group Membership Graph (LMMG) model, which allows each node to belong to multiple groups, with each latent group modeling the occurrence of links as well as the node feature structure. The LMMG model can be used to summarize network structure, predict links between nodes, and predict missing features of a node.\n\nIn addition to these models, I have studied the interactions between network structure and node attributes in large scale real-world networks. I have analyzed the conditions under which the MAG model can produce networks with log-normal or power-law degree distributions.\n\nI have also proposed a nonparametric multi-group membership model for dynamic networks, which can extract a summary of the common structure and the dynamics of the underlying relations between the entities in time-varying network data. My model contains three main components: the birth and death of individual groups are modeled with respect to the dynamics of the network structure via a distance dependent Indian Buffet Process, the evolution of individual node group memberships is captured via a Factorial Hidden Markov model, and the dynamics of the network structure are explained by explicitly modeling the connectivity structure of groups.\n\nIn my work on social networks, I have considered the dimensionality of social networks and developed experiments aimed at predicting that dimension. I have found evidence for a logarithmic dimension hypothesis in real-world networks such as Facebook and LinkedIn.\n\nMost recently, I have been working on discovering hypernymy in text-rich heterogeneous information networks (HINs) by exploiting context granularity. I have proposed a new framework, HyperMine, that extends the definition of context to the scenario of text-rich HINs and encodes signals of different granularities. HyperMine learns a hypernymy inference model using weak supervision acquired based on high-precision textual patterns. Extensive experiments on two large real-world datasets have demonstrated the effectiveness of HyperMine and the utility of modeling",
    "collaborators": [
      "David F. Gleich",
      "Pawe\u0142 Pra\u0142at",
      "Dieter Mitsche",
      "Erin Meger",
      "Mohsen Bayati",
      "Eric Horvitz",
      "William Baird",
      "Yao Zhu",
      "Amin Saberi",
      "Dejan Delic",
      "Thomas Lidbetter",
      "Tim Althoff",
      "Jure Leskovec",
      "Julian McAuley",
      "Hongwei Wang",
      "Lek-Heng Lim",
      "Austin R. Benson",
      "Anthony Bonato",
      "Zhiyuan Zhang"
    ],
    "institute": null
  }
}

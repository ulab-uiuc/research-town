{
  "Towards scalable and non-IID robust Hierarchical Federated Learning via Label-driven Knowledge Aggregator": {
    "paper_pk": null,
    "title": "Towards scalable and non-IID robust Hierarchical Federated Learning via Label-driven Knowledge Aggregator",
    "abstract": "In real-world applications, Federated Learning (FL) meets two challenges: (1) scalability, especially when applied to massive IoT networks, and (2) how to be robust against an environment with heterogeneous data. Realizing the first problem, we aim to design a novel FL framework named Full-stack FL (F2L). More specifically, F2L utilizes a hierarchical network architecture, making extending the FL network accessible without reconstructing the whole network system. Moreover, leveraging the advantages of hierarchical network design, we propose a new label-driven knowledge distillation (LKD) technique at the global server to address the second problem. As opposed to current knowledge distillation techniques, LKD is capable of training a student model, which consists of good knowledge from all teachers' models. Therefore, our proposed algorithm can effectively extract the knowledge of the regions' data distribution (i.e., the regional aggregated models) to reduce the divergence between clients' models when operating under the FL system with non-independent identically distributed data. Extensive experiment results reveal that: (i) our F2L method can significantly improve the overall FL efficiency in all global distillations, and (ii) F2L rapidly achieves convergence as global distillation stages occur instead of increasing on each communication cycle.",
    "authors": [
      "Duong Minh Nguyen",
      "Viet Quoc Pham",
      "Hoang Thai Dinh",
      "Diep Nguyen",
      "Long Tran-Thanh",
      "Won-Joo Hwang"
    ],
    "keywords": [
      "Federated Learning",
      "Knowledge Distillation",
      "non-IID"
    ],
    "real_all_scores": [
      6,
      3,
      8
    ],
    "real_confidences": [
      3,
      3,
      2
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning": {
    "paper_pk": null,
    "title": "Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning",
    "abstract": "Repeated parameter sharing in federated learning causes significant information leakage about private data, thus defeating its main purpose: data privacy.  Mitigating the risk of this information leakage, using state of the art differentially private algorithms, also does not come for free.  Randomized mechanisms can prevent convergence of models on learning even the useful representation functions, especially if there is more disagreement between local models on the classification functions (due to data heterogeneity). In this paper, we consider a representation federated learning objective that encourages various parties to collaboratively refine the consensus part of the model, with differential privacy guarantees, while separately allowing sufficient freedom for local personalization (without releasing it).  We prove that in the linear representation setting, while the objective is non-convex, our proposed new algorithm \\DPFEDREP\\ converges to a ball centered around the \\emph{global optimal} solution at a linear rate, and the radius of the ball is proportional to the reciprocal of the privacy budget.  With this novel utility analysis, we improve the SOTA utility-privacy trade-off for this problem by a factor of $\\sqrt{d}$, where $d$ is the input dimension.  We empirically evaluate our method with the image classification task on CIFAR10, CIFAR100, and EMNIST, and observe a significant performance improvement over the prior work under the same small privacy budget. The code can be found in this link, https://github.com/shenzebang/CENTAUR-Privacy-Federated-Representation-Learning.",
    "authors": [
      "Zebang Shen",
      "Jiayuan Ye",
      "Anmin Kang",
      "Hamed Hassani",
      "Reza Shokri"
    ],
    "keywords": [
      "Differential Privacy",
      "Representation Learning",
      "Federated Learning"
    ],
    "real_all_scores": [
      3,
      5,
      6,
      5
    ],
    "real_confidences": [
      4,
      5,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedGC: An Accurate and Efficient Federated Learning under Gradient Constraint for Heterogeneous Data": {
    "paper_pk": null,
    "title": "FedGC: An Accurate and Efficient Federated Learning under Gradient Constraint for Heterogeneous Data",
    "abstract": "Federated Learning (FL) is an important paradigm in large-scale distributed machine learning, which enables multiple clients to jointly learn a unified global model without transmitting their local data to a central server. FL has attracted growing attentions in many real-world applications, such as multi-center cardiovascular disease diagnosis and autonomous driving. Practically, the data across clients are always heterogeneous, i.e., not independently and identically distributed (Non-IID), making the local models suffer from catastrophic forgetting of the initial (or global) model. To mitigate this forgetting issue, existing FL methods may require additional regularization terms or generates pseudo data, resulting to 1) limited accuracy; 2) long training time and slow convergence rate for real-time applications; and 3) high communication cost. In this work, an accurate and efficient Federated Learning algorithm under Gradient Constraints (FedGC) is proposed, which provides three advantages: i) High accuracy is achieved by the proposed Client-Gradient-Constraint based projection method (CGC) to alleviate the forgetting issue occurred in clients, and the proposed Server-Gradient-Constraint based projection method (SGC) to effectively aggregate the gradients of clients; ii) Short training time and fast convergence rate are enabled by the proposed fast Pseudo-gradient-based mini-batch Gradient Descent (PGD) method and SGC; iii) Low communication cost is required due to the fast convergence rate and only gradients are necessary to be transmitted between server and clients. In the experiments, four real-world image datasets with three Non-IID types are evaluated, and five popular FL methods are used for comparison. The experimental results demonstrate that our FedGC not only significantly improves the accuracy and convergence rate on Non-IID data, but also drastically decreases the training time. Compared to the state-of-art FedReg, our FedGC improves the accuracy by up to 14.28% and speeds up the local training time by 15.5 times while decreasing 23% of the communication cost.",
    "authors": [
      "Peng Liu",
      "Jie Du",
      "Chi Man VONG"
    ],
    "keywords": [
      "Federated Learning",
      "Non-IID data"
    ],
    "real_all_scores": [
      6,
      6,
      6
    ],
    "real_confidences": [
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "A Hierarchical Bayesian Approach to Federated Learning": {
    "paper_pk": null,
    "title": "A Hierarchical Bayesian Approach to Federated Learning",
    "abstract": "We propose a novel hierarchical Bayesian approach to Federated learning (FL), where our models reasonably describe the generative process of clients' local data via hierarchical Bayesian modeling: constituting random variables of local models for clients that are governed by a higher-level global variate. Interestingly, the variational inference in our Bayesian model leads to an optimization problem whose block-coordinate descent  solution becomes a distributed algorithm that is separable over clients and allows them not to reveal their own private data at all, thus fully compatible with FL. We also highlight that our block-coordinate algorithm has particular forms that subsume the well-known FL algorithms including Fed-Avg and Fed-Prox as special cases. That is, we not only justify the previous Fed-Avg and Fed-Prox algorithms whose learning protocols look intuitive but theoretically less underpinned, but also generalise them even further via principled Bayesian approaches. Beyond introducing novel modeling and derivations, we also offer convergence analysis showing that our block-coordinate FL algorithm converges to an (local) optimum of the objective at the rate of $O(1/\\sqrt{t})$, the same rate as regular (centralised) SGD, as well as the generalisation error analysis where we prove that the test error of our model on unseen data is guaranteed to vanish as we increase the training data size, thus asymptotically optimal.",
    "authors": [
      "Minyoung Kim",
      "Timothy Hospedales"
    ],
    "keywords": [
      "Federated Learning",
      "Bayesian Methods",
      "Probabilistic Models"
    ],
    "real_all_scores": [
      8,
      3,
      3,
      3
    ],
    "real_confidences": [
      4,
      4,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation": {
    "paper_pk": null,
    "title": "The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation",
    "abstract": "Heterogeneity of data distributed across clients limits the performance of global models trained through federated learning, especially in the settings with highly imbalanced class distributions of local datasets. In recent years, personalized federated learning (pFL) has emerged as a potential solution to the challenges presented by heterogeneous data. However, existing pFL methods typically enhance performance of local models at the expense of the global model's accuracy. We propose FedHKD (Federated Hyper-Knowledge Distillation), a novel FL algorithm in which clients rely on knowledge distillation (KD) to train local models. In particular, each client extracts and sends to the server the means of local data representations and the corresponding soft predictions -- information that we refer to as ``hyper-knowledge\". The server aggregates this information and broadcasts it to the clients in support of local training. Notably, unlike other KD-based pFL methods, FedHKD does not rely on a public dataset nor it deploys a generative model at the server. We analyze convergence of FedHKD and conduct extensive experiments on visual datasets in a variety of scenarios, demonstrating that FedHKD provides significant improvement in both personalized as well as global model performance compared to state-of-the-art FL methods designed for heterogeneous data settings.",
    "authors": [
      "Huancheng Chen",
      "Chaining Wang",
      "Haris Vikalo"
    ],
    "keywords": [
      "Federated Learning",
      "Representation Learning",
      "Knowledge Distillation"
    ],
    "real_all_scores": [
      6,
      6,
      3,
      6
    ],
    "real_confidences": [
      3,
      2,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Kuiper: Moderated Asynchronous Federated Learning on Heterogeneous Mobile Devices with Non-IID Data": {
    "paper_pk": null,
    "title": "Kuiper: Moderated Asynchronous Federated Learning on Heterogeneous Mobile Devices with Non-IID Data",
    "abstract": "Federated learning allows multiple clients to jointly learn an ML model while keeping their data private. While synchronous federated learning (Sync-FL) requires the devices to share local gradients synchronously to provide better guarantees, it suffers from the problem of stragglers. This is the scenario where the faster clients have to wait for the slower ones, slowing the entire training process. Conventional techniques completely drop the updates from the stragglers and lose the opportunity to learn from the data they hold, which is especially important in a non-iid setting. Asynchronous learning (Async-FL) provides a potential solution to allow the clients to function at their own pace, which typically achieves faster convergence. Since edge devices have a low compute, it is hard to train a video action recognition task on them. We present Kuiper, a variant of Async-FL, to help heterogeneous edge devices with limited resources learn a heavy model on video-action-recognition tasks with data distributed non-IID. Kuiper introduces a novel aggregation scheme, which solves the straggler problem while considering the different data distribution at different clients. Kuiper shows a 11% faster convergence compared to Oort15 [OSDI-21], up to 12% and 9% improvement in test accuracy compared to FedBuff16 [AISTAT-22] and Oort [OSDI-21] on HMDB51, and 10% and 9% on UCF101.",
    "authors": [
      "Dipesh Tamboli",
      "Pranjal Jain",
      "Atul Sharma",
      "Biplab Banerjee",
      "Saurabh Bagchi",
      "Somali Chaterji"
    ],
    "keywords": [
      "Federated Learning",
      "Edge devices",
      "Non-IID",
      "Video action recognition"
    ],
    "real_all_scores": [
      3,
      1,
      3,
      3
    ],
    "real_confidences": [
      4,
      5,
      5,
      5
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Convergence Analysis of Split Learning on Non-IID Data": {
    "paper_pk": null,
    "title": "Convergence Analysis of Split Learning on Non-IID Data",
    "abstract": "Split Learning (SL) is one promising variant of Federated Learning (FL), where the AI model is split and trained at the clients and the server collaboratively. By offloading the computation-intensive portions to the server, SL enables efficient model training on resource-constrained clients. Despite its booming applications, SL still lacks rigorous convergence analysis on non-IID data, which is critical for hyperparameter selection. In this paper, we first prove that SL exhibits an $\\mathcal{O}(1/\\sqrt{T})$ convergence rate for non-convex objectives on non-IID data, where $T$ is the number of total steps. By comparing the convergence analysis and experimental results, SL can outperform FL in terms of convergence rate (w.r.t. per-client training/communication rounds, and hence, the computation efficiency) and exhibit comparable accuracy to FL on mildly non-IID data. In contrast, FL prevails on highly non-IID data.",
    "authors": [
      "Yipeng Li",
      "Xinchen Lyu"
    ],
    "keywords": [
      "Federated Learning",
      "Split Leanring",
      "Convergence analysis"
    ],
    "real_all_scores": [
      6,
      6,
      3,
      8
    ],
    "real_confidences": [
      3,
      4,
      4,
      2
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Bias Propagation in Federated Learning": {
    "paper_pk": null,
    "title": "Bias Propagation in Federated Learning",
    "abstract": "We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms that are robust to bias propagation.\n",
    "authors": [
      "Hongyan Chang",
      "Reza Shokri"
    ],
    "keywords": [
      "Fairness",
      "Algorithmic Bias",
      "Federated Learning"
    ],
    "real_all_scores": [
      8,
      6,
      6,
      6
    ],
    "real_confidences": [
      5,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models": {
    "paper_pk": null,
    "title": "Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models",
    "abstract": "Privacy is a central tenet of Federated learning (FL), in which a central server trains models without centralizing user data. However, gradient updates used in FL can leak user information.  While the most industrial uses of FL are for text applications (e.g. keystroke prediction), the majority of attacks on user privacy in FL have focused on simple image classifiers and threat models that assume honest execution of the FL protocol from the server. We propose a novel attack that reveals private user text by deploying malicious parameter vectors, and which succeeds even with mini-batches, multiple users, and long sequences. Unlike previous attacks on FL, the attack exploits characteristics of both the Transformer architecture and the token embedding, separately extracting tokens and positional embeddings to retrieve high-fidelity text. We argue that the threat model of malicious server states is highly relevant from a user-centric perspective, and show that in this scenario, text applications using transformer models are much more vulnerable than previously thought. ",
    "authors": [
      "Liam H Fowl",
      "Jonas Geiping",
      "Steven Reich",
      "Yuxin Wen",
      "Wojciech Czaja",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "keywords": [
      "Federated Learning",
      "Attack",
      "Privacy",
      "Transformers",
      "Gradient Inversion"
    ],
    "real_all_scores": [
      5,
      5,
      8
    ],
    "real_confidences": [
      5,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Benchmarking Algorithms for Domain Generalization in Federated Learning": {
    "paper_pk": null,
    "title": "Benchmarking Algorithms for Domain Generalization in Federated Learning",
    "abstract": "In this paper, we present a unified platform to study domain generalization in the federated learning (FL) context and conduct extensive empirical evaluations of the current state-of-the-art domain generalization algorithms adapted to FL. In particular, we perform a fair comparison of nine existing algorithms in solving domain generalization {either centralized domain generalization algorithms adapted to the FL context or existing FL domain generalization algorithms } to comprehensively explore the challenges introduced by FL. These challenges include statistical heterogeneity among clients, the number of clients, the number of communication rounds, etc. The evaluations are conducted on three diverse datasets including PACS (image dataset covering photo, sketch, cartoon, and painting domains), iWildCam (image dataset with 323 domains), and Py150 (natural language processing dataset with 8421 domains). The experiments show that the challenges brought by federated learning stay unsolved in the realistic experiment setting. Furthermore, the code base supports fair and reproducible new algorithm evaluation with easy implementation.",
    "authors": [
      "Ruqi Bai",
      "Saurabh Bagchi",
      "David I. Inouye"
    ],
    "keywords": [
      "Domain Generalization",
      "Federated Learning",
      "Benchmark."
    ],
    "real_all_scores": [
      5,
      3,
      3,
      3
    ],
    "real_confidences": [
      4,
      5,
      5,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "FedX: Federated Learning for Compositional Pairwise Risk Optimization": {
    "paper_pk": null,
    "title": "FedX: Federated Learning for Compositional Pairwise Risk Optimization",
    "abstract": "In this paper, we tackle a novel federated learning (FL) problem for optimizing a family of compositional pairwise risks, to which no existing FL algorithms are applicable. In particular, the objective has the form of $\\E_{\\z\\sim \\mathcal S_1} f(\\E_{\\z'\\sim\\mathcal S_2} \\ell(\\w; \\z, \\z'))$, where two sets of data $\\mathcal S_1, \\mathcal S_2$ are distributed over multiple machines, $\\ell(\\cdot; \\cdot,\\cdot)$ is a pairwise loss that only depends on the prediction outputs of the input data pairs $(\\z, \\z')$, and $f(\\cdot)$ is possibly a non-linear non-convex function. This problem has important applications in machine learning, e.g., AUROC maximization with a pairwise loss, and partial AUROC maximization with a compositional loss, etc. The challenges for designing a FL algorithm lie at the non-decomposability of the objective over multiple machines and the interdependency between different machines. We propose two provable FL algorithms (FedX) for handling linear and nolinear $f$, respectively. To tackle the challenges, we decouple the gradient's components with two types namely active parts and  lazy parts, where the {\\it active} parts depend on local data that can be computed with the local model  and the {\\it lazy} parts depend on other machines that are communicated/computed based on historical models. We develop a novel theoretical analysis to address the issue of latency of lazy parts and interdependency between the local gradient estimators and the involved data. We establish both iteration and communication complexities and exhibit that using the historical models for computing the lazy parts do not degrade the complexity results. We conduct empirical studies of FedX for AUROC and  partial AUROC maximization, and demonstrate their performance compared with multiple baselines.",
    "authors": [
      "Zhishuai Guo",
      "Rong Jin",
      "Jiebo Luo",
      "Tianbao Yang"
    ],
    "keywords": [
      "Federated Learning",
      "Pairwise Loss",
      "Compositional Optimization"
    ],
    "real_all_scores": [
      3,
      5,
      8,
      3
    ],
    "real_confidences": [
      5,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Federated Representation Learning via Maximal Coding Rate Reduction": {
    "paper_pk": null,
    "title": "Federated Representation Learning via Maximal Coding Rate Reduction",
    "abstract": "We propose a federated methodology to learn low-dimensional representations from a dataset that is distributed among several clients. In particular, we move away from the commonly-used cross-entropy loss in federated learning, and seek to learn shared low-dimensional representations of the data in a decentralized manner via the principle of maximal coding rate reduction (MCR2). Our proposed method, which we refer to as FLOW, utilizes MCR2 as the objective of choice, hence resulting in representations that are both between-class discriminative and within-class compressible. We theoretically show that our distributed algorithm achieves a first-order stationary point. Moreover, we demonstrate, via numerical experiments, the utility of the learned low-dimensional representations.",
    "authors": [
      "Juan Cervino",
      "Navid Naderializadeh",
      "Alejandro Ribeiro"
    ],
    "keywords": [
      "Federated Learning",
      "Representation Learning",
      "Information Theory"
    ],
    "real_all_scores": [
      6,
      8,
      6,
      6
    ],
    "real_confidences": [
      2,
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Panning for Gold in Federated Learning: Targeted Text Extraction under Arbitrarily Large-Scale Aggregation": {
    "paper_pk": null,
    "title": "Panning for Gold in Federated Learning: Targeted Text Extraction under Arbitrarily Large-Scale Aggregation",
    "abstract": "As federated learning (FL) matures, privacy attacks against FL systems in turn become more numerous and complex. Attacks on language models have progressed from recovering single sentences in simple classification tasks to recovering larger parts of user data. Current attacks against federated language models are sequence-agnostic and aim to extract as much data as possible from an FL update - often at the expense of fidelity for any particular sequence. Because of this, current attacks fail to extract any meaningful data under large-scale aggregation. In realistic settings, an attacker cares most about a small portion of user data that contains sensitive personal information, for example sequences containing the phrase \"my credit card number is ...\". In this work, we propose the first attack on FL that achieves targeted extraction of sequences that contain privacy-critical phrases, whereby we employ maliciously modified parameters to allow the transformer itself to filter relevant sequences from aggregated user data and encode them in the gradient update. Our attack can effectively extract sequences of interest even against extremely large-scale aggregation.",
    "authors": [
      "Hong-Min Chu",
      "Jonas Geiping",
      "Liam H Fowl",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "keywords": [
      "Federated Learning",
      "Privacy",
      "Security",
      "Privacy attack"
    ],
    "real_all_scores": [
      3,
      1,
      1,
      3
    ],
    "real_confidences": [
      2,
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "DIGEST: FAST AND COMMUNICATION EFFICIENT DECENTRALIZED LEARNING WITH LOCAL UPDATES": {
    "paper_pk": null,
    "title": "DIGEST: FAST AND COMMUNICATION EFFICIENT DECENTRALIZED LEARNING WITH LOCAL UPDATES",
    "abstract": "Decentralized learning advocates the elimination of centralized parameter servers\n(aggregation points) for potentially better utilization of underlying resources, de-\nlay reduction, and resiliency against parameter server unavailability and catas-\ntrophic failures. Gossip based decentralized algorithms, where each node in a net-\nwork has its own locally kept model on which it effectuates the learning by talking\nto its neighbors, received a lot of attention recently. Despite their potential, Gossip\nalgorithms introduce huge communication costs. In this work, we show that nodes\ndo not need to communicate as frequently as in Gossip for fast convergence; in\nfact, a sporadic exchange of a digest of a trained model is sufficient. Thus, we\ndesign a fast and communication-efficient decentralized learning mechanism; DI-\nGEST by particularly focusing on stochastic gradient descent (SGD). DIGEST is\na decentralized algorithm building on local-SGD algorithms, which are originally\ndesigned for communication efficient centralized learning. We show through anal-\nysis and experiments that DIGEST significantly reduces the communication cost\nwithout hurting convergence time for both iid and non-iid data.",
    "authors": [
      "Peyman Gholami",
      "Hulya Seferoglu"
    ],
    "keywords": [
      "Decentralized Learning",
      "Distributed Optimization",
      "Communication Efficient Learning",
      "Local SGD",
      "Federated Learning"
    ],
    "real_all_scores": [
      6,
      6,
      3,
      8
    ],
    "real_confidences": [
      3,
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedorAS: Federated Architecture Search under system heterogeneity": {
    "paper_pk": null,
    "title": "FedorAS: Federated Architecture Search under system heterogeneity",
    "abstract": "Federated learning (FL) has recently gained considerable attention due to its ability to learn on decentralised data while preserving client privacy. However, it also poses additional challenges related to the heterogeneity of the participating devices, both in terms of their computational capabilities and contributed data. Meanwhile, Neural Architecture Search (NAS) has been successfully used with centralised datasets, producing state-of-the-art results in constrained or unconstrained settings. However, such centralised datasets may not be always available for training. Most recent work at the intersection of NAS and FL attempts to alleviate this issue in a cross-silo federated setting, which assumes homogeneous compute environments with datacenter-grade hardware. \nIn this paper we explore the question of whether we can design architectures of different footprints in a cross-device federated setting, where the device landscape, availability and scale are very different. To this end, we design our system, FedorAS, to discover and train promising architectures in a resource-aware manner when dealing with devices of varying capabilities holding non-IID distributed data. We present empirical evidence of its effectiveness across different settings, spanning across three different modalities (vision, speech, text), and showcase its better performance compared to state-of-the-art federated solutions, while maintaining resource efficiency.",
    "authors": [
      "\u0141ukasz Dudziak",
      "Stefanos Laskaridis",
      "Javier Fernandez-Marques"
    ],
    "keywords": [
      "Federated Learning",
      "Neural Architecture Search",
      "Deep Learning",
      "Efficient DNN Training"
    ],
    "real_all_scores": [
      5,
      8,
      6
    ],
    "real_confidences": [
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "SuperFed: Weight Shared Federated Learning": {
    "paper_pk": null,
    "title": "SuperFed: Weight Shared Federated Learning",
    "abstract": "Federated Learning (FL) is a well-established technique for privacy preserving\ndistributed training. Much attention has been given to various aspects of FL training. A growing number of applications that consume FL-trained models, however, increasingly operate under dynamically and unpredictably variable conditions, rendering a single model insufficient. We argue for training a global \u201cfamily of models\u201d cost efficiently in a federated fashion. Training them independently for different tradeoff points incurs \u2248 O(k) cost for any k architectures of interest, however.\nStraightforward applications of FL techniques to recent weight-shared training\napproaches is either infeasible or prohibitively expensive. We propose SuperFed \u2014 an architectural framework that incurs O(1) cost to co-train a large family ofmodels in a federated fashion by leveraging weight-shared learning. We achieve an order of magnitude cost savings on both communication and computation by proposing two novel training mechanisms: (a) distribution of weight-shared models to federated clients, (b) central aggregation of arbitrarily overlapping weight-shared model parameters. The combination of these mechanisms is shown to reach an order of magnitude (9.43x) reduction in computation and communication cost for training a 5*10^18-sized family of models, compared to independently training as few as k = 9 DNNs without any accuracy loss.",
    "authors": [
      "Alind Khare",
      "Animesh Agrawal",
      "Alexey Tumanov"
    ],
    "keywords": [
      "Weight Shared",
      "Federated Learning"
    ],
    "real_all_scores": [
      5,
      5,
      3,
      3
    ],
    "real_confidences": [
      4,
      4,
      5,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Tackling Imbalanced Class in Federated Learning via Class Distribution Estimation": {
    "paper_pk": null,
    "title": "Tackling Imbalanced Class in Federated Learning via Class Distribution Estimation",
    "abstract": "Federated Learning (FL) has become an upsurging machine learning method due to its applicability in large-scale distributed system and its privacy-preserving property. However, in real-world applications, the presence of class imbalance issue, especially the mismatch between local and global class distribution, greatly degrades the performance of FL. Moreover, due to the privacy constrain, the class distribution information of clients can not be accessed directly. To tackle class imbalance issue under FL setting, a novel algorithm, FedRE, is proposed in this paper. We propose a new class distribution estimation method for the FedRE algorithm, which requires no extra client data information and thus has no privacy concern. Both experimental results and theoretical analysis are provided to support the validity of our distribution estimation method. The proposed algorithm is verified with several experiment, including different datasets with the presence of class imbalance and local-global distribution mismatch. The experimental results show that FedRE is effective and it outperforms other related methods in terms of both overall and minority class classification accuracy.",
    "authors": [
      "You-Ru Lu",
      "Xiaoqian Wang",
      "Dengfeng Sun"
    ],
    "keywords": [
      "Federated Learning",
      "class imbalance",
      "class distribution estimation"
    ],
    "real_all_scores": [
      6,
      5,
      6,
      6
    ],
    "real_confidences": [
      4,
      4,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning": {
    "paper_pk": null,
    "title": "CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning",
    "abstract": "Federated Learning (FL) is a setting for training machine learning models in distributed environments where the clients do not share their raw data but instead send model updates to a server. However, model updates can be subject to attacks and leak private information. Differential Privacy (DP) is a leading mitigation strategy which involves adding noise to clipped model updates, trading off performance for strong theoretical privacy guarantees. Previous work has shown that the threat model of DP is conservative and that the obtained guarantees may be vacuous or may overestimate information leakage in practice. In this paper, we aim to achieve a tighter measurement of the model exposure by considering a realistic threat model. We propose a novel method, CANIFE, that uses canaries - carefully crafted samples by a strong adversary to evaluate the empirical privacy of a training round. We apply this attack to vision models trained on CIFAR-10 and CelebA and to language models trained on Sent140 and Shakespeare. In particular, in realistic FL scenarios, we demonstrate that the empirical per-round epsilon obtained with CANIFE is 4 -- 5$\\times$ lower than the theoretical bound.",
    "authors": [
      "Samuel Maddock",
      "Alexandre Sablayrolles",
      "Pierre Stock"
    ],
    "keywords": [
      "Federated Learning",
      "Differential Privacy",
      "Empirical Privacy",
      "Model Auditing",
      "Membership Inference Attack"
    ],
    "real_all_scores": [
      8,
      8,
      6,
      8
    ],
    "real_confidences": [
      2,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-25%"
  },
  "Harnessing Client Drift with Decoupled Gradient Dissimilarity": {
    "paper_pk": null,
    "title": "Harnessing Client Drift with Decoupled Gradient Dissimilarity",
    "abstract": "The performance of Federated learning (FL) typically suffers from client drift caused by heterogeneous data, where data distributions vary with clients. Recent studies show that the gradient dissimilarity between clients induced by the data distribution discrepancy causes the client drift. Thus, existing methods mainly focus on correcting the gradients. However, it is challenging to identify which client should (or not) be corrected. This challenge raises a series of questions: will the local training, without gradient correction, contribute to the server model's generalization of other clients' distributions? when the generalization contribution holds? how to address the challenge when it fails? To answer these questions, we analyze the generalization contribution of local training and conclude that the generalization contribution of local training is bounded by the conditional Wasserstein distance between clients' distributions. Thus, the key to promote generalization contribution is to leverage similar conditional distributions for local training. As collecting data distribution can cause privacy leakage, we propose decoupling the deep models, i.e., splitting into high-level models and low-level models, for harnessing client drift. Namely, high-level models are trained on shared feature distributions, causing promoted generalization contribution and alleviated gradient dissimilarity. Experimental results demonstrate that FL with decoupled gradient dissimilarity is robust to data heterogeneity.",
    "authors": [
      "Zhenheng TANG",
      "Yonggang Zhang",
      "Shaohuai Shi",
      "Xinmei Tian",
      "Tongliang Liu",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "keywords": [
      "Federated Learning",
      "Deep Learning"
    ],
    "real_all_scores": [
      1,
      3,
      1,
      3
    ],
    "real_confidences": [
      3,
      5,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "QuAFL: Federated Averaging Made Asynchronous and Communication-Efficient": {
    "paper_pk": null,
    "title": "QuAFL: Federated Averaging Made Asynchronous and Communication-Efficient",
    "abstract": "Federated Learning (FL) is an emerging paradigm to enable the large-scale distributed training of machine learning models, while still providing privacy guarantees. \n  In this work, we address two of the main practical challenges when scaling federated optimization to large node counts: the need for tight synchronization between the central authority and individual computing nodes, and the large communication cost of transmissions between the central server and clients. \n  Specifically, we present a new variant of the classic federated averaging (FedAvg) algorithm, which supports both asynchronous communication and communication compression. We provide a new analysis technique showing that, in spite of these system relaxations, our algorithm can provide similar convergence to FedAvg in some parameter regimes.\n  On the experimental side, we show that our algorithm ensures fast  convergence for standard federated tasks. ",
    "authors": [
      "Hossein Zakerinia",
      "Shayan Talaei",
      "Giorgi Nadiradze",
      "Dan Alistarh"
    ],
    "keywords": [
      "Federated Learning",
      "Distributed optimization",
      "Load Balancing"
    ],
    "real_all_scores": [
      3,
      3,
      5,
      5
    ],
    "real_confidences": [
      4,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Can Fair Federated Learning reduce the need for personalization?": {
    "paper_pk": null,
    "title": "Can Fair Federated Learning reduce the need for personalization?",
    "abstract": "Federated Learning (FL) allows edge devices to collaboratively train machine learning models without sharing local data. Since the data distribution varies across client partitions, the performance of the federated model on local data also varies. To solve this, fair FL approaches attempt to reduce the accuracy disparity between local partitions by emphasizing clients with larger losses during training; while local adaptation personalizes the federated model by re-training on local data to provide a device participation incentive in cases where a federated model underperforms relative to one trained locally---their accuracy difference is less than zero. This paper evaluates Q-Fair Federated Learning (Q-FFL) in this relative domain and determines whether it provides a better starting point for personalization or supplants it. Contrary to expectation, Q-FFL does not significantly reduce the number of underperforming clients in a language task while doubling them in an image recognition task. Furthermore, fairness levels which maintain average accuracy provide no benefit to relative accuracy in federated or adapted models. We postulate that Q-FFL is unsuitable for our goal since clients with highly accurate local models require the federated model to have a disproportionate local partition accuracy to receive a benefit. Instead, we propose using knowledge distillation during FL training to create models with a higher local accuracy floor without forfeiting the ceiling. Our preliminary evaluation shows a 50% reduction in underperforming clients in the language task with no increase in underperforming clients for the image task. Thus, we argue that this simple change represents a more promising avenue for reducing the need for personalization than fairness.",
    "authors": [
      "Alex Iacob",
      "Pedro Porto Buarque de Gusmao",
      "Nicholas Donald Lane"
    ],
    "keywords": [
      "Federated Learning",
      "Fair Federated Learning",
      "FL",
      "Fair FL",
      "Local Adaptation",
      "Personalization",
      "Machine Learning",
      "ML",
      "Deep Learning",
      "DL",
      "Distributed Machine Learning"
    ],
    "real_all_scores": [
      3,
      5,
      6,
      6
    ],
    "real_confidences": [
      5,
      3,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Revisiting the Activation Function for Federated Image Classification": {
    "paper_pk": null,
    "title": "Revisiting the Activation Function for Federated Image Classification",
    "abstract": "Federated learning (FL) has become one of the most popular distributed machine learning paradigms; these paradigms enable training on a large corpus of decentralized data that resides on devices. The recent evolution in FL research is mainly credited to the refinements in training procedures by developing the optimization methods. However, there has been little verification of other technical improvements, especially improvements to the activation functions (e.g., ReLU), that are widely used in the conventional centralized approach (i.e., standard data-centric optimization). In this work, we verify the effectiveness of activation functions in various federated settings. We empirically observe that off-the-shelf activation functions that are used in centralized settings exhibit a totally different performance trend than do federated settings. The experimental results demonstrate that HardTanh achieves the best accuracy when severe data heterogeneity or low participation rate is present. We provide a thorough analysis to investigate why the representation powers of activation functions are changed in a federated setting by measuring the similarities in terms of weight parameters and representations. Lastly, we deliver guidelines for selecting activation functions in both a cross-silo setting (i.e., a number of clients <= 20) and a cross-device setting (i.e., a number of clients >= 100). We believe that our work provides benchmark data and intriguing insights for designing models FL models. ",
    "authors": [
      "Jaewoo Shin",
      "Taehyeon Kim",
      "Se-Young Yun"
    ],
    "keywords": [
      "Federated Learning",
      "Activation Function"
    ],
    "real_all_scores": [
      6,
      6,
      6
    ],
    "real_confidences": [
      1,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "FedDebias: Reducing the Local Learning Bias Improves Federated Learning on Heterogeneous Data": {
    "paper_pk": null,
    "title": "FedDebias: Reducing the Local Learning Bias Improves Federated Learning on Heterogeneous Data",
    "abstract": "Federated Learning (FL) is a machine learning paradigm that learns from data kept locally to safeguard the privacy of clients, whereas local SGD is typically employed on the clients' devices to improve communication efficiency. However, such a scheme is currently constrained by the slow and unstable convergence induced by clients' heterogeneous data. \nIn this work, we identify three under-explored phenomena of the biased local learning that may explain these challenges caused by local updates in supervised FL.\nAs a remedy, we propose FedDebias, a novel unified algorithm that reduces the local learning bias on features and classifiers to tackle these challenges. \nFedDebias consists of two components:\nThe first component alleviates the bias in the local classifiers by balancing the output distribution of models. \nThe second component learns client invariant features that are close to global features but considerably distinct from those learned from other input distributions. \nIn a series of experiments, we show that FedDebias consistently outperforms other SOTA FL and domain generalization (DG) baselines, in which both two components have individual performance gains.",
    "authors": [
      "Yongxin Guo",
      "Xiaoying Tang",
      "Tao Lin"
    ],
    "keywords": [
      "Federated Learning"
    ],
    "real_all_scores": [
      8,
      6,
      6,
      6,
      6,
      6
    ],
    "real_confidences": [
      4,
      4,
      4,
      5,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Anchor Sampling for Federated Learning with Partial Client Participation": {
    "paper_pk": null,
    "title": "Anchor Sampling for Federated Learning with Partial Client Participation",
    "abstract": "In federated learning, the support of partial client participation offers a flexible training strategy, but it deteriorates the model training efficiency. In this paper, we propose a framework FedAMD to improve the convergence property and maintain flexibility. The core idea is anchor sampling, which disjoints the partial participants into anchor and miner groups. Each client in the anchor group aims at the local bullseye with the gradient computation using a large batch. Guided by the bullseyes, clients in the miner group steer multiple near-optimal local updates using small batches and update the global model. With the joint efforts from both groups, FedAMD is able to accelerate the training process as well as improve the model performance. Measured by $\\epsilon$-approximation and compared to the state-of-the-art first-order methods, FedAMD achieves the convergence by up to $O(1/\\epsilon)$ fewer communication rounds under non-convex objectives. In specific, we achieve a linear convergence rate under PL conditions. Empirical studies on real-world datasets validate the effectiveness of FedAMD and demonstrate the superiority of our proposed algorithm: Not only does it considerably save computation and communication costs, but also the test accuracy significantly improves. ",
    "authors": [
      "Feijie Wu",
      "Song Guo",
      "Zhihao Qu",
      "Shiqi He",
      "Ziming Liu"
    ],
    "keywords": [
      "Federated Learning",
      "Optimization"
    ],
    "real_all_scores": [
      5,
      3,
      1,
      5
    ],
    "real_confidences": [
      3,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "FedMT: Federated Learning with Mixed-type Labels": {
    "paper_pk": null,
    "title": "FedMT: Federated Learning with Mixed-type Labels",
    "abstract": "In federated learning (FL), classifiers (e.g., deep networks) are trained on datasets from multiple centers without exchanging data across them, and thus improves sample efficiency. In the classical setting of FL, the same labeling criterion is usually employed across all centers being involved in training. This constraint greatly limits the applicability of FL. For example, standards used for disease diagnosis are more likely to be different across clinical centers, which mismatches the classical FL setting. In this paper, we consider an important yet under-explored setting of FL, namely FL with mixed-type labels where different labeling criteria can be employed by various centers, leading to inter-center label space differences and challenging existing FL methods designed for the classical setting. To effectively and efficiently train models with mixed-type labels, we propose a theory-guided and model-agnostic approach that can make use of the underlying correspondence between those label spaces and can be easily combined with various FL methods such as FedAvg. We present convergence analysis based on over-parameterized ReLU networks. We show that the proposed method can achieve linear convergence in label projection, and demonstrate the impact of the parameters of our new setting on the convergence rate. The proposed method is evaluated and the theoretical findings are validated on benchmark and medical datasets.",
    "authors": [
      "Qiong Zhang",
      "Aline Talhouk",
      "Gang Niu",
      "Xiaoxiao Li"
    ],
    "keywords": [
      "Federated Learning",
      "Mixed-type Labels",
      "Healthcare Application",
      "Neural Tangent Kernel"
    ],
    "real_all_scores": [
      3,
      3,
      3
    ],
    "real_confidences": [
      3,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Nearest Neighbor Machine Translation": {
    "paper_pk": null,
    "title": "Federated Nearest Neighbor Machine Translation",
    "abstract": "To protect user privacy and meet legal regulations, federated learning (FL) is attracting significant attention. Training neural machine translation (NMT) models with traditional FL algorithm (e.g., FedAvg) typically relies on multi-round model-based interactions. However, it is impractical and inefficient for machine translation tasks due to the vast communication overheads and heavy synchronization. In this paper, we propose a novel federated nearest neighbor (FedNN) machine translation framework that, instead of multi-round model-based interactions, leverages one-round memorization-based interaction to share knowledge across different clients to build low-overhead privacy-preserving systems. The whole approach equips the public NMT model trained on large-scale accessible data with a $k$-nearest-neighbor ($k$NN) classifier and integrates the external datastore constructed by private text data in all clients to form the final FL model.  A two-phase datastore encryption strategy is introduced to achieve privacy-preserving during this process.  Extensive experiments show that FedNN significantly reduces computational and communication costs compared with FedAvg, while maintaining promising performance in different FL settings.",
    "authors": [
      "Yichao Du",
      "Zhirui Zhang",
      "Bingzhe Wu",
      "Lemao Liu",
      "Tong Xu",
      "Enhong Chen"
    ],
    "keywords": [
      "Machine Translation",
      "Federated Learning",
      "Memorization Augmentation"
    ],
    "real_all_scores": [
      6,
      3,
      5
    ],
    "real_confidences": [
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Exp-$\\alpha$: Beyond Proportional Aggregation in Federated Learning": {
    "paper_pk": null,
    "title": "Exp-$\\alpha$: Beyond Proportional Aggregation in Federated Learning",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm, which computes gradients of a model locally on different clients and aggregates the updates to construct a new model collectively. Typically, the updates from local clients are aggregated with weights proportional to the size of clients' local datasets. In practice, clients have different local datasets suffering from data heterogeneity, such as imbalance. Although proportional aggregation still theoretically converges to the global optimum, it is provably slower when non-IID data is present (under convexity assumptions), the effect of which is exacerbated in practice. We posit that this analysis ignores convergence rate, which is especially important under such settings in the more realistic non-convex real world.  To account for this, we analyze a generic and time-varying aggregation strategy to reveal a surprising trade-off between convergence rate and convergence error under convexity assumptions. Inspired by the theory, we propose a new aggregation strategy, Exp-$\\alpha$, which weights clients differently based on their severity of data heterogeneity. It achieves stronger convergence rates at the theoretical cost of a non-vanishing convergence error. Through a series of controlled experiments, we empirically demonstrate the superior convergence behavior (both in terms of rate and, in practice, even error) of the proposed aggregation on three types of data heterogeneity: imbalance, label-flipping, and domain shift when combined with existing FL algorithms. For example, on our imbalance benchmark, Exp-$\\alpha$, combined with FedAvg, achieves a relative $12\\%$ increase in convergence rate and a relative $3\\%$ reduction in error across four FL communication settings. ",
    "authors": [
      "Junjiao Tian",
      "Xiaoliang Dai",
      "Chih-Yao Ma",
      "Zecheng He",
      "Yen-Cheng Liu",
      "Sayan Ghosh",
      "Peter Vajda",
      "Anqi Wu",
      "Zsolt Kira"
    ],
    "keywords": [
      "Federated Learning"
    ],
    "real_all_scores": [
      6,
      5,
      6
    ],
    "real_confidences": [
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Federated Self-supervised Learning for Heterogeneous Clients": {
    "paper_pk": null,
    "title": "Federated Self-supervised Learning for Heterogeneous Clients",
    "abstract": "Federated Learning has become an important learning paradigm due to its privacy and computational benefits. As the field advances, two key challenges that still remain to be addressed are: (1) system heterogeneity - variability in the compute and/or data resources present on each client, and (2) lack of labeled data in certain federated settings. Several recent developments have tried to overcome these challenges independently. In this work, we propose a unified and systematic framework, \\emph{Heterogeneous Self-supervised Federated Learning} (Hetero-SSFL) for enabling self-supervised learning with federation on heterogeneous clients. The proposed framework allows collaborative representation learning across all the clients without imposing architectural constraints or requiring presence of labeled data. The key idea in Hetero-SSFL is to let each client train its unique self-supervised model and enable the joint learning across clients by aligning the lower dimensional representations on a common dataset. The entire training procedure could be viewed as self and peer-supervised as both the local training and the alignment procedures do not require presence of any labeled data. As in conventional self-supervised learning, the obtained client models are task independent and can be used for varied end-tasks.\nWe provide a convergence guarantee of the proposed framework for non-convex objectives in heterogeneous settings and also empirically demonstrate that our proposed approach outperforms the state of the art methods by a significant margin. ",
    "authors": [
      "Disha Makhija",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "keywords": [
      "Federated Learning",
      "Self-supervised Learning"
    ],
    "real_all_scores": [
      3,
      5,
      6
    ],
    "real_confidences": [
      3,
      4,
      2
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Reconciling Security and Communication Efficiency in Federated Learning": {
    "paper_pk": null,
    "title": "Reconciling Security and Communication Efficiency in Federated Learning",
    "abstract": "Cross-device Federated Learning is an increasingly popular machine learning setting to train a model by leveraging a large population of client devices with high privacy and security guarantees. However, communication efficiency remains a major bottleneck when scaling federated learning to production environments, particularly due to bandwidth constraints during uplink communication. In this paper, we formalize and address the problem of compressing client-to-server model updates under the Secure Aggregation primitive, a core component of Federated Learning pipelines that allows the server to aggregate the client updates without accessing them individually. In particular, we adapt standard scalar quantization and pruning methods to Secure Aggregation and propose Secure Indexing, a variant of Secure Aggregation that supports quantization for extreme compression. We establish state-of-the-art results on LEAF benchmarks in a secure Federated Learning setup with up to 40x compression in uplink communication with no meaningful loss in utility compared to uncompressed baselines.",
    "authors": [
      "Karthik Prasad",
      "Sayan Ghosh",
      "Graham Cormode",
      "Ilya Mironov",
      "Ashkan Yousefpour",
      "Pierre Stock"
    ],
    "keywords": [
      "Federated Learning",
      "Secure Aggregation",
      "Compression",
      "Efficiency",
      "Product Quantization"
    ],
    "real_all_scores": [
      5,
      5,
      3
    ],
    "real_confidences": [
      3,
      3,
      2
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Learning with Openset Noisy Labels": {
    "paper_pk": null,
    "title": "Federated Learning with Openset Noisy Labels",
    "abstract": "Federated learning is a learning paradigm that allows the central server to learn from different data sources while keeping the data private at local. Without controlling and monitoring the local data collection process, it is highly likely that the locally available training labels are noisy, just as in a centralized data collection effort. Moreover, different clients may hold samples within different label spaces. The noisy label space is likely to be different from the unobservable clean label space, resulting in openset noisy labels. In this work, we study the challenge of federated learning from clients with openset noisy labels. We observe that many existing solutions, e.g., loss correction, in the noisy label literature cannot achieve their originally claimed effect in local training. A central contribution of this work is to propose an approach that communicates globally randomly selected ``contrastive labels\" among clients to prevent local models from memorizing the openset noise patterns individually. Randomized label generations are applied during label sharing to facilitate access to the contrastive labels while ensuring differential privacy (DP). Both the DP guarantee and the effectiveness of our approach are theoretically guaranteed. Compared with several baseline methods, our solution shows its efficiency in several public benchmarks and real-world datasets under different noise ratios and noise models. ",
    "authors": [
      "Zonglin Di",
      "Zhaowei Zhu",
      "Xin Eric Wang",
      "Yang Liu"
    ],
    "keywords": [
      "Federated Learning",
      "OpenSet Classification",
      "Noisy Label"
    ],
    "real_all_scores": [
      3,
      1,
      3
    ],
    "real_confidences": [
      3,
      4,
      2
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Semi-Variance Reduction for Fair Federated Learning": {
    "paper_pk": null,
    "title": "Semi-Variance Reduction for Fair Federated Learning",
    "abstract": "Ensuring fairness in Federated Learning (FL) systems, i.e. ensuring a satisfactory performance for all of the diverse clients in the systems, is an important and challenging problem. There are multiple fair FL algorithms in the literature, which have been relatively successful in providing fairness. However, these algorithms mostly emphasize on the loss functions of worst-off clients to improve their performance, which often results in the suppression of well-performing ones. As a consequence, the system's overall average performance is usually sacrificed for achieving fairness. Motivated by this and inspired by two well-known risk modeling methods in Finance, Mean-Variance and Mean-Semi-Variance, we propose and study two new fair FL algorithms, Variance Reduction (VRed) and Semi-Variance Reduction (Semi-VRed). VRed encourages equality between clients loss functions by penalizing their variance. In contrast, Semi-VRed penalizes the discrepancy of only the worst-off clients loss functions from the average loss. Through extensive experiments on multiple vision and language datasets, we show that, Semi-VRed achieves SoTA performance in scenarios with highly heterogeneous data distributions by improving both fairness and the system overall average performance at the same time.",
    "authors": [
      "Saber Malekmohammadi",
      "Guojun Zhang",
      "Yaoliang Yu"
    ],
    "keywords": [
      "Federated Learning",
      "Fairness"
    ],
    "real_all_scores": [
      6,
      5,
      5,
      5
    ],
    "real_confidences": [
      2,
      3,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedEED: Efficient Federated Distillation with Ensemble of Aggregated Models": {
    "paper_pk": null,
    "title": "FedEED: Efficient Federated Distillation with Ensemble of Aggregated Models",
    "abstract": "In this paper, we study the key components of the knowledge distillation-based model aggregation in federated learning (FL). We first propose a generalized distillation framework where the process of federated distillation is divided into three key stages. By investigating the contributions of each stage, we introduce a new FL framework, named Federated Efficient Ensemble Distillation (FedEED), where the ensemble teacher is created based on aggregated models. Experiment results showed that FedEED outperforms the state-of-the-art methods, including FedAvg and FedDF, on the benchmark datasets. Besides performance, FedEED also demonstrated improved scalability and privacy when compared with existing distillation-based aggregation algorithms. In particular, FedEED does not require direct access to users' model, which can protect the users' privacy. Furthermore, due to the ensemble created by aggregated models, FedEED is highly scalable, and the asymmetric distillation scheme allows parallelism between server-side distillation and clients-side local training, which could speed up the training of large scale learning system.",
    "authors": [
      "Ho Man Kwan",
      "Shenghui Song"
    ],
    "keywords": [
      "Federated Learning",
      "Knowledge Distillation"
    ],
    "real_all_scores": [
      6,
      5,
      6,
      5
    ],
    "real_confidences": [
      1,
      3,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "SWIFT: Rapid Decentralized Federated Learning via Wait-Free Model Communication": {
    "paper_pk": null,
    "title": "SWIFT: Rapid Decentralized Federated Learning via Wait-Free Model Communication",
    "abstract": "The decentralized Federated Learning (FL) setting avoids the role of a potentially unreliable or untrustworthy central host by utilizing groups of clients to collaboratively train a model via localized training and model/gradient sharing. Most existing decentralized FL algorithms require synchronization of client models where the speed of synchronization depends upon the slowest client. In this work, we propose SWIFT: a novel wait-free decentralized FL algorithm that allows clients to conduct training at their own speed. Theoretically, we prove that SWIFT matches the gold-standard iteration convergence rate $\\mathcal{O}(1/\\sqrt{T})$ of parallel stochastic gradient descent for convex and non-convex smooth optimization (total iterations $T$). Furthermore, we provide theoretical results for IID and non-IID settings without any bounded-delay assumption for slow clients which is required by other asynchronous decentralized FL algorithms. Although SWIFT achieves the same iteration convergence rate with respect to $T$ as other state-of-the-art (SOTA) parallel stochastic algorithms, it converges faster with respect to runtime due to its wait-free structure. Our experimental results demonstrate that SWIFT's runtime is reduced due to a large reduction in communication time per epoch, which falls by an order of magnitude compared to synchronous counterparts. Furthermore, SWIFT produces loss levels for image classification, over IID and non-IID data settings, upwards of 50\\% faster than existing SOTA algorithms.",
    "authors": [
      "Marco Bornstein",
      "Tahseen Rabbani",
      "Evan Z Wang",
      "Amrit Bedi",
      "Furong Huang"
    ],
    "keywords": [
      "Federated Learning",
      "Asynchronous",
      "Decentralized",
      "Wait-Free"
    ],
    "real_all_scores": [
      3,
      5,
      10,
      3,
      3
    ],
    "real_confidences": [
      3,
      3,
      3,
      5,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Supernet Training for Federated Image Classification Under System Heterogeneity": {
    "paper_pk": null,
    "title": "Supernet Training for Federated Image Classification Under System Heterogeneity",
    "abstract": "Efficient deployment of deep neural networks across many devices and resource constraints, particularly on edge devices, is one of the most challenging problems in the presence of data-privacy preservation issues. Conventional approaches have evolved to either improve a single global model while keeping each local heterogeneous training data decentralized (i.e. data heterogeneity; Federated Learning (FL)) or to train an overarching network that supports diverse architectural settings to address heterogeneous systems equipped with different computational capabilities (i.e. system heterogeneity; Neural Architecture Search). However, few studies have considered both directions simultaneously. This paper proposes the federation of supernet training (FedSup) framework to consider both scenarios simultaneously, i.e., where clients send and receive a supernet that contains all possible architectures sampled from itself. The approach is inspired by observing that averaging parameters during model aggregation for FL is similar to weight-sharing in supernet training. Thus, the proposed FedSup framework combines a weight-sharing approach widely used for training single shot models with FL averaging (FedAvg). Furthermore, we develop an efficient algorithm (E-FedSup) by sending the sub-model to clients on the broadcast stage to reduce communication costs and training overhead, including several strategies to enhance supernet training in the FL environment. We verify the proposed approach with extensive empirical evaluations. The resulting framework also ensures data and model heterogeneity robustness on several standard benchmarks.",
    "authors": [
      "Taehyeon Kim",
      "Se-Young Yun"
    ],
    "keywords": [
      "Federated Learning",
      "Image Classification",
      "Supernet Training",
      "System Heterogeneity"
    ],
    "real_all_scores": [
      6,
      8,
      6
    ],
    "real_confidences": [
      3,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Personalized Federated Learning with Feature Alignment and Classifier Collaboration": {
    "paper_pk": null,
    "title": "Personalized Federated Learning with Feature Alignment and Classifier Collaboration",
    "abstract": "Data heterogeneity is one of the most challenging issues in federated learning, which motivates a variety of approaches to learn personalized models for participating clients. One such approach in deep neural networks based tasks is employing a shared feature representation and learning a customized classifier head for each client. However, previous works do not utilize the global knowledge during local representation learning and also neglect the fine-grained collaboration between local classifier heads, which limits the model generalization ability. In this work, we conduct explicit local-global feature alignment by leveraging global semantic knowledge for learning a better representation. Moreover, we quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights. Finally, extensive evaluation results on benchmark datasets with various heterogeneous data scenarios demonstrate the effectiveness of our proposed method.",
    "authors": [
      "Jian Xu",
      "Xinyi Tong",
      "Shao-Lun Huang"
    ],
    "keywords": [
      "Federated Learning",
      "Personalization",
      "Collaboration"
    ],
    "real_all_scores": [
      3,
      5,
      6,
      3
    ],
    "real_confidences": [
      3,
      4,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Hybrid Federated Learning for Feature & Sample Heterogeneity: Algorithms and Implementation": {
    "paper_pk": null,
    "title": "Hybrid Federated Learning for Feature & Sample Heterogeneity: Algorithms and Implementation",
    "abstract": " Federated learning (FL) is a popular distributed machine learning paradigm dealing with distributed and private data sets. Based on the data partition pattern, FL is often categorized into horizontal, vertical, and hybrid settings. All three settings have many applications, but the hybrid FL remains relatively less explored, because it deals with the challenging situation where both the feature space and the data samples are heterogeneous.\n    This work designs a novel mathematical model that effectively allows the clients to aggregate distributed data with heterogeneous, and possibly overlapping features and samples. Our main idea is to partition each client's model into a feature extractor part and a classifier part, where the former can be used to process the input data, while the latter is used to perform the learning from the extracted features. The heterogeneous feature aggregation is done through building a server model, which assimilates local classifiers and feature extractors through a carefully designed matching mechanism. A communication-efficient algorithm is then designed to train both the client and server models. Finally, we conducted numerical experiments on multiple image classification data sets to validate the performance of the proposed algorithm. To our knowledge, this is the first formulation and algorithm developed for hybrid FL.",
    "authors": [
      "Xinwei Zhang",
      "Wotao Yin",
      "Mingyi Hong",
      "Tianyi Chen"
    ],
    "keywords": [
      "Federated Learning",
      "Model Ensemble",
      "Model Design",
      "Algorithm Design"
    ],
    "real_all_scores": [
      3,
      5,
      3,
      5,
      6
    ],
    "real_confidences": [
      4,
      3,
      4,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "GLASU: A Communication-Efficient Algorithm for Federated Learning with Vertically Distributed Graph Data": {
    "paper_pk": null,
    "title": "GLASU: A Communication-Efficient Algorithm for Federated Learning with Vertically Distributed Graph Data",
    "abstract": "Vertical federated learning (VFL) is a distributed learning paradigm, where computing clients collectively train a model based on the partial features of the same set of samples they possess. Current research on VFL focuses on the case when samples are independent, but it rarely addresses an emerging scenario when samples are interrelated through a graph. For graph-structured data, graph neural networks (GNNs) are rather competitive machine learning models, but a naive implementation in the VFL setting causes a significant communication overhead; moreover, the analysis is faced with a challenge caused by the biased stochastic gradients. In this paper, we propose a model splitting method that splits a backbone GNN across the clients and the server and a communication-efficient algorithm, GLASU, to train such a model. GLASU adopts lazy aggregation and stale updates to skip aggregation when evaluating the model and skip feature exchanges during training, greatly reducing communication. We offer a theoretical analysis and conduct extensive numerical experiments on real-world datasets, showing that the proposed algorithm effectively trains a GNN model, whose performance matches that of the backbone GNN when trained in a centralized manner.",
    "authors": [
      "Xinwei Zhang",
      "Mingyi Hong",
      "Jie Chen"
    ],
    "keywords": [
      "Federated Learning",
      "Graph Neural Network",
      "Feature Distributed Federated Learning"
    ],
    "real_all_scores": [
      3,
      3,
      3,
      5
    ],
    "real_confidences": [
      3,
      2,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Fair Federated Learning via Bounded Group Loss": {
    "paper_pk": null,
    "title": "Fair Federated Learning via Bounded Group Loss",
    "abstract": "In federated learning, fair prediction across protected groups is an important constraint for many applications. Unfortunately, prior work studying group fair federated learning lacks formal convergence or fairness guarantees. In this work we propose a general framework for provably fair federated learning. In particular, we explore and extend the notion of Bounded Group Loss as a theoretically-grounded approach for group fairness. Using this setup, we propose a scalable federated optimization method that optimizes the empirical risk under a number of group fairness constraints. We provide convergence guarantees for the method as well as fairness guarantees for the resulting solution. Empirically, we evaluate our method across common benchmarks from fair ML and federated learning, showing that it can provide both fairer and more accurate predictions than baseline approaches.",
    "authors": [
      "Shengyuan Hu",
      "Steven Wu",
      "Virginia Smith"
    ],
    "keywords": [
      "Federated Learning",
      "Group Fairness"
    ],
    "real_all_scores": [
      5,
      5,
      5,
      5
    ],
    "real_confidences": [
      4,
      4,
      5,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor Attacks in Federated Learning": {
    "paper_pk": null,
    "title": "Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor Attacks in Federated Learning",
    "abstract": "Federated learning is particularly susceptible to model poisoning and backdoor attacks because individual users have direct control over the training data and model updates.  At the same time, the attack power of an individual user is limited because their updates are quickly drowned out by those of many other users. Existing attacks do not account for future behaviors of other users, and thus require many sequential updates and their effects are quickly erased. We propose an attack that anticipates and accounts for the entire federated learning pipeline, including behaviors of other clients, and ensures that backdoors are effective quickly and persist even after multiple rounds of community updates. We show that this new attack is effective in realistic scenarios where the attacker only contributes to a small fraction of randomly sampled rounds and demonstrate this attack on image classification, next-word prediction, and sentiment analysis.",
    "authors": [
      "Yuxin Wen",
      "Jonas Geiping",
      "Liam H Fowl",
      "Hossein Souri",
      "Rama Chellappa",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "keywords": [
      "Privacy",
      "Federated Learning"
    ],
    "real_all_scores": [
      10,
      8,
      6,
      8
    ],
    "real_confidences": [
      4,
      3,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-25%"
  },
  "Neighborhood Gradient Clustering: An Efficient Decentralized Learning Method for Non-IID Data Distributions": {
    "paper_pk": null,
    "title": "Neighborhood Gradient Clustering: An Efficient Decentralized Learning Method for Non-IID Data Distributions",
    "abstract": "Decentralized learning algorithms enable the training of deep learning models over large distributed datasets generated at different devices and locations, without the need for a central server. In practical scenarios, the distributed datasets can have significantly different data distributions across the agents. The current state-of-the-art decentralized algorithms mostly assume the data distributions to be Independent and Identically Distributed (IID). This paper focuses on improving decentralized learning over non-IID data distributions with minimal compute and memory overheads. We propose Neighborhood Gradient Clustering (NGC), a novel decentralized learning algorithm that modifies the local gradients of each agent using self- and cross-gradient information. Cross-gradients for a pair of neighboring agents are the derivatives of the model parameters of an agent with respect to the dataset of the other agent. In particular, the proposed method replaces the local gradients of the model with the weighted mean of the self-gradients, model-variant cross-gradients (derivatives of the received neighbors\u2019 model parameters with respect to the local dataset - computed locally), and data-variant cross-gradients (derivatives of the local model with respect to its neighbors\u2019 datasets - received through communication). The data-variant cross-gradients are aggregated through an additional communication round without breaking the privacy constraints of the decentralized setting. Further, we present CompNGC, a compressed version of NGC that reduces the communication overhead by $32 \\times$ by compressing the cross-gradients. We demonstrate the empirical convergence and efficiency of the proposed technique over non-IID data distributions sampled from the CIFAR-10 dataset on various model architectures and graph topologies. Our experiments demonstrate that NGC and CompNGC outperform the existing state-of-the-art (SoTA) decentralized learning algorithm over non-IID data by $1-5\\%$ with significantly less compute and memory requirements. Further, we also show that the proposed NGC method outperforms the baseline by $5-40\\%$ with no additional communication. ",
    "authors": [
      "Sai Aparna Aketi",
      "Sangamesh Kodge",
      "Kaushik Roy"
    ],
    "keywords": [
      "Federated Learning",
      "Distributed Machine Learning",
      "Decentralized Learning",
      "Communication Efficient",
      "Energy Efficient",
      "Non-IID Data Distribution",
      "Convergence"
    ],
    "real_all_scores": [
      6,
      8,
      8,
      8
    ],
    "real_confidences": [
      5,
      3,
      5,
      5
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-5%"
  },
  "FedCL: Critical Learning Periods-aware Adaptive Client Selection in Federated Learning": {
    "paper_pk": null,
    "title": "FedCL: Critical Learning Periods-aware Adaptive Client Selection in Federated Learning",
    "abstract": "Federated learning (FL) is a distributed optimization paradigm that learns from data samples distributed across a number of clients.  Adaptive client selection that is cognizant of the training progress of clients has become a major trend to improve FL efficiency but not yet well-understood.   Most existing FL methods such as FedAvg and its state-of-the-art variants implicitly assume that all learning phases during the FL training process are equally important.  Unfortunately, this assumption has been revealed to be invalid due to recent findings on critical learning (CL) periods, in which small gradient errors may lead to an irrecoverable deficiency on final test accuracy.  In this paper, we develop FedCL, a CL periods-aware FL framework to reveal that adaptively augmenting exiting FL methods with CL periods, the resultant performance is significantly improved when the client selection is guided by the discovered CL periods.  Experiments based on various machine learning models and datasets validate that the proposed FedCL framework consistently achieves an improved model accuracy while maintains comparable or even better communication efficiency as compared to state-of-the-art methods, demonstrating a promising and easily adopted method for tackling the heterogeneity of FL training.  \n",
    "authors": [
      "Gang Yan",
      "Hao Wang",
      "Xu Yuan",
      "Jian Li"
    ],
    "keywords": [
      "Critical Learning Periods",
      "Federated Learning",
      "Client Selection"
    ],
    "real_all_scores": [
      8,
      6,
      6
    ],
    "real_confidences": [
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Does Federated Learning Really Need Backpropagation?": {
    "paper_pk": null,
    "title": "Does Federated Learning Really Need Backpropagation?",
    "abstract": "Federated learning (FL) provides general principles for decentralized clients to train a server model collectively without sharing local data. FL is a promising framework with practical applications, but its standard training paradigm requires the clients to backpropagate through the model to compute gradients. Since these clients are typically edge devices and not fully trusted, executing backpropagation on them incurs computational and storage overhead as well as white-box vulnerability. In light of this, we develop backpropagation-free federated learning, dubbed BAFFLE, in which backpropagation is replaced by multiple forward processes to estimate gradients. BAFFLE is 1) memory-efficient and easily fits uploading bandwidth; 2) compatible with inference-only hardware optimization and model quantization or pruning; and 3) well-suited to trusted execution environments, because the clients in BAFFLE only execute forward propagation and return a set of scalars to the server. In experiments, we demonstrate that BAFFLE-trained models can achieve empirically comparable performance to conventional FL models.",
    "authors": [
      "Haozhe Feng",
      "Tianyu Pang",
      "Chao Du",
      "Wei Chen",
      "Shuicheng YAN",
      "Min Lin"
    ],
    "keywords": [
      "Federated Learning",
      "Backpropagation-Free Training"
    ],
    "real_all_scores": [
      6,
      6,
      8,
      6,
      6
    ],
    "real_confidences": [
      3,
      4,
      3,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Federated Learning for Inference at Anytime and Anywhere": {
    "paper_pk": null,
    "title": "Federated Learning for Inference at Anytime and Anywhere",
    "abstract": "Federated learning has been predominantly concerned with collaborative training of deep networks from scratch, and especially the many challenges that arise, such as communication cost, robustness to heterogeneous data, and support for diverse device capabilities. However, there is no unified framework that addresses all these problems together. This paper studies the challenges and opportunities of exploiting pre-trained Transformer models in FL. In particular, we propose to efficiently adapt such pre-trained models by injecting a novel attention-based adapter module at each transformer block that both modulates the forward pass and makes an early prediction. Training only the lightweight adapter by FL leads to fast and communication-efficient learning even in the presence of heterogeneous data and devices. Extensive experiments on standard FL benchmarks, including CIFAR- 100, FEMNIST and SpeechCommandsv2 demonstrate that this simple framework provides fast and accurate FL while supporting heterogenous device capabilities, efficient personalization, and scalable-cost anytime inference.",
    "authors": [
      "Zicheng Liu",
      "Da Li",
      "Javier Fernandez-Marques",
      "Stefanos Laskaridis",
      "Yan Gao",
      "\u0141ukasz Dudziak",
      "Stan Z. Li",
      "Shell Xu Hu",
      "Timothy Hospedales"
    ],
    "keywords": [
      "Federated Learning"
    ],
    "real_all_scores": [
      6,
      5,
      3,
      3
    ],
    "real_confidences": [
      4,
      3,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "DepthFL : Depthwise Federated Learning for Heterogeneous Clients": {
    "paper_pk": null,
    "title": "DepthFL : Depthwise Federated Learning for Heterogeneous Clients",
    "abstract": "Federated learning is for training a global model without collecting private local data from clients. As they repeatedly need to upload locally-updated weights or gradients instead, clients require both computation and communication resources enough to participate in learning, but in reality their resources are heterogeneous. To enable resource-constrained clients to train smaller local models, width scaling techniques have been used, which reduces the channels of a global model. Unfortunately, width scaling suffers from heterogeneity of local models when averaging them, leading to a lower accuracy than when simply excluding resource-constrained clients from training. This paper proposes a new approach based on depth scaling called DepthFL. DepthFL defines local models of different depths by pruning the deepest layers off the global model, and allocates them to clients depending on their available resources. Since many clients do not have enough resources to train deep local models, this would make deep layers partially-trained with insufficient data, unlike shallow layers that are fully trained. DepthFL alleviates this problem by mutual self-distillation of knowledge among the classifiers of various depths within a local model. Our experiments show that depth-scaled local models build a global model better than width-scaled ones, and that self-distillation is highly effective in training data-insufficient deep layers.",
    "authors": [
      "Minjae Kim",
      "Sangyoon Yu",
      "Suhyun Kim",
      "Soo-Mook Moon"
    ],
    "keywords": [
      "Federated Learning",
      "Heterogeneity"
    ],
    "real_all_scores": [
      6,
      5,
      6,
      6
    ],
    "real_confidences": [
      3,
      4,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Local Coefficient Optimization in Federated Learning": {
    "paper_pk": null,
    "title": "Local Coefficient Optimization in Federated Learning",
    "abstract": "Federated learning emerges as a promising approach to build a large-scale cooperative learning system among multiple clients without sharing their raw data. However, given a specific global objective, finding the optimal sampling weights for each client remains largely unexplored. This is particularly challenging when clients' data distributions are non-i.i.d. and clients partially participate.\n\nIn this paper, we model the above task as a bi-level optimization problem which takes the correlations among different clients into account. We present a double-loop primal-dual-based algorithm to solve the bi-level optimization problem. We further provide rigorous convergence analysis for our algorithm under mild assumptions. Finally, we perform extensive empirical studies under both toy examples and learning models from real datasets to verify the effectiveness of the proposed method. ",
    "authors": [
      "Congliang Chen",
      "Chi Zhang",
      "Bingzhe Wu",
      "Yatao Bian",
      "Zhi-Quan Luo",
      "Peilin Zhao"
    ],
    "keywords": [
      "Federated Learning",
      "Bilevel optimization"
    ],
    "real_all_scores": [
      3,
      5,
      6,
      3
    ],
    "real_confidences": [
      4,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "MANDERA: Malicious Node Detection in Federated Learning via Ranking": {
    "paper_pk": null,
    "title": "MANDERA: Malicious Node Detection in Federated Learning via Ranking",
    "abstract": "Byzantine attacks hinder the deployment of federated learning algorithms. Although we know that the benign gradients and Byzantine attacked gradients are distributed differently, to detect the malicious gradients is challenging due to (1) the gradient is high-dimensional and each dimension has its unique distribution and (2) the benign gradients and the attacked gradients are always mixed (two-sample test methods cannot apply directly). To address the above, for the first time, we propose MANDERA which is theoretically guaranteed to efficiently detect all malicious gradients under Byzantine attacks with no prior knowledge or history about the number of attacked nodes. \nSpecifically, we transfer the original updating gradient matrix into a ranking matrix. By such an operation, the scales of different dimensions of the gradients in the ranking space become identical. The high-dimensional benign gradients and the malicious gradients can be easily separated. The effectiveness of MANDERA is further confirmed by experimentation on four Byzantine attack implementations (Gaussian, Zero Gradient, Sign Flipping, Shifted Mean), comparing with state-of-the-art defenses. The experiments cover both IID and Non-IID datasets.",
    "authors": [
      "Wanchuang Zhu",
      "Benjamin Zi Hao Zhao",
      "Simon Luo",
      "Tongliang Liu",
      "Ke Deng"
    ],
    "keywords": [
      "Federated Learning",
      "Byzantine attack",
      "malicious node detection",
      "ranking"
    ],
    "real_all_scores": [
      1,
      3,
      3
    ],
    "real_confidences": [
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Multimodal Federated Learning via Contrastive Representation Ensemble": {
    "paper_pk": null,
    "title": "Multimodal Federated Learning via Contrastive Representation Ensemble",
    "abstract": "With the increasing amount of multimedia data on modern mobile systems and IoT infrastructures, harnessing these rich multimodal data without breaching user privacy becomes a critical issue. Federated learning (FL) serves as a privacy-conscious alternative to centralized machine learning. However, existing FL methods extended to multimodal data all rely on model aggregation on single modality level, which restrains the server and clients to have identical model architecture for each modality. This limits the global model in terms of both model complexity and data capacity, not to mention task diversity. In this work, we propose \\textit{Contrastive Representation Ensemble and Aggregation for Multimodal FL (CreamFL)}, a multimodal federated learning framework that enables training larger server models from clients with heterogeneous model architectures and data modalities, while only communicating knowledge on public dataset. To achieve better multimodal representation fusion, we design a global-local cross-modal ensemble strategy to aggregate client representations. To mitigate local model drift caused by two unprecedented heterogeneous factors stemming from multimodal discrepancy (\\textit{modality gap} and \\textit{task gap}), we further propose two inter-modal and intra-modal contrasts to regularize local training, which complements information of the absent modality for uni-modal clients and regularizes local clients to head towards global consensus. Thorough evaluations and ablation studies on image-text retrieval and visual question answering tasks showcase the superiority of CreamFL over state-of-the-art FL methods and its practical value.",
    "authors": [
      "Qiying Yu",
      "Yang Liu",
      "Yimu Wang",
      "Ke Xu",
      "Jingjing Liu"
    ],
    "keywords": [
      "Federated Learning",
      "Multi-modal Learning",
      "Representation-level Ensemble Knowledge Transfer"
    ],
    "real_all_scores": [
      5,
      5,
      3,
      6
    ],
    "real_confidences": [
      3,
      4,
      4,
      2
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Learning of Large Models at the Edge via Principal Sub-Model Training": {
    "paper_pk": null,
    "title": "Federated Learning of Large Models at the Edge via Principal Sub-Model Training",
    "abstract": "Limited compute, memory, and communication capabilities of edge users create a significant bottleneck for federated learning (FL) of large models. Current literature typically tackles the challenge with a heterogeneous client setting or allows training to be offloaded to the server. However, the former requires a fraction of clients to train near-full models, which may not be achievable at the edge; while the latter can compromise privacy with sharing of intermediate representations or labels. In this work, we consider a realistic, but much less explored, cross-device FL setting in which no client has the capacity to train a full large model nor is willing to share any intermediate representations with the server. To this end, we present Principal Sub-Model (PriSM) training methodology, which leverages models\u2019 low-rank structure and kernel orthogonality to train sub-models in the orthogonal kernel space. More specifically, by applying singular value decomposition to original kernels in the server model, PriSM first obtains a set of principal orthogonal kernels with importance weighed by their singular values. Thereafter, PriSM utilizes a novel sampling strategy that selects different subsets of the principal kernels independently to create sub-models for clients with reduced computation and communication requirements. Importantly, a kernel with a large singular value is assigned with a high sampling probability. Thus, each sub-model is a low-rank approximation of the full large model, and all clients together achieve nearly full coverage of the principal kernels. To further improve memory efficiency, PriSM exploits low-rank structure in intermediate representations and allows each sub-model to learn only a subset of them while still preserving training performance. Our extensive evaluations on multiple datasets in various resource-constrained settings demonstrate that PriSM can yield an improved performance of up to $10\\%$ compared to existing alternatives, when training sub-models with only $20\\%$ principal kernels ($\\sim 5\\%$ of the full server model.).",
    "authors": [
      "Yue Niu",
      "Saurav Prakash",
      "Souvik Kundu",
      "Sunwoo Lee",
      "Salman Avestimehr"
    ],
    "keywords": [
      "Federated Learning",
      "Resource-Constrained Clients",
      "Sub-Model Training"
    ],
    "real_all_scores": [
      3,
      6,
      5,
      5
    ],
    "real_confidences": [
      5,
      5,
      5,
      5
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Personalized Subgraph Federated Learning": {
    "paper_pk": null,
    "title": "Personalized Subgraph Federated Learning",
    "abstract": "In real-world scenarios, subgraphs of a larger global graph may be distributed across multiple devices or institutions, and only locally accessible due to privacy restrictions, although there may be links between them. Recently proposed subgraph Federated Learning (FL) methods deal with those missing links across private local subgraphs while distributively training Graph Neural Networks (GNNs) on them. However, they have overlooked the inevitable heterogeneity among subgraphs, caused by subgraphs comprising different communities of a global graph, therefore, consequently collapsing the incompatible knowledge from local GNN models trained on heterogeneous graph distributions. To overcome such a limitation, we introduce a new subgraph FL problem, personalized subgraph FL, which focuses on the joint improvement of the interrelated local GNN models rather than learning a single global GNN model, and propose a novel framework, FEDerated Personalized sUBgraph learning (FED-PUB), to tackle it. A crucial challenge in personalized subgraph FL is that the server does not know which subgraph each client has. FED-PUB thus utilizes functional embeddings of the local GNNs using random graphs as inputs to compute similarities between them, and use them to perform weighted averaging for server-side aggregation. Further, it learns a personalized sparse mask at each client to select and update only the subgraph-relevant subset of the aggregated parameters. We validate FED-PUB for its subgraph FL performance on six datasets, considering both non-overlapping and overlapping subgraphs, on which ours largely outperforms relevant baselines.",
    "authors": [
      "Jinheon Baek",
      "Wonyong Jeong",
      "Jiongdao Jin",
      "Jaehong Yoon",
      "Sung Ju Hwang"
    ],
    "keywords": [
      "Graph Representation Learning",
      "Graph Neural Networks",
      "Federated Learning",
      "Subgraph Federated Learning"
    ],
    "real_all_scores": [
      5,
      6,
      6
    ],
    "real_confidences": [
      2,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback": {
    "paper_pk": null,
    "title": "Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback",
    "abstract": "Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of optimization algorithms. To handle the tuning parameters in OSMD that depend on the unknown problem parameters, we use the online ensemble method and doubling trick. We prove a dynamic regret bound relative to any sampling sequence. The regret bound depends on the total variation of the comparator sequence, which naturally captures the intrinsic difficulty of the problem. To the best of our knowledge, these theoretical contributions are new and the proof technique is of independent interest. Through both synthetic and real data experiments, we illustrate advantages of the proposed client sampling algorithm over the widely used uniform sampling and existing online learning based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent.",
    "authors": [
      "Boxin Zhao",
      "Ziqi Liu",
      "Chaochao Chen",
      "mladen kolar",
      "Zhiqiang Zhang",
      "JUN ZHOU"
    ],
    "keywords": [
      "Federated Learning",
      "Client Sampling",
      "Optimization"
    ],
    "real_all_scores": [
      3,
      6,
      3
    ],
    "real_confidences": [
      4,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedPSE: Personalized Sparsification with Element-wise Aggregation for Federated Learning": {
    "paper_pk": null,
    "title": "FedPSE: Personalized Sparsification with Element-wise Aggregation for Federated Learning",
    "abstract": "Federated learning (FL) is a popular distributed machine learning framework in which clients aggregate models' parameters instead of sharing their individual data. In FL, clients communicate with the server under limited network bandwidth frequently, which arises the communication challenge. To resolve this challenge, multiple compression methods have been proposed to reduce the transmitted parameters. However, these techniques show that the federated performance degrades significantly with Non-IID (non-identically independently distributed) datasets. To address this issue, we propose an effective method, called FedPSE, which solves the efficiency challenge of FL with heterogeneous data. FedPSE compresses the local updates on clients using Top-K sparsification and aggregates these updates on the server by element-wise average.  Then clients download the personalized sparse updates from the server to update their individual local models.  We then theoretically analyze the convergence of FedPSE under the non-convex setting.  Moreover, extensive experiments on four benchmark tasks demonstrate that our FedPSE outperforms the state-of-the-art methods on Non-IID datasets in terms of both efficiency and accuracy.",
    "authors": [
      "Longfei Zheng",
      "Yingting Liu",
      "Xiaolong Xu",
      "Chaochao Chen",
      "Weipeng Sun",
      "Xiaolong Hu",
      "Lei Wang",
      "Li Wang"
    ],
    "keywords": [
      "Federated Learning",
      "Non-IID",
      "Communication Efficiency"
    ],
    "real_all_scores": [
      8,
      5,
      6,
      6
    ],
    "real_confidences": [
      3,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-25%"
  },
  "Multigraph Topology Design for Cross-Silo Federated Learning": {
    "paper_pk": null,
    "title": "Multigraph Topology Design for Cross-Silo Federated Learning",
    "abstract": "Cross-silo federated learning utilizes a few hundred reliable data silos with high-speed access links to jointly train a model. While this approach becomes a popular setting in federated learning, designing a robust topology to reduce the training time is still an open problem.\nIn this paper, we present a new multigraph topology for cross-silo federated learning. We first construct the multigraph using the overlay graph. We then parse this multigraph into different simple graphs with isolated nodes. The existence of isolated nodes allows us to perform model aggregation without waiting for other nodes, hence reducing the training time. We further propose a new distributed learning algorithm to use with our multigraph topology. The intensive experiments on public datasets show that our proposed method significantly reduces the training time compared with recent state-of-the-art topologies while ensuring convergence and maintaining the accuracy.",
    "authors": [
      "Tuong Khanh Long Do",
      "Binh Xuan Nguyen",
      "Toan Tran",
      "Erman Tjiputra",
      "Quang D. Tran",
      "Hien Nguyen",
      "Vuong Pham",
      "Anh Nguyen"
    ],
    "keywords": [
      "Federated Learning",
      "Topology Design",
      "Multigraph"
    ],
    "real_all_scores": [
      8,
      8,
      8,
      6
    ],
    "real_confidences": [
      4,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Exploit Unlabeled Data on the Server! Federated Learning via Uncertainty-aware Ensemble Distillation and Self-Supervision": {
    "paper_pk": null,
    "title": "Exploit Unlabeled Data on the Server! Federated Learning via Uncertainty-aware Ensemble Distillation and Self-Supervision",
    "abstract": "Federated Learning (FL) is a distributed machine learning paradigm that involves the cooperation of multiple clients to train a server model. In practice, it is hard to assume that each client possesses large-scale data or many clients are always available to participate in FL for the same round, which may lead to data deficiency. This deficiency degrades the entire learning process. To resolve this challenge, we propose a Federated learning with entropy-weighted ensemble Distillation and Self-supervised learning (FedDS). FedDS reliably deals with situations where not only the amount of data per client but also the number of clients is scarce. This advantage is achieved by leveraging the prevalent unlabeled data in the server. We demonstrate the effectiveness of FedDS on classification tasks for CIFAR-10/100 and PathMNIST. In CIFAR-10, our method shows the improvement over FedAVG by 12.54% in data deficient regime, and by 17.16% and 23.56% in more challenging scenarios of noisy label or Byzantine client cases, respectively.",
    "authors": [
      "Jae-Min Park",
      "Won-jun Jang",
      "Tae-Hyun Oh",
      "Si-Hyeon Lee"
    ],
    "keywords": [
      "Federated Learning",
      "Knowledge Distillation",
      "Ensemble Distillation",
      "Self-supervised Learning",
      "Uncertainty"
    ],
    "real_all_scores": [
      5,
      3,
      6
    ],
    "real_confidences": [
      3,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Single-shot General Hyper-parameter Optimization for Federated Learning": {
    "paper_pk": null,
    "title": "Single-shot General Hyper-parameter Optimization for Federated Learning",
    "abstract": "We address the problem of hyper-parameter optimization (HPO) for federated learning (FL-HPO). We introduce Federated Loss SuRface Aggregation (FLoRA), a general FL-HPO solution framework that can address use cases of tabular data and any Machine Learning (ML) model including gradient boosting training algorithms, SVMs, neural networks, among others and thereby further expands the scope of FL-HPO. FLoRA enables single-shot FL-HPO: identifying a single set of good hyper-parameters that are subsequently used in a single FL training. Thus, it enables FL-HPO solutions with minimal additional communication overhead compared to FL training without HPO. Utilizing standard smoothness assumptions, we theoretically characterize the optimality gap of FLoRA for any convex and non-convex loss functions, which explicitly accounts for the heterogeneous nature of the parties' local data distributions, a dominant characteristic of FL systems. Our empirical evaluation of FLoRA for multiple FL algorithms on seven OpenML datasets demonstrates significant model accuracy improvements over the baselines, and robustness to increasing number of parties involved in FL-HPO training.",
    "authors": [
      "Yi Zhou",
      "Parikshit Ram",
      "Theodoros Salonidis",
      "Nathalie Baracaldo",
      "Horst Samulowitz",
      "Heiko Ludwig"
    ],
    "keywords": [
      "Federated Learning",
      "Hyperparameter Optimization",
      "Optimality Gap Analysis"
    ],
    "real_all_scores": [
      6,
      8,
      6,
      5
    ],
    "real_confidences": [
      3,
      4,
      2,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Test-Time Robust Personalization for Federated Learning": {
    "paper_pk": null,
    "title": "Test-Time Robust Personalization for Federated Learning",
    "abstract": "Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalization on FL models additionally adapts the global model to different clients, achieving promising results on consistent local training & test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under the evolving local test set during deployment, where various types of distribution shifts can arise. In this work, we identify the pitfalls of existing works under test-time distribution shifts and propose Federated Test-time Head Ensemble plus tuning (FedTHE+), which personalizes FL models with robustness to various test-time distribution shifts. We illustrate the advancement of FedTHE+ (and its degraded computationally efficient variant FedTHE) over strong competitors, for training various neural architectures (CNN, ResNet, and Transformer) on CIFAR10 and ImageNet and evaluating on diverse test distributions. Along with this, we build a benchmark for assessing the performance and robustness of personalized FL methods during deployment. Code: \\url{https://github.com/LINs-lab/FedTHE}.\n",
    "authors": [
      "Liangze Jiang",
      "Tao Lin"
    ],
    "keywords": [
      "Federated Learning",
      "Personalized Federated Learning",
      "Test-time Robustness"
    ],
    "real_all_scores": [
      6,
      6,
      8
    ],
    "real_confidences": [
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "FADE: Enabling Large-Scale Federated Adversarial Training on Resource-Constrained Edge Devices": {
    "paper_pk": null,
    "title": "FADE: Enabling Large-Scale Federated Adversarial Training on Resource-Constrained Edge Devices",
    "abstract": "Federated adversarial training can effectively complement adversarial robustness into the privacy-preserving federated learning systems. However, the high demand for memory capacity and computing power makes large-scale federated adversarial training infeasible on resource-constrained edge devices. Few previous studies in federated adversarial training have tried to tackle both memory and computational constraints at the same time. In this paper, we propose a new framework named Federated Adversarial Decoupled Learning (FADE) to enable AT on resource-constrained edge devices. FADE decouples the entire model into small modules to fit into the resource budget of each edge device respectively, and each device only needs to perform AT on a single module in each communication round. We also propose an auxiliary weight decay to alleviate objective inconsistency and achieve better accuracy-robustness balance in FADE. FADE offers a theoretical guarantee for convergence and adversarial robustness, and our experimental results show that FADE can significantly reduce the consumption of memory and computing power while maintaining accuracy and robustness.",
    "authors": [
      "Minxue Tang",
      "Jianyi Zhang",
      "Mingyuan Ma",
      "Louis DiValentin",
      "Aolin Ding",
      "Amin Hassanzadeh",
      "Hai Li",
      "Yiran Chen"
    ],
    "keywords": [
      "Federated Learning",
      "Adversarial Training"
    ],
    "real_all_scores": [
      6,
      5,
      3
    ],
    "real_confidences": [
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Adversarial Collaborative Learning on Non-IID Features": {
    "paper_pk": null,
    "title": "Adversarial Collaborative Learning on Non-IID Features",
    "abstract": "Federated Learning (FL) has been a popular approach to enable collaborative learning on multiple parties without exchanging raw data. However, the model performance of FL may degrade a lot due to non-IID data. While many FL algorithms focus on non-IID labels, FL on non-IID features has largely been overlooked. Different from typical FL approaches, the paper proposes a new learning concept called ADCOL (Adversarial Collaborative Learning) for non-IID features. Instead of adopting the widely used model-averaging scheme, ADCOL conducts training in an adversarial way: the server aims to train a discriminator to distinguish the representations of the parties, while the parties aim to generate a common representation distribution. Our experiments on three tasks show that ADCOL achieves better performance than state-of-the-art FL algorithms on non-IID features.",
    "authors": [
      "Qinbin Li",
      "Bingsheng He",
      "Dawn Song"
    ],
    "keywords": [
      "Federated Learning",
      "Collaborative Learning"
    ],
    "real_all_scores": [
      6,
      5,
      6,
      3
    ],
    "real_confidences": [
      4,
      5,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "GAIN: Enhancing Byzantine Robustness in Federated Learning with Gradient Decomposition": {
    "paper_pk": null,
    "title": "GAIN: Enhancing Byzantine Robustness in Federated Learning with Gradient Decomposition",
    "abstract": "Federated learning provides a privacy-aware learning framework by enabling participants to jointly train models without exposing their private data. However, federated learning has exhibited vulnerabilities to Byzantine attacks, where the adversary aims to destroy the convergence and performance of the global model. Meanwhile, we observe that most existing robust AGgregation Rules (AGRs) fail to stop the aggregated gradient deviating from the optimal gradient (the average of honest gradients) in the non-IID setting. We attribute the reason of the failure of these AGRs to two newly proposed concepts: identification failure and integrity failure. The identification failure mainly comes from the exacerbated curse of dimensionality in the non-IID setting. The integrity failure is a combined result of conservative filtering strategy and gradient heterogeneity. In order to address both failures, we propose GAIN, a gradient decomposition scheme that can help adapt existing robust algorithms to heterogeneous datasets. We theoretically show that integrating exisiting robust AGRs into our GAIN can mitigate the deviation of aggregated gradient, thus improve the performance. Experiments on various real-world datasets verify the efficacy of our proposed GAIN",
    "authors": [
      "Yuchen Liu",
      "Chen Chen",
      "Lingjuan Lyu",
      "Fangzhao Wu",
      "Tianlei Hu",
      "Sai Wu",
      "Gang Chen"
    ],
    "keywords": [
      "Federated Learning",
      "Byzantine Robustness."
    ],
    "real_all_scores": [
      3,
      5,
      6
    ],
    "real_confidences": [
      4,
      5,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients": {
    "paper_pk": null,
    "title": "AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients",
    "abstract": "The development and deployment of federated learning (FL) have been bottlenecked by the heavy communication overheads of high-dimensional models between the distributed device nodes and the central server. To achieve better error-communication trade-offs, recent efforts have been made to either adaptively reduce the communication frequency by skipping unimportant updates, a.k.a. lazily-aggregated quantization (LAQ), or adjust the quantization bits for each communication. In this paper, we propose a unifying communication efficient framework for FL based on adaptive quantization of lazily-aggregated gradients (AQUILA), which adaptively adjusts two mutually-dependent factors, the communication frequency, and the quantization level, in a synergistic way. Specifically, we start from a careful investigation of the classical LAQ scheme and formulate AQUILA as an optimization problem where the optimal quantization level per communication is selected by minimizing the model deviation caused by update skipping. Meanwhile, we create a new lazy aggregation strategy to fit the novel quantization criterion better and thus keep the communication frequency at an appropriate level. The effectiveness and convergence of the proposed AQUILA framework are theoretically verified. The experimental results demonstrate that AQUILA can reduce around 60% of overall transmitted bits compared to existing methods while achieving the same level of model accuracy in a number of non-homogeneous FL scenarios, including Non-IID data distribution and heterogeneous model architecture. The proposed AQUILA is highly adaptive and compatible with existing FL settings.",
    "authors": [
      "Zihao Zhao",
      "Yuzhu Mao",
      "Zhenpeng Shi",
      "Muhammad Zeeshan",
      "Yang Liu",
      "Tian Lan",
      "Wenbo Ding"
    ],
    "keywords": [
      "Federated Learning",
      "communication efficiency",
      "adaptive quantization"
    ],
    "real_all_scores": [
      5,
      6,
      5,
      3
    ],
    "real_confidences": [
      4,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Communication Efficient Fair Federated Recommender System": {
    "paper_pk": null,
    "title": "Communication Efficient Fair Federated Recommender System",
    "abstract": "Federated Recommender Systems (FRSs) aim to provide recommendations to clients in a distributed manner with privacy preservation. FRSs suffer from high communication costs due to the communication between the server and many clients. Some past literature on federated supervised learning shows that sampling clients randomly improve communication efficiency without jeopardizing accuracy. However, each user is considered a separate client in FRS and clients communicate only item gradients. Thus, incorporating random sampling and determining the number of clients to be sampled in each communication round to retain the model's accuracy in FRS becomes challenging. This paper provides sample complexity bounds on the number of clients that must be sampled in an FRS to preserve accuracy. Next, we consider the issue of demographic bias in FRS, quantified as the difference in the average error rates across different groups. Supervised learning algorithms mitigate the group bias by adding the fairness constraint in the training loss, which requires sharing protected attributes with the server. This is prohibited in a federated setting to ensure clients' privacy. We design \\ouralgo, a Random Sampling based Fair Federated Recommender System, which trains to achieve a fair global model. In addition, it also trains local clients towards a fair global model to reduce demographic bias at the client level without the need to share their protected attributes. We empirically demonstrate all our results across the two most popular real-world datasets (ML1M, ML100k) and different sensitive features (age and gender) to prove that RS-FairFRS helps reduce communication cost and demographic bias with improved model accuracy.\n",
    "authors": [
      "KIRANDEEP KAUR",
      "Sujit Gujar",
      "Shweta Jain"
    ],
    "keywords": [
      "Federated Learning",
      "Recommender Systems",
      "Bias and Fairness"
    ],
    "real_all_scores": [
      6,
      3,
      5
    ],
    "real_confidences": [
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Data Leakage in Tabular Federated Learning": {
    "paper_pk": null,
    "title": "Data Leakage in Tabular Federated Learning",
    "abstract": "While federated learning (FL) promises to preserve privacy in distributed training of deep learning models, recent work in the image and NLP domains showed that training updates leak private data of participating clients. At the same time, most high-stakes applications of FL (e.g., legal and financial) use tabular data. Compared to the NLP and image domains, reconstruction of tabular data poses several unique challenges: (i) categorical features introduce a significantly more difficult mixed discrete-continuous optimization problem, (ii) the mix of categorical and continuous features causes high variance in the final reconstructions, and (iii) structured data makes it difficult for the adversary to judge reconstruction quality. In this work, we tackle these challenges and propose the first comprehensive reconstruction attack on tabular data, called TabLeak. TabLeak is based on three key ingredients: (i) a softmax structural prior, implicitly converting the mixed discrete-continuous optimization problem into an easier fully continuous one, (ii) a way to reduce the variance of our reconstructions through a pooled ensembling scheme exploiting the structure of tabular data, and (iii) an entropy measure which  can successfully assess reconstruction quality. Our experimental evaluation demonstrates the effectiveness of TabLeak, reaching a state-of-the-art on four popular tabular datasets. For instance, on the Adult dataset, we improve attack accuracy by 10% compared to the baseline on the practically relevant batch size of 32 and further obtain non-trivial reconstructions for batch sizes as large as 128. Our findings are important as they show that performing FL on tabular data, which often poses high privacy risks, is highly vulnerable.",
    "authors": [
      "Mark Vero",
      "Mislav Balunovic",
      "Dimitar Iliev Dimitrov",
      "Martin Vechev"
    ],
    "keywords": [
      "federated learning",
      "tabular data",
      "data leakage attacks",
      "gradient inversion"
    ],
    "real_all_scores": [
      6,
      6,
      6
    ],
    "real_confidences": [
      4,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "DELTA: Diverse Client Sampling for Fasting Federated Learning": {
    "paper_pk": null,
    "title": "DELTA: Diverse Client Sampling for Fasting Federated Learning",
    "abstract": "Partial client participation has been widely adopted in Federated Learning (FL) to efficiently reduce the communication burden. However, an improper client sampling scheme will select unrepresentative subsets, which will cause a large variance in the model update and slows down the convergence. Existing sampling methods are either biased or can be further improved to accelerate the convergence. In this paper, we propose an unbiased sampling scheme, termed DELTA, to alleviate this problem. In particular, DELTA characterizes the impact of client diversity and local variance and samples the representative clients who carry valuable information for global model updates. Moreover, DELTA is a provably optimal unbiased sampling scheme that minimizes the variance caused by partial client participation and achieves better convergence than other unbiased sampling schemes. We corroborate our results with experiments on both synthetic and real data sets.",
    "authors": [
      "Lin Wang",
      "Yongxin Guo",
      "Tao Lin",
      "Xiaoying Tang"
    ],
    "keywords": [
      "federated learning",
      "client sampling"
    ],
    "real_all_scores": [
      6,
      3,
      3,
      3
    ],
    "real_confidences": [
      3,
      4,
      5,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "On the Importance and Applicability of Pre-Training for Federated Learning": {
    "paper_pk": null,
    "title": "On the Importance and Applicability of Pre-Training for Federated Learning",
    "abstract": "Pre-training is prevalent in nowadays deep learning to improve the learned model's performance. However, in the literature on federated learning (FL), neural networks are mostly initialized with random weights. These attract our interest in conducting a systematic study to explore pre-training for FL. Across multiple visual recognition benchmarks, we found that pre-training can not only improve FL, but also close its accuracy gap to the counterpart centralized learning, especially in the challenging cases of non-IID clients' data. To make our findings applicable to situations where pre-trained models are not directly available, we explore pre-training with synthetic data or even with clients' data in a decentralized manner, and found that they can already improve FL notably. Interestingly, many of the techniques we explore are complementary to each other to further boost the performance, and we view this as a critical result toward scaling up deep FL for real-world applications. We conclude our paper with an attempt to understand the effect of pre-training on FL. We found that pre-training enables the learned global models under different clients' data conditions to converge to the same loss basin, and makes global aggregation in FL more stable. Nevertheless, pre-training seems to not alleviate local model drifting, a fundamental problem in FL under non-IID data.",
    "authors": [
      "Hong-You Chen",
      "Cheng-Hao Tu",
      "Ziwei Li",
      "Han Wei Shen",
      "Wei-Lun Chao"
    ],
    "keywords": [
      "federated learning",
      "pre-training"
    ],
    "real_all_scores": [
      3,
      8,
      6,
      5
    ],
    "real_confidences": [
      5,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Learning from Small Datasets": {
    "paper_pk": null,
    "title": "Federated Learning from Small Datasets",
    "abstract": "Federated learning allows multiple parties to collaboratively train a joint model without having to share any local data. It enables applications of machine learning in settings where data is inherently distributed and undisclosable, such as in the medical domain. Joint training is usually achieved by aggregating local models. When local datasets are small, locally trained models can vary greatly from a globally good model. Bad local models can arbitrarily deteriorate the aggregate model quality, causing federating learning to fail in these settings. We propose a novel approach that avoids this problem by interleaving model aggregation and permutation steps. During a permutation step we redistribute local models across clients through the server, while preserving data privacy, to allow each local model to train on a daisy chain of local datasets. This enables successful training in data-sparse domains. Combined with model aggregation, this approach enables effective learning even if the local datasets are extremely small, while retaining the privacy benefits of federated learning.",
    "authors": [
      "Michael Kamp",
      "Jonas Fischer",
      "Jilles Vreeken"
    ],
    "keywords": [
      "federated learning",
      "distributed",
      "sparse data",
      "daisy chain",
      "small datasets"
    ],
    "real_all_scores": [
      1,
      3,
      6,
      6,
      3
    ],
    "real_confidences": [
      4,
      2,
      2,
      3,
      2
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Effective passive membership inference attacks in federated learning against overparameterized models": {
    "paper_pk": null,
    "title": "Effective passive membership inference attacks in federated learning against overparameterized models",
    "abstract": "This work considers the challenge of performing membership inference attacks in a federated learning setting ---for image classification--- where an adversary can only observe the communication between the central node and a single client (a passive white-box attack). Passive attacks are one of the hardest-to-detect attacks, since they can be performed without modifying how the behavior of the central server or its clients, and assumes *no access to private data instances*. The key insight of our method is empirically observing that, near parameters that generalize well in test, the gradient of large overparameterized neural network models statistically behave like high-dimensional independent isotropic random vectors.  Using this insight, we devise two attacks that are often little impacted by existing and proposed defenses. Finally, we validated the hypothesis that our attack depends on the overparametrization by showing that increasing the level of overparametrization (without changing the neural network architecture) positively correlates with our attack effectiveness.",
    "authors": [
      "Jiacheng Li",
      "Ninghui Li",
      "Bruno Ribeiro"
    ],
    "keywords": [
      "membership inference attack",
      "federated learning",
      "overparameterization",
      "neural networks",
      "image classification"
    ],
    "real_all_scores": [
      3,
      8,
      6
    ],
    "real_confidences": [
      4,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Hyperparameter Optimization through Neural Network Partitioning": {
    "paper_pk": null,
    "title": "Hyperparameter Optimization through Neural Network Partitioning",
    "abstract": "Well-tuned hyperparameters are crucial for obtaining good generalization behavior in neural networks. They can enforce appropriate inductive biases, regularize the model and improve performance --- especially in the presence of limited data. In this work, we propose a simple and efficient way for optimizing hyperparameters inspired by the marginal likelihood, an optimization objective that requires no validation data. Our method partitions the training data and a neural network model into $K$ data shards and parameter partitions, respectively. Each partition is associated with and optimized only on specific data shards. Combining these partitions into subnetworks allows us to define the \"out-of-training-sample\" loss of a subnetwork, i.e., the loss on data shards unseen by the subnetwork, as the objective for hyperparameter optimization. We demonstrate that we can apply this objective to optimize a variety of different hyperparameters in a single training run while being significantly computationally cheaper than alternative methods aiming to optimize the marginal likelihood for neural networks. Lastly, we also focus on optimizing hyperparameters in federated learning, where retraining and cross-validation are particularly challenging.",
    "authors": [
      "Bruno Kacper Mlodozeniec",
      "Matthias Reisser",
      "Christos Louizos"
    ],
    "keywords": [
      "Hyperparameter optimization",
      "invariances",
      "data-augmentation",
      "marginal likelihood",
      "federated learning"
    ],
    "real_all_scores": [
      8,
      8,
      6,
      8,
      6
    ],
    "real_confidences": [
      4,
      3,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-25%"
  },
  "Single SMPC Invocation DPHelmet: Differentially Private Distributed Learning on a Large Scale": {
    "paper_pk": null,
    "title": "Single SMPC Invocation DPHelmet: Differentially Private Distributed Learning on a Large Scale",
    "abstract": "Distributing machine learning predictors enables the collection of large-scale datasets while leaving sensitive raw data at trustworthy sites. We introduce a learning technique that is scalable to a large number of users, satisfies Differential Privacy, and is applicable to non-trivial tasks, such as CIFAR-10. For a large number of participants, communication cost is one of the main challenges. We achieve a low communication cost by requiring only a single invocation of an efficient secure multiparty summation protocol. By relying on state-of-the-art feature extractors, we are able to utilize differentially private convex learners for non-trivial tasks such as CIFAR-10. Convex learners have proven to have a strong utility-private tradeoff. Our experimental results show that for $1{,}000$ users with $50$ data points each, our scheme outperforms state-of-the-art scalable distributed learning methods (differentially private federated learning, short DP-FL) while requiring around $500$ times fewer communication costs: For CIFAR-10, we achieve a classification accuracy of $67.3\\,\\%$ for an $\\varepsilon = 0.59$ while DP-FL achieves $57.6\\,\\%$. We also show the learnability properties convergence and uniform stability.",
    "authors": [
      "Moritz Kirschte",
      "Sebastian Meiser",
      "Saman Ardalan",
      "Esfandiar Mohammadi"
    ],
    "keywords": [
      "differential privacy",
      "distributed learning",
      "privacy-preserving machine learning",
      "privacy",
      "federated learning"
    ],
    "real_all_scores": [
      3,
      3,
      3
    ],
    "real_confidences": [
      4,
      5,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization": {
    "paper_pk": null,
    "title": "Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization",
    "abstract": "We propose a federated learning method with weighted nodes in which the weights can be modified to optimize the model\u2019s performance on a separate validation set. The problem is formulated as a bilevel optimization problem where the inner problem is a federated learning problem with weighted nodes and the outer problem focuses on optimizing the weights based on the validation performance of the model returned from the inner problem. A communication-efficient federated optimization algorithm is designed to solve this bilevel optimization problem. We analyze the generalization performance of the output model and identify the scenarios when our method is in theory superior to training a model locally and superior to federated learning with static and evenly distributed weights. ",
    "authors": [
      "Yankun Huang",
      "Qihang Lin",
      "Nick Street",
      "Stephen Baek"
    ],
    "keywords": [
      "federated learning",
      "bilevel optimization",
      "distributed optimization",
      "generalization performance"
    ],
    "real_all_scores": [
      3,
      5,
      1,
      3
    ],
    "real_confidences": [
      4,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data": {
    "paper_pk": null,
    "title": "EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data",
    "abstract": " Gradient clipping is an important technique for deep neural networks with exploding gradients, such as recurrent neural networks. Recent studies have shown that the loss functions of these networks do not satisfy the conventional smoothness condition, but instead satisfy a relaxed smoothness condition, i.e., the Lipschitz constant of the gradient scales linearly in terms of the gradient norm. Due to this observation, several gradient clipping algorithms have been developed for nonconvex and relaxed-smooth functions. However, the existing algorithms only apply to the single-machine or multiple-machine setting with homogeneous data across machines. It remains unclear how to design provably efficient gradient clipping algorithms in the general Federated Learning (FL) setting with heterogeneous data and limited communication rounds. In this paper, we design EPISODE, the very first algorithm to solve FL problems with heterogeneous data in the nonconvex and relaxed smoothness setting. The key ingredients of the algorithm are two new techniques called \\textit{episodic gradient clipping} and \\textit{periodic resampled corrections}. At the beginning of each round, EPISODE resamples stochastic gradients from each client and obtains the global averaged gradient, which is used to (1) determine whether to apply gradient clipping for the entire round and (2) construct local gradient corrections for each client. Notably, our algorithm and analysis provide a unified framework for both homogeneous and heterogeneous data under any noise level of the stochastic gradient, and it achieves state-of-the-art complexity results. In particular, we prove that EPISODE can achieve linear speedup in the number of machines, and it requires significantly fewer communication rounds. Experiments on several heterogeneous datasets, including text classification and image classification, show the superior performance of EPISODE over several strong baselines in FL. The code is available at https://github.com/MingruiLiu-ML-Lab/episode.",
    "authors": [
      "Michael Crawshaw",
      "Yajie Bao",
      "Mingrui Liu"
    ],
    "keywords": [
      "Non-convex optimization",
      "federated learning",
      "heterogeneous data",
      "gradient clipping",
      "relaxed smoothness"
    ],
    "real_all_scores": [
      6,
      3,
      3,
      3
    ],
    "real_confidences": [
      4,
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Towards Federated Learning of Deep Graph Neural Networks": {
    "paper_pk": null,
    "title": "Towards Federated Learning of Deep Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) learn node representations by recursively aggregating neighborhood information on graph data. However, in the federated setting, data samples (nodes) located in different clients may be connected to each other, leading to huge information loss to the training method.\nExisting federated graph learning frameworks solve such a problem by generating missing neighbors or sending information across clients directly. None are suitable for training deep GNNs, which require a more expansive receptive field and higher communication costs.\nIn this work, we introduce a novel framework named  $Fed^2GNN$ for federated graph learning of deep GNNs via reconstructing neighborhood information of nodes. Specifically, we design a graph structure named rooted tree. The node embedding obtained by encoding on the rooted tree is the same as that obtained by encoding on the induced subgraph surrounding the node, which allows us to reconstruct the neighborhood information by building the rooted tree of the node. An encoder-decoder framework is then proposed, wherein we first encode missing neighbor information and then decode it to build the rooted tree.\nExtensive experiments on real-world network datasets show the effectiveness of our framework for training deep GNNs while also achieving better performance for training shadow GNN models",
    "authors": [
      "Zhihua Tian",
      "Yuan Ding",
      "Rui Zhang",
      "Jian Liu",
      "Kui Ren"
    ],
    "keywords": [
      "federated learning",
      "graph representation learning",
      "deep graph neural networks"
    ],
    "real_all_scores": [
      5,
      8,
      6,
      3
    ],
    "real_confidences": [
      3,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach": {
    "paper_pk": null,
    "title": "Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach",
    "abstract": "The canonical formulation of federated learning treats it as a distributed optimization problem where the model parameters are optimized against a global loss function that decomposes across client loss functions. A recent alternative formulation instead treats federated learning as a distributed inference problem, where the goal is to infer a global posterior from partitioned client data (Al-Shedivat et al., 2021). This paper extends the inference view and describes a variational inference formulation of federated learning where the goal is to find a global variational posterior that well-approximates the true posterior. This naturally motivates an expectation propagation approach to federated learning (FedEP), where approximations to the global posterior are iteratively refined through probabilistic message-passing between the central server and the clients. We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting. We apply FedEP on standard federated learning benchmarks and find that it outperforms strong baselines in terms of both convergence speed and accuracy.",
    "authors": [
      "Han Guo",
      "Philip Greengard",
      "Hongyi Wang",
      "Andrew Gelman",
      "Yoon Kim",
      "Eric Xing"
    ],
    "keywords": [
      "federated learning",
      "variational inference",
      "expectation propagation"
    ],
    "real_all_scores": [
      3,
      3,
      5,
      3
    ],
    "real_confidences": [
      4,
      5,
      3,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedProp: Cross-client Label Propagation for Federated Semi-supervised Learning": {
    "paper_pk": null,
    "title": "FedProp: Cross-client Label Propagation for Federated Semi-supervised Learning",
    "abstract": "Federated learning (FL) allows multiple clients to jointly train a machine learning model in such a way that no client has to share their data with any other participating party. In the supervised setting, where all client data is fully labeled, FL has been widely adopted for learning tasks that require data privacy. However, it is an ongoing research question how to best perform federated learning in a semi-supervised setting, where the clients possess data that is only partially labeled or even completely unlabeled. In this work, we propose a new method, FedProp, that follows a manifold-based approach to semi-supervised learning (SSL). It estimates the data manifold jointly from the data of multiple clients and computes pseudo-labels using cross-client label propagation. To avoid that clients have to share their data with anyone, FedProp employs two cryptographically secure yet highly efficient protocols: multi-party Hamming distance computation and secure aggregation. Experiments on three standard benchmarks show that FedProp achieves higher classification accuracy than previous federated SSL methods. Furthermore, as a pseudo-label-based technique, FedProp is complementary to other federated SSL approaches, in particular consistency-based ones. We demonstrate experimentally that further accuracy gains are possible by combining both.",
    "authors": [
      "Jonathan Scott",
      "Michelle Yeo",
      "Christoph H Lampert"
    ],
    "keywords": [
      "federated learning",
      "semi-supervised learning",
      "label propagation",
      "cryptographically secure computation"
    ],
    "real_all_scores": [
      6,
      6,
      6
    ],
    "real_confidences": [
      3,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter Optimization": {
    "paper_pk": null,
    "title": "FedHPO-Bench: A Benchmark Suite for Federated Hyperparameter Optimization",
    "abstract": "Hyperparameter optimization (HPO) is crucial for machine learning algorithms to achieve satisfactory performance. Its research progress has been boosted by existing HPO benchmarks. Nonetheless, existing efforts in benchmarking all focus on HPO for traditional centralized learning while ignoring federated learning (FL), a promising paradigm for collaboratively learning models from dispersed data. In this paper, we first identify some uniqueness of HPO for FL algorithms from various aspects. Due to this uniqueness, existing HPO benchmarks no longer satisfy the need to compare HPO methods in the FL setting. To facilitate the research of HPO in the FL setting, we propose and implement a benchmark suite FedHPO-Bench that incorporates comprehensive FedHPO problems, enables flexible customization of the function evaluations, and eases continuing extensions. We also conduct extensive experiments based on FedHPO-Bench to provide the community with more insights into FedHPO. We open-sourced FedHPO-Bench at https://github.com/FedHPO-Bench/FedHPO-Bench-ICLR23.",
    "authors": [
      "Zhen WANG",
      "Weirui Kuang",
      "Ce Zhang",
      "Bolin Ding",
      "Yaliang Li"
    ],
    "keywords": [
      "federated learning",
      "hyperparameter optimization"
    ],
    "real_all_scores": [
      5,
      6,
      5,
      3
    ],
    "real_confidences": [
      3,
      4,
      5,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Weakly-Supervised Domain Adaptation in Federated Learning": {
    "paper_pk": null,
    "title": "Weakly-Supervised Domain Adaptation in Federated Learning",
    "abstract": "Federated domain adaptation (FDA) describes the setting where a set of source clients seek to optimize the performance of a target client. To be effective, FDA must address some of the distributional challenges of Federated learning (FL). For instance, FL systems exhibit distribution shifts across clients. Further, labeled data are not always available among the clients. To this end, we propose and compare novel approaches for FDA, combining the few labeled target samples with the source data when auxiliary labels are available to the clients. The in-distribution auxiliary information is included during local training to boost out-of-domain accuracy. Also, during fine-tuning, we devise a simple yet efficient gradient projection method to detect the valuable components from each source client model towards the target direction. The extensive experiments on medical imaging datasets show that our proposed framework significantly improves federated domain adaptation performance.",
    "authors": [
      "Enyi Jiang",
      "Oluwasanmi O Koyejo"
    ],
    "keywords": [
      "federated learning",
      "domain adaptation",
      "healthcare"
    ],
    "real_all_scores": [
      3,
      6,
      3
    ],
    "real_confidences": [
      3,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Machine Unlearning of Federated Clusters": {
    "paper_pk": null,
    "title": "Machine Unlearning of Federated Clusters",
    "abstract": "Federated clustering (FC) is an unsupervised learning problem that arises in a number of practical applications, including personalized recommender and healthcare systems. With the adoption of recent laws ensuring the \"right to be forgotten\", the problem of machine unlearning for FC methods has become of significant importance. We introduce, for the first time, the problem of machine unlearning for FC, and propose an efficient unlearning mechanism for a customized secure FC framework. Our FC framework utilizes special initialization procedures that we show are well-suited for unlearning. To protect client data privacy, we develop the secure compressed multiset aggregation (SCMA) framework that addresses sparse secure federated learning (FL) problems encountered during clustering as well as more general problems. To simultaneously facilitate low communication complexity and secret sharing protocols, we integrate Reed-Solomon encoding with special evaluation points into our SCMA pipeline, and prove that the client communication cost is logarithmic in the vector dimension. Additionally, to demonstrate the benefits of our unlearning mechanism over complete retraining, we provide a theoretical analysis for the unlearning performance of our approach. Simulation results show that the new FC framework exhibits superior clustering performance compared to previously reported FC baselines when the cluster sizes are highly imbalanced. Compared to completely retraining K-means++ locally and globally for each removal request, our unlearning procedure offers an average speed-up of roughly 84x across seven datasets. Our implementation for the proposed method is available at https://github.com/thupchnsky/mufc.",
    "authors": [
      "Chao Pan",
      "Jin Sima",
      "Saurav Prakash",
      "Vishal Rana",
      "Olgica Milenkovic"
    ],
    "keywords": [
      "federated learning",
      "federated clustering",
      "machine unlearning",
      "secure aggregation"
    ],
    "real_all_scores": [
      6,
      6,
      3
    ],
    "real_confidences": [
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Dual personalization for federated recommendation on devices": {
    "paper_pk": null,
    "title": "Dual personalization for federated recommendation on devices",
    "abstract": "Federated recommendation is a new Internet service architecture that aims to provide privacy-preserving recommendation services in federated settings. Existing solutions are used to combine distributed recommendation algorithms and privacy-preserving mechanisms. Thus it inherently takes the form of heavyweight models at the server and hinders the deployment of on-device intelligent models to end-users. This paper proposes a novel Personalized Federated Recommendation (PFedRec) framework to learn many user-specific lightweight models to be deployed on smart devices rather than a heavyweight model on a server. Moreover, we propose a new dual personalization mechanism to effectively learn fine-grained personalization on both users and items. The overall learning process is formulated into a unified federated optimization framework. Specifically, unlike previous methods that share exactly the same item embeddings across users in a federated system, dual personalization allows mild finetuning of item embeddings for each user to generate user-specific views for item representations which can be integrated into existing federated recommendation methods to gain improvements immediately. Experiments on multiple benchmark datasets have demonstrated the effectiveness of PFedRec and the dual personalization mechanism. Moreover, we provide visualizations and in-depth analysis of the personalization techniques in item embedding, which shed novel insights on the design of RecSys in federated settings.",
    "authors": [
      "Chunxu Zhang",
      "Guodong Long",
      "Tianyi Zhou",
      "Zijian Zhang",
      "Bo Yang"
    ],
    "keywords": [
      "federated learning",
      "personalization",
      "recommmendation system"
    ],
    "real_all_scores": [
      8,
      6,
      8
    ],
    "real_confidences": [
      5,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Precision Collaboration for Federated Learning": {
    "paper_pk": null,
    "title": "Precision Collaboration for Federated Learning",
    "abstract": "Inherent heterogeneity of local data distributions, which causes inefficient model learning and significant degradation of model performance, has been a key challenge in Federated Learning (FL). So far, plenty of efforts have focused on addressing data heterogeneity by relying on a hypothetical clustering structure or a consistent information sharing mechanism. However, because of the diversity of the real-world local data, these assumptions may be largely violated. In this work, we argue that information sharing is mostly fragmented in the federated network in reality. More specifically, the distribution overlaps are not consistent but scattered in local clients. In this work, we propose the concept ``Precision Collaboration'' which refers to learning from the informative overlaps precisely while avoiding the potential negative transfer induced by others. In particular, we propose to infer the local data manifolds and estimate the exact local data density simultaneously. The learned manifold aims to precisely identify the overlaps from other clients, and the estimated likelihood allows to generate samples from the manifold in an optimal sampling density. Experiments show that our proposed PCFL significantly overcomes baselines on benchmarks and a real-world clinical scenario.",
    "authors": [
      "Sen Cui",
      "Abudukelimu Wuerkaixi",
      "Jian Liang",
      "Weishen Pan",
      "Jianwei Zhang",
      "Changshui Zhang",
      "Fei Wang"
    ],
    "keywords": [
      "federated learning",
      "personalized federated learning"
    ],
    "real_all_scores": [
      3,
      8,
      3
    ],
    "real_confidences": [
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Trusted Aggregation (TAG): Model Filtering Backdoor Defense In Federated Learning": {
    "paper_pk": null,
    "title": "Trusted Aggregation (TAG): Model Filtering Backdoor Defense In Federated Learning",
    "abstract": "Federated Learning is a framework for training machine learning models from multiple local data sets without access to the data in aggregate. A shared model is jointly learned through an interactive process between server and clients that combines locally learned model gradients or weights. However, the lack of data transparency naturally raises concerns about model security. Recently, several state-of-the-art backdoor attacks have been proposed, which achieve high attack success rates while simultaneously being difficult to detect, leading to compromised federated learning models. In this paper, motivated by differences in the output layer distribution between models trained with and without the presence of backdoor attacks, we propose a defense method that can prevent backdoor attacks from influencing the model while maintaining the accuracy of the original classification task. TAG leverages a small validation data set to estimate the largest change that a benign user's local training can make to the output layer of the shared model, which can be used as a cutoff for returning user models. Experimental results on multiple data sets show that TAG defends against backdoor attacks even when 40\\% of the user submissions to update the shared model are malicious.",
    "authors": [
      "Joseph Lavond",
      "Minhao Cheng",
      "Yao Li"
    ],
    "keywords": [
      "federated learning",
      "backdoor attack",
      "robust aggregation"
    ],
    "real_all_scores": [
      8,
      8,
      8,
      8
    ],
    "real_confidences": [
      4,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-25%"
  },
  "Faster federated optimization under second-order similarity": {
    "paper_pk": null,
    "title": "Faster federated optimization under second-order similarity",
    "abstract": "Federated learning (FL) is a subfield of machine learning where multiple clients try to collaboratively learn a model over a network under communication constraints. We consider finite-sum federated optimization under a second-order function similarity condition and strong convexity, and propose two new algorithms: SVRP and Catalyzed SVRP. This second-order similarity condition has grown popular recently, and is satisfied in many applications including distributed statistical learning and differentially private empirical risk minimization. The first algorithm, SVRP, combines approximate stochastic proximal point evaluations, client sampling, and variance reduction. We show that SVRP is communication efficient and achieves superior performance to many existing algorithms when function similarity is high enough. Our second algorithm, Catalyzed SVRP, is a Catalyst-accelerated variant of SVRP that achieves even better performance and uniformly improves upon existing algorithms for federated optimization under second-order similarity and strong convexity. In the course of analyzing these algorithms, we provide a new analysis of the Stochastic Proximal Point Method (SPPM) that might be of independent interest. Our analysis of SPPM is simple, allows for approximate proximal point evaluations, does not require any smoothness assumptions, and shows a clear benefit in communication complexity over ordinary distributed stochastic gradient descent.",
    "authors": [
      "Ahmed Khaled",
      "Chi Jin"
    ],
    "keywords": [
      "federated learning",
      "distributed optimization",
      "hessian similarity",
      "client sampling",
      "stochastic proximal point",
      "proximal point method",
      "distributed learning"
    ],
    "real_all_scores": [
      3,
      5,
      5,
      8
    ],
    "real_confidences": [
      4,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Mixed Federated Learning: Joint Decentralized and Centralized Learning": {
    "paper_pk": null,
    "title": "Mixed Federated Learning: Joint Decentralized and Centralized Learning",
    "abstract": "Federated learning (FL) enables learning from decentralized privacy-sensitive data, with computations on raw data confined to take place at edge clients.  This paper introduces mixed FL, which incorporates an additional loss term calculated at the coordinating server (while maintaining FL\u2019s private data restrictions). For example, additional datacenter data can be leveraged to jointly learn from centralized (datacenter) and decentralized (federated) training data and better match an expected inference data distribution.Mixed FL also enables offloading some intensive computations (e.g., embedding regularization) to the server, greatly reducing communication and client computation load.  For these and other mixed FL use cases, we present three algorithms: PARALLEL TRAINING, 1-WAY GRADIENT TRANSFER, and 2-WAY GRADIENT TRANSFER.  We perform extensive experiments of the algorithms on three tasks, demonstrating that mixed FL can blend training data to achieve an oracle\u2019s accuracy on an inference distribution, and can reduce communication and computation overhead by more than 90%. Finally, we state convergence bounds for all algorithms, and give intuition on the mixed FL problems best suited to each. The theory confirms our empirical observations of how the algorithms perform under different mixed FL problem settings.",
    "authors": [
      "Sean Augenstein",
      "Andrew Hard",
      "Lin Ning",
      "Karan Singhal",
      "Satyen Kale",
      "Kurt Partridge",
      "Rajiv Mathews"
    ],
    "keywords": [
      "federated learning",
      "decentralized learning",
      "privacy",
      "security",
      "distribution shift",
      "distribution skew",
      "mobile computing"
    ],
    "real_all_scores": [
      3,
      3,
      1,
      1
    ],
    "real_confidences": [
      3,
      1,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "On Convergence of Federated Averaging Langevin Dynamics": {
    "paper_pk": null,
    "title": "On Convergence of Federated Averaging Langevin Dynamics",
    "abstract": "We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty quantification and mean predictions with distributed clients. In particular, we generalize beyond normal posterior distributions and consider a general class of models. We develop theoretical guarantees for FA-LD for strongly log-concave distributions with non-i.i.d data and study how the injected noise and the stochastic-gradient noise, the heterogeneity of data, and the varying learning rates affect the convergence. Such an analysis sheds light on the optimal choice of local updates to minimize communication cost. Important to our approach is that the communication efficiency does not deteriorate with the injected noise in the Langevin algorithms. In addition, we examine in our FA-LD algorithm both independent and correlated noise used over different clients. We observe there is a trade-off between the pairs among communication, accuracy, and data privacy. As local devices may become inactive in federated networks, we also show convergence results based on different averaging schemes where only partial device updates are available. In such a case, we discover an additional bias that does not decay to zero.",
    "authors": [
      "Wei Deng",
      "Qian Zhang",
      "Yian Ma",
      "Zhao Song",
      "Guang Lin"
    ],
    "keywords": [
      "Langevin dynamics",
      "federated learning",
      "posterior inference",
      "MCMC",
      "stochastic gradient Langevin dynamics",
      "differential privacy"
    ],
    "real_all_scores": [
      5,
      3,
      5
    ],
    "real_confidences": [
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "FOCUS: Fairness via Agent-Awareness for Federated Learning on Heterogeneous Data": {
    "paper_pk": null,
    "title": "FOCUS: Fairness via Agent-Awareness for Federated Learning on Heterogeneous Data",
    "abstract": "Federated learning (FL) provides an effective collaborative training paradigm, allowing local agents to train a global model jointly without sharing their local data to protect privacy.\nOn the other hand, due to the heterogeneous nature of local agents, it is challenging to optimize or even define the fairness for agents, which may discourage valuable participation. For instance, the trained global model may sacrifice the performance of a minority user with high-quality data based on loss optimization over all users.\nExisting work usually considers accuracy equity as fairness for different users in FL, which is limited especially under the heterogeneous setting, since it is intuitively \"unfair\" that agents with low-quality data would achieve similar accuracy.\nIn this work, we aim to address such limitations and propose a formal fairness definition in FL, fairness via agent-awareness (FAA), which takes the heterogeneous data contributions of local agents into account. In addition, we propose a fair FL training algorithm based on agent clustering (FOCUS) to achieve FAA. Theoretically, we prove the convergence and optimality of  FOCUS under mild conditions for linear and general convex loss functions with bounded smoothness. We also prove that FOCUS always achieves higher fairness measured by FAA compared with standard FedAvg protocol under both linear and general convex loss functions. Empirically, we evaluate FOCUS on four datasets, including synthetic data, images, and texts under different settings, and we show that FOCUS achieves significantly higher fairness based on FAA while maintaining similar or even higher prediction accuracy compared with FedAvg and other existing fair FL algorithms.\n",
    "authors": [
      "Wenda Chu",
      "Chulin Xie",
      "Boxin Wang",
      "Linyi Li",
      "Lang Yin",
      "Han Zhao",
      "Bo Li"
    ],
    "keywords": [
      "federated learning",
      "fairness",
      "data heterogeneity",
      "clustering",
      "expectation\u2013maximization (EM)"
    ],
    "real_all_scores": [
      3,
      5,
      3,
      5
    ],
    "real_confidences": [
      4,
      4,
      5,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedFA:  Federated Feature Augmentation": {
    "paper_pk": null,
    "title": "FedFA:  Federated Feature Augmentation",
    "abstract": "Federated learning is a distributed paradigm that allows multiple parties to collaboratively train deep models without exchanging the raw data. However, the data distribution among clients is naturally non-i.i.d., which leads to severe degradation of the learnt model. The primary goal of this paper is to develop a robust federated learning algorithm to address feature shift in clients\u2019 samples, which can be caused by various factors, e.g., acquisition differences in medical imaging. To reach this goal, we propose FedFA to tackle federated learning from a dis- tinct perspective of federated feature augmentation. FedFA is based on a major insight that each client\u2019s data distribution can be characterized by statistics (i.e., mean and standard deviation) of latent features; and it is likely to manipulate these local statistics globally, i.e., based on information in the entire federation, to let clients have a better sense of the underlying distribution and therefore alleviate local data bias. Based on this insight, we propose to augment each local feature statistic probabilistically based on a normal distribution, whose mean is the original statistic and variance quantifies the augmentation scope. Key to our approach is the determination of a meaningful Gaussian variance, which is accomplished by taking into account not only biased data of each individual client, but also underlying feature statistics characterized by all participating clients. We offer both theoretical and empirical justifications to verify the effectiveness of FedFA. Our code is available at https://github.com/tfzhou/FedFA.\n\t",
    "authors": [
      "Tianfei Zhou",
      "Ender Konukoglu"
    ],
    "keywords": [
      "federated learning",
      "feature augmentation"
    ],
    "real_all_scores": [
      6,
      8,
      3,
      5
    ],
    "real_confidences": [
      5,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Federated Training of Dual Encoding Models on Small Non-IID Client Datasets": {
    "paper_pk": null,
    "title": "Federated Training of Dual Encoding Models on Small Non-IID Client Datasets",
    "abstract": "Dual encoding models that encode a pair of inputs are widely used for representation learning. Many approaches train dual encoding models by maximizing agreement between pairs of encodings on centralized training data. However, in many scenarios, datasets are inherently decentralized across many clients (user devices or organizations) due to privacy concerns, motivating federated learning. In this work, we focus on federated training of dual encoding models on decentralized data composed of many small, non-IID (independent and identically distributed) client datasets. We show that existing approaches that work well in centralized settings perform poorly when naively adapted to this setting using federated averaging. We observe that, we can simulate large-batch loss computation on individual clients for loss functions that are based on encoding statistics. Based on this insight, we propose a novel federated training approach, Distributed Cross Correlation Optimization (DCCO), which trains dual encoding models using encoding statistics aggregated across clients, without sharing individual data samples. Our experimental results on two datasets demonstrate that the proposed DCCO approach outperforms federated variants of existing approaches by a large margin.",
    "authors": [
      "Raviteja Vemulapalli",
      "Warren Richard Morningstar",
      "Philip Andrew Mansfield",
      "Hubert Eichner",
      "Karan Singhal",
      "Arash Afkanpour",
      "Bradley Green"
    ],
    "keywords": [
      "dual encoding models",
      "federated learning",
      "representation learning",
      "self-supervised learning",
      "federated self-supervised learning"
    ],
    "real_all_scores": [
      3,
      5,
      5,
      5
    ],
    "real_confidences": [
      3,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning": {
    "paper_pk": null,
    "title": "When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning",
    "abstract": "Federated Learning has become a widely-used framework which allows learning a global model on decentralized local datasets under the condition of protecting local data privacy. However, federated learning faces severe optimization difficulty when training samples are not independently and identically distributed (non-i.i.d.). In this paper, we point out that the client sampling practice plays a decisive role in the aforementioned optimization difficulty. We find that the negative client sampling will cause the merged data distribution of currently sampled clients heavily inconsistent with that of all available clients, and further make the aggregated gradient unreliable. To address this issue, we propose a novel learning rate adaptation mechanism to adaptively adjust the server learning rate for the aggregated gradient in each round, according to the consistency between the merged data distribution of currently sampled clients and that of all available clients. Specifically, we make theoretical deductions to find a meaningful and robust indicator that is positively related to the optimal server learning rate and can effectively reflect the merged data distribution of sampled clients, and we utilize it for the server learning rate adaptation. Extensive experiments on multiple image and text classification tasks validate the great effectiveness of our method.",
    "authors": [
      "Wenkai Yang",
      "Yankai Lin",
      "Guangxiang Zhao",
      "Peng Li",
      "Jie Zhou",
      "Xu Sun"
    ],
    "keywords": [
      "federated learning",
      "client sampling"
    ],
    "real_all_scores": [
      6,
      5,
      6,
      3
    ],
    "real_confidences": [
      3,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection": {
    "paper_pk": null,
    "title": "Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection",
    "abstract": "Deep neural networks have witnessed huge successes in many challenging prediction tasks and yet they often suffer from out-of-distribution (OoD) samples, misclassifying them with high confidence. Recent advances show promising OoD detection performance for centralized training, and however, OoD detection in federated learning (FL) is largely overlooked, even though many security sensitive applications such as autonomous driving and voice recognition authorization are commonly trained using FL for data privacy concerns. The main challenge that prevents previous state-of-the-art OoD detection methods from being incorporated to FL is that they require large amount of real OoD samples. However, in real-world scenarios, such large-scale OoD training data can be costly or even infeasible to obtain, especially for resource-limited local devices. On the other hand, a notorious challenge in FL is data heterogeneity where each client collects non-identically and independently distributed (non-iid) data. We propose to take advantage of such heterogeneity and turn the curse into a blessing that facilitates OoD detection in FL. The key is that for each client, non-iid data from other clients (unseen external classes) can serve as an alternative to real OoD samples. Specifically, we propose a novel Federated Out-of-Distribution Synthesizer (FOSTER), which learns a class-conditional generator to synthesize virtual external-class OoD samples, and maintains data confidentiality and communication efficiency required by FL. Experimental results show that our method outperforms the state-of-the-art by 2.49%, 2.88%, 1.42% AUROC, and 0.01%, 0.89%, 1.74% ID accuracy, on CIFAR-10, CIFAR-100, and STL10, respectively.",
    "authors": [
      "Shuyang Yu",
      "Junyuan Hong",
      "Haotao Wang",
      "Zhangyang Wang",
      "Jiayu Zhou"
    ],
    "keywords": [
      "out-of-distribution detection",
      "federated learning",
      "heterogeneity"
    ],
    "real_all_scores": [
      3,
      5,
      5,
      5
    ],
    "real_confidences": [
      3,
      3,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning": {
    "paper_pk": null,
    "title": "Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning",
    "abstract": "Multi-Agent Reinforcement Learning currently focuses on implementations where all data and training can be centralized to one machine. But what if local agents are split across multiple tasks, and need to keep data private between each? We develop the first application of Personalized Federated Hypernetworks (PFH) to Reinforcement Learning (RL). We then present a novel application of PFH to few-shot transfer, and demonstrate significant initial increases in learning. PFH has never been demonstrated beyond supervised learning benchmarks, so we apply PFH to an important domain: RL price-setting for energy demand response. We consider a general case across where agents are split across multiple microgrids, wherein energy consumption data must be kept private within each microgrid. Together, our work explores how the fields of personalized federated learning and RL can come together to make learning efficient across multiple tasks while keeping data secure.",
    "authors": [
      "Doseok Jang",
      "Larry Yan",
      "Lucas Spangher",
      "Selvaprabu Nadarajah",
      "Costas Spanos"
    ],
    "keywords": [
      "microgrid clusters",
      "energy demand response",
      "transactive energy control",
      "neural networks",
      "multi-agent reinforcement learning",
      "reinforcement learning",
      "multi-task learning",
      "transfer learning",
      "hypernetworks",
      "federated learning",
      "personalized federated learning",
      "microgrids"
    ],
    "real_all_scores": [
      5,
      5,
      3
    ],
    "real_confidences": [
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Better Generative Replay for Continual Federated Learning": {
    "paper_pk": null,
    "title": "Better Generative Replay for Continual Federated Learning",
    "abstract": "Federated Learning (FL) aims to develop a centralized server that learns from distributed clients via communications without accessing the clients\u2019 local data. However, existing works mainly focus on federated learning in a single task sce- nario with static data. In this paper, we introduce the continual federated learning (CFL) problem, where clients incrementally learn new tasks and history data can- not be stored due to certain reasons, such as limited storage and data retention policy 1. Generative replay (GR) based methods are effective for continual learning without storing history data. However, we fail when trying to intuitively adapt GR models for this setting. By analyzing the behaviors of clients during training, we find the unstable training process caused by distributed training on non-IID data leads to a notable performance degradation. To address this problem, we propose our FedCIL model with two simple but effective solutions: 1. model consolidation and 2. consistency enforcement. Experimental results on multiple benchmark datasets demonstrate that our method significantly outperforms baselines. Code is available at: https://github.com/daiqing98/FedCIL.",
    "authors": [
      "Daiqing Qi",
      "Handong Zhao",
      "Sheng Li"
    ],
    "keywords": [
      "federated learning",
      "continual learning"
    ],
    "real_all_scores": [
      1,
      3,
      5,
      3
    ],
    "real_confidences": [
      5,
      4,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FedDAR: Federated Domain-Aware Representation Learning": {
    "paper_pk": null,
    "title": "FedDAR: Federated Domain-Aware Representation Learning",
    "abstract": "Cross-silo Federated learning (FL) has become a promising tool in machine learning applications for healthcare. It allows hospitals/institutions to train models with sufficient data while the data is kept private. To make sure the FL model is robust when facing heterogeneous data among FL clients, most efforts focus on personalizing models for clients. However, the latent relationships between clients' data are ignored. In this work, we focus on a special non-iid FL problem, called Domain-mixed FL, where each client's data distribution is assumed to be a mixture of several predefined domains.  Recognizing the diversity of domains and the similarity within domains, we propose a novel method, FedDAR, which learns a domain shared representation and domain-wise personalized prediction heads in a decoupled manner. For simplified linear regression settings, we have theoretically proved that FedDAR enjoys a linear convergence rate.  For general settings, we have performed intensive empirical studies on both synthetic and real-world medical datasets which demonstrate its superiority over prior FL methods. Our code is available at https://github.com/zlz0414/FedDAR.     ",
    "authors": [
      "Aoxiao Zhong",
      "Hao He",
      "Zhaolin Ren",
      "Na Li",
      "Quanzheng Li"
    ],
    "keywords": [
      "federated learning",
      "healthcare",
      "fairness",
      "personalization"
    ],
    "real_all_scores": [
      8,
      10,
      8
    ],
    "real_confidences": [
      3,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-5%"
  },
  "Enhance Local Consistency for Free: A Multi-Step Inertial Momentum Approach": {
    "paper_pk": null,
    "title": "Enhance Local Consistency for Free: A Multi-Step Inertial Momentum Approach",
    "abstract": "Federated learning (FL), as a collaborative distributed training paradigm with several edge computing devices under the coordination of a centralized server, is plagued by inconsistent local stationary points due to the heterogeneity of the local partial participation clients, which precipitates the local client-drifts problems and sparks off the unstable and slow convergence, especially on the aggravated heterogeneous dataset. To address these issues, we propose a novel federated learning algorithm, named FedMIM, which adopts the multi-step inertial momentum on the edge devices and enhances the local consistency for free during the training to improve the robustness of the heterogeneity. Specifically, we incorporate the weighted global gradient estimations as the inertial correction terms to guide both the local iterates and stochastic gradient estimation, which can reckon the global objective optimization on the edges' heterogeneous dataset naturally and maintain the demanding consistent iteration locally.   Theoretically, we show that FedMIM achieves the $\\mathcal{O}\\big({1}/{\\sqrt{SKT}}\\big)$ convergence rate with a linear speedup property with respect to the number of selected clients $S$ and proper local interval $K$ in each communication round under the nonconvex setting. Empirically, we conduct comprehensive experiments on various real-world datasets and demonstrate the efficacy of the proposed FedMIM against several state-of-the-art baselines.",
    "authors": [
      "Yixing Liu",
      "Yan Sun",
      "Li Shen",
      "Baoyuan Wu",
      "Zhengtao Ding",
      "Dacheng Tao"
    ],
    "keywords": [
      "federated learning",
      "optimization"
    ],
    "real_all_scores": [
      3,
      6,
      5
    ],
    "real_confidences": [
      3,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "A New Paradigm for Federated Structure Non-IID Subgraph Learning": {
    "paper_pk": null,
    "title": "A New Paradigm for Federated Structure Non-IID Subgraph Learning",
    "abstract": "Federated graph learning (FGL), a distributed training framework for graph neural networks (GNNs) has attracted much attention for breaking the centralized machine learning assumptions. Despite its effectiveness, the differences in data collection perspectives and quality lead to the challenges of heterogeneity, especially the domain-specific graph is partitioned into subgraphs in different institutions. However, existing FGL methods implement graph data augmentation or personalization with community split which follows the cluster homogeneity assumptions. Hence we investigate the above issues and suggest that subgraph heterogeneity is essentially the structure variations. From the observations on FGL, we first define the structure non-independent identical distribution (Non-IID) problem, which presents covariant shift challenges among client-wise subgraphs. Meanwhile, we propose a new paradigm for general federated data settings called Adaptive Federated Graph Learning (AdaFGL). The motivation behind it is to implement adaptive propagation mechanisms based on federated global knowledge and non-params label propagation. We conduct extensive experiments with community split and structure Non-IID settings, our approach achieves state-of-the-art performance on five benchmark datasets.",
    "authors": [
      "Xunkai Li",
      "Wentao Zhang",
      "Rong-Hua Li",
      "Yulin Zhao",
      "Yinlin Zhu",
      "Guoren Wang"
    ],
    "keywords": [
      "graph neural network",
      "federated learning",
      "structure non-iid subgraphs"
    ],
    "real_all_scores": [
      1,
      5,
      3
    ],
    "real_confidences": [
      5,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "FedSpeed: Larger Local Interval, Less Communication Round, and Higher Generalization Accuracy": {
    "paper_pk": null,
    "title": "FedSpeed: Larger Local Interval, Less Communication Round, and Higher Generalization Accuracy",
    "abstract": "Federated learning (FL) is an emerging distributed machine learning framework which jointly trains a global model via a large number of local devices with data privacy protections. Its performance suffers from the non-vanishing biases introduced by the local inconsistent optimal and the rugged client-drifts by the local over-fitting. In this paper, we propose a novel and practical method, FedSpeed, to alleviate the negative impacts posed by these problems.  Concretely, FedSpeed applies the prox-correction term on the current local updates to efficiently reduce the biases introduced by the prox-term, a necessary regularizer to maintain the strong local consistency. Furthermore, FedSpeed merges the vanilla stochastic gradient with a perturbation computed from an extra gradient ascent step in the neighborhood, thereby alleviating the issue of local over-fitting. Our theoretical analysis indicates that the convergence rate is related to both the communication rounds $T$ and local intervals $K$ with a tighter upper bound $\\mathcal{O}(\\frac{1}{T})$ if $K=\\mathcal{O}(T)$.  Moreover, we conduct extensive experiments on the real-world dataset to demonstrate the efficiency of our proposed FedSpeed, which converges significantly faster and achieves the state-of-the-art (SOTA) performance on the general FL experimental settings than several baselines including FedAvg, FedProx, FedCM, FedAdam, SCAFFOLD, FedDyn, FedADMM, etc.",
    "authors": [
      "Yan Sun",
      "Li Shen",
      "Tiansheng Huang",
      "Liang Ding",
      "Dacheng Tao"
    ],
    "keywords": [
      "federated learning"
    ],
    "real_all_scores": [
      8,
      8,
      8,
      8
    ],
    "real_confidences": [
      3,
      4,
      2,
      2
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Instance-wise Batch Label Restoration via Gradients in Federated Learning": {
    "paper_pk": null,
    "title": "Instance-wise Batch Label Restoration via Gradients in Federated Learning",
    "abstract": "Gradient inversion attacks have posed a serious threat to the privacy of federated learning. The attacks search for the optimal pair of input and label best matching the shared gradients and the search space of the attacks can be reduced by pre-restoring labels. Recently, label restoration technique allows for the extraction of labels from gradients analytically, but even the state-of-the-art remains limited to identify the presence of categories (i.e., the class-wise label restoration). This work considers the more real-world settings, where there are multiple instances of each class in a training batch. An analytic method is proposed to perform instance-wise batch label restoration from only the gradient of the final layer. On the basis of the approximate recovered class-wise embeddings and post-softmax probabilities, we establish linear equations of the gradients, probabilities and labels to derive the Number of Instances (NoI) per class by the Moore-Penrose pseudoinverse algorithm. Our experimental evaluations reach over 99% Label existence Accuracy (LeAcc) and exceed 96% Label number Accuracy (LnAcc) in most cases on three image datasets and four classification models. The two metrics are used to evaluate class-wise and instance-wise label restoration accuracy, respectively. And the recovery is made feasible even with a batch size of 4096 and partially negative activations (e.g., Leaky ReLU and Swish). Furthermore, we demonstrate that our method facilitates the existing gradient inversion attacks by exploiting the recovered labels, with an increase of 6-7 in PSNR on both MNIST and CIFAR100. Our code is\navailable at https://github.com/BUAA-CST/iLRG.",
    "authors": [
      "Kailang Ma",
      "Yu Sun",
      "Jian Cui",
      "Dawei Li",
      "Zhenyu Guan",
      "Jianwei Liu"
    ],
    "keywords": [
      "federated learning",
      "batch label restoration",
      "gradient inversion attack."
    ],
    "real_all_scores": [
      5,
      3,
      5,
      5
    ],
    "real_confidences": [
      4,
      5,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Federated Semi-supervised Learning with Dual Regulator": {
    "paper_pk": null,
    "title": "Federated Semi-supervised Learning with Dual Regulator",
    "abstract": "Federated learning emerges as a powerful method to learn from decentralized heterogeneous data while protecting data privacy. Federated semi-supervised learning (FSSL) is even more practical and challenging, where only a fraction of data can be labeled due to high annotation cost. Existing FSSL methods, however, assume independent and identically distributed (IID) labeled data across clients and consistent class distribution between labeled and unlabeled data within a client. In this work, we propose a novel FSSL framework with dual regulator, FedDure, to optimize and customize model training according to specific data distributions of clients. FedDure lifts the previous assumption with a coarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg regularizes the updating of local model by tracking the learning effect on labeled data distribution; F-reg learns an adaptive weighting scheme tailored for unlabeled instances in each client. We further formulate the client model training as bi-level optimization that adaptively optimize the model in the client with two regulators. Theoretically, we show the convergence guarantee of dual regulator. Empirically, we demonstrate that FedDure is superior to the existing methods across wide range of settings, notably by more than 12% on CIFAR-10 and CINIC-10 datasets.",
    "authors": [
      "Sikai Bai",
      "Shuaicheng Li",
      "Weiming Zhuang",
      "Kunlin Yang",
      "Jun Hou",
      "Shuai Yi",
      "Shuai Zhang",
      "Junyu Gao",
      "Song Guo"
    ],
    "keywords": [
      "federated learning",
      "semi-supervised learning",
      "dual regulator",
      "class imbalance"
    ],
    "real_all_scores": [
      6,
      6,
      5,
      3,
      6
    ],
    "real_confidences": [
      3,
      5,
      4,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification": {
    "paper_pk": null,
    "title": "FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification",
    "abstract": "Modern deep learning systems are increasingly deployed in situations such as personalization and federated learning where it is necessary to support i) learning on small amounts of data, and ii) communication efficient distributed training protocols. In this work, we develop FiLM Transfer (FiT) which fulfills these requirements in the image classification setting by combining ideas from transfer learning (fixed pretrained backbones and fine-tuned FiLM adapter layers) and meta-learning (automatically configured Naive Bayes classifiers and episodic training) to yield parameter efficient models with superior classification accuracy at low-shot. The resulting parameter efficiency is key for enabling few-shot learning, inexpensive model updates for personalization, and communication efficient federated learning. We experiment with FiT on a wide range of downstream datasets and show that it achieves better classification accuracy than the leading Big Transfer (BiT) algorithm at low-shot and achieves state-of-the art accuracy on the challenging VTAB-1k benchmark, with fewer than 1% of the updateable parameters. Finally, we demonstrate the parameter efficiency and superior accuracy of FiT in distributed low-shot applications including model personalization and federated learning where model update size is an important performance metric.",
    "authors": [
      "Aliaksandra Shysheya",
      "John F Bronskill",
      "Massimiliano Patacchiola",
      "Sebastian Nowozin",
      "Richard E Turner"
    ],
    "keywords": [
      "few-shot learning",
      "transfer learning",
      "federated learning"
    ],
    "real_all_scores": [
      5,
      3,
      3
    ],
    "real_confidences": [
      4,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses": {
    "paper_pk": null,
    "title": "Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses",
    "abstract": "This paper studies federated learning (FL)\u2014especially cross-silo FL\u2014with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person\u2019s data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo $i$\u2019s communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo $i$ (e.g. hospital $i$) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-silo FL) that people trust their own silo, but not the server or other silos. In this work, we provide tight (up to logarithms) upper and lower bounds for ISRL-DP FL with convex/strongly convex loss functions and homogeneous (i.i.d.) silo data. Remarkably, we show that similar bounds are attainable for smooth losses with arbitrary heterogeneous silo data distributions, via an accelerated ISRL-DP algorithm. We also provide tight upper and lower bounds for ISRL-DP federated empirical risk minimization, and use acceleration to attain the optimal bounds in fewer rounds of communication than the state-of-the-art. Finally, with a secure \u201cshuffler\u201d to anonymize silo messages (but without a trusted server), our algorithm attains the optimal central DP rates under more practical trust assumptions. Numerical experiments show favorable privacy-accuracy tradeoffs for our algorithm in classification and regression tasks.",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "keywords": [
      "differential privacy",
      "federated learning",
      "distributed optimization",
      "private optimization",
      "stochastic convex optimization",
      "cross-silo federated learning"
    ],
    "real_all_scores": [
      8,
      6,
      8,
      5
    ],
    "real_confidences": [
      3,
      3,
      4,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Sharper Rates and Flexible Framework for Nonconvex SGD with Client and Data Sampling": {
    "paper_pk": null,
    "title": "Sharper Rates and Flexible Framework for Nonconvex SGD with Client and Data Sampling",
    "abstract": "We revisit the classical problem of finding an approximately stationary point of the average of $n$ smooth and possibly nonconvex functions. The optimal complexity of stochastic first-order methods in terms of the number of gradient evaluations of individual functions is $\\mathcal{O}\\left(n + n^{1/2}\\varepsilon^{-1}\\right)$, attained by the optimal SGD methods SPIDER (Cong Fang et al., 2018) and PAGE (Zhize Li et al., 2020), for example, where $\\varepsilon$ is the error tolerance. However, i) the big-$\\mathcal{O}$ notation hides crucial dependencies on the smoothness constants associated with the functions, and ii) the rates and theory in these methods assume simplistic sampling mechanisms that do not offer any flexibility. In this work we remedy the situation. First, we generalize the PAGE algorithm so that it can provably work with virtually any (unbiased) sampling mechanism. This is particularly useful in federated learning, as it allows us to construct and better understand the impact of various combinations of client and data sampling strategies. Second, our analysis is sharper as we make explicit use of certain novel inequalities  that capture the intricate interplay between the smoothness constants and the sampling procedure. Indeed, our analysis is better even for the simple sampling procedure analyzed in the PAGE paper. However, this already improved bound can be further sharpened by a different sampling scheme which we propose. In summary, we provide the most general and most accurate analysis of optimal SGD in the smooth nonconvex regime. Finally, our theoretical findings are supposed with carefully designed experiments.",
    "authors": [
      "Alexander Tyurin",
      "Lukang Sun",
      "Konstantin Pavlovich Burlachenko",
      "Peter Richt\u00e1rik"
    ],
    "keywords": [
      "nonconvex optimization",
      "empirical risk minimization",
      "SGD",
      "variance reduction",
      "data sampling",
      "client sampling",
      "optimal methods",
      "biased gradient estimator",
      "federated learning"
    ],
    "real_all_scores": [
      5,
      6,
      6,
      8
    ],
    "real_confidences": [
      5,
      3,
      2,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Smart Multi-tenant Federated Learning": {
    "paper_pk": null,
    "title": "Smart Multi-tenant Federated Learning",
    "abstract": "Federated learning (FL) is an emerging distributed machine learning method that empowers in-situ model training on decentralized edge devices. However, multiple simultaneous training activities could overload resource-constrained devices. In this work, we propose a smart multi-tenant FL system, MuFL, to effectively coordinate and execute simultaneous training activities. We first formalize the problem of multi-tenant FL, define multi-tenant FL scenarios, and introduce a vanilla multi-tenant FL system that trains activities sequentially to form baselines. Then, we propose two approaches to optimize multi-tenant FL: 1) activity consolidation merges training activities into one activity with a multi-task architecture; 2) after training it for rounds, activity splitting divides it into groups by employing affinities among activities such that activities within a group have better synergy. Extensive experiments demonstrate that MuFL outperforms other methods while consuming 40% less energy. We hope this work will inspire the community to further study and optimize multi-tenant FL.",
    "authors": [
      "Weiming Zhuang",
      "Yonggang Wen",
      "Shuai Zhang"
    ],
    "keywords": [
      "federated learning",
      "multi-tenant federated learning"
    ],
    "real_all_scores": [
      8,
      5,
      6,
      6
    ],
    "real_confidences": [
      4,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning": {
    "paper_pk": null,
    "title": "FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning",
    "abstract": "Federated learning (FL) has recently become a hot research topic, in which Byzantine robustness, communication efficiency and privacy preservation are three important aspects. However, the tension among these three aspects makes it hard to simultaneously take all of them into account. In view of this challenge, we theoretically analyze the conditions that a communication compression method should satisfy to be compatible with existing Byzantine-robust methods and privacy-preserving methods. Motivated by the analysis results, we propose a novel communication compression method called consensus sparsification (ConSpar). To the best of our knowledge, ConSpar is the first communication compression method that is designed to be compatible with both Byzantine-robust methods and privacy-preserving methods. Based on ConSpar, we further propose a novel FL framework called FedREP, which is Byzantine-robust, communication-efficient and privacy-preserving. We theoretically prove the Byzantine robustness and the convergence of FedREP. Empirical results show that FedREP can significantly outperform communication-efficient privacy-preserving baselines. Furthermore, compared with Byzantine-robust communication-efficient baselines, FedREP can achieve comparable accuracy with an extra advantage of privacy preservation.",
    "authors": [
      "Yi-Rui Yang",
      "Kun Wang",
      "Wu-Jun Li"
    ],
    "keywords": [
      "federated learning",
      "Byzantine robustness",
      "communication efficiency",
      "privacy preservation"
    ],
    "real_all_scores": [
      3,
      3,
      3,
      1
    ],
    "real_confidences": [
      4,
      3,
      4,
      5
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Towards Addressing Label Skews in One-Shot Federated Learning": {
    "paper_pk": null,
    "title": "Towards Addressing Label Skews in One-Shot Federated Learning",
    "abstract": "Federated learning (FL) has been a popular research area, where multiple clients collaboratively train a model without sharing their local raw data. Among existing FL solutions, one-shot FL is a promising and challenging direction, where the clients conduct FL training with a single communication round. However, while label skew is a common real-world scenario where some clients may have few or no data of some classes, existing one-shot FL approaches that conduct voting on the local models are not able to produce effective global models. Due to the limited number of classes in each party, the local models misclassify the data from unseen classes into seen classes, which leads to very ineffective global models from voting. To address the label skew issue in one-shot FL, we propose a novel approach named FedOV which generates diverse outliers and introduces them as an additional unknown class in local training to improve the voting performance. Specifically, based on open-set recognition, we propose novel outlier generation approaches by corrupting the original features and further develop adversarial learning to enhance the outliers. Our extensive experiments show that FedOV can significantly improve the test accuracy compared to state-of-the-art approaches in various label skew settings.",
    "authors": [
      "Yiqun Diao",
      "Qinbin Li",
      "Bingsheng He"
    ],
    "keywords": [
      "federated learning"
    ],
    "real_all_scores": [
      5,
      3,
      5
    ],
    "real_confidences": [
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Learning to aggregate: A parameterized aggregator to debias aggregation for cross-device federated learning": {
    "paper_pk": null,
    "title": "Learning to aggregate: A parameterized aggregator to debias aggregation for cross-device federated learning",
    "abstract": "Federated learning (FL) emerged as a novel machine learning setting that enables collaboratively training deep models on decentralized private data. Due to the heterogeneity (non-iidness) of the decentralized data, FL methods (e.g. FedAvg) suffers from unstable and slow convergence. Recent works explain the non-iid problem in FL as the client drift, and deal with it by enforcing regularization at local updates. However, these works neglect the heterogeneity among different communication rounds: the data of sampled candidates at different communication rounds are also of non-iid distribution, and we term it as period drift, which as well as client drift can lead to aggregation bias that degrade convergence. To deal with it, we propose a novel aggregation strategy, named FedPA, that uses a Parameterized Aggregator, as an alternative of averaging. We frame FedPA within a meta-learning setting, and formulates the aggregator as a meta-learner, to learn to aggregate the model parameters of clients. FedPA can directly learn the aggregation bias and well calibrate and control the direction of aggregated parameters to a better direction towards the optimum. Experiments show that FedPA can achieve competitive performances compared with conventional baselines.",
    "authors": [
      "Tao Shen",
      "Kun Kuang",
      "Yaliang Li",
      "Feng Wang",
      "Zheqi Lv",
      "Hongxia Yang",
      "Chao Wu",
      "Fei Wu"
    ],
    "keywords": [
      "Federated learning"
    ],
    "real_all_scores": [
      6,
      6,
      5,
      6
    ],
    "real_confidences": [
      4,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning": {
    "paper_pk": null,
    "title": "FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that enables different parties to train a model together for high quality and strong privacy protection. In this scenario, individual participants may get compromised and perform backdoor attacks by poisoning the data (or gradients). Existing work on robust aggregation and certified FL robustness does not study how hardening benign clients can affect the global model (and the malicious clients). In this work, we theoretically analyze the connection among cross-entropy loss, attack success rate, and clean accuracy in this setting. Moreover, we propose a trigger reverse engineering based defense and show that our method can achieve robustness improvement with guarantee (i.e., reducing the attack success rate) without affecting benign accuracy. We conduct comprehensive experiments across different datasets and attack settings. Our results on nine competing SOTA defense methods show the empirical superiority of our method on both single-shot and continuous FL backdoor attacks. Code is available at https://github.com/KaiyuanZh/FLIP.",
    "authors": [
      "Kaiyuan Zhang",
      "Guanhong Tao",
      "Qiuling Xu",
      "Siyuan Cheng",
      "Shengwei An",
      "Yingqi Liu",
      "Shiwei Feng",
      "Guangyu Shen",
      "Pin-Yu Chen",
      "Shiqing Ma",
      "Xiangyu Zhang"
    ],
    "keywords": [
      "Federated learning",
      "backdoor mitigation"
    ],
    "real_all_scores": [
      6,
      6,
      8,
      8
    ],
    "real_confidences": [
      3,
      2,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: notable-top-25%"
  },
  "Learning Shareable Bases for Personalized Federated Image Classification": {
    "paper_pk": null,
    "title": "Learning Shareable Bases for Personalized Federated Image Classification",
    "abstract": "Personalized federated learning (PFL) aims to leverage the collective wisdom of clients' data while constructing customized models that are tailored to individual client's data distributions. The existing work of PFL mostly aims to personalize for participating clients. In this paper, we focus on a less studied but practically important scenario---generating a personalized model for a new client efficiently. Different from most previous approaches that learn a whole or partial network for each client, we explicitly model the clients' overall meta distribution and embed each client into a low dimension space. We propose FedBasis, a novel PFL algorithm that learns a set of few, shareable basis models, upon which each client only needs to learn the coefficients for combining them into a personalized network. FedBasis is parameter-efficient, robust, and more accurate compared to other competitive PFL baselines, especially in a low data regime, without increasing the inference cost. To demonstrate its applicability, we further present a PFL evaluation protocol for image classification, featuring larger data discrepancies across clients in both the image and label spaces as well as more faithful training and test splits.",
    "authors": [
      "Hong-You Chen",
      "Jike zhong",
      "Mingda Zhang",
      "Xuhui Jia",
      "Hang Qi",
      "Boqing Gong",
      "Wei-Lun Chao",
      "Li Zhang"
    ],
    "keywords": [
      "Federated learning",
      "Computer vision"
    ],
    "real_all_scores": [
      3,
      3,
      1,
      5
    ],
    "real_confidences": [
      3,
      4,
      5,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Robust Federated Learning with Majority Adversaries via Projection-based Re-weighting": {
    "paper_pk": null,
    "title": "Robust Federated Learning with Majority Adversaries via Projection-based Re-weighting",
    "abstract": "Most robust aggregators for distributed or federated learning assume that adversarial clients are the minority in the system. In contrast, this paper considers the majority adversary setting. We first show that a filtering method using a few trusted clients can defend against many standard attacks. However, a new attack called Mimic-Shift can circumvent simple filtering. To this end, we develop a re-weighting strategy that identifies and down-weights the potential adversaries under the majority adversary regime. We show that our aggregator converges to a neighborhood around the optimum under the Mimic-Shift attack. Empirical results further show that our aggregator achieves negligible accuracy loss with a majority of adversarial clients, outperforming strong baselines.",
    "authors": [
      "Xiaoyang Wang",
      "Klara Nahrstedt",
      "Oluwasanmi O Koyejo"
    ],
    "keywords": [
      "Federated learning",
      "robustness",
      "adversarial attack",
      "majority adversary"
    ],
    "real_all_scores": [
      5,
      5,
      3,
      3
    ],
    "real_confidences": [
      4,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Invariant Aggregator for Defending against Federated Backdoor Attacks": {
    "paper_pk": null,
    "title": "Invariant Aggregator for Defending against Federated Backdoor Attacks",
    "abstract": "Federated learning is gaining popularity as it enables training of high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Specifically, an adversary can perform backdoor attacks to control model predictions via poisoning the training dataset with a trigger. In this work, we propose a mitigation for backdoor attacks in a federated learning setup. Our solution forces the model optimization trajectory to focus on the invariant directions that are generally useful for utility and avoid selecting directions that favor few and possibly malicious clients. Concretely, we consider the sign consistency of the pseudo-gradient (the client update) as an estimation of the invariance. Following this, our approach performs dimension-wise filtering to remove pseudo-gradient elements with low sign consistency. Then, a robust mean estimator eliminates outliers among the remaining dimensions. Our theoretical analysis further shows the necessity of the defense combination and illustrates how our proposed solution defends the federated learning model. Empirical results on three datasets with different modalities and varying number of clients show that our approach mitigates backdoor attacks with a negligible cost on the model utility.\n",
    "authors": [
      "Xiaoyang Wang",
      "Dimitrios Dimitriadis",
      "Oluwasanmi O Koyejo",
      "Shruti Tople"
    ],
    "keywords": [
      "Federated learning",
      "robustness",
      "backdoor attack",
      "invariant learning"
    ],
    "real_all_scores": [
      8,
      8,
      6
    ],
    "real_confidences": [
      4,
      3,
      2
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Client-agnostic Learning and Zero-shot Adaptation for Federated Domain Generalization": {
    "paper_pk": null,
    "title": "Client-agnostic Learning and Zero-shot Adaptation for Federated Domain Generalization",
    "abstract": "Federated domain generalization (federated DG) aims to learn a client-agnostic global model from various distributed source domains and generalize the model to new clients in completely unseen domains. The main challenges of federated DG are the difficulty of building the global model with local client models from different domains while keeping data private and low generalizability to test clients, where data distribution deviates from those of training clients. To solve these challenges, we present two strategies: (1) client-agnostic learning with mixed instance-global statistics and (2) zero-shot adaptation with estimated statistics. In client-agnostic learning, we first augment local features by using data distribution of other clients via global statistics in the global model's batch normalization layers. This approach allows the generation of diverse domains by mixing local and global feature statistics while keeping data private. Local models then learn client-invariant representations by applying our client-agnostic objectives with the augmented data. Next, we propose a zero-shot adapter to help the learned global model to directly bridge a large domain gap between seen and unseen clients. At inference time, the adapter mixes instance statistics of a test input with global statistics that are vulnerable to distribution shift. With the aid of the adapter, the global model improves generalizability further by reflecting test distribution. We comprehensively evaluate our methods on several benchmarks in federated DG.",
    "authors": [
      "Seunghan Yang",
      "Seokeon Choi",
      "Hyunsin Park",
      "Sungha Choi",
      "Simyung Chang",
      "Sungrack Yun"
    ],
    "keywords": [
      "Federated learning",
      "Domain generalization",
      "Zero-shot adaptation"
    ],
    "real_all_scores": [
      3,
      3,
      5,
      5
    ],
    "real_confidences": [
      3,
      4,
      3,
      1
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity of Neural Networks": {
    "paper_pk": null,
    "title": "Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity of Neural Networks",
    "abstract": "Based on the concepts of Wasserstein barycenter (WB) and Gromov-Wasserstein barycenter (GWB), we propose a unified mathematical framework for neural network (NN) model fusion and utilize it to reveal new insights about the linear mode connectivity of SGD solutions. In our framework, the fusion occurs in a layer-wise manner and builds on an interpretation of a node in a network as a function of the layer preceding it. \nThe versatility of our mathematical framework allows us to talk about model fusion and linear mode connectivity for a broad class of NNs, including fully connected NN, CNN, ResNet, RNN, and LSTM, in each case exploiting the specific structure of the network architecture. We present extensive numerical experiments to: 1) illustrate the strengths of our approach in relation to other model fusion methodologies and 2) from a certain perspective, provide new empirical evidence for recent conjectures which say that two local minima found by gradient-based methods end up lying on the same basin of the loss landscape after a proper permutation of weights is applied to one of the models.",
    "authors": [
      "Aditya Kumar Akash",
      "Sixu Li",
      "Nicolas Garcia Trillos"
    ],
    "keywords": [
      "Linear mode connectivity",
      "Neural network model fusion",
      "Wasserstein barycenter",
      "Federated learning"
    ],
    "real_all_scores": [
      5,
      6,
      3,
      5,
      3
    ],
    "real_confidences": [
      5,
      3,
      4,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Generalization Bounds for Federated Learning: Fast Rates, Unparticipating Clients and Unbounded Losses": {
    "paper_pk": null,
    "title": "Generalization Bounds for Federated Learning: Fast Rates, Unparticipating Clients and Unbounded Losses",
    "abstract": "In {federated learning}, the underlying data distributions may be different across clients. This paper provides a theoretical analysis of generalization error of {federated learning}, which captures both heterogeneity and relatedness of the distributions. In particular, we assume that the heterogeneous distributions are sampled from a meta-distribution. In this two-level distribution framework, we characterize the generalization error not only for clients participating in the training but also for unparticipating clients. We first show that the generalization error for unparticipating clients can be bounded by participating generalization error and participating gap caused by clients' sampling. We further establish fast learning bounds of order $\\mathcal{O}(\\frac{1}{mn} + \\frac{1}{m})$ for unparticipating clients, where $m$ is the number of clients and $n$ is the sample size at each client. To our knowledge, the obtained fast bounds are state-of-the-art in the two-level distribution framework. Moreover, previous theoretical results mostly require the loss function to be bounded. We derive convergence bounds of order $\\mathcal{O}(\\frac{1}{\\sqrt{mn}} + \\frac{1}{\\sqrt{m}})$ under unbounded assumptions, including sub-exponential and sub-Weibull losses. ",
    "authors": [
      "Xiaolin Hu",
      "Shaojie Li",
      "Yong Liu"
    ],
    "keywords": [
      "Federated learning",
      "Generalization error",
      "Risk bound",
      "Unbounded losses",
      "Learning theory"
    ],
    "real_all_scores": [
      5,
      5,
      6,
      3
    ],
    "real_confidences": [
      3,
      4,
      2,
      4
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Communication-Efficient and Drift-Robust Federated Learning via Elastic Net": {
    "paper_pk": null,
    "title": "Communication-Efficient and Drift-Robust Federated Learning via Elastic Net",
    "abstract": "Federated learning (FL) is a distributed method to train a global model over a set of local clients while keeping data localized, which reduces risks of privacy and security. FL framework faces important challenges including expensive communication cost and client drift problem. Leveraging the elastic net, we propose a communication-efficient and drift-robust FL framework to improve the communication efficiency and resolve the client drift problem. We repurpose two types of the elastic net regularizers (i.e., $\\ell_1$ and $\\ell_2$ penalties on the local model updates): (1) the $\\ell_1$-norm regularizer sparsifies the local updates to enhance the communication efficiency and (2) the $\\ell_2$-norm regularizer attempts to resolve the client drift problem by limiting the impact of drifting local updates due to data heterogeneity. Our framework is general; hence, it can be integrated with prior FL techniques, e.g., FedAvg, FedProx, SCAFFOLD, and FedDyn. We show that our framework effectively resolves the communication cost problem and the client drift problem simultaneously.",
    "authors": [
      "Seonhyeong Kim",
      "jiheon woo",
      "Daewon Seo",
      "Yongjune Kim"
    ],
    "keywords": [
      "Federated learning",
      "Data heterogeneity",
      "Optimization"
    ],
    "real_all_scores": [
      3,
      3,
      3
    ],
    "real_confidences": [
      2,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  },
  "Find Your Friends: Personalized Federated Learning with the Right Collaborators": {
    "paper_pk": null,
    "title": "Find Your Friends: Personalized Federated Learning with the Right Collaborators",
    "abstract": "In the traditional federated learning setting, a central server coordinates a network of clients to train one global model. However, the global model may serve many clients poorly due to data heterogeneity. Moreover, there may not exist a trusted central party that can coordinate the clients to ensure that each of them can benefit from others. To address these concerns, we present a novel decentralized framework, FedeRiCo, where each client can learn as much or as little from other clients as is optimal for its local data distribution. Based on expectation-maximization, FedeRiCo estimates the utilities of other participants\u2019 models on each client\u2019s data so that everyone can select the right collaborators for learning. As a result, our algorithm outperforms other federated, personalized, and/or decentralized approaches on several benchmark datasets, being the only approach that consistently performs better than training with local data only.",
    "authors": [
      "Yi Sui",
      "Junfeng Wen",
      "Yenson Lau",
      "Brendan Leigh Ross",
      "Jesse C Cresswell"
    ],
    "keywords": [
      "Federated learning",
      "Personalized federated learning",
      "Decentralized federated learning"
    ],
    "real_all_scores": [
      3,
      3,
      5,
      3
    ],
    "real_confidences": [
      3,
      3,
      4,
      3
    ],
    "real_contents": [],
    "real_decision": "Reject"
  },
  "Communication-Efficient Federated Learning with Accelerated Client Gradient": {
    "paper_pk": null,
    "title": "Communication-Efficient Federated Learning with Accelerated Client Gradient",
    "abstract": "Federated learning often suffers from slow and unstable convergence due to heterogeneous characteristics of participating client datasets.\nSuch a tendency is aggravated when the client participation ratio is low since the information collected from the clients is prone to have large variations.\nTo tackle this challenge, we propose a novel federated learning framework, which improves the consistency across clients and facilitates the convergence of the server model.\nThis is achieved by making the server broadcast a global model with a gradient acceleration.\nBy adopting the strategy, the proposed algorithm conveys the projective global update information to participants effectively with no extra communication cost and relieves the clients from storing the previous models.\nWe also regularize local updates by aligning each of the clients with the overshot global model to reduce bias and improve the stability of our algorithm.\nWe perform comprehensive empirical studies on real data under various settings and demonstrate remarkable performance gains of the proposed method in terms of accuracy and communication efficiency compared to the state-of-the-art methods, especially with low client participation rates.\nWe will release our code to facilitate and disseminate our work.",
    "authors": [
      "Geeho Kim",
      "Jinkyu Kim",
      "Bohyung Han"
    ],
    "keywords": [
      "Federated learning",
      "Data heterogeneity",
      "Deep Neural Networks",
      "Distributed Optimization"
    ],
    "real_all_scores": [
      6,
      6,
      6,
      8
    ],
    "real_confidences": [
      2,
      3,
      3,
      4
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "FedGSNR: Accelerating Federated Learning on Non-IID Data via Maximum Gradient Signal to Noise Ratio": {
    "paper_pk": null,
    "title": "FedGSNR: Accelerating Federated Learning on Non-IID Data via Maximum Gradient Signal to Noise Ratio",
    "abstract": "Federated learning (FL) allows participants jointly training a model without direct data sharing. In such a process, participants rather than the central server perform local updates of stochastic gradient descent (SGD) and the central server aggregates the gradients from the participants to update the global model. However, the non-iid training data in participants significantly impact global model convergence.Most of existing studies addressed this issue by utilizing variance reduction or regularization. However, these studies focusing on specific datasets lack theoretical guarantee for efficient model training. In this paper, we provide a novel perspective on the non-iid issue by optimizing Gradient Signal to Noise Ratio (GSNR) during model training. In each participant, we decompose local gradients calculated on the non-iid training data into the signal and noise components and then speed up the model convergence by maximizing GSNR. We prove that GSNR can be maximized by using the optimal number of local updates. Subsequently, we develop FedGSNR to compute the optimal number of local updates for each participant, which can be applied to existing gradient calculation algorithms to accelerate the global model convergence. Moreover, according to the positive correlation between GSNR and the quality of shared information, FedGSNR allows the server to accurately evaluate contributions of different participants (i.e., the quality of local datasets) by utilizing GSNR. Extensive experimental evaluations demonstrate that FedGSNR achieves on average a 1.69\u00d7 speedup with comparable accuracy.",
    "authors": [
      "Qi Tan",
      "Yi Zhao",
      "Ke Xu",
      "Qi Li"
    ],
    "keywords": [
      "Federated learning",
      "Gradient Signal to Noise Ratio",
      "Optimal Local Updates",
      "Non-IID Data"
    ],
    "real_all_scores": [
      6,
      6,
      8,
      5
    ],
    "real_confidences": [
      3,
      5,
      3,
      2
    ],
    "real_contents": [],
    "real_decision": "Accept: poster"
  },
  "Understanding the Training Dynamics in Federated Deep Learning via Aggregation Weight Optimization": {
    "paper_pk": null,
    "title": "Understanding the Training Dynamics in Federated Deep Learning via Aggregation Weight Optimization",
    "abstract": "From the server's perspective, federated learning (FL) learns a global model by iteratively sampling a cohort of clients and updating the global model with the sum local gradient of the cohort. We find this process is analogous to mini-batch SGD of centralized training. In mini-batch SGD, a model is learned by iteratively sampling a batch of data and updating the model with the sum gradient of the batch. In this paper, we delve into the training dynamics in FL by learning from the experience of optimization and generalization in mini-batch SGD. Specifically, we focus on two aspects: \\emph{client coherence} (refers to sample coherence in mini-batch SGD) and \\emph{global weight shrinking regularization} (refers to weight decay in mini-batch SGD). We find the roles of the two aspects are both determined by the aggregation weights assigned to each client during global model updating. Thus, we use aggregation weight optimization on the server as a tool to study how client heterogeneity and the number of local epochs affect the global training dynamics in FL. Besides, we propose an effective method for \\textbf{Fed}erated \\textbf{A}ggregation \\textbf{W}eight \\textbf{O}ptimization, named as \\textsc{\\textbf{FedAWO}}. Extensive experiments verify that our method can improve the generalization of the global model by a large margin on different datasets and models.",
    "authors": [
      "Zexi Li",
      "Tao Lin",
      "Xinyi Shang",
      "Chao Wu"
    ],
    "keywords": [
      "Federated learning",
      "deep learning",
      "weighted aggregation",
      "training dynamics",
      "optimization",
      "neural network."
    ],
    "real_all_scores": [
      5,
      5,
      3,
      5,
      5
    ],
    "real_confidences": [
      3,
      3,
      5,
      3,
      3
    ],
    "real_contents": [],
    "real_decision": ""
  }
}

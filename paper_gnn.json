{
  "634fa166-583f-42e9-9c49-8da79fc0e07f": {
    "pk": "634fa166-583f-42e9-9c49-8da79fc0e07f",
    "authors": [
      "Zhantao Yang",
      "Ruili Feng",
      "Keyu Yan",
      "Huangji Wang",
      "Zhicai Wang",
      "Shangwen Zhu",
      "Han Zhang",
      "Jie Xiao",
      "Pingyu Wu",
      "Kai Zhu",
      "Jixuan Chen",
      "Chen-Wei Xie",
      "Chaojie Mao",
      "Yue Yang",
      "Hongyang Zhang",
      "Yu Liu",
      "Fan Cheng"
    ],
    "title": "BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations",
    "abstract": "This paper presents Bag-of-Concept Graph (BACON) to gift models with limited linguistic abilities to taste the privilege of Vision Language Models (VLMs) and boost downstream tasks such as detection, visual question answering (VQA), and image generation. Since the visual scenes in physical worlds are structured with complex relations between objects, BACON breaks down annotations into basic minimum elements and presents them in a graph structure. Element-wise style enables easy understanding, and structural composition liberates difficult locating. Careful prompt design births the BACON captions with the help of public-available VLMs and segmentation methods. In this way, we gather a dataset with 100K annotated images, which endow VLMs with remarkable capabilities, such as accurately generating BACON, transforming prompts into BACON format, envisioning scenarios in the style of BACONr, and dynamically modifying elements within BACON through interactive dialogue and more. Wide representative experiments, including detection, VQA, and image generation tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel in their current cutting-edge solutions.",
    "url": "http://arxiv.org/abs/2407.03314v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "70ac7bf2-aba5-4825-a732-b94e3330200c": {
    "pk": "70ac7bf2-aba5-4825-a732-b94e3330200c",
    "authors": [
      "Sijie Xu",
      "Shenyan Zong",
      "Chang-Sheng Mei",
      "Guofeng Shen",
      "Yueran Zhao",
      "He Wang"
    ],
    "title": "Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method",
    "abstract": "Proton resonance frequency (PRF) based MR thermometry is essential for focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance temporal resolution in dynamic MR temperature map reconstruction using an improved deep learning method. The training-optimized methods and five classical neural networks were applied on the 2-fold and 4-fold under-sampling k-space data to reconstruct the temperature maps. The enhanced training modules included offline/online data augmentations, knowledge distillation, and the amplitude-phase decoupling loss function. The heating experiments were performed by a FUS transducer on phantom and ex vivo tissues, respectively. These data were manually under-sampled to imitate acceleration procedures and trained in our method to get the reconstruction model. The additional dozen or so testing datasets were separately obtained for evaluating the real-time performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were found for 2 times and 4 times k-space under-sampling strategies and the ResUNet-based deep learning reconstruction performed exceptionally well. In 2-fold acceleration scenario, the RMSE of temperature map patches provided the values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex vivo testing datasets. The DICE value of temperature areas enclosed by 43 degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree centigrade. In 4 times under-sampling case, these evaluating values decreased by approximately 10%. This study demonstrates that deep learning-based reconstruction can significantly enhance the accuracy and efficiency of MR thermometry for clinical FUS thermal therapies.",
    "url": "http://arxiv.org/abs/2407.03308v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "physics.med-ph",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "6c297740-ee93-4de7-bb31-3525dc09f7f2": {
    "pk": "6c297740-ee93-4de7-bb31-3525dc09f7f2",
    "authors": [
      "Yilun Xu",
      "Gabriele Corso",
      "Tommi Jaakkola",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "title": "DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents",
    "abstract": "Diffusion models (DMs) have revolutionized generative learning. They utilize a diffusion process to encode data into a simple Gaussian distribution. However, encoding a complex, potentially multimodal data distribution into a single continuous Gaussian distribution arguably represents an unnecessarily challenging learning problem. We propose Discrete-Continuous Latent Variable Diffusion Models (DisCo-Diff) to simplify this task by introducing complementary discrete latent variables. We augment DMs with learnable discrete latents, inferred with an encoder, and train DM and encoder end-to-end. DisCo-Diff does not rely on pre-trained networks, making the framework universally applicable. The discrete latents significantly simplify learning the DM's complex noise-to-data mapping by reducing the curvature of the DM's generative ODE. An additional autoregressive transformer models the distribution of the discrete latents, a simple step because DisCo-Diff requires only few discrete variables with small codebooks. We validate DisCo-Diff on toy data, several image synthesis tasks as well as molecular docking, and find that introducing discrete latents consistently improves model performance. For example, DisCo-Diff achieves state-of-the-art FID scores on class-conditioned ImageNet-64/128 datasets with ODE sampler.",
    "url": "http://arxiv.org/abs/2407.03300v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "f4156326-7bcc-40d6-84dd-df9de212fc91": {
    "pk": "f4156326-7bcc-40d6-84dd-df9de212fc91",
    "authors": [
      "Zhe Min",
      "Zachary M. C. Baum",
      "Shaheer U. Saeed",
      "Mark Emberton",
      "Dean C. Barratt",
      "Zeike A. Taylor",
      "Yipeng Hu"
    ],
    "title": "Biomechanics-informed Non-rigid Medical Image Registration and its Inverse Material Property Estimation with Linear and Nonlinear Elasticity",
    "abstract": "This paper investigates both biomechanical-constrained non-rigid medical image registrations and accurate identifications of material properties for soft tissues, using physics-informed neural networks (PINNs). The complex nonlinear elasticity theory is leveraged to formally establish the partial differential equations (PDEs) representing physics laws of biomechanical constraints that need to be satisfied, with which registration and identification tasks are treated as forward (i.e., data-driven solutions of PDEs) and inverse (i.e., parameter estimation) problems under PINNs respectively. Two net configurations (i.e., Cfg1 and Cfg2) have also been compared for both linear and nonlinear physics model. Two sets of experiments have been conducted, using pairs of undeformed and deformed MR images from clinical cases of prostate cancer biopsy.   Our contributions are summarised as follows. 1) We developed a learning-based biomechanical-constrained non-rigid registration algorithm using PINNs, where linear elasticity is generalised to the nonlinear version. 2) We demonstrated extensively that nonlinear elasticity shows no statistical significance against linear models in computing point-wise displacement vectors but their respective benefits may depend on specific patients, with finite-element (FE) computed ground-truth. 3) We formulated and solved the inverse parameter estimation problem, under the joint optimisation scheme of registration and parameter identification using PINNs, whose solutions can be accurately found by locating saddle points.",
    "url": "http://arxiv.org/abs/2407.03292v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "dc078db6-efcb-4366-a145-b6d11e95153f": {
    "pk": "dc078db6-efcb-4366-a145-b6d11e95153f",
    "authors": [
      "Mintae Kim",
      "Hoon Lee",
      "Sangwon Hwang",
      "Merouane Debbah",
      "Inkyu Lee"
    ],
    "title": "Cooperative Multi-Agent Deep Reinforcement Learning Methods for UAV-aided Mobile Edge Computing Networks",
    "abstract": "This paper presents a cooperative multi-agent deep reinforcement learning (MADRL) approach for unmmaned aerial vehicle (UAV)-aided mobile edge computing (MEC) networks. An UAV with computing capability can provide task offlaoding services to ground internet-of-things devices (IDs). With partial observation of the entire network state, the UAV and the IDs individually determine their MEC strategies, i.e., UAV trajectory, resource allocation, and task offloading policy. This requires joint optimization of decision-making process and coordination strategies among the UAV and the IDs. To address this difficulty, the proposed cooperative MADRL approach computes two types of action variables, namely message action and solution action, each of which is generated by dedicated actor neural networks (NNs). As a result, each agent can automatically encapsulate its coordination messages to enhance the MEC performance in the decentralized manner. The proposed actor structure is designed based on graph attention networks such that operations are possible regardless of the number of IDs. A scalable training algorithm is also proposed to train a group of NNs for arbitrary network configurations. Numerical results demonstrate the superiority of the proposed cooperative MADRL approach over conventional methods.",
    "url": "http://arxiv.org/abs/2407.03280v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.IT",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "da96fff0-2da6-40ff-ac5a-ee41695914aa": {
    "pk": "da96fff0-2da6-40ff-ac5a-ee41695914aa",
    "authors": [
      "Jingyuan Hong",
      "Manasi Nandi",
      "Weiwei Jin",
      "Jordi Alastruey"
    ],
    "title": "Using Photoplethysmography to Detect Real-time Blood Pressure Changes with a Calibration-free Deep Learning Model",
    "abstract": "Blood pressure (BP) changes are linked to individual health status in both clinical and non-clinical settings. This study developed a deep learning model to classify systolic (SBP), diastolic (DBP), and mean (MBP) BP changes using photoplethysmography (PPG) waveforms. Data from the Vital Signs Database (VitalDB) comprising 1,005 ICU patients with synchronized PPG and BP recordings was used. BP changes were categorized into three labels: Spike (increase above a threshold), Stable (change within a plus or minus threshold), and Dip (decrease below a threshold). Four time-series classification models were studied: multi-layer perceptron, convolutional neural network, residual network, and Encoder. A subset of 500 patients was randomly selected for training and validation, ensuring a uniform distribution across BP change labels. Two test datasets were compiled: Test-I (n=500) with a uniform distribution selection process, and Test-II (n=5) without. The study also explored the impact of including second-deviation PPG (sdPPG) waveforms as additional input information. The Encoder model with a Softmax weighting process using both PPG and sdPPG waveforms achieved the highest detection accuracy--exceeding 71.3% and 85.4% in Test-I and Test-II, respectively, with thresholds of 30 mmHg for SBP, 15 mmHg for DBP, and 20 mmHg for MBP. Corresponding F1-scores were over 71.8% and 88.5%. These findings confirm that PPG waveforms are effective for real-time monitoring of BP changes in ICU settings and suggest potential for broader applications.",
    "url": "http://arxiv.org/abs/2407.03274v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "eess.SP",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "7bdeb023-73c1-463d-8a48-f7af3bac36a0": {
    "pk": "7bdeb023-73c1-463d-8a48-f7af3bac36a0",
    "authors": [
      "Lia Morra",
      "Antonio Santangelo",
      "Pietro Basci",
      "Luca Piano",
      "Fabio Garcea",
      "Fabrizio Lamberti",
      "Massimo Leone"
    ],
    "title": "For a semiotic AI: Bridging computer vision and visual semiotics for computational observation of large scale facial image archives",
    "abstract": "Social networks are creating a digital world in which the cognitive, emotional, and pragmatic value of the imagery of human faces and bodies is arguably changing. However, researchers in the digital humanities are often ill-equipped to study these phenomena at scale. This work presents FRESCO (Face Representation in E-Societies through Computational Observation), a framework designed to explore the socio-cultural implications of images on social media platforms at scale. FRESCO deconstructs images into numerical and categorical variables using state-of-the-art computer vision techniques, aligning with the principles of visual semiotics. The framework analyzes images across three levels: the plastic level, encompassing fundamental visual features like lines and colors; the figurative level, representing specific entities or concepts; and the enunciation level, which focuses particularly on constructing the point of view of the spectator and observer. These levels are analyzed to discern deeper narrative layers within the imagery. Experimental validation confirms the reliability and utility of FRESCO, and we assess its consistency and precision across two public datasets. Subsequently, we introduce the FRESCO score, a metric derived from the framework's output that serves as a reliable measure of similarity in image content.",
    "url": "http://arxiv.org/abs/2407.03268v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.CV",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "4e5e6938-80a2-4ae8-be5b-b393095f600e": {
    "pk": "4e5e6938-80a2-4ae8-be5b-b393095f600e",
    "authors": [
      "Jessica Pointing"
    ],
    "title": "Do Quantum Neural Networks have Simplicity Bias?",
    "abstract": "One hypothesis for the success of deep neural networks (DNNs) is that they are highly expressive, which enables them to be applied to many problems, and they have a strong inductive bias towards solutions that are simple, known as simplicity bias, which allows them to generalise well on unseen data because most real-world data is structured (i.e. simple). In this work, we explore the inductive bias and expressivity of quantum neural networks (QNNs), which gives us a way to compare their performance to those of DNNs. Our results show that it is possible to have simplicity bias with certain QNNs, but we prove that this type of QNN limits the expressivity of the QNN. We also show that it is possible to have QNNs with high expressivity, but they either have no inductive bias or a poor inductive bias and result in a worse generalisation performance compared to DNNs. We demonstrate that an artificial (restricted) inductive bias can be produced by intentionally restricting the expressivity of a QNN. Our results suggest a bias-expressivity tradeoff. Our conclusion is that the QNNs we studied can not generally offer an advantage over DNNs, because these QNNs either have a poor inductive bias or poor expressivity compared to DNNs.",
    "url": "http://arxiv.org/abs/2407.03266v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "quant-ph",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "b10a0593-b976-47db-a6c1-5421b9779350": {
    "pk": "b10a0593-b976-47db-a6c1-5421b9779350",
    "authors": [
      "Abhishek Chandra",
      "Bram Daniels",
      "Mitrofan Curti",
      "Koen Tiels",
      "Elena A. Lomonova"
    ],
    "title": "Magnetic Hysteresis Modeling with Neural Operators",
    "abstract": "Hysteresis modeling is crucial to comprehend the behavior of magnetic devices, facilitating optimal designs. Hitherto, deep learning-based methods employed to model hysteresis, face challenges in generalizing to novel input magnetic fields. This paper addresses the generalization challenge by proposing neural operators for modeling constitutive laws that exhibit magnetic hysteresis by learning a mapping between magnetic fields. In particular, two prominent neural operators -- deep operator network and Fourier neural operator -- are employed to predict novel first-order reversal curves and minor loops, where novel means they are not used to train the model. In addition, a rate-independent Fourier neural operator is proposed to predict material responses at sampling rates different from those used during training to incorporate the rate-independent characteristics of magnetic hysteresis. The presented numerical experiments demonstrate that neural operators efficiently model magnetic hysteresis, outperforming the traditional neural recurrent methods on various metrics and generalizing to novel magnetic fields. The findings emphasize the advantages of using neural operators for modeling hysteresis under varying magnetic conditions, underscoring their importance in characterizing magnetic material based devices.",
    "url": "http://arxiv.org/abs/2407.03261v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.LG",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  },
  "6fa706ee-ae8a-4242-8e11-9a792339ef95": {
    "pk": "6fa706ee-ae8a-4242-8e11-9a792339ef95",
    "authors": [
      "Waleed Iqbal",
      "Gareth Tyson",
      "Ignacio Castro"
    ],
    "title": "How Similar Are Elected Politicians and Their Constituents? Quantitative Evidence From Online Social Network",
    "abstract": "How similar are politicians to those who vote for them? This is a critical question at the heart of democratic representation and particularly relevant at times when political dissatisfaction and populism are on the rise. To answer this question we compare the online discourse of elected politicians and their constituents. We collect a two and a half years (September 2020 - February 2023) constituency-level dataset for USA and UK that includes: (i) the Twitter timelines (5.6 Million tweets) of elected political representatives (595 UK Members of Parliament and 433 USA Representatives), (ii) the Nextdoor posts (21.8 Million posts) of the constituency (98.4% USA and 91.5% UK constituencies). We find that elected politicians tend to be equally similar to their constituents in terms of content and style regardless of whether a constituency elects a right or left-wing politician. The size of the electoral victory and the level of income of a constituency shows a nuanced picture. The narrower the electoral victory, the more similar the style and the more dissimilar the content is. The lower the income of a constituency, the more similar the content is. In terms of style, poorer constituencies tend to have a more similar sentiment and more dissimilar psychological text traits (i.e. measured with LIWC categories).",
    "url": "http://arxiv.org/abs/2407.03255v1",
    "timestamp": 1719936000,
    "section_contents": null,
    "table_captions": null,
    "figure_captions": null,
    "bibliography": null,
    "keywords": null,
    "domain": "cs.SI",
    "references": null,
    "citation_count": 0,
    "award": null,
    "embed": null
  }
}